{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/lrakotoarivony/Micronet_Challenge/blob/main/Project_Model_Cifar10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kM1Yz4abgeAp"
   },
   "source": [
    "# Notebook réalisé par Lucas Rakotoarivony & Jérémie Sicard\n",
    "\n",
    "Ce Notebook présente les différents résultats et travaux que nous avons effectués dans le cadre du Micronet Challenge.  \n",
    "Nous avons choisi de travailler avec l'architecture Densenet.  \n",
    "Il est important de préciser que l'objectif de ce projet n'est pas d'obtenir l'accuracy la plus importante mais le score Micronet le plus faible tout en ayant un modèle avec une accuracy supérieure à 90%. Pour rappel le score de Micronet se base sur deux facteurs, le nombre de paramètres et le nombre de flops (floating points operations)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WMHg7fp3QQP0"
   },
   "source": [
    "# Data & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "wYrygCr3QQP7"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "import torch.nn.utils.prune as prune\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from util import *\n",
    "from Densenet import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OBhdlahUQQP9",
    "outputId": "ac83b715-e6a2-4c30-d277-b8e42078e3fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "n_classes_cifar10 = 10\n",
    "train_size = 0.8\n",
    "R = 5\n",
    "\n",
    "\n",
    "# Download the entire CIFAR10 dataset\n",
    "\n",
    "from torchvision.datasets import CIFAR10\n",
    "import numpy as np \n",
    "from torch.utils.data import Subset\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "## Normalization is different when training from scratch and when training using an imagenet pretrained backbone\n",
    "\n",
    "normalize_scratch = transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "\n",
    "\n",
    "# Data augmentation is needed in order to train from scratch\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    normalize_scratch,\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    normalize_scratch,\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "### The data from CIFAR10 will be downloaded in the following dataset\n",
    "rootdir = './data/cifar10'\n",
    "\n",
    "c10train = CIFAR10(rootdir,train=True,download=True,transform=transform_train)\n",
    "c10test = CIFAR10(rootdir,train=False,download=True,transform=transform_test)\n",
    "\n",
    "\n",
    "\n",
    "# CIFAR10 is sufficiently large so that training a model up to the state of the art performance will take approximately 3 hours on the 1060 GPU available on your machine. \n",
    "\n",
    "\n",
    "def train_validation_split(train_size, num_train_examples):\n",
    "    # obtain training indices that will be used for validation\n",
    "    indices = list(range(num_train_examples))\n",
    "    np.random.shuffle(indices)\n",
    "    idx_split = int(np.floor(train_size * num_train_examples))\n",
    "    train_index, valid_index = indices[:idx_split], indices[idx_split:]\n",
    "\n",
    "    # define samplers for obtaining training and validation batches\n",
    "    train_sampler = SubsetRandomSampler(train_index)\n",
    "    valid_sampler = SubsetRandomSampler(valid_index)\n",
    "\n",
    "    return train_sampler,valid_sampler\n",
    "\n",
    "def generate_subset(dataset,n_classes,reducefactor,n_ex_class_init):\n",
    "\n",
    "    nb_examples_per_class = int(np.floor(n_ex_class_init / reducefactor))\n",
    "    # Generate the indices. They are the same for each class, could easily be modified to have different ones. But be careful to keep the random seed! \n",
    "\n",
    "    indices_split = np.random.RandomState(seed=42).choice(n_ex_class_init,nb_examples_per_class,replace=False)\n",
    "\n",
    "    all_indices = []\n",
    "    for curclas in range(n_classes):\n",
    "        curtargets = np.where(np.array(dataset.targets) == curclas)\n",
    "        indices_curclas = curtargets[0]\n",
    "        indices_subset = indices_curclas[indices_split]\n",
    "        #print(len(indices_subset))\n",
    "        all_indices.append(indices_subset)\n",
    "    all_indices = np.hstack(all_indices)\n",
    "    \n",
    "    return Subset(dataset,indices=all_indices)\n",
    "    \n",
    "\n",
    "\n",
    "### These dataloader are ready to be used to train for scratch \n",
    "cifar10_train= generate_subset(dataset=c10train,n_classes=n_classes_cifar10,reducefactor=R,n_ex_class_init=5000)\n",
    "num_train_examples=len(cifar10_train)\n",
    "train_sampler,valid_sampler=train_validation_split(train_size, num_train_examples)\n",
    "\n",
    "cifar10_test = generate_subset(dataset=c10test,n_classes=n_classes_cifar10,reducefactor=1,n_ex_class_init=1000) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "5jquWwc-QQP-"
   },
   "outputs": [],
   "source": [
    "trainloader = DataLoader(c10train,batch_size=64,sampler=train_sampler)\n",
    "validloader = DataLoader(c10train,batch_size=64,sampler=valid_sampler)\n",
    "testloader = DataLoader(c10test,batch_size=64) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kse9bIgDQQQA"
   },
   "source": [
    "# Device & Criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2bJJAjcDQQQA",
    "outputId": "835eae3d-a5b8-4fee-fa64-4b75b5ea927e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device '+str(device))\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IUoUD0qZQQQD"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseNet(\n",
       "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (dense1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(24, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (bn1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(40, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(48, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (bn1): BatchNorm2d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(56, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "  )\n",
       "  (trans1): Transition(\n",
       "    (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  )\n",
       "  (dense2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (bn1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(40, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(48, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (bn1): BatchNorm2d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(56, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(72, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (6): Bottleneck(\n",
       "      (bn1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(80, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (7): Bottleneck(\n",
       "      (bn1): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(88, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (8): Bottleneck(\n",
       "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (9): Bottleneck(\n",
       "      (bn1): BatchNorm2d(104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(104, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "  )\n",
       "  (trans2): Transition(\n",
       "    (bn): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv): Conv2d(112, 56, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  )\n",
       "  (dense3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (bn1): BatchNorm2d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(56, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(72, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (bn1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(80, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (bn1): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(88, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (6): Bottleneck(\n",
       "      (bn1): BatchNorm2d(104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(104, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (7): Bottleneck(\n",
       "      (bn1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(112, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (8): Bottleneck(\n",
       "      (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (9): Bottleneck(\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (10): Bottleneck(\n",
       "      (bn1): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(136, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (11): Bottleneck(\n",
       "      (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (12): Bottleneck(\n",
       "      (bn1): BatchNorm2d(152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(152, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (13): Bottleneck(\n",
       "      (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(160, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (14): Bottleneck(\n",
       "      (bn1): BatchNorm2d(168, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(168, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (15): Bottleneck(\n",
       "      (bn1): BatchNorm2d(176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(176, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (16): Bottleneck(\n",
       "      (bn1): BatchNorm2d(184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(184, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (17): Bottleneck(\n",
       "      (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (18): Bottleneck(\n",
       "      (bn1): BatchNorm2d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(200, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (19): Bottleneck(\n",
       "      (bn1): BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(208, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "  )\n",
       "  (trans3): Transition(\n",
       "    (bn): BatchNorm2d(216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv): Conv2d(216, 108, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  )\n",
       "  (dense4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(108, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (bn1): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(116, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (bn1): BatchNorm2d(124, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(124, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (bn1): BatchNorm2d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(132, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (bn1): BatchNorm2d(140, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(140, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (bn1): BatchNorm2d(148, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(148, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (6): Bottleneck(\n",
       "      (bn1): BatchNorm2d(156, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(156, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (7): Bottleneck(\n",
       "      (bn1): BatchNorm2d(164, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(164, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (8): Bottleneck(\n",
       "      (bn1): BatchNorm2d(172, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(172, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (9): Bottleneck(\n",
       "      (bn1): BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(180, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (10): Bottleneck(\n",
       "      (bn1): BatchNorm2d(188, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(188, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (11): Bottleneck(\n",
       "      (bn1): BatchNorm2d(196, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(196, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "  )\n",
       "  (bn): BatchNorm2d(204, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (linear): Linear(in_features=204, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = densenet_cifar()\n",
    "model.to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aHWyF4tTg7yT",
    "outputId": "beb5a7e5-3a6a-49ff-8208-a9af36568a6a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de paramètre de ce modèle : 331226\n"
     ]
    }
   ],
   "source": [
    "pytorch_total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f'Nombre de paramètre de ce modèle : {pytorch_total_params}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bRcopO2qgeA4"
   },
   "source": [
    "Voici les paramètres que nous avons utilisé pour entrainer ce modèle from scratch. (très long à exécuter sans GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "jaGghNTTQQQE"
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(),lr=0.1, momentum=0.9,weight_decay=1e-4) \n",
    "scheduler = MultiStepLR(optimizer, milestones=[90, 110], gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2AlbZJntsobK"
   },
   "outputs": [],
   "source": [
    "train_losses, valid_losses, train_acc, valid_acc = training(trainloader, validloader, model, criterion, optimizer,120,scheduler,'models\\\\Densenet_from_scratch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OqhRwBtvQQQF"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "plt.subplot(3,1,1)\n",
    "plt.plot(range(n_epochs), train_losses)\n",
    "plt.plot(range(n_epochs), valid_losses)\n",
    "\n",
    "plt.legend(['train', 'validation'], prop={'size': 10})\n",
    "plt.title('loss function', size=10)\n",
    "plt.xlabel('epoch', size=10)\n",
    "plt.ylabel('loss value', size=10)\n",
    "\n",
    "plt.subplot(3,1,3)\n",
    "plt.plot(range(n_epochs), train_acc)\n",
    "plt.plot(range(n_epochs), valid_acc)\n",
    "\n",
    "plt.legend(['train', 'validation'], prop={'size': 10})\n",
    "plt.title('accuracy', size=10)\n",
    "plt.xlabel('epoch', size=10)\n",
    "plt.ylabel('acc value', size=10)\n",
    "plt.savefig(\"Densenet_training_scratch.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rL1Ey3hKgeA5"
   },
   "source": [
    "Si vous désirez utiliser un modèle déjà entrainé."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bew5LaNhaFqr",
    "outputId": "df3dcb22-9b41-4ec4-ffab-7d5d59e39067"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    loaded_cpt=torch.load('models\\\\Densenet_cifar_trained.pt')\n",
    "else:\n",
    "    loaded_cpt=torch.load('models\\\\Densenet_cifar_trained.pt', map_location=torch.device('cpu'))\n",
    "model.load_state_dict(loaded_cpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YwWTkVCWfBLM",
    "outputId": "4c4c6a7d-3ce5-4026-aa22-d6de235f4f09"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.337965\n",
      "\n",
      "test accuracy of plane: 92% (921/1000)\n",
      "test accuracy of car: 96% (965/1000)\n",
      "test accuracy of bird: 90% (901/1000)\n",
      "test accuracy of cat: 83% (833/1000)\n",
      "test accuracy of deer: 94% (945/1000)\n",
      "test accuracy of dog: 86% (869/1000)\n",
      "test accuracy of frog: 92% (926/1000)\n",
      "test accuracy of horse: 94% (941/1000)\n",
      "test accuracy of ship: 95% (956/1000)\n",
      "test accuracy of truck: 94% (948/1000)\n",
      "\n",
      "test accuracy (overall): 92.05% (9205/10000)\n"
     ]
    }
   ],
   "source": [
    "evaluation(model, testloader, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score flops: 0.06795413525587332 Score Params: 0.02964266390023521\n",
      "Final score: 0.09759679915610853\n"
     ]
    }
   ],
   "source": [
    "flops , params = score(model)\n",
    "print(\"Score flops: {} Score Params: {}\".format(flops,params))\n",
    "print(\"Final score: {}\".format(flops + params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bm9hzZnmgeA6"
   },
   "source": [
    "# Pruning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avant de réaliser notre pruning, il est nécessaire d'avoir un modèle entrainé (nous pouvons alors d'utiliser le notre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "WEybhgUNgeA6",
    "outputId": "b6008bf4-4ef1-4805-d379-7ab4f7ffd38a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseNet(\n",
       "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (dense1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(24, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (bn1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(40, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(48, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (bn1): BatchNorm2d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(56, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "  )\n",
       "  (trans1): Transition(\n",
       "    (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  )\n",
       "  (dense2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (bn1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(40, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(48, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (bn1): BatchNorm2d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(56, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(72, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (6): Bottleneck(\n",
       "      (bn1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(80, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (7): Bottleneck(\n",
       "      (bn1): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(88, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (8): Bottleneck(\n",
       "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (9): Bottleneck(\n",
       "      (bn1): BatchNorm2d(104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(104, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "  )\n",
       "  (trans2): Transition(\n",
       "    (bn): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv): Conv2d(112, 56, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  )\n",
       "  (dense3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (bn1): BatchNorm2d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(56, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(72, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (bn1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(80, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (bn1): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(88, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (6): Bottleneck(\n",
       "      (bn1): BatchNorm2d(104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(104, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (7): Bottleneck(\n",
       "      (bn1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(112, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (8): Bottleneck(\n",
       "      (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (9): Bottleneck(\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (10): Bottleneck(\n",
       "      (bn1): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(136, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (11): Bottleneck(\n",
       "      (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (12): Bottleneck(\n",
       "      (bn1): BatchNorm2d(152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(152, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (13): Bottleneck(\n",
       "      (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(160, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (14): Bottleneck(\n",
       "      (bn1): BatchNorm2d(168, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(168, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (15): Bottleneck(\n",
       "      (bn1): BatchNorm2d(176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(176, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (16): Bottleneck(\n",
       "      (bn1): BatchNorm2d(184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(184, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (17): Bottleneck(\n",
       "      (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (18): Bottleneck(\n",
       "      (bn1): BatchNorm2d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(200, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (19): Bottleneck(\n",
       "      (bn1): BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(208, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "  )\n",
       "  (trans3): Transition(\n",
       "    (bn): BatchNorm2d(216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv): Conv2d(216, 108, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  )\n",
       "  (dense4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(108, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (bn1): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(116, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (bn1): BatchNorm2d(124, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(124, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (bn1): BatchNorm2d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(132, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (bn1): BatchNorm2d(140, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(140, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (bn1): BatchNorm2d(148, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(148, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (6): Bottleneck(\n",
       "      (bn1): BatchNorm2d(156, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(156, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (7): Bottleneck(\n",
       "      (bn1): BatchNorm2d(164, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(164, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (8): Bottleneck(\n",
       "      (bn1): BatchNorm2d(172, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(172, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (9): Bottleneck(\n",
       "      (bn1): BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(180, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (10): Bottleneck(\n",
       "      (bn1): BatchNorm2d(188, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(188, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (11): Bottleneck(\n",
       "      (bn1): BatchNorm2d(196, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(196, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "  )\n",
       "  (bn): BatchNorm2d(204, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (linear): Linear(in_features=204, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pruned = densenet_cifar()\n",
    "model_pruned.to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    loaded_cpt=torch.load('models\\\\Densenet_cifar_trained.pt')\n",
    "else:\n",
    "    loaded_cpt=torch.load('models\\\\Densenet_cifar_trained.pt', map_location=torch.device('cpu'))\n",
    "model_pruned.load_state_dict(loaded_cpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.337965\n",
      "\n",
      "test accuracy of plane: 92% (921/1000)\n",
      "test accuracy of car: 96% (965/1000)\n",
      "test accuracy of bird: 90% (901/1000)\n",
      "test accuracy of cat: 83% (833/1000)\n",
      "test accuracy of deer: 94% (945/1000)\n",
      "test accuracy of dog: 86% (869/1000)\n",
      "test accuracy of frog: 92% (926/1000)\n",
      "test accuracy of horse: 94% (941/1000)\n",
      "test accuracy of ship: 95% (956/1000)\n",
      "test accuracy of truck: 94% (948/1000)\n",
      "\n",
      "test accuracy (overall): 92.05% (9205/10000)\n"
     ]
    }
   ],
   "source": [
    "evaluation(model_pruned, testloader, criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jd61NjUtgeA7"
   },
   "source": [
    "Nous allons réaliser de l'unstructured pruning de façon itérative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A chaque itération, nous allons pruner de façon globale 20 % des poids du modèle qui ont la plus faible norme L1.\n",
    "Nous allons également réentrainer en utilisant la technique du learning weight rewinding qui diffère nottament d'une technique plus conventionnelle (celle du fine tuning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous trouverez davantage d'informations sur le lien suivant :\n",
    "https://iclr.cc/virtual_2020/poster_S1gSj0NKvB.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons également réentrainer entre chaque itération de pruning en utilisant la technique du learning rate rewinding. \n",
    "En considérant le modèle actuel à un instant T, le réentrainer en utilisant la technique du learning rate rewinding consiste à utiliser le modèle pruné actuel (instant T), les poids actuels associés (instant T) mais en utilisant le learning rate des X epochs précédentes (instant T-X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans notre cas d'étude, nous avons choisi de réentrainer le modèle après chaque phase de pruning de 60 epochs.\n",
    "Ainsi nous utilisons :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lr = 0.1 pour les epochs de [1 à 29] ;\n",
    "Lr = 0.01 pour les epochs de [30 à 49] ;\n",
    "Lr = 0.001 pour les epochs de [50 à 60]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enfin, nous avons également choisi de faire 7 étapes de pruning afin d'obtenir un ratio de compression égal environ à 4.76."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(),lr=0.1, momentum=0.9,weight_decay=1e-4) \n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "scheduler = MultiStepLR(optimizer, milestones=[30, 50], gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_to_prune=[]\n",
    "for name, module in model_pruned.named_modules():\n",
    "    if isinstance(module, torch.nn.Conv2d) or isinstance(module, torch.nn.Linear) :\n",
    "        parameters_to_prune.append((module,'weight'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.336704\n",
      "\n",
      "test accuracy of plane: 92% (924/1000)\n",
      "test accuracy of car: 96% (960/1000)\n",
      "test accuracy of bird: 89% (897/1000)\n",
      "test accuracy of cat: 81% (818/1000)\n",
      "test accuracy of deer: 94% (943/1000)\n",
      "test accuracy of dog: 87% (872/1000)\n",
      "test accuracy of frog: 93% (930/1000)\n",
      "test accuracy of horse: 94% (949/1000)\n",
      "test accuracy of ship: 95% (955/1000)\n",
      "test accuracy of truck: 94% (949/1000)\n",
      "\n",
      "test accuracy (overall): 91.97% (9197/10000)\n",
      "test Loss: 0.373786\n",
      "\n",
      "test accuracy of plane: 91% (911/1000)\n",
      "test accuracy of car: 96% (964/1000)\n",
      "test accuracy of bird: 90% (903/1000)\n",
      "test accuracy of cat: 82% (828/1000)\n",
      "test accuracy of deer: 94% (941/1000)\n",
      "test accuracy of dog: 88% (881/1000)\n",
      "test accuracy of frog: 92% (920/1000)\n",
      "test accuracy of horse: 89% (893/1000)\n",
      "test accuracy of ship: 95% (955/1000)\n",
      "test accuracy of truck: 93% (933/1000)\n",
      "\n",
      "test accuracy (overall): 91.29% (9129/10000)\n",
      "test Loss: 0.388742\n",
      "\n",
      "test accuracy of plane: 93% (931/1000)\n",
      "test accuracy of car: 96% (960/1000)\n",
      "test accuracy of bird: 89% (899/1000)\n",
      "test accuracy of cat: 82% (829/1000)\n",
      "test accuracy of deer: 93% (939/1000)\n",
      "test accuracy of dog: 84% (845/1000)\n",
      "test accuracy of frog: 85% (857/1000)\n",
      "test accuracy of horse: 94% (944/1000)\n",
      "test accuracy of ship: 93% (935/1000)\n",
      "test accuracy of truck: 94% (946/1000)\n",
      "\n",
      "test accuracy (overall): 90.85% (9085/10000)\n",
      "test Loss: 0.482012\n",
      "\n",
      "test accuracy of plane: 89% (890/1000)\n",
      "test accuracy of car: 92% (925/1000)\n",
      "test accuracy of bird: 93% (931/1000)\n",
      "test accuracy of cat: 72% (728/1000)\n",
      "test accuracy of deer: 92% (929/1000)\n",
      "test accuracy of dog: 88% (880/1000)\n",
      "test accuracy of frog: 87% (878/1000)\n",
      "test accuracy of horse: 87% (871/1000)\n",
      "test accuracy of ship: 86% (861/1000)\n",
      "test accuracy of truck: 90% (906/1000)\n",
      "\n",
      "test accuracy (overall): 87.99% (8799/10000)\n",
      "test Loss: 0.587265\n",
      "\n",
      "test accuracy of plane: 88% (883/1000)\n",
      "test accuracy of car: 81% (814/1000)\n",
      "test accuracy of bird: 82% (821/1000)\n",
      "test accuracy of cat: 62% (628/1000)\n",
      "test accuracy of deer: 88% (882/1000)\n",
      "test accuracy of dog: 88% (887/1000)\n",
      "test accuracy of frog: 84% (843/1000)\n",
      "test accuracy of horse: 90% (906/1000)\n",
      "test accuracy of ship: 84% (846/1000)\n",
      "test accuracy of truck: 89% (892/1000)\n",
      "\n",
      "test accuracy (overall): 84.02% (8402/10000)\n",
      "test Loss: 1.016551\n",
      "\n",
      "test accuracy of plane: 83% (833/1000)\n",
      "test accuracy of car: 49% (490/1000)\n",
      "test accuracy of bird: 93% (930/1000)\n",
      "test accuracy of cat: 79% (794/1000)\n",
      "test accuracy of deer: 85% (857/1000)\n",
      "test accuracy of dog: 54% (540/1000)\n",
      "test accuracy of frog: 74% (748/1000)\n",
      "test accuracy of horse: 76% (769/1000)\n",
      "test accuracy of ship: 66% (664/1000)\n",
      "test accuracy of truck: 81% (817/1000)\n",
      "\n",
      "test accuracy (overall): 74.42% (7442/10000)\n",
      "test Loss: 1.295276\n",
      "\n",
      "test accuracy of plane: 54% (540/1000)\n",
      "test accuracy of car: 25% (252/1000)\n",
      "test accuracy of bird: 42% (421/1000)\n",
      "test accuracy of cat: 84% (847/1000)\n",
      "test accuracy of deer: 89% (897/1000)\n",
      "test accuracy of dog: 54% (542/1000)\n",
      "test accuracy of frog: 67% (677/1000)\n",
      "test accuracy of horse: 82% (823/1000)\n",
      "test accuracy of ship: 84% (844/1000)\n",
      "test accuracy of truck: 85% (859/1000)\n",
      "\n",
      "test accuracy (overall): 67.02% (6702/10000)\n"
     ]
    }
   ],
   "source": [
    "steps_pruning = 7\n",
    "for steps in range (steps_pruning):\n",
    "    prune.global_unstructured(parameters_to_prune, pruning_method=prune.L1Unstructured, amount=0.2)\n",
    "    evaluation(model_pruned, testloader, criterion)\n",
    "    training_pruning(trainloader,model_pruned, criterion, optimizer,60,scheduler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'accuracy au bout de la 7ème étape de pruning est égale à :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.656300\n",
      "\n",
      "test accuracy of plane: 74% (743/1000)\n",
      "test accuracy of car: 78% (786/1000)\n",
      "test accuracy of bird: 79% (795/1000)\n",
      "test accuracy of cat: 76% (761/1000)\n",
      "test accuracy of deer: 88% (880/1000)\n",
      "test accuracy of dog: 73% (731/1000)\n",
      "test accuracy of frog: 87% (874/1000)\n",
      "test accuracy of horse: 80% (804/1000)\n",
      "test accuracy of ship: 90% (903/1000)\n",
      "test accuracy of truck: 88% (886/1000)\n",
      "\n",
      "test accuracy (overall): 81.63% (8163/10000)\n"
     ]
    }
   ],
   "source": [
    "evaluation(model_pruned, testloader, criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous observons que le pruning est bien réalisé : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity in conv1t: 25.93%\n",
      "Sparsity in dense1.0.conv1t: 64.84%\n",
      "Sparsity in dense1.0.conv2t: 79.17%\n",
      "Sparsity in dense1.1.conv1t: 69.40%\n",
      "Sparsity in dense1.1.conv2t: 71.74%\n",
      "Sparsity in dense1.2.conv1t: 70.02%\n",
      "Sparsity in dense1.2.conv2t: 74.00%\n",
      "Sparsity in dense1.3.conv1t: 80.78%\n",
      "Sparsity in dense1.3.conv2t: 77.13%\n",
      "Sparsity in dense1.4.conv1t: 79.49%\n",
      "Sparsity in dense1.4.conv2t: 76.09%\n",
      "Sparsity in dense1.5.conv1t: 73.72%\n",
      "Sparsity in dense1.5.conv2t: 73.39%\n",
      "Sparsity in trans1.convt: 48.34%\n",
      "Sparsity in dense2.0.conv1t: 69.82%\n",
      "Sparsity in dense2.0.conv2t: 72.70%\n",
      "Sparsity in dense2.1.conv1t: 76.41%\n",
      "Sparsity in dense2.1.conv2t: 77.65%\n",
      "Sparsity in dense2.2.conv1t: 75.13%\n",
      "Sparsity in dense2.2.conv2t: 70.18%\n",
      "Sparsity in dense2.3.conv1t: 73.66%\n",
      "Sparsity in dense2.3.conv2t: 73.09%\n",
      "Sparsity in dense2.4.conv1t: 72.71%\n",
      "Sparsity in dense2.4.conv2t: 70.31%\n",
      "Sparsity in dense2.5.conv1t: 73.74%\n",
      "Sparsity in dense2.5.conv2t: 69.14%\n",
      "Sparsity in dense2.6.conv1t: 70.12%\n",
      "Sparsity in dense2.6.conv2t: 69.70%\n",
      "Sparsity in dense2.7.conv1t: 73.65%\n",
      "Sparsity in dense2.7.conv2t: 69.75%\n",
      "Sparsity in dense2.8.conv1t: 74.87%\n",
      "Sparsity in dense2.8.conv2t: 70.40%\n",
      "Sparsity in dense2.9.conv1t: 79.72%\n",
      "Sparsity in dense2.9.conv2t: 78.82%\n",
      "Sparsity in trans2.convt: 48.95%\n",
      "Sparsity in dense3.0.conv1t: 82.14%\n",
      "Sparsity in dense3.0.conv2t: 78.52%\n",
      "Sparsity in dense3.1.conv1t: 82.52%\n",
      "Sparsity in dense3.1.conv2t: 73.87%\n",
      "Sparsity in dense3.2.conv1t: 82.03%\n",
      "Sparsity in dense3.2.conv2t: 77.00%\n",
      "Sparsity in dense3.3.conv1t: 78.87%\n",
      "Sparsity in dense3.3.conv2t: 74.44%\n",
      "Sparsity in dense3.4.conv1t: 74.89%\n",
      "Sparsity in dense3.4.conv2t: 70.01%\n",
      "Sparsity in dense3.5.conv1t: 78.09%\n",
      "Sparsity in dense3.5.conv2t: 71.57%\n",
      "Sparsity in dense3.6.conv1t: 80.86%\n",
      "Sparsity in dense3.6.conv2t: 74.35%\n",
      "Sparsity in dense3.7.conv1t: 81.19%\n",
      "Sparsity in dense3.7.conv2t: 73.87%\n",
      "Sparsity in dense3.8.conv1t: 82.14%\n",
      "Sparsity in dense3.8.conv2t: 73.35%\n",
      "Sparsity in dense3.9.conv1t: 80.35%\n",
      "Sparsity in dense3.9.conv2t: 73.00%\n",
      "Sparsity in dense3.10.conv1t: 78.54%\n",
      "Sparsity in dense3.10.conv2t: 72.05%\n",
      "Sparsity in dense3.11.conv1t: 78.93%\n",
      "Sparsity in dense3.11.conv2t: 67.71%\n",
      "Sparsity in dense3.12.conv1t: 78.50%\n",
      "Sparsity in dense3.12.conv2t: 72.44%\n",
      "Sparsity in dense3.13.conv1t: 79.12%\n",
      "Sparsity in dense3.13.conv2t: 71.92%\n",
      "Sparsity in dense3.14.conv1t: 79.41%\n",
      "Sparsity in dense3.14.conv2t: 70.36%\n",
      "Sparsity in dense3.15.conv1t: 79.78%\n",
      "Sparsity in dense3.15.conv2t: 70.23%\n",
      "Sparsity in dense3.16.conv1t: 80.32%\n",
      "Sparsity in dense3.16.conv2t: 72.35%\n",
      "Sparsity in dense3.17.conv1t: 79.04%\n",
      "Sparsity in dense3.17.conv2t: 70.57%\n",
      "Sparsity in dense3.18.conv1t: 79.89%\n",
      "Sparsity in dense3.18.conv2t: 71.88%\n",
      "Sparsity in dense3.19.conv1t: 79.51%\n",
      "Sparsity in dense3.19.conv2t: 71.01%\n",
      "Sparsity in trans3.convt: 74.22%\n",
      "Sparsity in dense4.0.conv1t: 90.31%\n",
      "Sparsity in dense4.0.conv2t: 85.59%\n",
      "Sparsity in dense4.1.conv1t: 91.59%\n",
      "Sparsity in dense4.1.conv2t: 83.68%\n",
      "Sparsity in dense4.2.conv1t: 90.57%\n",
      "Sparsity in dense4.2.conv2t: 85.63%\n",
      "Sparsity in dense4.3.conv1t: 93.28%\n",
      "Sparsity in dense4.3.conv2t: 88.72%\n",
      "Sparsity in dense4.4.conv1t: 90.67%\n",
      "Sparsity in dense4.4.conv2t: 90.19%\n",
      "Sparsity in dense4.5.conv1t: 94.28%\n",
      "Sparsity in dense4.5.conv2t: 92.93%\n",
      "Sparsity in dense4.6.conv1t: 91.87%\n",
      "Sparsity in dense4.6.conv2t: 89.80%\n",
      "Sparsity in dense4.7.conv1t: 90.42%\n",
      "Sparsity in dense4.7.conv2t: 87.50%\n",
      "Sparsity in dense4.8.conv1t: 91.62%\n",
      "Sparsity in dense4.8.conv2t: 90.49%\n",
      "Sparsity in dense4.9.conv1t: 91.75%\n",
      "Sparsity in dense4.9.conv2t: 92.10%\n",
      "Sparsity in dense4.10.conv1t: 93.09%\n",
      "Sparsity in dense4.10.conv2t: 93.14%\n",
      "Sparsity in dense4.11.conv1t: 93.53%\n",
      "Sparsity in dense4.11.conv2t: 93.36%\n",
      "Sparsity in lineart: 44.61%\n",
      "Global sparsity: 79.03%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'79.0286865234375'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sparsity(model_pruned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cc8A4ugcgeA7"
   },
   "source": [
    "Si vous voulez travailler avec notre modèle déjà pruné."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_to_prune=[]\n",
    "for name, module in model_pruned.named_modules():\n",
    "    if isinstance(module, torch.nn.Conv2d) or isinstance(module, torch.nn.Linear) :\n",
    "        parameters_to_prune.append((module,'weight'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "prune.global_unstructured(parameters_to_prune, pruning_method=prune.L1Unstructured, amount=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "C9Fh1sQLgeA8",
    "outputId": "ea359b59-9eb5-4a69-ba8c-bb40944961fc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    loaded_cpt=torch.load('models\\\\Densenet_cifar_pruned.pt')\n",
    "else:\n",
    "    loaded_cpt=torch.load('models\\\\Densenet_cifar_pruned.pt', map_location=torch.device('cpu'))\n",
    "model_pruned.load_state_dict(loaded_cpt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GmnCTg6qgeA8"
   },
   "source": [
    "Il est nécessaire d'exécuter un forward afin que le modèle soit pruné de manière correcte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "yOdTZYw_geA9",
    "outputId": "826c356a-ec70-453c-d753-53d5e86f4ad3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.304136\n",
      "\n",
      "test accuracy of plane: 93% (939/1000)\n",
      "test accuracy of car: 97% (974/1000)\n",
      "test accuracy of bird: 90% (903/1000)\n",
      "test accuracy of cat: 84% (843/1000)\n",
      "test accuracy of deer: 95% (950/1000)\n",
      "test accuracy of dog: 88% (881/1000)\n",
      "test accuracy of frog: 94% (944/1000)\n",
      "test accuracy of horse: 93% (935/1000)\n",
      "test accuracy of ship: 94% (949/1000)\n",
      "test accuracy of truck: 94% (947/1000)\n",
      "\n",
      "test accuracy (overall): 92.65% (9265/10000)\n"
     ]
    }
   ],
   "source": [
    "evaluation(model_pruned, testloader, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "tI2vBSyhgeA-",
    "outputId": "bcb5ebb4-3029-41aa-b7b0-fe20aa5a9670",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity in conv1t: 26.85%\n",
      "Sparsity in dense1.0.conv1t: 74.80%\n",
      "Sparsity in dense1.0.conv2t: 76.65%\n",
      "Sparsity in dense1.1.conv1t: 71.61%\n",
      "Sparsity in dense1.1.conv2t: 69.97%\n",
      "Sparsity in dense1.2.conv1t: 76.37%\n",
      "Sparsity in dense1.2.conv2t: 77.17%\n",
      "Sparsity in dense1.3.conv1t: 83.52%\n",
      "Sparsity in dense1.3.conv2t: 77.86%\n",
      "Sparsity in dense1.4.conv1t: 78.78%\n",
      "Sparsity in dense1.4.conv2t: 73.52%\n",
      "Sparsity in dense1.5.conv1t: 77.12%\n",
      "Sparsity in dense1.5.conv2t: 74.78%\n",
      "Sparsity in trans1.convt: 56.93%\n",
      "Sparsity in dense2.0.conv1t: 71.29%\n",
      "Sparsity in dense2.0.conv2t: 72.83%\n",
      "Sparsity in dense2.1.conv1t: 78.52%\n",
      "Sparsity in dense2.1.conv2t: 74.78%\n",
      "Sparsity in dense2.2.conv1t: 77.28%\n",
      "Sparsity in dense2.2.conv2t: 70.01%\n",
      "Sparsity in dense2.3.conv1t: 79.63%\n",
      "Sparsity in dense2.3.conv2t: 71.66%\n",
      "Sparsity in dense2.4.conv1t: 76.32%\n",
      "Sparsity in dense2.4.conv2t: 71.74%\n",
      "Sparsity in dense2.5.conv1t: 76.56%\n",
      "Sparsity in dense2.5.conv2t: 70.36%\n",
      "Sparsity in dense2.6.conv1t: 71.68%\n",
      "Sparsity in dense2.6.conv2t: 70.27%\n",
      "Sparsity in dense2.7.conv1t: 77.70%\n",
      "Sparsity in dense2.7.conv2t: 73.00%\n",
      "Sparsity in dense2.8.conv1t: 76.89%\n",
      "Sparsity in dense2.8.conv2t: 70.92%\n",
      "Sparsity in dense2.9.conv1t: 79.78%\n",
      "Sparsity in dense2.9.conv2t: 76.91%\n",
      "Sparsity in trans2.convt: 55.95%\n",
      "Sparsity in dense3.0.conv1t: 82.42%\n",
      "Sparsity in dense3.0.conv2t: 77.95%\n",
      "Sparsity in dense3.1.conv1t: 85.35%\n",
      "Sparsity in dense3.1.conv2t: 76.74%\n",
      "Sparsity in dense3.2.conv1t: 85.68%\n",
      "Sparsity in dense3.2.conv2t: 78.43%\n",
      "Sparsity in dense3.3.conv1t: 81.91%\n",
      "Sparsity in dense3.3.conv2t: 77.13%\n",
      "Sparsity in dense3.4.conv1t: 80.43%\n",
      "Sparsity in dense3.4.conv2t: 73.91%\n",
      "Sparsity in dense3.5.conv1t: 81.41%\n",
      "Sparsity in dense3.5.conv2t: 74.57%\n",
      "Sparsity in dense3.6.conv1t: 83.38%\n",
      "Sparsity in dense3.6.conv2t: 76.87%\n",
      "Sparsity in dense3.7.conv1t: 83.59%\n",
      "Sparsity in dense3.7.conv2t: 75.52%\n",
      "Sparsity in dense3.8.conv1t: 83.54%\n",
      "Sparsity in dense3.8.conv2t: 74.96%\n",
      "Sparsity in dense3.9.conv1t: 83.13%\n",
      "Sparsity in dense3.9.conv2t: 76.26%\n",
      "Sparsity in dense3.10.conv1t: 81.07%\n",
      "Sparsity in dense3.10.conv2t: 75.78%\n",
      "Sparsity in dense3.11.conv1t: 82.60%\n",
      "Sparsity in dense3.11.conv2t: 70.57%\n",
      "Sparsity in dense3.12.conv1t: 80.10%\n",
      "Sparsity in dense3.12.conv2t: 74.96%\n",
      "Sparsity in dense3.13.conv1t: 81.88%\n",
      "Sparsity in dense3.13.conv2t: 74.48%\n",
      "Sparsity in dense3.14.conv1t: 80.71%\n",
      "Sparsity in dense3.14.conv2t: 73.05%\n",
      "Sparsity in dense3.15.conv1t: 81.27%\n",
      "Sparsity in dense3.15.conv2t: 70.27%\n",
      "Sparsity in dense3.16.conv1t: 79.99%\n",
      "Sparsity in dense3.16.conv2t: 72.27%\n",
      "Sparsity in dense3.17.conv1t: 80.58%\n",
      "Sparsity in dense3.17.conv2t: 71.01%\n",
      "Sparsity in dense3.18.conv1t: 80.02%\n",
      "Sparsity in dense3.18.conv2t: 71.48%\n",
      "Sparsity in dense3.19.conv1t: 80.11%\n",
      "Sparsity in dense3.19.conv2t: 70.62%\n",
      "Sparsity in trans3.convt: 74.43%\n",
      "Sparsity in dense4.0.conv1t: 89.06%\n",
      "Sparsity in dense4.0.conv2t: 80.21%\n",
      "Sparsity in dense4.1.conv1t: 87.77%\n",
      "Sparsity in dense4.1.conv2t: 82.38%\n",
      "Sparsity in dense4.2.conv1t: 89.44%\n",
      "Sparsity in dense4.2.conv2t: 83.03%\n",
      "Sparsity in dense4.3.conv1t: 90.10%\n",
      "Sparsity in dense4.3.conv2t: 83.25%\n",
      "Sparsity in dense4.4.conv1t: 85.47%\n",
      "Sparsity in dense4.4.conv2t: 82.20%\n",
      "Sparsity in dense4.5.conv1t: 89.70%\n",
      "Sparsity in dense4.5.conv2t: 86.15%\n",
      "Sparsity in dense4.6.conv1t: 87.20%\n",
      "Sparsity in dense4.6.conv2t: 82.29%\n",
      "Sparsity in dense4.7.conv1t: 86.47%\n",
      "Sparsity in dense4.7.conv2t: 80.77%\n",
      "Sparsity in dense4.8.conv1t: 87.45%\n",
      "Sparsity in dense4.8.conv2t: 82.25%\n",
      "Sparsity in dense4.9.conv1t: 86.34%\n",
      "Sparsity in dense4.9.conv2t: 82.42%\n",
      "Sparsity in dense4.10.conv1t: 88.16%\n",
      "Sparsity in dense4.10.conv2t: 84.11%\n",
      "Sparsity in dense4.11.conv1t: 88.04%\n",
      "Sparsity in dense4.11.conv2t: 82.81%\n",
      "Sparsity in lineart: 67.50%\n",
      "Global sparsity: 79.03%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'79.0286865234375'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sparsity(model_pruned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "b_daCLkUgeA_",
    "outputId": "56a38f6b-0321-4474-8b1c-482679e0c5db",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-9.8413e-01, -1.4156e+00, -6.8998e-01],\n",
      "          [ 2.9501e-01,  2.5201e-01, -2.1341e-01],\n",
      "          [ 1.1402e+00,  1.6780e+00,  2.3051e-01]],\n",
      "\n",
      "         [[ 2.8061e-01,  1.4054e-01,  2.8852e-01],\n",
      "          [-1.0003e-01, -1.5904e-01,  0.0000e+00],\n",
      "          [-3.6462e-01, -1.8441e-01, -1.7617e-01]],\n",
      "\n",
      "         [[ 7.9544e-01,  8.7149e-01,  5.3565e-01],\n",
      "          [-4.3006e-02, -2.3282e-01,  2.8181e-01],\n",
      "          [-9.3424e-01, -1.1104e+00, -2.4479e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 3.4305e-01,  1.0020e+00,  5.2035e-01],\n",
      "          [ 6.1827e-01,  1.2533e+00,  6.1121e-01],\n",
      "          [ 4.5072e-01,  9.9235e-01, -0.0000e+00]],\n",
      "\n",
      "         [[-3.3692e-01, -5.0674e-01, -2.5158e-01],\n",
      "          [-4.8995e-01, -6.7966e-01, -4.1674e-01],\n",
      "          [-2.7760e-01, -3.8856e-01, -2.1192e-01]],\n",
      "\n",
      "         [[ 0.0000e+00, -4.3839e-01, -7.1969e-02],\n",
      "          [-2.5402e-01, -6.4782e-01, -1.4823e-01],\n",
      "          [-2.6778e-01, -5.2079e-01,  0.0000e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000e+00, -4.7254e-01, -0.0000e+00],\n",
      "          [-3.8899e-01, -7.3799e-01,  0.0000e+00],\n",
      "          [-2.4230e-01, -5.5155e-01, -0.0000e+00]],\n",
      "\n",
      "         [[-0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00, -0.0000e+00],\n",
      "          [-0.0000e+00, -1.7516e-01, -1.5319e-01]],\n",
      "\n",
      "         [[-0.0000e+00,  6.0962e-01, -0.0000e+00],\n",
      "          [ 3.5902e-01,  9.3090e-01,  1.7458e-01],\n",
      "          [ 0.0000e+00,  7.0812e-01,  0.0000e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000e+00,  4.4110e-01, -0.0000e+00],\n",
      "          [ 3.3788e-01, -4.7360e-01,  1.6912e-01],\n",
      "          [ 2.8527e-01, -8.1426e-01,  4.1107e-01]],\n",
      "\n",
      "         [[ 0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
      "          [ 4.7869e-01, -1.0405e+00,  3.2554e-01],\n",
      "          [ 4.1865e-01, -9.4973e-01,  5.0380e-01]],\n",
      "\n",
      "         [[ 0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
      "          [-0.0000e+00, -3.6631e-01,  7.8856e-02],\n",
      "          [ 3.6756e-01, -3.8304e-01,  3.3946e-01]]],\n",
      "\n",
      "\n",
      "        [[[-3.6982e-01, -5.0541e-01, -2.3014e-01],\n",
      "          [-1.2593e-01, -1.7216e-01, -0.0000e+00],\n",
      "          [ 4.3483e-01,  5.2029e-01,  3.8644e-01]],\n",
      "\n",
      "         [[-5.6961e-01, -6.1926e-01, -3.9938e-01],\n",
      "          [-0.0000e+00, -1.4251e-01, -1.2758e-01],\n",
      "          [ 5.1014e-01,  6.8602e-01,  5.4614e-01]],\n",
      "\n",
      "         [[-4.6835e-01, -5.0148e-01, -2.4086e-01],\n",
      "          [-0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
      "          [ 3.4259e-01,  5.1157e-01,  4.6065e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 3.1324e-01, -2.9141e-01,  2.0902e-01],\n",
      "          [-2.8571e-01, -1.0938e+00, -3.6303e-01],\n",
      "          [-0.0000e+00, -1.0641e-01,  1.9788e-01]],\n",
      "\n",
      "         [[ 2.6431e-01, -4.0834e-01,  1.5142e-01],\n",
      "          [-3.9989e-01, -1.1577e+00, -3.2436e-01],\n",
      "          [ 1.8260e-01, -2.8917e-01,  1.3830e-01]],\n",
      "\n",
      "         [[ 0.0000e+00, -1.9971e-01,  1.5384e-01],\n",
      "          [ 0.0000e+00, -7.1164e-01, -1.1820e-01],\n",
      "          [ 0.0000e+00,  1.4409e-02,  0.0000e+00]]],\n",
      "\n",
      "\n",
      "        [[[-0.0000e+00, -3.1543e-01, -0.0000e+00],\n",
      "          [-2.0661e-01,  1.1168e+00, -1.5757e-01],\n",
      "          [ 0.0000e+00, -6.1981e-01,  0.0000e+00]],\n",
      "\n",
      "         [[-0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [-0.0000e+00,  1.6292e+00, -1.5669e-01],\n",
      "          [ 0.0000e+00, -1.1785e+00, -0.0000e+00]],\n",
      "\n",
      "         [[ 0.0000e+00, -3.7768e-01, -0.0000e+00],\n",
      "          [-2.1569e-01,  7.9693e-01, -1.7729e-01],\n",
      "          [-0.0000e+00, -2.7482e-01,  0.0000e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
      "          [ 0.0000e+00,  1.2448e-02,  0.0000e+00],\n",
      "          [-0.0000e+00,  4.0000e-04, -0.0000e+00]],\n",
      "\n",
      "         [[-1.2301e-01, -2.8946e-01, -2.0428e-01],\n",
      "          [-3.8193e-01, -5.0708e-01, -3.6042e-01],\n",
      "          [-3.4098e-01, -4.6607e-01, -3.2657e-01]],\n",
      "\n",
      "         [[ 0.0000e+00,  4.1621e-01,  1.6965e-01],\n",
      "          [ 2.6947e-01,  6.0528e-01,  3.3295e-01],\n",
      "          [ 2.2254e-01,  4.5765e-01,  1.8941e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000e+00,  6.9632e-01,  9.7630e-02],\n",
      "          [ 5.1361e-02,  5.7410e-01,  1.3419e-01],\n",
      "          [ 0.0000e+00,  2.9380e-01, -1.3187e-01]],\n",
      "\n",
      "         [[-2.7805e-01, -5.3869e-01, -2.2904e-01],\n",
      "          [-5.9110e-01, -1.0547e+00, -5.2018e-01],\n",
      "          [-1.1395e-01, -4.5911e-01, -0.0000e+00]],\n",
      "\n",
      "         [[ 2.6841e-01, -0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  1.3813e-01,  0.0000e+00],\n",
      "          [ 2.4214e-01,  0.0000e+00,  2.4853e-01]]],\n",
      "\n",
      "\n",
      "        [[[-0.0000e+00, -3.7970e-01, -0.0000e+00],\n",
      "          [-3.4311e-01, -7.3491e-01, -4.0605e-01],\n",
      "          [ 0.0000e+00, -4.7254e-01, -0.0000e+00]],\n",
      "\n",
      "         [[-0.0000e+00,  7.6190e-01,  2.6392e-01],\n",
      "          [ 5.9488e-01,  1.0001e+00,  5.4895e-01],\n",
      "          [ 2.8909e-01,  6.4266e-01,  2.6684e-01]],\n",
      "\n",
      "         [[-7.8513e-02, -4.7072e-01, -2.1646e-01],\n",
      "          [-5.1391e-01, -9.9281e-01, -5.8917e-01],\n",
      "          [-2.5533e-01, -0.0000e+00,  0.0000e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 1.3364e-01,  3.6325e-01,  1.5123e-01],\n",
      "          [ 4.3976e-01,  6.6283e-01,  3.7862e-01],\n",
      "          [ 2.0271e-01,  3.8074e-01,  1.3587e-01]],\n",
      "\n",
      "         [[-3.3478e-01, -8.1483e-01, -3.3363e-01],\n",
      "          [-4.7842e-01, -1.0189e+00, -5.2572e-01],\n",
      "          [-2.2282e-01, -6.5238e-01, -2.8692e-01]],\n",
      "\n",
      "         [[ 1.3697e-01,  2.4855e-01,  1.8996e-01],\n",
      "          [ 4.3519e-01,  5.9202e-01,  5.0296e-01],\n",
      "          [ 2.0306e-01,  3.6001e-01,  2.4826e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.6956e-01,  0.0000e+00, -0.0000e+00],\n",
      "          [ 8.1218e-01, -2.9444e-01, -5.1109e-01],\n",
      "          [ 4.1659e-01, -3.4501e-01, -2.5072e-01]],\n",
      "\n",
      "         [[ 3.1337e-01, -0.0000e+00, -2.8899e-01],\n",
      "          [ 9.8871e-01, -3.7623e-01, -5.9153e-01],\n",
      "          [ 6.1956e-01, -2.8930e-01, -2.6043e-01]],\n",
      "\n",
      "         [[ 0.0000e+00, -1.8084e-01, -0.0000e+00],\n",
      "          [ 6.4552e-01, -2.9018e-01, -4.6191e-01],\n",
      "          [ 3.8976e-01, -1.9373e-01, -1.7750e-01]]],\n",
      "\n",
      "\n",
      "        [[[-0.0000e+00, -2.0706e-01,  0.0000e+00],\n",
      "          [ 0.0000e+00, -3.8073e-01, -3.1366e-01],\n",
      "          [ 3.5945e-01,  2.4533e-01,  1.9286e-01]],\n",
      "\n",
      "         [[-0.0000e+00, -4.8968e-01, -0.0000e+00],\n",
      "          [-0.0000e+00, -5.3423e-01, -3.0764e-01],\n",
      "          [ 5.9013e-01,  5.1361e-01,  4.5835e-01]],\n",
      "\n",
      "         [[ 0.0000e+00, -3.0440e-01,  0.0000e+00],\n",
      "          [ 0.0000e+00, -4.4996e-01, -2.3117e-01],\n",
      "          [ 2.6832e-01,  2.0487e-01,  2.7745e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000e+00,  0.0000e+00, -0.0000e+00],\n",
      "          [-8.1087e-01,  0.0000e+00,  8.6806e-01],\n",
      "          [-4.0330e-01, -0.0000e+00,  3.1898e-01]],\n",
      "\n",
      "         [[-4.9240e-01,  0.0000e+00,  5.5338e-01],\n",
      "          [-1.1292e+00, -0.0000e+00,  1.1279e+00],\n",
      "          [-5.8523e-01, -0.0000e+00,  6.4221e-01]],\n",
      "\n",
      "         [[-2.3918e-01, -0.0000e+00,  0.0000e+00],\n",
      "          [-8.8233e-01, -0.0000e+00,  8.6712e-01],\n",
      "          [-4.2717e-01,  0.0000e+00,  4.6224e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.4984e-01, -0.0000e+00, -0.0000e+00],\n",
      "          [ 1.3402e-01,  1.4740e-01,  0.0000e+00],\n",
      "          [ 1.1590e-01,  2.1890e-01,  9.2538e-02]],\n",
      "\n",
      "         [[ 0.0000e+00,  5.2597e-02,  0.0000e+00],\n",
      "          [ 2.7897e-01,  4.2815e-01,  3.8612e-01],\n",
      "          [ 3.9241e-02,  2.1514e-01,  1.6046e-01]],\n",
      "\n",
      "         [[ 1.1231e-01,  0.0000e+00,  0.0000e+00],\n",
      "          [ 2.0778e-01, -0.0000e+00,  2.1491e-01],\n",
      "          [-1.0233e-01, -2.1000e-01, -5.9420e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 4.0058e-01,  6.2361e-01,  4.3968e-01],\n",
      "          [-0.0000e+00, -7.9785e-02,  0.0000e+00],\n",
      "          [-4.1013e-01, -6.6082e-01, -2.5601e-01]],\n",
      "\n",
      "         [[ 5.2743e-01,  7.0398e-01,  6.0337e-01],\n",
      "          [ 0.0000e+00, -2.0621e-01,  0.0000e+00],\n",
      "          [-4.6769e-01, -7.5969e-01, -4.2095e-01]],\n",
      "\n",
      "         [[ 2.6357e-01,  4.1237e-01,  2.5023e-01],\n",
      "          [-0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
      "          [-2.8227e-01, -4.3426e-01, -3.1690e-01]]]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(model_pruned.conv1.weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "onH0khiNgeA_"
   },
   "source": [
    "On voit que notre accuracy a augmenté (environ 0.6%), de plus le nombre de paramètres réduit à zéro est assez important.  \n",
    "De ce fait notre score Micronet associé aux nombres de paramètres a diminué de manière importante ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# En exécutant cette cellule, nous perdons le mask associé au pruning, mais cela nous permet de pouvoir calculer le score micronet\n",
    "for name, module in model_pruned.named_modules():\n",
    "# prune X % of connections in all 2D-conv layers\n",
    "    if isinstance(module, torch.nn.Conv2d):\n",
    "        prune.remove(module, 'weight')\n",
    "\n",
    "    elif isinstance(module, torch.nn.Linear):\n",
    "        prune.remove(module, 'weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score flops: 0.06795413525587332 Score Params: 0.007276917533816564\n",
      "Final score: 0.07523105278968989\n"
     ]
    }
   ],
   "source": [
    "flops , params = score(model_pruned)\n",
    "print(\"Score flops: {} Score Params: {}\".format(flops,params))\n",
    "print(\"Final score: {}\".format(flops + params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w38B9iUbq0eQ"
   },
   "source": [
    "# Quantization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bTHdwmwCgeBA"
   },
   "source": [
    "Nous allons tout d'abord présenter deux méthodes de Quantization que nous avons utilisé (Binary Connect et BWN). Vous trouverez plus d'informations sur les liens suivants.  \n",
    "Binary Connect : https://proceedings.neurips.cc/paper/2015/hash/3e15cc11f979ed25912dff5b0669f2cd-Abstract.html$  \n",
    "BWN : https://link.springer.com/chapter/10.1007/978-3-319-46493-0_32  \n",
    "Ces méthodes sont intéressantes cependant leur utilisation ne nous permettaient pas d'obtenir une accuracy supérieure à 90% donc nous nous sommes tournés vers une autre méthode.\n",
    "Nous allons quand même montrer un exemple d'utilisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1mcX8Go1ctxQ"
   },
   "outputs": [],
   "source": [
    "modelbc = BC(model)\n",
    "modelbc.model = modelbc.model.to(device)\n",
    "\n",
    "optimizer_bc = torch.optim.SGD(modelbc.model.parameters(),lr = 0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 298
    },
    "id": "n5HPG0p0cwrP",
    "outputId": "6dfe54f9-d03b-4dd2-f92d-5e36ec58d4d2"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-eb003743ae54>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-2df4b830d952>\u001b[0m in \u001b[0;36mtraining\u001b[0;34m(train_loader, valid_loader, model, criterion, optimizer, n_epochs)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mvalid_loss_min\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInf\u001b[0m  \u001b[0;31m# set initial \"min\" to infinity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;31m# monitor losses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mclass_correct_train\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mclass_total_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'SGD' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "train_losses, valid_losses, train_acc, valid_acc = training_binary(100, trainloader, validloader, modelbc, criterion, optimizer_bc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2o8R6BjBgeBB"
   },
   "outputs": [],
   "source": [
    "evaluation_binary(modelbc,testloader,criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MIUUZjphgeBB"
   },
   "source": [
    "Nous allons maintenant nous intéresser à une autre méthode de Quantization, l'ApOT Quantization : https://iclr.cc/virtual_2020/poster_BkgXT24tDS.html  \n",
    "Pour résumer, cette méthode nous permet de quantizer les valeurs de paramères sur un n bits (dans notre cas 4 bits)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LrPN9yGJrU8x",
    "outputId": "b1b6305f-a44e-46d6-a02b-90f8ebc08504",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseNet_Quant(\n",
       "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (dense1): Sequential(\n",
       "    (0): Bottleneck_Quant(\n",
       "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantConv2d(\n",
       "        16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantConv2d(\n",
       "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck_Quant(\n",
       "      (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantConv2d(\n",
       "        24, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantConv2d(\n",
       "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "    )\n",
       "    (2): Bottleneck_Quant(\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantConv2d(\n",
       "        32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantConv2d(\n",
       "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "    )\n",
       "    (3): Bottleneck_Quant(\n",
       "      (bn1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantConv2d(\n",
       "        40, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantConv2d(\n",
       "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "    )\n",
       "    (4): Bottleneck_Quant(\n",
       "      (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantConv2d(\n",
       "        48, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantConv2d(\n",
       "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "    )\n",
       "    (5): Bottleneck_Quant(\n",
       "      (bn1): BatchNorm2d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantConv2d(\n",
       "        56, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantConv2d(\n",
       "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (trans1): Transition_Quant(\n",
       "    (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv): QuantConv2d(\n",
       "      64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "      (weight_quant): weight_quantize_fn()\n",
       "    )\n",
       "  )\n",
       "  (dense2): Sequential(\n",
       "    (0): Bottleneck_Quant(\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantConv2d(\n",
       "        32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantConv2d(\n",
       "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck_Quant(\n",
       "      (bn1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantConv2d(\n",
       "        40, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantConv2d(\n",
       "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "    )\n",
       "    (2): Bottleneck_Quant(\n",
       "      (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantConv2d(\n",
       "        48, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantConv2d(\n",
       "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "    )\n",
       "    (3): Bottleneck_Quant(\n",
       "      (bn1): BatchNorm2d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantConv2d(\n",
       "        56, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantConv2d(\n",
       "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "    )\n",
       "    (4): Bottleneck_Quant(\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantConv2d(\n",
       "        64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantConv2d(\n",
       "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "    )\n",
       "    (5): Bottleneck_Quant(\n",
       "      (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantConv2d(\n",
       "        72, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantConv2d(\n",
       "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "    )\n",
       "    (6): Bottleneck_Quant(\n",
       "      (bn1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantConv2d(\n",
       "        80, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantConv2d(\n",
       "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "    )\n",
       "    (7): Bottleneck_Quant(\n",
       "      (bn1): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantConv2d(\n",
       "        88, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantConv2d(\n",
       "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "    )\n",
       "    (8): Bottleneck_Quant(\n",
       "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantConv2d(\n",
       "        96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantConv2d(\n",
       "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "    )\n",
       "    (9): Bottleneck_Quant(\n",
       "      (bn1): BatchNorm2d(104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantConv2d(\n",
       "        104, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantConv2d(\n",
       "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (trans2): Transition_Quant(\n",
       "    (bn): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv): QuantConv2d(\n",
       "      112, 56, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "      (weight_quant): weight_quantize_fn()\n",
       "    )\n",
       "  )\n",
       "  (dense3): Sequential(\n",
       "    (0): Bottleneck_Quant(\n",
       "      (bn1): BatchNorm2d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantConv2d(\n",
       "        56, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantConv2d(\n",
       "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck_Quant(\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantConv2d(\n",
       "        64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantConv2d(\n",
       "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "    )\n",
       "    (2): Bottleneck_Quant(\n",
       "      (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantConv2d(\n",
       "        72, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantConv2d(\n",
       "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "    )\n",
       "    (3): Bottleneck_Quant(\n",
       "      (bn1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantConv2d(\n",
       "        80, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantConv2d(\n",
       "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "    )\n",
       "    (4): Bottleneck_Quant(\n",
       "      (bn1): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantConv2d(\n",
       "        88, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantConv2d(\n",
       "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "    )\n",
       "    (5): Bottleneck_Quant(\n",
       "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantConv2d(\n",
       "        96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantConv2d(\n",
       "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "    )\n",
       "    (6): Bottleneck_Quant(\n",
       "      (bn1): BatchNorm2d(104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantConv2d(\n",
       "        104, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantConv2d(\n",
       "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "    )\n",
       "    (7): Bottleneck_Quant(\n",
       "      (bn1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantConv2d(\n",
       "        112, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantConv2d(\n",
       "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "    )\n",
       "    (8): Bottleneck_Quant(\n",
       "      (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantConv2d(\n",
       "        120, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantConv2d(\n",
       "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "    )\n",
       "    (9): Bottleneck_Quant(\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantConv2d(\n",
       "        128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantConv2d(\n",
       "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "    )\n",
       "    (10): Bottleneck_Quant(\n",
       "      (bn1): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantConv2d(\n",
       "        136, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantConv2d(\n",
       "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "    )\n",
       "    (11): Bottleneck_Quant(\n",
       "      (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantConv2d(\n",
       "        144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantConv2d(\n",
       "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "    )\n",
       "    (12): Bottleneck_Quant(\n",
       "      (bn1): BatchNorm2d(152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantConv2d(\n",
       "        152, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantConv2d(\n",
       "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "    )\n",
       "    (13): Bottleneck_Quant(\n",
       "      (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantConv2d(\n",
       "        160, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantConv2d(\n",
       "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "    )\n",
       "    (14): Bottleneck_Quant(\n",
       "      (bn1): BatchNorm2d(168, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantConv2d(\n",
       "        168, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantConv2d(\n",
       "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "    )\n",
       "    (15): Bottleneck_Quant(\n",
       "      (bn1): BatchNorm2d(176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantConv2d(\n",
       "        176, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantConv2d(\n",
       "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "    )\n",
       "    (16): Bottleneck_Quant(\n",
       "      (bn1): BatchNorm2d(184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantConv2d(\n",
       "        184, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantConv2d(\n",
       "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "    )\n",
       "    (17): Bottleneck_Quant(\n",
       "      (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantConv2d(\n",
       "        192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantConv2d(\n",
       "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "    )\n",
       "    (18): Bottleneck_Quant(\n",
       "      (bn1): BatchNorm2d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantConv2d(\n",
       "        200, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantConv2d(\n",
       "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "    )\n",
       "    (19): Bottleneck_Quant(\n",
       "      (bn1): BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantConv2d(\n",
       "        208, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantConv2d(\n",
       "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (trans3): Transition_Quant(\n",
       "    (bn): BatchNorm2d(216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv): QuantConv2d(\n",
       "      216, 108, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "      (weight_quant): weight_quantize_fn()\n",
       "    )\n",
       "  )\n",
       "  (dense4): Sequential(\n",
       "    (0): Bottleneck_Quant(\n",
       "      (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantConv2d(\n",
       "        108, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantConv2d(\n",
       "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck_Quant(\n",
       "      (bn1): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantConv2d(\n",
       "        116, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantConv2d(\n",
       "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "    )\n",
       "    (2): Bottleneck_Quant(\n",
       "      (bn1): BatchNorm2d(124, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantConv2d(\n",
       "        124, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantConv2d(\n",
       "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "    )\n",
       "    (3): Bottleneck_Quant(\n",
       "      (bn1): BatchNorm2d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantConv2d(\n",
       "        132, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantConv2d(\n",
       "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "    )\n",
       "    (4): Bottleneck_Quant(\n",
       "      (bn1): BatchNorm2d(140, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantConv2d(\n",
       "        140, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantConv2d(\n",
       "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "    )\n",
       "    (5): Bottleneck_Quant(\n",
       "      (bn1): BatchNorm2d(148, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantConv2d(\n",
       "        148, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantConv2d(\n",
       "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "    )\n",
       "    (6): Bottleneck_Quant(\n",
       "      (bn1): BatchNorm2d(156, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantConv2d(\n",
       "        156, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantConv2d(\n",
       "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "    )\n",
       "    (7): Bottleneck_Quant(\n",
       "      (bn1): BatchNorm2d(164, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantConv2d(\n",
       "        164, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantConv2d(\n",
       "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "    )\n",
       "    (8): Bottleneck_Quant(\n",
       "      (bn1): BatchNorm2d(172, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantConv2d(\n",
       "        172, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantConv2d(\n",
       "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "    )\n",
       "    (9): Bottleneck_Quant(\n",
       "      (bn1): BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantConv2d(\n",
       "        180, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantConv2d(\n",
       "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "    )\n",
       "    (10): Bottleneck_Quant(\n",
       "      (bn1): BatchNorm2d(188, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantConv2d(\n",
       "        188, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantConv2d(\n",
       "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "    )\n",
       "    (11): Bottleneck_Quant(\n",
       "      (bn1): BatchNorm2d(196, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantConv2d(\n",
       "        196, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantConv2d(\n",
       "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (bn): BatchNorm2d(204, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (linear): Linear(in_features=204, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_quant = densenet_cifar_quant()\n",
    "model_quant.to(device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AKm3vlj-geBC"
   },
   "source": [
    "On peut bien entendu l'entrainer from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "0jWqjBAcgeBC"
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(),lr=0.1, momentum=0.9,weight_decay=1e-4) \n",
    "scheduler = MultiStepLR(optimizer, milestones=[90, 110], gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "zp3SdWATgeBC",
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-b36e0ca6cd4a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_losses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_losses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_acc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_quant\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m120\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'models\\\\densenet_quantized.pt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\OneDrive\\Documents\\IMT\\FISE_A2\\UE_Implementations_optimisées\\Micronet_Challenge\\util.py\u001b[0m in \u001b[0;36mtraining\u001b[1;34m(train_loader, valid_loader, model, criterion, optimizer, n_epochs, scheduler, filename)\u001b[0m\n\u001b[0;32m     23\u001b[0m             \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# clear the gradients of all optimized variables\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# forward pass: compute predicted outputs by passing inputs to the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# calculate the loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# backward pass: compute gradient of the loss with respect to model parameters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\Documents\\IMT\\FISE_A2\\UE_Implementations_optimisées\\Micronet_Challenge\\Densenet.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    158\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrans2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdense2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrans3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdense3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 160\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdense4\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    161\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mavg_pool2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    115\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\Documents\\IMT\\FISE_A2\\UE_Implementations_optimisées\\Micronet_Challenge\\Densenet.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbn2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\Documents\\IMT\\FISE_A2\\UE_Implementations_optimisées\\Micronet_Challenge\\util.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    550\u001b[0m             \u001b[0mweight_q\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight_quant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m         \u001b[1;32melse\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 552\u001b[1;33m             \u001b[0mweight_q\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight_quant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    553\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mact_alq\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mact_alpha\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m         return F.conv2d(x, weight_q, self.bias, self.stride,\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\Documents\\IMT\\FISE_A2\\UE_Implementations_optimisées\\Micronet_Challenge\\util.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, weight, mask, mask_flag)\u001b[0m\n\u001b[0;32m    481\u001b[0m             \u001b[0mwei\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    482\u001b[0m             \u001b[0mmean\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwei\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mwei\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mas_tuple\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 483\u001b[1;33m             \u001b[0mstd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwei\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mwei\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mas_tuple\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    484\u001b[0m             \u001b[1;31m#print(x[x.nonzero(as_tuple=True)].mean())\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    485\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_losses, valid_losses, train_acc, valid_acc = training(trainloader, validloader, model_quant, criterion, optimizer,120,scheduler,'models\\\\densenet_quantized.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TPxEUqUMgeBC"
   },
   "source": [
    "Ou loader un modèle déjà existant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e_7pAZEDgeBC",
    "outputId": "1c6606c3-3955-48a1-d9b3-a742195ddedf",
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for DenseNet_Quant:\n\tMissing key(s) in state_dict: \"dense1.0.conv1.act_alpha\", \"dense1.0.conv1.weight_quant.wgt_alpha\", \"dense1.0.conv2.act_alpha\", \"dense1.0.conv2.weight_quant.wgt_alpha\", \"dense1.1.conv1.act_alpha\", \"dense1.1.conv1.weight_quant.wgt_alpha\", \"dense1.1.conv2.act_alpha\", \"dense1.1.conv2.weight_quant.wgt_alpha\", \"dense1.2.conv1.act_alpha\", \"dense1.2.conv1.weight_quant.wgt_alpha\", \"dense1.2.conv2.act_alpha\", \"dense1.2.conv2.weight_quant.wgt_alpha\", \"dense1.3.conv1.act_alpha\", \"dense1.3.conv1.weight_quant.wgt_alpha\", \"dense1.3.conv2.act_alpha\", \"dense1.3.conv2.weight_quant.wgt_alpha\", \"dense1.4.conv1.act_alpha\", \"dense1.4.conv1.weight_quant.wgt_alpha\", \"dense1.4.conv2.act_alpha\", \"dense1.4.conv2.weight_quant.wgt_alpha\", \"dense1.5.conv1.act_alpha\", \"dense1.5.conv1.weight_quant.wgt_alpha\", \"dense1.5.conv2.act_alpha\", \"dense1.5.conv2.weight_quant.wgt_alpha\", \"trans1.conv.act_alpha\", \"trans1.conv.weight_quant.wgt_alpha\", \"dense2.0.conv1.act_alpha\", \"dense2.0.conv1.weight_quant.wgt_alpha\", \"dense2.0.conv2.act_alpha\", \"dense2.0.conv2.weight_quant.wgt_alpha\", \"dense2.1.conv1.act_alpha\", \"dense2.1.conv1.weight_quant.wgt_alpha\", \"dense2.1.conv2.act_alpha\", \"dense2.1.conv2.weight_quant.wgt_alpha\", \"dense2.2.conv1.act_alpha\", \"dense2.2.conv1.weight_quant.wgt_alpha\", \"dense2.2.conv2.act_alpha\", \"dense2.2.conv2.weight_quant.wgt_alpha\", \"dense2.3.conv1.act_alpha\", \"dense2.3.conv1.weight_quant.wgt_alpha\", \"dense2.3.conv2.act_alpha\", \"dense2.3.conv2.weight_quant.wgt_alpha\", \"dense2.4.conv1.act_alpha\", \"dense2.4.conv1.weight_quant.wgt_alpha\", \"dense2.4.conv2.act_alpha\", \"dense2.4.conv2.weight_quant.wgt_alpha\", \"dense2.5.conv1.act_alpha\", \"dense2.5.conv1.weight_quant.wgt_alpha\", \"dense2.5.conv2.act_alpha\", \"dense2.5.conv2.weight_quant.wgt_alpha\", \"dense2.6.conv1.act_alpha\", \"dense2.6.conv1.weight_quant.wgt_alpha\", \"dense2.6.conv2.act_alpha\", \"dense2.6.conv2.weight_quant.wgt_alpha\", \"dense2.7.conv1.act_alpha\", \"dense2.7.conv1.weight_quant.wgt_alpha\", \"dense2.7.conv2.act_alpha\", \"dense2.7.conv2.weight_quant.wgt_alpha\", \"dense2.8.conv1.act_alpha\", \"dense2.8.conv1.weight_quant.wgt_alpha\", \"dense2.8.conv2.act_alpha\", \"dense2.8.conv2.weight_quant.wgt_alpha\", \"dense2.9.conv1.act_alpha\", \"dense2.9.conv1.weight_quant.wgt_alpha\", \"dense2.9.conv2.act_alpha\", \"dense2.9.conv2.weight_quant.wgt_alpha\", \"dense2.10.conv1.act_alpha\", \"dense2.10.conv1.weight_quant.wgt_alpha\", \"dense2.10.conv2.act_alpha\", \"dense2.10.conv2.weight_quant.wgt_alpha\", \"dense2.11.conv1.act_alpha\", \"dense2.11.conv1.weight_quant.wgt_alpha\", \"dense2.11.conv2.act_alpha\", \"dense2.11.conv2.weight_quant.wgt_alpha\", \"trans2.conv.act_alpha\", \"trans2.conv.weight_quant.wgt_alpha\", \"dense3.0.conv1.act_alpha\", \"dense3.0.conv1.weight_quant.wgt_alpha\", \"dense3.0.conv2.act_alpha\", \"dense3.0.conv2.weight_quant.wgt_alpha\", \"dense3.1.conv1.act_alpha\", \"dense3.1.conv1.weight_quant.wgt_alpha\", \"dense3.1.conv2.act_alpha\", \"dense3.1.conv2.weight_quant.wgt_alpha\", \"dense3.2.conv1.act_alpha\", \"dense3.2.conv1.weight_quant.wgt_alpha\", \"dense3.2.conv2.act_alpha\", \"dense3.2.conv2.weight_quant.wgt_alpha\", \"dense3.3.conv1.act_alpha\", \"dense3.3.conv1.weight_quant.wgt_alpha\", \"dense3.3.conv2.act_alpha\", \"dense3.3.conv2.weight_quant.wgt_alpha\", \"dense3.4.conv1.act_alpha\", \"dense3.4.conv1.weight_quant.wgt_alpha\", \"dense3.4.conv2.act_alpha\", \"dense3.4.conv2.weight_quant.wgt_alpha\", \"dense3.5.conv1.act_alpha\", \"dense3.5.conv1.weight_quant.wgt_alpha\", \"dense3.5.conv2.act_alpha\", \"dense3.5.conv2.weight_quant.wgt_alpha\", \"dense3.6.conv1.act_alpha\", \"dense3.6.conv1.weight_quant.wgt_alpha\", \"dense3.6.conv2.act_alpha\", \"dense3.6.conv2.weight_quant.wgt_alpha\", \"dense3.7.conv1.act_alpha\", \"dense3.7.conv1.weight_quant.wgt_alpha\", \"dense3.7.conv2.act_alpha\", \"dense3.7.conv2.weight_quant.wgt_alpha\", \"dense3.8.conv1.act_alpha\", \"dense3.8.conv1.weight_quant.wgt_alpha\", \"dense3.8.conv2.act_alpha\", \"dense3.8.conv2.weight_quant.wgt_alpha\", \"dense3.9.conv1.act_alpha\", \"dense3.9.conv1.weight_quant.wgt_alpha\", \"dense3.9.conv2.act_alpha\", \"dense3.9.conv2.weight_quant.wgt_alpha\", \"dense3.10.conv1.act_alpha\", \"dense3.10.conv1.weight_quant.wgt_alpha\", \"dense3.10.conv2.act_alpha\", \"dense3.10.conv2.weight_quant.wgt_alpha\", \"dense3.11.conv1.act_alpha\", \"dense3.11.conv1.weight_quant.wgt_alpha\", \"dense3.11.conv2.act_alpha\", \"dense3.11.conv2.weight_quant.wgt_alpha\", \"dense3.12.conv1.act_alpha\", \"dense3.12.conv1.weight_quant.wgt_alpha\", \"dense3.12.conv2.act_alpha\", \"dense3.12.conv2.weight_quant.wgt_alpha\", \"dense3.13.conv1.act_alpha\", \"dense3.13.conv1.weight_quant.wgt_alpha\", \"dense3.13.conv2.act_alpha\", \"dense3.13.conv2.weight_quant.wgt_alpha\", \"dense3.14.conv1.act_alpha\", \"dense3.14.conv1.weight_quant.wgt_alpha\", \"dense3.14.conv2.act_alpha\", \"dense3.14.conv2.weight_quant.wgt_alpha\", \"dense3.15.conv1.act_alpha\", \"dense3.15.conv1.weight_quant.wgt_alpha\", \"dense3.15.conv2.act_alpha\", \"dense3.15.conv2.weight_quant.wgt_alpha\", \"dense3.16.conv1.act_alpha\", \"dense3.16.conv1.weight_quant.wgt_alpha\", \"dense3.16.conv2.act_alpha\", \"dense3.16.conv2.weight_quant.wgt_alpha\", \"dense3.17.conv1.act_alpha\", \"dense3.17.conv1.weight_quant.wgt_alpha\", \"dense3.17.conv2.act_alpha\", \"dense3.17.conv2.weight_quant.wgt_alpha\", \"dense3.18.conv1.act_alpha\", \"dense3.18.conv1.weight_quant.wgt_alpha\", \"dense3.18.conv2.act_alpha\", \"dense3.18.conv2.weight_quant.wgt_alpha\", \"dense3.19.conv1.act_alpha\", \"dense3.19.conv1.weight_quant.wgt_alpha\", \"dense3.19.conv2.act_alpha\", \"dense3.19.conv2.weight_quant.wgt_alpha\", \"dense3.20.conv1.act_alpha\", \"dense3.20.conv1.weight_quant.wgt_alpha\", \"dense3.20.conv2.act_alpha\", \"dense3.20.conv2.weight_quant.wgt_alpha\", \"dense3.21.conv1.act_alpha\", \"dense3.21.conv1.weight_quant.wgt_alpha\", \"dense3.21.conv2.act_alpha\", \"dense3.21.conv2.weight_quant.wgt_alpha\", \"dense3.22.conv1.act_alpha\", \"dense3.22.conv1.weight_quant.wgt_alpha\", \"dense3.22.conv2.act_alpha\", \"dense3.22.conv2.weight_quant.wgt_alpha\", \"dense3.23.conv1.act_alpha\", \"dense3.23.conv1.weight_quant.wgt_alpha\", \"dense3.23.conv2.act_alpha\", \"dense3.23.conv2.weight_quant.wgt_alpha\", \"trans3.conv.act_alpha\", \"trans3.conv.weight_quant.wgt_alpha\", \"dense4.0.conv1.act_alpha\", \"dense4.0.conv1.weight_quant.wgt_alpha\", \"dense4.0.conv2.act_alpha\", \"dense4.0.conv2.weight_quant.wgt_alpha\", \"dense4.1.conv1.act_alpha\", \"dense4.1.conv1.weight_quant.wgt_alpha\", \"dense4.1.conv2.act_alpha\", \"dense4.1.conv2.weight_quant.wgt_alpha\", \"dense4.2.conv1.act_alpha\", \"dense4.2.conv1.weight_quant.wgt_alpha\", \"dense4.2.conv2.act_alpha\", \"dense4.2.conv2.weight_quant.wgt_alpha\", \"dense4.3.conv1.act_alpha\", \"dense4.3.conv1.weight_quant.wgt_alpha\", \"dense4.3.conv2.act_alpha\", \"dense4.3.conv2.weight_quant.wgt_alpha\", \"dense4.4.conv1.act_alpha\", \"dense4.4.conv1.weight_quant.wgt_alpha\", \"dense4.4.conv2.act_alpha\", \"dense4.4.conv2.weight_quant.wgt_alpha\", \"dense4.5.conv1.act_alpha\", \"dense4.5.conv1.weight_quant.wgt_alpha\", \"dense4.5.conv2.act_alpha\", \"dense4.5.conv2.weight_quant.wgt_alpha\", \"dense4.6.conv1.act_alpha\", \"dense4.6.conv1.weight_quant.wgt_alpha\", \"dense4.6.conv2.act_alpha\", \"dense4.6.conv2.weight_quant.wgt_alpha\", \"dense4.7.conv1.act_alpha\", \"dense4.7.conv1.weight_quant.wgt_alpha\", \"dense4.7.conv2.act_alpha\", \"dense4.7.conv2.weight_quant.wgt_alpha\", \"dense4.8.conv1.act_alpha\", \"dense4.8.conv1.weight_quant.wgt_alpha\", \"dense4.8.conv2.act_alpha\", \"dense4.8.conv2.weight_quant.wgt_alpha\", \"dense4.9.conv1.act_alpha\", \"dense4.9.conv1.weight_quant.wgt_alpha\", \"dense4.9.conv2.act_alpha\", \"dense4.9.conv2.weight_quant.wgt_alpha\", \"dense4.10.conv1.act_alpha\", \"dense4.10.conv1.weight_quant.wgt_alpha\", \"dense4.10.conv2.act_alpha\", \"dense4.10.conv2.weight_quant.wgt_alpha\", \"dense4.11.conv1.act_alpha\", \"dense4.11.conv1.weight_quant.wgt_alpha\", \"dense4.11.conv2.act_alpha\", \"dense4.11.conv2.weight_quant.wgt_alpha\", \"dense4.12.conv1.act_alpha\", \"dense4.12.conv1.weight_quant.wgt_alpha\", \"dense4.12.conv2.act_alpha\", \"dense4.12.conv2.weight_quant.wgt_alpha\", \"dense4.13.conv1.act_alpha\", \"dense4.13.conv1.weight_quant.wgt_alpha\", \"dense4.13.conv2.act_alpha\", \"dense4.13.conv2.weight_quant.wgt_alpha\", \"dense4.14.conv1.act_alpha\", \"dense4.14.conv1.weight_quant.wgt_alpha\", \"dense4.14.conv2.act_alpha\", \"dense4.14.conv2.weight_quant.wgt_alpha\", \"dense4.15.conv1.act_alpha\", \"dense4.15.conv1.weight_quant.wgt_alpha\", \"dense4.15.conv2.act_alpha\", \"dense4.15.conv2.weight_quant.wgt_alpha\". \n\tsize mismatch for conv1.weight: copying a param with shape torch.Size([64, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([24, 3, 3, 3]).\n\tsize mismatch for dense1.0.bn1.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([24]).\n\tsize mismatch for dense1.0.bn1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([24]).\n\tsize mismatch for dense1.0.bn1.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([24]).\n\tsize mismatch for dense1.0.bn1.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([24]).\n\tsize mismatch for dense1.0.conv1.weight: copying a param with shape torch.Size([128, 64, 1, 1]) from checkpoint, the shape in current model is torch.Size([48, 24, 1, 1]).\n\tsize mismatch for dense1.0.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense1.0.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense1.0.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense1.0.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense1.0.conv2.weight: copying a param with shape torch.Size([32, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([12, 48, 3, 3]).\n\tsize mismatch for dense1.1.bn1.weight: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([36]).\n\tsize mismatch for dense1.1.bn1.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([36]).\n\tsize mismatch for dense1.1.bn1.running_mean: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([36]).\n\tsize mismatch for dense1.1.bn1.running_var: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([36]).\n\tsize mismatch for dense1.1.conv1.weight: copying a param with shape torch.Size([128, 96, 1, 1]) from checkpoint, the shape in current model is torch.Size([48, 36, 1, 1]).\n\tsize mismatch for dense1.1.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense1.1.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense1.1.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense1.1.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense1.1.conv2.weight: copying a param with shape torch.Size([32, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([12, 48, 3, 3]).\n\tsize mismatch for dense1.2.bn1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense1.2.bn1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense1.2.bn1.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense1.2.bn1.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense1.2.conv1.weight: copying a param with shape torch.Size([128, 128, 1, 1]) from checkpoint, the shape in current model is torch.Size([48, 48, 1, 1]).\n\tsize mismatch for dense1.2.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense1.2.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense1.2.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense1.2.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense1.2.conv2.weight: copying a param with shape torch.Size([32, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([12, 48, 3, 3]).\n\tsize mismatch for dense1.3.bn1.weight: copying a param with shape torch.Size([160]) from checkpoint, the shape in current model is torch.Size([60]).\n\tsize mismatch for dense1.3.bn1.bias: copying a param with shape torch.Size([160]) from checkpoint, the shape in current model is torch.Size([60]).\n\tsize mismatch for dense1.3.bn1.running_mean: copying a param with shape torch.Size([160]) from checkpoint, the shape in current model is torch.Size([60]).\n\tsize mismatch for dense1.3.bn1.running_var: copying a param with shape torch.Size([160]) from checkpoint, the shape in current model is torch.Size([60]).\n\tsize mismatch for dense1.3.conv1.weight: copying a param with shape torch.Size([128, 160, 1, 1]) from checkpoint, the shape in current model is torch.Size([48, 60, 1, 1]).\n\tsize mismatch for dense1.3.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense1.3.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense1.3.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense1.3.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense1.3.conv2.weight: copying a param with shape torch.Size([32, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([12, 48, 3, 3]).\n\tsize mismatch for dense1.4.bn1.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([72]).\n\tsize mismatch for dense1.4.bn1.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([72]).\n\tsize mismatch for dense1.4.bn1.running_mean: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([72]).\n\tsize mismatch for dense1.4.bn1.running_var: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([72]).\n\tsize mismatch for dense1.4.conv1.weight: copying a param with shape torch.Size([128, 192, 1, 1]) from checkpoint, the shape in current model is torch.Size([48, 72, 1, 1]).\n\tsize mismatch for dense1.4.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense1.4.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense1.4.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense1.4.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense1.4.conv2.weight: copying a param with shape torch.Size([32, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([12, 48, 3, 3]).\n\tsize mismatch for dense1.5.bn1.weight: copying a param with shape torch.Size([224]) from checkpoint, the shape in current model is torch.Size([84]).\n\tsize mismatch for dense1.5.bn1.bias: copying a param with shape torch.Size([224]) from checkpoint, the shape in current model is torch.Size([84]).\n\tsize mismatch for dense1.5.bn1.running_mean: copying a param with shape torch.Size([224]) from checkpoint, the shape in current model is torch.Size([84]).\n\tsize mismatch for dense1.5.bn1.running_var: copying a param with shape torch.Size([224]) from checkpoint, the shape in current model is torch.Size([84]).\n\tsize mismatch for dense1.5.conv1.weight: copying a param with shape torch.Size([128, 224, 1, 1]) from checkpoint, the shape in current model is torch.Size([48, 84, 1, 1]).\n\tsize mismatch for dense1.5.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense1.5.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense1.5.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense1.5.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense1.5.conv2.weight: copying a param with shape torch.Size([32, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([12, 48, 3, 3]).\n\tsize mismatch for trans1.bn.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([96]).\n\tsize mismatch for trans1.bn.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([96]).\n\tsize mismatch for trans1.bn.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([96]).\n\tsize mismatch for trans1.bn.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([96]).\n\tsize mismatch for trans1.conv.weight: copying a param with shape torch.Size([128, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([48, 96, 1, 1]).\n\tsize mismatch for dense2.0.bn1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense2.0.bn1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense2.0.bn1.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense2.0.bn1.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense2.0.conv1.weight: copying a param with shape torch.Size([128, 128, 1, 1]) from checkpoint, the shape in current model is torch.Size([48, 48, 1, 1]).\n\tsize mismatch for dense2.0.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense2.0.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense2.0.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense2.0.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense2.0.conv2.weight: copying a param with shape torch.Size([32, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([12, 48, 3, 3]).\n\tsize mismatch for dense2.1.bn1.weight: copying a param with shape torch.Size([160]) from checkpoint, the shape in current model is torch.Size([60]).\n\tsize mismatch for dense2.1.bn1.bias: copying a param with shape torch.Size([160]) from checkpoint, the shape in current model is torch.Size([60]).\n\tsize mismatch for dense2.1.bn1.running_mean: copying a param with shape torch.Size([160]) from checkpoint, the shape in current model is torch.Size([60]).\n\tsize mismatch for dense2.1.bn1.running_var: copying a param with shape torch.Size([160]) from checkpoint, the shape in current model is torch.Size([60]).\n\tsize mismatch for dense2.1.conv1.weight: copying a param with shape torch.Size([128, 160, 1, 1]) from checkpoint, the shape in current model is torch.Size([48, 60, 1, 1]).\n\tsize mismatch for dense2.1.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense2.1.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense2.1.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense2.1.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense2.1.conv2.weight: copying a param with shape torch.Size([32, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([12, 48, 3, 3]).\n\tsize mismatch for dense2.2.bn1.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([72]).\n\tsize mismatch for dense2.2.bn1.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([72]).\n\tsize mismatch for dense2.2.bn1.running_mean: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([72]).\n\tsize mismatch for dense2.2.bn1.running_var: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([72]).\n\tsize mismatch for dense2.2.conv1.weight: copying a param with shape torch.Size([128, 192, 1, 1]) from checkpoint, the shape in current model is torch.Size([48, 72, 1, 1]).\n\tsize mismatch for dense2.2.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense2.2.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense2.2.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense2.2.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense2.2.conv2.weight: copying a param with shape torch.Size([32, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([12, 48, 3, 3]).\n\tsize mismatch for dense2.3.bn1.weight: copying a param with shape torch.Size([224]) from checkpoint, the shape in current model is torch.Size([84]).\n\tsize mismatch for dense2.3.bn1.bias: copying a param with shape torch.Size([224]) from checkpoint, the shape in current model is torch.Size([84]).\n\tsize mismatch for dense2.3.bn1.running_mean: copying a param with shape torch.Size([224]) from checkpoint, the shape in current model is torch.Size([84]).\n\tsize mismatch for dense2.3.bn1.running_var: copying a param with shape torch.Size([224]) from checkpoint, the shape in current model is torch.Size([84]).\n\tsize mismatch for dense2.3.conv1.weight: copying a param with shape torch.Size([128, 224, 1, 1]) from checkpoint, the shape in current model is torch.Size([48, 84, 1, 1]).\n\tsize mismatch for dense2.3.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense2.3.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense2.3.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense2.3.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense2.3.conv2.weight: copying a param with shape torch.Size([32, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([12, 48, 3, 3]).\n\tsize mismatch for dense2.4.bn1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([96]).\n\tsize mismatch for dense2.4.bn1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([96]).\n\tsize mismatch for dense2.4.bn1.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([96]).\n\tsize mismatch for dense2.4.bn1.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([96]).\n\tsize mismatch for dense2.4.conv1.weight: copying a param with shape torch.Size([128, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([48, 96, 1, 1]).\n\tsize mismatch for dense2.4.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense2.4.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense2.4.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense2.4.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense2.4.conv2.weight: copying a param with shape torch.Size([32, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([12, 48, 3, 3]).\n\tsize mismatch for dense2.5.bn1.weight: copying a param with shape torch.Size([288]) from checkpoint, the shape in current model is torch.Size([108]).\n\tsize mismatch for dense2.5.bn1.bias: copying a param with shape torch.Size([288]) from checkpoint, the shape in current model is torch.Size([108]).\n\tsize mismatch for dense2.5.bn1.running_mean: copying a param with shape torch.Size([288]) from checkpoint, the shape in current model is torch.Size([108]).\n\tsize mismatch for dense2.5.bn1.running_var: copying a param with shape torch.Size([288]) from checkpoint, the shape in current model is torch.Size([108]).\n\tsize mismatch for dense2.5.conv1.weight: copying a param with shape torch.Size([128, 288, 1, 1]) from checkpoint, the shape in current model is torch.Size([48, 108, 1, 1]).\n\tsize mismatch for dense2.5.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense2.5.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense2.5.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense2.5.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense2.5.conv2.weight: copying a param with shape torch.Size([32, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([12, 48, 3, 3]).\n\tsize mismatch for dense2.6.bn1.weight: copying a param with shape torch.Size([320]) from checkpoint, the shape in current model is torch.Size([120]).\n\tsize mismatch for dense2.6.bn1.bias: copying a param with shape torch.Size([320]) from checkpoint, the shape in current model is torch.Size([120]).\n\tsize mismatch for dense2.6.bn1.running_mean: copying a param with shape torch.Size([320]) from checkpoint, the shape in current model is torch.Size([120]).\n\tsize mismatch for dense2.6.bn1.running_var: copying a param with shape torch.Size([320]) from checkpoint, the shape in current model is torch.Size([120]).\n\tsize mismatch for dense2.6.conv1.weight: copying a param with shape torch.Size([128, 320, 1, 1]) from checkpoint, the shape in current model is torch.Size([48, 120, 1, 1]).\n\tsize mismatch for dense2.6.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense2.6.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense2.6.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense2.6.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense2.6.conv2.weight: copying a param with shape torch.Size([32, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([12, 48, 3, 3]).\n\tsize mismatch for dense2.7.bn1.weight: copying a param with shape torch.Size([352]) from checkpoint, the shape in current model is torch.Size([132]).\n\tsize mismatch for dense2.7.bn1.bias: copying a param with shape torch.Size([352]) from checkpoint, the shape in current model is torch.Size([132]).\n\tsize mismatch for dense2.7.bn1.running_mean: copying a param with shape torch.Size([352]) from checkpoint, the shape in current model is torch.Size([132]).\n\tsize mismatch for dense2.7.bn1.running_var: copying a param with shape torch.Size([352]) from checkpoint, the shape in current model is torch.Size([132]).\n\tsize mismatch for dense2.7.conv1.weight: copying a param with shape torch.Size([128, 352, 1, 1]) from checkpoint, the shape in current model is torch.Size([48, 132, 1, 1]).\n\tsize mismatch for dense2.7.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense2.7.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense2.7.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense2.7.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense2.7.conv2.weight: copying a param with shape torch.Size([32, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([12, 48, 3, 3]).\n\tsize mismatch for dense2.8.bn1.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([144]).\n\tsize mismatch for dense2.8.bn1.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([144]).\n\tsize mismatch for dense2.8.bn1.running_mean: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([144]).\n\tsize mismatch for dense2.8.bn1.running_var: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([144]).\n\tsize mismatch for dense2.8.conv1.weight: copying a param with shape torch.Size([128, 384, 1, 1]) from checkpoint, the shape in current model is torch.Size([48, 144, 1, 1]).\n\tsize mismatch for dense2.8.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense2.8.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense2.8.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense2.8.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense2.8.conv2.weight: copying a param with shape torch.Size([32, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([12, 48, 3, 3]).\n\tsize mismatch for dense2.9.bn1.weight: copying a param with shape torch.Size([416]) from checkpoint, the shape in current model is torch.Size([156]).\n\tsize mismatch for dense2.9.bn1.bias: copying a param with shape torch.Size([416]) from checkpoint, the shape in current model is torch.Size([156]).\n\tsize mismatch for dense2.9.bn1.running_mean: copying a param with shape torch.Size([416]) from checkpoint, the shape in current model is torch.Size([156]).\n\tsize mismatch for dense2.9.bn1.running_var: copying a param with shape torch.Size([416]) from checkpoint, the shape in current model is torch.Size([156]).\n\tsize mismatch for dense2.9.conv1.weight: copying a param with shape torch.Size([128, 416, 1, 1]) from checkpoint, the shape in current model is torch.Size([48, 156, 1, 1]).\n\tsize mismatch for dense2.9.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense2.9.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense2.9.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense2.9.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense2.9.conv2.weight: copying a param with shape torch.Size([32, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([12, 48, 3, 3]).\n\tsize mismatch for dense2.10.bn1.weight: copying a param with shape torch.Size([448]) from checkpoint, the shape in current model is torch.Size([168]).\n\tsize mismatch for dense2.10.bn1.bias: copying a param with shape torch.Size([448]) from checkpoint, the shape in current model is torch.Size([168]).\n\tsize mismatch for dense2.10.bn1.running_mean: copying a param with shape torch.Size([448]) from checkpoint, the shape in current model is torch.Size([168]).\n\tsize mismatch for dense2.10.bn1.running_var: copying a param with shape torch.Size([448]) from checkpoint, the shape in current model is torch.Size([168]).\n\tsize mismatch for dense2.10.conv1.weight: copying a param with shape torch.Size([128, 448, 1, 1]) from checkpoint, the shape in current model is torch.Size([48, 168, 1, 1]).\n\tsize mismatch for dense2.10.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense2.10.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense2.10.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense2.10.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense2.10.conv2.weight: copying a param with shape torch.Size([32, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([12, 48, 3, 3]).\n\tsize mismatch for dense2.11.bn1.weight: copying a param with shape torch.Size([480]) from checkpoint, the shape in current model is torch.Size([180]).\n\tsize mismatch for dense2.11.bn1.bias: copying a param with shape torch.Size([480]) from checkpoint, the shape in current model is torch.Size([180]).\n\tsize mismatch for dense2.11.bn1.running_mean: copying a param with shape torch.Size([480]) from checkpoint, the shape in current model is torch.Size([180]).\n\tsize mismatch for dense2.11.bn1.running_var: copying a param with shape torch.Size([480]) from checkpoint, the shape in current model is torch.Size([180]).\n\tsize mismatch for dense2.11.conv1.weight: copying a param with shape torch.Size([128, 480, 1, 1]) from checkpoint, the shape in current model is torch.Size([48, 180, 1, 1]).\n\tsize mismatch for dense2.11.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense2.11.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense2.11.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense2.11.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense2.11.conv2.weight: copying a param with shape torch.Size([32, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([12, 48, 3, 3]).\n\tsize mismatch for trans2.bn.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for trans2.bn.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for trans2.bn.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for trans2.bn.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for trans2.conv.weight: copying a param with shape torch.Size([256, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([96, 192, 1, 1]).\n\tsize mismatch for dense3.0.bn1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([96]).\n\tsize mismatch for dense3.0.bn1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([96]).\n\tsize mismatch for dense3.0.bn1.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([96]).\n\tsize mismatch for dense3.0.bn1.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([96]).\n\tsize mismatch for dense3.0.conv1.weight: copying a param with shape torch.Size([128, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([48, 96, 1, 1]).\n\tsize mismatch for dense3.0.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.0.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.0.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.0.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.0.conv2.weight: copying a param with shape torch.Size([32, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([12, 48, 3, 3]).\n\tsize mismatch for dense3.1.bn1.weight: copying a param with shape torch.Size([288]) from checkpoint, the shape in current model is torch.Size([108]).\n\tsize mismatch for dense3.1.bn1.bias: copying a param with shape torch.Size([288]) from checkpoint, the shape in current model is torch.Size([108]).\n\tsize mismatch for dense3.1.bn1.running_mean: copying a param with shape torch.Size([288]) from checkpoint, the shape in current model is torch.Size([108]).\n\tsize mismatch for dense3.1.bn1.running_var: copying a param with shape torch.Size([288]) from checkpoint, the shape in current model is torch.Size([108]).\n\tsize mismatch for dense3.1.conv1.weight: copying a param with shape torch.Size([128, 288, 1, 1]) from checkpoint, the shape in current model is torch.Size([48, 108, 1, 1]).\n\tsize mismatch for dense3.1.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.1.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.1.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.1.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.1.conv2.weight: copying a param with shape torch.Size([32, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([12, 48, 3, 3]).\n\tsize mismatch for dense3.2.bn1.weight: copying a param with shape torch.Size([320]) from checkpoint, the shape in current model is torch.Size([120]).\n\tsize mismatch for dense3.2.bn1.bias: copying a param with shape torch.Size([320]) from checkpoint, the shape in current model is torch.Size([120]).\n\tsize mismatch for dense3.2.bn1.running_mean: copying a param with shape torch.Size([320]) from checkpoint, the shape in current model is torch.Size([120]).\n\tsize mismatch for dense3.2.bn1.running_var: copying a param with shape torch.Size([320]) from checkpoint, the shape in current model is torch.Size([120]).\n\tsize mismatch for dense3.2.conv1.weight: copying a param with shape torch.Size([128, 320, 1, 1]) from checkpoint, the shape in current model is torch.Size([48, 120, 1, 1]).\n\tsize mismatch for dense3.2.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.2.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.2.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.2.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.2.conv2.weight: copying a param with shape torch.Size([32, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([12, 48, 3, 3]).\n\tsize mismatch for dense3.3.bn1.weight: copying a param with shape torch.Size([352]) from checkpoint, the shape in current model is torch.Size([132]).\n\tsize mismatch for dense3.3.bn1.bias: copying a param with shape torch.Size([352]) from checkpoint, the shape in current model is torch.Size([132]).\n\tsize mismatch for dense3.3.bn1.running_mean: copying a param with shape torch.Size([352]) from checkpoint, the shape in current model is torch.Size([132]).\n\tsize mismatch for dense3.3.bn1.running_var: copying a param with shape torch.Size([352]) from checkpoint, the shape in current model is torch.Size([132]).\n\tsize mismatch for dense3.3.conv1.weight: copying a param with shape torch.Size([128, 352, 1, 1]) from checkpoint, the shape in current model is torch.Size([48, 132, 1, 1]).\n\tsize mismatch for dense3.3.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.3.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.3.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.3.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.3.conv2.weight: copying a param with shape torch.Size([32, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([12, 48, 3, 3]).\n\tsize mismatch for dense3.4.bn1.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([144]).\n\tsize mismatch for dense3.4.bn1.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([144]).\n\tsize mismatch for dense3.4.bn1.running_mean: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([144]).\n\tsize mismatch for dense3.4.bn1.running_var: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([144]).\n\tsize mismatch for dense3.4.conv1.weight: copying a param with shape torch.Size([128, 384, 1, 1]) from checkpoint, the shape in current model is torch.Size([48, 144, 1, 1]).\n\tsize mismatch for dense3.4.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.4.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.4.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.4.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.4.conv2.weight: copying a param with shape torch.Size([32, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([12, 48, 3, 3]).\n\tsize mismatch for dense3.5.bn1.weight: copying a param with shape torch.Size([416]) from checkpoint, the shape in current model is torch.Size([156]).\n\tsize mismatch for dense3.5.bn1.bias: copying a param with shape torch.Size([416]) from checkpoint, the shape in current model is torch.Size([156]).\n\tsize mismatch for dense3.5.bn1.running_mean: copying a param with shape torch.Size([416]) from checkpoint, the shape in current model is torch.Size([156]).\n\tsize mismatch for dense3.5.bn1.running_var: copying a param with shape torch.Size([416]) from checkpoint, the shape in current model is torch.Size([156]).\n\tsize mismatch for dense3.5.conv1.weight: copying a param with shape torch.Size([128, 416, 1, 1]) from checkpoint, the shape in current model is torch.Size([48, 156, 1, 1]).\n\tsize mismatch for dense3.5.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.5.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.5.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.5.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.5.conv2.weight: copying a param with shape torch.Size([32, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([12, 48, 3, 3]).\n\tsize mismatch for dense3.6.bn1.weight: copying a param with shape torch.Size([448]) from checkpoint, the shape in current model is torch.Size([168]).\n\tsize mismatch for dense3.6.bn1.bias: copying a param with shape torch.Size([448]) from checkpoint, the shape in current model is torch.Size([168]).\n\tsize mismatch for dense3.6.bn1.running_mean: copying a param with shape torch.Size([448]) from checkpoint, the shape in current model is torch.Size([168]).\n\tsize mismatch for dense3.6.bn1.running_var: copying a param with shape torch.Size([448]) from checkpoint, the shape in current model is torch.Size([168]).\n\tsize mismatch for dense3.6.conv1.weight: copying a param with shape torch.Size([128, 448, 1, 1]) from checkpoint, the shape in current model is torch.Size([48, 168, 1, 1]).\n\tsize mismatch for dense3.6.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.6.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.6.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.6.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.6.conv2.weight: copying a param with shape torch.Size([32, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([12, 48, 3, 3]).\n\tsize mismatch for dense3.7.bn1.weight: copying a param with shape torch.Size([480]) from checkpoint, the shape in current model is torch.Size([180]).\n\tsize mismatch for dense3.7.bn1.bias: copying a param with shape torch.Size([480]) from checkpoint, the shape in current model is torch.Size([180]).\n\tsize mismatch for dense3.7.bn1.running_mean: copying a param with shape torch.Size([480]) from checkpoint, the shape in current model is torch.Size([180]).\n\tsize mismatch for dense3.7.bn1.running_var: copying a param with shape torch.Size([480]) from checkpoint, the shape in current model is torch.Size([180]).\n\tsize mismatch for dense3.7.conv1.weight: copying a param with shape torch.Size([128, 480, 1, 1]) from checkpoint, the shape in current model is torch.Size([48, 180, 1, 1]).\n\tsize mismatch for dense3.7.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.7.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.7.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.7.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.7.conv2.weight: copying a param with shape torch.Size([32, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([12, 48, 3, 3]).\n\tsize mismatch for dense3.8.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for dense3.8.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for dense3.8.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for dense3.8.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for dense3.8.conv1.weight: copying a param with shape torch.Size([128, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([48, 192, 1, 1]).\n\tsize mismatch for dense3.8.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.8.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.8.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.8.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.8.conv2.weight: copying a param with shape torch.Size([32, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([12, 48, 3, 3]).\n\tsize mismatch for dense3.9.bn1.weight: copying a param with shape torch.Size([544]) from checkpoint, the shape in current model is torch.Size([204]).\n\tsize mismatch for dense3.9.bn1.bias: copying a param with shape torch.Size([544]) from checkpoint, the shape in current model is torch.Size([204]).\n\tsize mismatch for dense3.9.bn1.running_mean: copying a param with shape torch.Size([544]) from checkpoint, the shape in current model is torch.Size([204]).\n\tsize mismatch for dense3.9.bn1.running_var: copying a param with shape torch.Size([544]) from checkpoint, the shape in current model is torch.Size([204]).\n\tsize mismatch for dense3.9.conv1.weight: copying a param with shape torch.Size([128, 544, 1, 1]) from checkpoint, the shape in current model is torch.Size([48, 204, 1, 1]).\n\tsize mismatch for dense3.9.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.9.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.9.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.9.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.9.conv2.weight: copying a param with shape torch.Size([32, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([12, 48, 3, 3]).\n\tsize mismatch for dense3.10.bn1.weight: copying a param with shape torch.Size([576]) from checkpoint, the shape in current model is torch.Size([216]).\n\tsize mismatch for dense3.10.bn1.bias: copying a param with shape torch.Size([576]) from checkpoint, the shape in current model is torch.Size([216]).\n\tsize mismatch for dense3.10.bn1.running_mean: copying a param with shape torch.Size([576]) from checkpoint, the shape in current model is torch.Size([216]).\n\tsize mismatch for dense3.10.bn1.running_var: copying a param with shape torch.Size([576]) from checkpoint, the shape in current model is torch.Size([216]).\n\tsize mismatch for dense3.10.conv1.weight: copying a param with shape torch.Size([128, 576, 1, 1]) from checkpoint, the shape in current model is torch.Size([48, 216, 1, 1]).\n\tsize mismatch for dense3.10.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.10.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.10.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.10.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.10.conv2.weight: copying a param with shape torch.Size([32, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([12, 48, 3, 3]).\n\tsize mismatch for dense3.11.bn1.weight: copying a param with shape torch.Size([608]) from checkpoint, the shape in current model is torch.Size([228]).\n\tsize mismatch for dense3.11.bn1.bias: copying a param with shape torch.Size([608]) from checkpoint, the shape in current model is torch.Size([228]).\n\tsize mismatch for dense3.11.bn1.running_mean: copying a param with shape torch.Size([608]) from checkpoint, the shape in current model is torch.Size([228]).\n\tsize mismatch for dense3.11.bn1.running_var: copying a param with shape torch.Size([608]) from checkpoint, the shape in current model is torch.Size([228]).\n\tsize mismatch for dense3.11.conv1.weight: copying a param with shape torch.Size([128, 608, 1, 1]) from checkpoint, the shape in current model is torch.Size([48, 228, 1, 1]).\n\tsize mismatch for dense3.11.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.11.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.11.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.11.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.11.conv2.weight: copying a param with shape torch.Size([32, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([12, 48, 3, 3]).\n\tsize mismatch for dense3.12.bn1.weight: copying a param with shape torch.Size([640]) from checkpoint, the shape in current model is torch.Size([240]).\n\tsize mismatch for dense3.12.bn1.bias: copying a param with shape torch.Size([640]) from checkpoint, the shape in current model is torch.Size([240]).\n\tsize mismatch for dense3.12.bn1.running_mean: copying a param with shape torch.Size([640]) from checkpoint, the shape in current model is torch.Size([240]).\n\tsize mismatch for dense3.12.bn1.running_var: copying a param with shape torch.Size([640]) from checkpoint, the shape in current model is torch.Size([240]).\n\tsize mismatch for dense3.12.conv1.weight: copying a param with shape torch.Size([128, 640, 1, 1]) from checkpoint, the shape in current model is torch.Size([48, 240, 1, 1]).\n\tsize mismatch for dense3.12.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.12.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.12.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.12.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.12.conv2.weight: copying a param with shape torch.Size([32, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([12, 48, 3, 3]).\n\tsize mismatch for dense3.13.bn1.weight: copying a param with shape torch.Size([672]) from checkpoint, the shape in current model is torch.Size([252]).\n\tsize mismatch for dense3.13.bn1.bias: copying a param with shape torch.Size([672]) from checkpoint, the shape in current model is torch.Size([252]).\n\tsize mismatch for dense3.13.bn1.running_mean: copying a param with shape torch.Size([672]) from checkpoint, the shape in current model is torch.Size([252]).\n\tsize mismatch for dense3.13.bn1.running_var: copying a param with shape torch.Size([672]) from checkpoint, the shape in current model is torch.Size([252]).\n\tsize mismatch for dense3.13.conv1.weight: copying a param with shape torch.Size([128, 672, 1, 1]) from checkpoint, the shape in current model is torch.Size([48, 252, 1, 1]).\n\tsize mismatch for dense3.13.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.13.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.13.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.13.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.13.conv2.weight: copying a param with shape torch.Size([32, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([12, 48, 3, 3]).\n\tsize mismatch for dense3.14.bn1.weight: copying a param with shape torch.Size([704]) from checkpoint, the shape in current model is torch.Size([264]).\n\tsize mismatch for dense3.14.bn1.bias: copying a param with shape torch.Size([704]) from checkpoint, the shape in current model is torch.Size([264]).\n\tsize mismatch for dense3.14.bn1.running_mean: copying a param with shape torch.Size([704]) from checkpoint, the shape in current model is torch.Size([264]).\n\tsize mismatch for dense3.14.bn1.running_var: copying a param with shape torch.Size([704]) from checkpoint, the shape in current model is torch.Size([264]).\n\tsize mismatch for dense3.14.conv1.weight: copying a param with shape torch.Size([128, 704, 1, 1]) from checkpoint, the shape in current model is torch.Size([48, 264, 1, 1]).\n\tsize mismatch for dense3.14.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.14.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.14.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.14.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.14.conv2.weight: copying a param with shape torch.Size([32, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([12, 48, 3, 3]).\n\tsize mismatch for dense3.15.bn1.weight: copying a param with shape torch.Size([736]) from checkpoint, the shape in current model is torch.Size([276]).\n\tsize mismatch for dense3.15.bn1.bias: copying a param with shape torch.Size([736]) from checkpoint, the shape in current model is torch.Size([276]).\n\tsize mismatch for dense3.15.bn1.running_mean: copying a param with shape torch.Size([736]) from checkpoint, the shape in current model is torch.Size([276]).\n\tsize mismatch for dense3.15.bn1.running_var: copying a param with shape torch.Size([736]) from checkpoint, the shape in current model is torch.Size([276]).\n\tsize mismatch for dense3.15.conv1.weight: copying a param with shape torch.Size([128, 736, 1, 1]) from checkpoint, the shape in current model is torch.Size([48, 276, 1, 1]).\n\tsize mismatch for dense3.15.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.15.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.15.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.15.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.15.conv2.weight: copying a param with shape torch.Size([32, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([12, 48, 3, 3]).\n\tsize mismatch for dense3.16.bn1.weight: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([288]).\n\tsize mismatch for dense3.16.bn1.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([288]).\n\tsize mismatch for dense3.16.bn1.running_mean: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([288]).\n\tsize mismatch for dense3.16.bn1.running_var: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([288]).\n\tsize mismatch for dense3.16.conv1.weight: copying a param with shape torch.Size([128, 768, 1, 1]) from checkpoint, the shape in current model is torch.Size([48, 288, 1, 1]).\n\tsize mismatch for dense3.16.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.16.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.16.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.16.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.16.conv2.weight: copying a param with shape torch.Size([32, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([12, 48, 3, 3]).\n\tsize mismatch for dense3.17.bn1.weight: copying a param with shape torch.Size([800]) from checkpoint, the shape in current model is torch.Size([300]).\n\tsize mismatch for dense3.17.bn1.bias: copying a param with shape torch.Size([800]) from checkpoint, the shape in current model is torch.Size([300]).\n\tsize mismatch for dense3.17.bn1.running_mean: copying a param with shape torch.Size([800]) from checkpoint, the shape in current model is torch.Size([300]).\n\tsize mismatch for dense3.17.bn1.running_var: copying a param with shape torch.Size([800]) from checkpoint, the shape in current model is torch.Size([300]).\n\tsize mismatch for dense3.17.conv1.weight: copying a param with shape torch.Size([128, 800, 1, 1]) from checkpoint, the shape in current model is torch.Size([48, 300, 1, 1]).\n\tsize mismatch for dense3.17.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.17.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.17.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.17.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.17.conv2.weight: copying a param with shape torch.Size([32, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([12, 48, 3, 3]).\n\tsize mismatch for dense3.18.bn1.weight: copying a param with shape torch.Size([832]) from checkpoint, the shape in current model is torch.Size([312]).\n\tsize mismatch for dense3.18.bn1.bias: copying a param with shape torch.Size([832]) from checkpoint, the shape in current model is torch.Size([312]).\n\tsize mismatch for dense3.18.bn1.running_mean: copying a param with shape torch.Size([832]) from checkpoint, the shape in current model is torch.Size([312]).\n\tsize mismatch for dense3.18.bn1.running_var: copying a param with shape torch.Size([832]) from checkpoint, the shape in current model is torch.Size([312]).\n\tsize mismatch for dense3.18.conv1.weight: copying a param with shape torch.Size([128, 832, 1, 1]) from checkpoint, the shape in current model is torch.Size([48, 312, 1, 1]).\n\tsize mismatch for dense3.18.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.18.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.18.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.18.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.18.conv2.weight: copying a param with shape torch.Size([32, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([12, 48, 3, 3]).\n\tsize mismatch for dense3.19.bn1.weight: copying a param with shape torch.Size([864]) from checkpoint, the shape in current model is torch.Size([324]).\n\tsize mismatch for dense3.19.bn1.bias: copying a param with shape torch.Size([864]) from checkpoint, the shape in current model is torch.Size([324]).\n\tsize mismatch for dense3.19.bn1.running_mean: copying a param with shape torch.Size([864]) from checkpoint, the shape in current model is torch.Size([324]).\n\tsize mismatch for dense3.19.bn1.running_var: copying a param with shape torch.Size([864]) from checkpoint, the shape in current model is torch.Size([324]).\n\tsize mismatch for dense3.19.conv1.weight: copying a param with shape torch.Size([128, 864, 1, 1]) from checkpoint, the shape in current model is torch.Size([48, 324, 1, 1]).\n\tsize mismatch for dense3.19.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.19.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.19.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.19.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.19.conv2.weight: copying a param with shape torch.Size([32, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([12, 48, 3, 3]).\n\tsize mismatch for dense3.20.bn1.weight: copying a param with shape torch.Size([896]) from checkpoint, the shape in current model is torch.Size([336]).\n\tsize mismatch for dense3.20.bn1.bias: copying a param with shape torch.Size([896]) from checkpoint, the shape in current model is torch.Size([336]).\n\tsize mismatch for dense3.20.bn1.running_mean: copying a param with shape torch.Size([896]) from checkpoint, the shape in current model is torch.Size([336]).\n\tsize mismatch for dense3.20.bn1.running_var: copying a param with shape torch.Size([896]) from checkpoint, the shape in current model is torch.Size([336]).\n\tsize mismatch for dense3.20.conv1.weight: copying a param with shape torch.Size([128, 896, 1, 1]) from checkpoint, the shape in current model is torch.Size([48, 336, 1, 1]).\n\tsize mismatch for dense3.20.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.20.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.20.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.20.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.20.conv2.weight: copying a param with shape torch.Size([32, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([12, 48, 3, 3]).\n\tsize mismatch for dense3.21.bn1.weight: copying a param with shape torch.Size([928]) from checkpoint, the shape in current model is torch.Size([348]).\n\tsize mismatch for dense3.21.bn1.bias: copying a param with shape torch.Size([928]) from checkpoint, the shape in current model is torch.Size([348]).\n\tsize mismatch for dense3.21.bn1.running_mean: copying a param with shape torch.Size([928]) from checkpoint, the shape in current model is torch.Size([348]).\n\tsize mismatch for dense3.21.bn1.running_var: copying a param with shape torch.Size([928]) from checkpoint, the shape in current model is torch.Size([348]).\n\tsize mismatch for dense3.21.conv1.weight: copying a param with shape torch.Size([128, 928, 1, 1]) from checkpoint, the shape in current model is torch.Size([48, 348, 1, 1]).\n\tsize mismatch for dense3.21.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.21.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.21.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.21.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.21.conv2.weight: copying a param with shape torch.Size([32, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([12, 48, 3, 3]).\n\tsize mismatch for dense3.22.bn1.weight: copying a param with shape torch.Size([960]) from checkpoint, the shape in current model is torch.Size([360]).\n\tsize mismatch for dense3.22.bn1.bias: copying a param with shape torch.Size([960]) from checkpoint, the shape in current model is torch.Size([360]).\n\tsize mismatch for dense3.22.bn1.running_mean: copying a param with shape torch.Size([960]) from checkpoint, the shape in current model is torch.Size([360]).\n\tsize mismatch for dense3.22.bn1.running_var: copying a param with shape torch.Size([960]) from checkpoint, the shape in current model is torch.Size([360]).\n\tsize mismatch for dense3.22.conv1.weight: copying a param with shape torch.Size([128, 960, 1, 1]) from checkpoint, the shape in current model is torch.Size([48, 360, 1, 1]).\n\tsize mismatch for dense3.22.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.22.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.22.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.22.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.22.conv2.weight: copying a param with shape torch.Size([32, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([12, 48, 3, 3]).\n\tsize mismatch for dense3.23.bn1.weight: copying a param with shape torch.Size([992]) from checkpoint, the shape in current model is torch.Size([372]).\n\tsize mismatch for dense3.23.bn1.bias: copying a param with shape torch.Size([992]) from checkpoint, the shape in current model is torch.Size([372]).\n\tsize mismatch for dense3.23.bn1.running_mean: copying a param with shape torch.Size([992]) from checkpoint, the shape in current model is torch.Size([372]).\n\tsize mismatch for dense3.23.bn1.running_var: copying a param with shape torch.Size([992]) from checkpoint, the shape in current model is torch.Size([372]).\n\tsize mismatch for dense3.23.conv1.weight: copying a param with shape torch.Size([128, 992, 1, 1]) from checkpoint, the shape in current model is torch.Size([48, 372, 1, 1]).\n\tsize mismatch for dense3.23.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.23.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.23.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.23.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.23.conv2.weight: copying a param with shape torch.Size([32, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([12, 48, 3, 3]).\n\tsize mismatch for trans3.bn.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for trans3.bn.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for trans3.bn.running_mean: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for trans3.bn.running_var: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for trans3.conv.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([192, 384, 1, 1]).\n\tsize mismatch for dense4.0.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for dense4.0.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for dense4.0.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for dense4.0.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for dense4.0.conv1.weight: copying a param with shape torch.Size([128, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([48, 192, 1, 1]).\n\tsize mismatch for dense4.0.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense4.0.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense4.0.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense4.0.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense4.0.conv2.weight: copying a param with shape torch.Size([32, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([12, 48, 3, 3]).\n\tsize mismatch for dense4.1.bn1.weight: copying a param with shape torch.Size([544]) from checkpoint, the shape in current model is torch.Size([204]).\n\tsize mismatch for dense4.1.bn1.bias: copying a param with shape torch.Size([544]) from checkpoint, the shape in current model is torch.Size([204]).\n\tsize mismatch for dense4.1.bn1.running_mean: copying a param with shape torch.Size([544]) from checkpoint, the shape in current model is torch.Size([204]).\n\tsize mismatch for dense4.1.bn1.running_var: copying a param with shape torch.Size([544]) from checkpoint, the shape in current model is torch.Size([204]).\n\tsize mismatch for dense4.1.conv1.weight: copying a param with shape torch.Size([128, 544, 1, 1]) from checkpoint, the shape in current model is torch.Size([48, 204, 1, 1]).\n\tsize mismatch for dense4.1.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense4.1.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense4.1.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense4.1.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense4.1.conv2.weight: copying a param with shape torch.Size([32, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([12, 48, 3, 3]).\n\tsize mismatch for dense4.2.bn1.weight: copying a param with shape torch.Size([576]) from checkpoint, the shape in current model is torch.Size([216]).\n\tsize mismatch for dense4.2.bn1.bias: copying a param with shape torch.Size([576]) from checkpoint, the shape in current model is torch.Size([216]).\n\tsize mismatch for dense4.2.bn1.running_mean: copying a param with shape torch.Size([576]) from checkpoint, the shape in current model is torch.Size([216]).\n\tsize mismatch for dense4.2.bn1.running_var: copying a param with shape torch.Size([576]) from checkpoint, the shape in current model is torch.Size([216]).\n\tsize mismatch for dense4.2.conv1.weight: copying a param with shape torch.Size([128, 576, 1, 1]) from checkpoint, the shape in current model is torch.Size([48, 216, 1, 1]).\n\tsize mismatch for dense4.2.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense4.2.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense4.2.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense4.2.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense4.2.conv2.weight: copying a param with shape torch.Size([32, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([12, 48, 3, 3]).\n\tsize mismatch for dense4.3.bn1.weight: copying a param with shape torch.Size([608]) from checkpoint, the shape in current model is torch.Size([228]).\n\tsize mismatch for dense4.3.bn1.bias: copying a param with shape torch.Size([608]) from checkpoint, the shape in current model is torch.Size([228]).\n\tsize mismatch for dense4.3.bn1.running_mean: copying a param with shape torch.Size([608]) from checkpoint, the shape in current model is torch.Size([228]).\n\tsize mismatch for dense4.3.bn1.running_var: copying a param with shape torch.Size([608]) from checkpoint, the shape in current model is torch.Size([228]).\n\tsize mismatch for dense4.3.conv1.weight: copying a param with shape torch.Size([128, 608, 1, 1]) from checkpoint, the shape in current model is torch.Size([48, 228, 1, 1]).\n\tsize mismatch for dense4.3.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense4.3.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense4.3.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense4.3.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense4.3.conv2.weight: copying a param with shape torch.Size([32, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([12, 48, 3, 3]).\n\tsize mismatch for dense4.4.bn1.weight: copying a param with shape torch.Size([640]) from checkpoint, the shape in current model is torch.Size([240]).\n\tsize mismatch for dense4.4.bn1.bias: copying a param with shape torch.Size([640]) from checkpoint, the shape in current model is torch.Size([240]).\n\tsize mismatch for dense4.4.bn1.running_mean: copying a param with shape torch.Size([640]) from checkpoint, the shape in current model is torch.Size([240]).\n\tsize mismatch for dense4.4.bn1.running_var: copying a param with shape torch.Size([640]) from checkpoint, the shape in current model is torch.Size([240]).\n\tsize mismatch for dense4.4.conv1.weight: copying a param with shape torch.Size([128, 640, 1, 1]) from checkpoint, the shape in current model is torch.Size([48, 240, 1, 1]).\n\tsize mismatch for dense4.4.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense4.4.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense4.4.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense4.4.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense4.4.conv2.weight: copying a param with shape torch.Size([32, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([12, 48, 3, 3]).\n\tsize mismatch for dense4.5.bn1.weight: copying a param with shape torch.Size([672]) from checkpoint, the shape in current model is torch.Size([252]).\n\tsize mismatch for dense4.5.bn1.bias: copying a param with shape torch.Size([672]) from checkpoint, the shape in current model is torch.Size([252]).\n\tsize mismatch for dense4.5.bn1.running_mean: copying a param with shape torch.Size([672]) from checkpoint, the shape in current model is torch.Size([252]).\n\tsize mismatch for dense4.5.bn1.running_var: copying a param with shape torch.Size([672]) from checkpoint, the shape in current model is torch.Size([252]).\n\tsize mismatch for dense4.5.conv1.weight: copying a param with shape torch.Size([128, 672, 1, 1]) from checkpoint, the shape in current model is torch.Size([48, 252, 1, 1]).\n\tsize mismatch for dense4.5.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense4.5.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense4.5.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense4.5.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense4.5.conv2.weight: copying a param with shape torch.Size([32, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([12, 48, 3, 3]).\n\tsize mismatch for dense4.6.bn1.weight: copying a param with shape torch.Size([704]) from checkpoint, the shape in current model is torch.Size([264]).\n\tsize mismatch for dense4.6.bn1.bias: copying a param with shape torch.Size([704]) from checkpoint, the shape in current model is torch.Size([264]).\n\tsize mismatch for dense4.6.bn1.running_mean: copying a param with shape torch.Size([704]) from checkpoint, the shape in current model is torch.Size([264]).\n\tsize mismatch for dense4.6.bn1.running_var: copying a param with shape torch.Size([704]) from checkpoint, the shape in current model is torch.Size([264]).\n\tsize mismatch for dense4.6.conv1.weight: copying a param with shape torch.Size([128, 704, 1, 1]) from checkpoint, the shape in current model is torch.Size([48, 264, 1, 1]).\n\tsize mismatch for dense4.6.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense4.6.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense4.6.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense4.6.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense4.6.conv2.weight: copying a param with shape torch.Size([32, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([12, 48, 3, 3]).\n\tsize mismatch for dense4.7.bn1.weight: copying a param with shape torch.Size([736]) from checkpoint, the shape in current model is torch.Size([276]).\n\tsize mismatch for dense4.7.bn1.bias: copying a param with shape torch.Size([736]) from checkpoint, the shape in current model is torch.Size([276]).\n\tsize mismatch for dense4.7.bn1.running_mean: copying a param with shape torch.Size([736]) from checkpoint, the shape in current model is torch.Size([276]).\n\tsize mismatch for dense4.7.bn1.running_var: copying a param with shape torch.Size([736]) from checkpoint, the shape in current model is torch.Size([276]).\n\tsize mismatch for dense4.7.conv1.weight: copying a param with shape torch.Size([128, 736, 1, 1]) from checkpoint, the shape in current model is torch.Size([48, 276, 1, 1]).\n\tsize mismatch for dense4.7.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense4.7.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense4.7.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense4.7.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense4.7.conv2.weight: copying a param with shape torch.Size([32, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([12, 48, 3, 3]).\n\tsize mismatch for dense4.8.bn1.weight: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([288]).\n\tsize mismatch for dense4.8.bn1.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([288]).\n\tsize mismatch for dense4.8.bn1.running_mean: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([288]).\n\tsize mismatch for dense4.8.bn1.running_var: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([288]).\n\tsize mismatch for dense4.8.conv1.weight: copying a param with shape torch.Size([128, 768, 1, 1]) from checkpoint, the shape in current model is torch.Size([48, 288, 1, 1]).\n\tsize mismatch for dense4.8.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense4.8.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense4.8.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense4.8.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense4.8.conv2.weight: copying a param with shape torch.Size([32, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([12, 48, 3, 3]).\n\tsize mismatch for dense4.9.bn1.weight: copying a param with shape torch.Size([800]) from checkpoint, the shape in current model is torch.Size([300]).\n\tsize mismatch for dense4.9.bn1.bias: copying a param with shape torch.Size([800]) from checkpoint, the shape in current model is torch.Size([300]).\n\tsize mismatch for dense4.9.bn1.running_mean: copying a param with shape torch.Size([800]) from checkpoint, the shape in current model is torch.Size([300]).\n\tsize mismatch for dense4.9.bn1.running_var: copying a param with shape torch.Size([800]) from checkpoint, the shape in current model is torch.Size([300]).\n\tsize mismatch for dense4.9.conv1.weight: copying a param with shape torch.Size([128, 800, 1, 1]) from checkpoint, the shape in current model is torch.Size([48, 300, 1, 1]).\n\tsize mismatch for dense4.9.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense4.9.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense4.9.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense4.9.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense4.9.conv2.weight: copying a param with shape torch.Size([32, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([12, 48, 3, 3]).\n\tsize mismatch for dense4.10.bn1.weight: copying a param with shape torch.Size([832]) from checkpoint, the shape in current model is torch.Size([312]).\n\tsize mismatch for dense4.10.bn1.bias: copying a param with shape torch.Size([832]) from checkpoint, the shape in current model is torch.Size([312]).\n\tsize mismatch for dense4.10.bn1.running_mean: copying a param with shape torch.Size([832]) from checkpoint, the shape in current model is torch.Size([312]).\n\tsize mismatch for dense4.10.bn1.running_var: copying a param with shape torch.Size([832]) from checkpoint, the shape in current model is torch.Size([312]).\n\tsize mismatch for dense4.10.conv1.weight: copying a param with shape torch.Size([128, 832, 1, 1]) from checkpoint, the shape in current model is torch.Size([48, 312, 1, 1]).\n\tsize mismatch for dense4.10.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense4.10.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense4.10.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense4.10.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense4.10.conv2.weight: copying a param with shape torch.Size([32, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([12, 48, 3, 3]).\n\tsize mismatch for dense4.11.bn1.weight: copying a param with shape torch.Size([864]) from checkpoint, the shape in current model is torch.Size([324]).\n\tsize mismatch for dense4.11.bn1.bias: copying a param with shape torch.Size([864]) from checkpoint, the shape in current model is torch.Size([324]).\n\tsize mismatch for dense4.11.bn1.running_mean: copying a param with shape torch.Size([864]) from checkpoint, the shape in current model is torch.Size([324]).\n\tsize mismatch for dense4.11.bn1.running_var: copying a param with shape torch.Size([864]) from checkpoint, the shape in current model is torch.Size([324]).\n\tsize mismatch for dense4.11.conv1.weight: copying a param with shape torch.Size([128, 864, 1, 1]) from checkpoint, the shape in current model is torch.Size([48, 324, 1, 1]).\n\tsize mismatch for dense4.11.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense4.11.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense4.11.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense4.11.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense4.11.conv2.weight: copying a param with shape torch.Size([32, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([12, 48, 3, 3]).\n\tsize mismatch for dense4.12.bn1.weight: copying a param with shape torch.Size([896]) from checkpoint, the shape in current model is torch.Size([336]).\n\tsize mismatch for dense4.12.bn1.bias: copying a param with shape torch.Size([896]) from checkpoint, the shape in current model is torch.Size([336]).\n\tsize mismatch for dense4.12.bn1.running_mean: copying a param with shape torch.Size([896]) from checkpoint, the shape in current model is torch.Size([336]).\n\tsize mismatch for dense4.12.bn1.running_var: copying a param with shape torch.Size([896]) from checkpoint, the shape in current model is torch.Size([336]).\n\tsize mismatch for dense4.12.conv1.weight: copying a param with shape torch.Size([128, 896, 1, 1]) from checkpoint, the shape in current model is torch.Size([48, 336, 1, 1]).\n\tsize mismatch for dense4.12.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense4.12.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense4.12.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense4.12.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense4.12.conv2.weight: copying a param with shape torch.Size([32, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([12, 48, 3, 3]).\n\tsize mismatch for dense4.13.bn1.weight: copying a param with shape torch.Size([928]) from checkpoint, the shape in current model is torch.Size([348]).\n\tsize mismatch for dense4.13.bn1.bias: copying a param with shape torch.Size([928]) from checkpoint, the shape in current model is torch.Size([348]).\n\tsize mismatch for dense4.13.bn1.running_mean: copying a param with shape torch.Size([928]) from checkpoint, the shape in current model is torch.Size([348]).\n\tsize mismatch for dense4.13.bn1.running_var: copying a param with shape torch.Size([928]) from checkpoint, the shape in current model is torch.Size([348]).\n\tsize mismatch for dense4.13.conv1.weight: copying a param with shape torch.Size([128, 928, 1, 1]) from checkpoint, the shape in current model is torch.Size([48, 348, 1, 1]).\n\tsize mismatch for dense4.13.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense4.13.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense4.13.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense4.13.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense4.13.conv2.weight: copying a param with shape torch.Size([32, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([12, 48, 3, 3]).\n\tsize mismatch for dense4.14.bn1.weight: copying a param with shape torch.Size([960]) from checkpoint, the shape in current model is torch.Size([360]).\n\tsize mismatch for dense4.14.bn1.bias: copying a param with shape torch.Size([960]) from checkpoint, the shape in current model is torch.Size([360]).\n\tsize mismatch for dense4.14.bn1.running_mean: copying a param with shape torch.Size([960]) from checkpoint, the shape in current model is torch.Size([360]).\n\tsize mismatch for dense4.14.bn1.running_var: copying a param with shape torch.Size([960]) from checkpoint, the shape in current model is torch.Size([360]).\n\tsize mismatch for dense4.14.conv1.weight: copying a param with shape torch.Size([128, 960, 1, 1]) from checkpoint, the shape in current model is torch.Size([48, 360, 1, 1]).\n\tsize mismatch for dense4.14.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense4.14.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense4.14.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense4.14.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense4.14.conv2.weight: copying a param with shape torch.Size([32, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([12, 48, 3, 3]).\n\tsize mismatch for dense4.15.bn1.weight: copying a param with shape torch.Size([992]) from checkpoint, the shape in current model is torch.Size([372]).\n\tsize mismatch for dense4.15.bn1.bias: copying a param with shape torch.Size([992]) from checkpoint, the shape in current model is torch.Size([372]).\n\tsize mismatch for dense4.15.bn1.running_mean: copying a param with shape torch.Size([992]) from checkpoint, the shape in current model is torch.Size([372]).\n\tsize mismatch for dense4.15.bn1.running_var: copying a param with shape torch.Size([992]) from checkpoint, the shape in current model is torch.Size([372]).\n\tsize mismatch for dense4.15.conv1.weight: copying a param with shape torch.Size([128, 992, 1, 1]) from checkpoint, the shape in current model is torch.Size([48, 372, 1, 1]).\n\tsize mismatch for dense4.15.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense4.15.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense4.15.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense4.15.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense4.15.conv2.weight: copying a param with shape torch.Size([32, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([12, 48, 3, 3]).\n\tsize mismatch for bn.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for bn.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for bn.running_mean: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for bn.running_var: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for linear.weight: copying a param with shape torch.Size([10, 1024]) from checkpoint, the shape in current model is torch.Size([10, 384]).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-b1876a2c1ea8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mloaded_cpt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'models\\\\model_121.pt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cpu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mmodel_quant\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloaded_cpt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[1;34m(self, state_dict, strict)\u001b[0m\n\u001b[0;32m   1043\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1044\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[1;32m-> 1045\u001b[1;33m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[0;32m   1046\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1047\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for DenseNet_Quant:\n\tMissing key(s) in state_dict: \"dense1.0.conv1.act_alpha\", \"dense1.0.conv1.weight_quant.wgt_alpha\", \"dense1.0.conv2.act_alpha\", \"dense1.0.conv2.weight_quant.wgt_alpha\", \"dense1.1.conv1.act_alpha\", \"dense1.1.conv1.weight_quant.wgt_alpha\", \"dense1.1.conv2.act_alpha\", \"dense1.1.conv2.weight_quant.wgt_alpha\", \"dense1.2.conv1.act_alpha\", \"dense1.2.conv1.weight_quant.wgt_alpha\", \"dense1.2.conv2.act_alpha\", \"dense1.2.conv2.weight_quant.wgt_alpha\", \"dense1.3.conv1.act_alpha\", \"dense1.3.conv1.weight_quant.wgt_alpha\", \"dense1.3.conv2.act_alpha\", \"dense1.3.conv2.weight_quant.wgt_alpha\", \"dense1.4.conv1.act_alpha\", \"dense1.4.conv1.weight_quant.wgt_alpha\", \"dense1.4.conv2.act_alpha\", \"dense1.4.conv2.weight_quant.wgt_alpha\", \"dense1.5.conv1.act_alpha\", \"dense1.5.conv1.weight_quant.wgt_alpha\", \"dense1.5.conv2.act_alpha\", \"dense1.5.conv2.weight_quant.wgt_alpha\", \"trans1.conv.act_alpha\", \"trans1.conv.weight_quant.wgt_alpha\", \"dense2.0.conv1.act_alpha\", \"dense2.0.conv1.weight_quant.wgt_alpha\", \"dense2.0.conv2.act_alpha\", \"dense2.0.conv2.weight_quant.wgt_alpha\", \"dense2.1.conv1.act_alpha\", \"dense2.1.conv1.weight_quant.wgt_alpha\", \"dense2.1.conv2.act_alpha\", \"dense2.1.conv2.weight_quant.wgt_alpha\", \"dense2.2.conv1.act_alpha\", \"dense2.2.conv1.weight_quant.wgt_alpha\", \"dense2.2.conv2.act_alpha\", \"dense2.2.conv2.weight_quant.wgt_alpha\", \"dense2.3.conv1.act_alpha\", \"dense2.3.conv1.weight_quant.wgt_alpha\", \"dense2.3.conv2.act_alpha\", \"dense2.3.conv2.weight_quant.wgt_alpha\", \"dense2.4.conv1.act_alpha\", \"dense2.4.conv1.weight_quant.wgt_alpha\", \"dense2.4.conv2.act_alpha\", \"dense2.4.conv2.weight_quant.wgt_alpha\", \"dense2.5.conv1.act_alpha\", \"dense2.5.conv1.weight_quant.wgt_alpha\", \"dense2.5.conv2.act_alpha\", \"dense2.5.conv2.weight_quant.wgt_alpha\", \"dense2.6.conv1.act_alpha\", \"dense2.6.conv1.weight_quant.wgt_alpha\", \"dense2.6.conv2.act_alpha\", \"dense2.6.conv2.weight_quant.wgt_alpha\", \"dense2.7.conv1.act_alpha\", \"dense2.7.conv1.weight_quant.wgt_alpha\", \"dense2.7.conv2.act_alpha\", \"dense2.7.conv2.weight_quant.wgt_alpha\", \"dense2.8.conv1.act_alpha\", \"dense2.8.conv1.weight_quant.wgt_alpha\", \"dense2.8.conv2.act_alpha\", \"dense2.8.conv2.weight_quant.wgt_alpha\", \"dense2.9.conv1.act_alpha\", \"dense2.9.conv1.weight_quant.wgt_alpha\", \"dense2.9.conv2.act_alpha\", \"dense2.9.conv2.weight_quant.wgt_alpha\", \"dense2.10.conv1.act_alpha\", \"dense2.10.conv1.weight_quant.wgt_alpha\", \"dense2.10.conv2.act_alpha\", \"dense2.10.conv2.weight_quant.wgt_alpha\", \"dense2.11.conv1.act_alpha\", \"dense2.11.conv1.weight_quant.wgt_alpha\", \"dense2.11.conv2.act_alpha\", \"dense2.11.conv2.weight_quant.wgt_alpha\", \"trans2.conv.act_alpha\", \"trans2.conv.weight_quant.wgt_alpha\", \"dense3.0.conv1.act_alpha\", \"dense3.0.conv1.weight_quant.wgt_alpha\", \"dense3.0.conv2.act_alpha\", \"dense3.0.conv2.weight_quant.wgt_alpha\", \"dense3.1.conv1.act_alpha\", \"dense3.1.conv1.weight_quant.wgt_alpha\", \"dense3.1.conv2.act_alpha\", \"dense3.1.conv2.weight_quant.wgt_alpha\", \"dense3.2.conv1.act_alpha\", \"dense3.2.conv1.weight_quant.wgt_alpha\", \"dense3.2.conv2.act_alpha\", \"dense3.2.conv2.weight_quant.wgt_alpha\", \"dense3.3.conv1.act_alpha\", \"dense3.3.conv1.weight_quant.wgt_alpha\", \"dense3.3.conv2.act_alpha\", \"dense3.3.conv2.weight_quant.wgt_alpha\", \"dense3.4.conv1.act_alpha\", \"dense3.4.conv1.weight_quant.wgt_alpha\", \"dense3.4.conv2.act_alpha\", \"dense3.4.conv2.weight_quant.wgt_alpha\", \"dense3.5.conv1.act_alpha\", \"dense3.5.conv1.weight_quant.wgt_alpha\", \"dense3.5.conv2.act_alpha\", \"dense3.5.conv2.weight_quant.wgt_alpha\", \"dense3.6.conv1.act_alpha\", \"dense3.6.conv1.weight_quant.wgt_alpha\", \"dense3.6.conv2.act_alpha\", \"dense3.6.conv2.weight_quant.wgt_alpha\", \"dense3.7.conv1.act_alpha\", \"dense3.7.conv1.weight_quant.wgt_alpha\", \"dense3.7.conv2.act_alpha\", \"dense3.7.conv2.weight_quant.wgt_alpha\", \"dense3.8.conv1.act_alpha\", \"dense3.8.conv1.weight_quant.wgt_alpha\", \"dense3.8.conv2.act_alpha\", \"dense3.8.conv2.weight_quant.wgt_alpha\", \"dense3.9.conv1.act_alpha\", \"dense3.9.conv1.weight_quant.wgt_alpha\", \"dense3.9.conv2.act_alpha\", \"dense3.9.conv2.weight_quant.wgt_alpha\", \"dense3.10.conv1.act_alpha\", \"dense3.10.conv1.weight_quant.wgt_alpha\", \"dense3.10.conv2.act_alpha\", \"dense3.10.conv2.weight_quant.wgt_alpha\", \"dense3.11.conv1.act_alpha\", \"dense3.11.conv1.weight_quant.wgt_alpha\", \"dense3.11.conv2.act_alpha\", \"dense3.11.conv2.weight_quant.wgt_alpha\", \"dense3.12.conv1.act_alpha\", \"dense3.12.conv1.weight_quant.wgt_alpha\", \"dense3.12.conv2.act_alpha\", \"dense3.12.conv2.weight_quant.wgt_alpha\", \"dense3.13.conv1.act_alpha\", \"dense3.13.conv1.weight_quant.wgt_alpha\", \"dense3.13.conv2.act_alpha\", \"dense3.13.conv2.weight_quant.wgt_alpha\", \"dense3.14.conv1.act_alpha\", \"dense3.14.conv1.weight_quant.wgt_alpha\", \"dense3.14.conv2.act_alpha\", \"dense3.14.conv2.weight_quant.wgt_alpha\", \"dense3.15.conv1.act_alpha\", \"dense3.15.conv1.weight_quant.wgt_alpha\", \"dense3.15.conv2.act_alpha\", \"dense3.15.conv2.weight_quant.wgt_alpha\", \"dense3.16.conv1.act_alpha\", \"dense3.16.conv1.weight_quant.wgt_alpha\", \"dense3.16.conv2.act_alpha\", \"dense3.16.conv2.weight_quant.wgt_alpha\", \"dense3.17.conv1.act_alpha\", \"dense3.17.conv1.weight_quant.wgt_alpha\", \"dense3.17.conv2.act_alpha\", \"dense3.17.conv2.weight_quant.wgt_alpha\", \"dense3.18.conv1.act_alpha\", \"dense3.18.conv1.weight_quant.wgt_alpha\", \"dense3.18.conv2.act_alpha\", \"dense3.18.conv2.weight_quant.wgt_alpha\", \"dense3.19.conv1.act_alpha\", \"dense3.19.conv1.weight_quant.wgt_alpha\", \"dense3.19.conv2.act_alpha\", \"dense3.19.conv2.weight_quant.wgt_alpha\", \"dense3.20.conv1.act_alpha\", \"dense3.20.conv1.weight_quant.wgt_alpha\", \"dense3.20.conv2.act_alpha\", \"dense3.20.conv2.weight_quant.wgt_alpha\", \"dense3.21.conv1.act_alpha\", \"dense3.21.conv1.weight_quant.wgt_alpha\", \"dense3.21.conv2.act_alpha\", \"dense3.21.conv2.weight_quant.wgt_alpha\", \"dense3.22.conv1.act_alpha\", \"dense3.22.conv1.weight_quant.wgt_alpha\", \"dense3.22.conv2.act_alpha\", \"dense3.22.conv2.weight_quant.wgt_alpha\", \"dense3.23.conv1.act_alpha\", \"dense3.23.conv1.weight_quant.wgt_alpha\", \"dense3.23.conv2.act_alpha\", \"dense3.23.conv2.weight_quant.wgt_alpha\", \"trans3.conv.act_alpha\", \"trans3.conv.weight_quant.wgt_alpha\", \"dense4.0.conv1.act_alpha\", \"dense4.0.conv1.weight_quant.wgt_alpha\", \"dense4.0.conv2.act_alpha\", \"dense4.0.conv2.weight_quant.wgt_alpha\", \"dense4.1.conv1.act_alpha\", \"dense4.1.conv1.weight_quant.wgt_alpha\", \"dense4.1.conv2.act_alpha\", \"dense4.1.conv2.weight_quant.wgt_alpha\", \"dense4.2.conv1.act_alpha\", \"dense4.2.conv1.weight_quant.wgt_alpha\", \"dense4.2.conv2.act_alpha\", \"dense4.2.conv2.weight_quant.wgt_alpha\", \"dense4.3.conv1.act_alpha\", \"dense4.3.conv1.weight_quant.wgt_alpha\", \"dense4.3.conv2.act_alpha\", \"dense4.3.conv2.weight_quant.wgt_alpha\", \"dense4.4.conv1.act_alpha\", \"dense4.4.conv1.weight_quant.wgt_alpha\", \"dense4.4.conv2.act_alpha\", \"dense4.4.conv2.weight_quant.wgt_alpha\", \"dense4.5.conv1.act_alpha\", \"dense4.5.conv1.weight_quant.wgt_alpha\", \"dense4.5.conv2.act_alpha\", \"dense4.5.conv2.weight_quant.wgt_alpha\", \"dense4.6.conv1.act_alpha\", \"dense4.6.conv1.weight_quant.wgt_alpha\", \"dense4.6.conv2.act_alpha\", \"dense4.6.conv2.weight_quant.wgt_alpha\", \"dense4.7.conv1.act_alpha\", \"dense4.7.conv1.weight_quant.wgt_alpha\", \"dense4.7.conv2.act_alpha\", \"dense4.7.conv2.weight_quant.wgt_alpha\", \"dense4.8.conv1.act_alpha\", \"dense4.8.conv1.weight_quant.wgt_alpha\", \"dense4.8.conv2.act_alpha\", \"dense4.8.conv2.weight_quant.wgt_alpha\", \"dense4.9.conv1.act_alpha\", \"dense4.9.conv1.weight_quant.wgt_alpha\", \"dense4.9.conv2.act_alpha\", \"dense4.9.conv2.weight_quant.wgt_alpha\", \"dense4.10.conv1.act_alpha\", \"dense4.10.conv1.weight_quant.wgt_alpha\", \"dense4.10.conv2.act_alpha\", \"dense4.10.conv2.weight_quant.wgt_alpha\", \"dense4.11.conv1.act_alpha\", \"dense4.11.conv1.weight_quant.wgt_alpha\", \"dense4.11.conv2.act_alpha\", \"dense4.11.conv2.weight_quant.wgt_alpha\", \"dense4.12.conv1.act_alpha\", \"dense4.12.conv1.weight_quant.wgt_alpha\", \"dense4.12.conv2.act_alpha\", \"dense4.12.conv2.weight_quant.wgt_alpha\", \"dense4.13.conv1.act_alpha\", \"dense4.13.conv1.weight_quant.wgt_alpha\", \"dense4.13.conv2.act_alpha\", \"dense4.13.conv2.weight_quant.wgt_alpha\", \"dense4.14.conv1.act_alpha\", \"dense4.14.conv1.weight_quant.wgt_alpha\", \"dense4.14.conv2.act_alpha\", \"dense4.14.conv2.weight_quant.wgt_alpha\", \"dense4.15.conv1.act_alpha\", \"dense4.15.conv1.weight_quant.wgt_alpha\", \"dense4.15.conv2.act_alpha\", \"dense4.15.conv2.weight_quant.wgt_alpha\". \n\tsize mismatch for conv1.weight: copying a param with shape torch.Size([64, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([24, 3, 3, 3]).\n\tsize mismatch for dense1.0.bn1.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([24]).\n\tsize mismatch for dense1.0.bn1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([24]).\n\tsize mismatch for dense1.0.bn1.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([24]).\n\tsize mismatch for dense1.0.bn1.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([24]).\n\tsize mismatch for dense1.0.conv1.weight: copying a param with shape torch.Size([128, 64, 1, 1]) from checkpoint, the shape in current model is torch.Size([48, 24, 1, 1]).\n\tsize mismatch for dense1.0.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense1.0.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense1.0.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense1.0.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense1.0.conv2.weight: copying a param with shape torch.Size([32, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([12, 48, 3, 3]).\n\tsize mismatch for dense1.1.bn1.weight: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([36]).\n\tsize mismatch for dense1.1.bn1.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([36]).\n\tsize mismatch for dense1.1.bn1.running_mean: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([36]).\n\tsize mismatch for dense1.1.bn1.running_var: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([36]).\n\tsize mismatch for dense1.1.conv1.weight: copying a param with shape torch.Size([128, 96, 1, 1]) from checkpoint, the shape in current model is torch.Size([48, 36, 1, 1]).\n\tsize mismatch for dense1.1.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense1.1.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense1.1.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense1.1.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense1.1.conv2.weight: copying a param with shape torch.Size([32, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([12, 48, 3, 3]).\n\tsize mismatch for dense1.2.bn1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense1.2.bn1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense1.2.bn1.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense1.2.bn1.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense1.2.conv1.weight: copying a param with shape torch.Size([128, 128, 1, 1]) from checkpoint, the shape in current model is torch.Size([48, 48, 1, 1]).\n\tsize mismatch for dense1.2.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense1.2.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense1.2.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense1.2.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense1.2.conv2.weight: copying a param with shape torch.Size([32, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([12, 48, 3, 3]).\n\tsize mismatch for dense1.3.bn1.weight: copying a param with shape torch.Size([160]) from checkpoint, the shape in current model is torch.Size([60]).\n\tsize mismatch for dense1.3.bn1.bias: copying a param with shape torch.Size([160]) from checkpoint, the shape in current model is torch.Size([60]).\n\tsize mismatch for dense1.3.bn1.running_mean: copying a param with shape torch.Size([160]) from checkpoint, the shape in current model is torch.Size([60]).\n\tsize mismatch for dense1.3.bn1.running_var: copying a param with shape torch.Size([160]) from checkpoint, the shape in current model is torch.Size([60]).\n\tsize mismatch for dense1.3.conv1.weight: copying a param with shape torch.Size([128, 160, 1, 1]) from checkpoint, the shape in current model is torch.Size([48, 60, 1, 1]).\n\tsize mismatch for dense1.3.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense1.3.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense1.3.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense1.3.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense1.3.conv2.weight: copying a param with shape torch.Size([32, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([12, 48, 3, 3]).\n\tsize mismatch for dense1.4.bn1.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([72]).\n\tsize mismatch for dense1.4.bn1.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([72]).\n\tsize mismatch for dense1.4.bn1.running_mean: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([72]).\n\tsize mismatch for dense1.4.bn1.running_var: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([72]).\n\tsize mismatch for dense1.4.conv1.weight: copying a param with shape torch.Size([128, 192, 1, 1]) from checkpoint, the shape in current model is torch.Size([48, 72, 1, 1]).\n\tsize mismatch for dense1.4.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense1.4.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense1.4.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense1.4.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense1.4.conv2.weight: copying a param with shape torch.Size([32, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([12, 48, 3, 3]).\n\tsize mismatch for dense1.5.bn1.weight: copying a param with shape torch.Size([224]) from checkpoint, the shape in current model is torch.Size([84]).\n\tsize mismatch for dense1.5.bn1.bias: copying a param with shape torch.Size([224]) from checkpoint, the shape in current model is torch.Size([84]).\n\tsize mismatch for dense1.5.bn1.running_mean: copying a param with shape torch.Size([224]) from checkpoint, the shape in current model is torch.Size([84]).\n\tsize mismatch for dense1.5.bn1.running_var: copying a param with shape torch.Size([224]) from checkpoint, the shape in current model is torch.Size([84]).\n\tsize mismatch for dense1.5.conv1.weight: copying a param with shape torch.Size([128, 224, 1, 1]) from checkpoint, the shape in current model is torch.Size([48, 84, 1, 1]).\n\tsize mismatch for dense1.5.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense1.5.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense1.5.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense1.5.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense1.5.conv2.weight: copying a param with shape torch.Size([32, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([12, 48, 3, 3]).\n\tsize mismatch for trans1.bn.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([96]).\n\tsize mismatch for trans1.bn.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([96]).\n\tsize mismatch for trans1.bn.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([96]).\n\tsize mismatch for trans1.bn.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([96]).\n\tsize mismatch for trans1.conv.weight: copying a param with shape torch.Size([128, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([48, 96, 1, 1]).\n\tsize mismatch for dense2.0.bn1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense2.0.bn1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense2.0.bn1.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense2.0.bn1.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense2.0.conv1.weight: copying a param with shape torch.Size([128, 128, 1, 1]) from checkpoint, the shape in current model is torch.Size([48, 48, 1, 1]).\n\tsize mismatch for dense2.0.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense2.0.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense2.0.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense2.0.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense2.0.conv2.weight: copying a param with shape torch.Size([32, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([12, 48, 3, 3]).\n\tsize mismatch for dense2.1.bn1.weight: copying a param with shape torch.Size([160]) from checkpoint, the shape in current model is torch.Size([60]).\n\tsize mismatch for dense2.1.bn1.bias: copying a param with shape torch.Size([160]) from checkpoint, the shape in current model is torch.Size([60]).\n\tsize mismatch for dense2.1.bn1.running_mean: copying a param with shape torch.Size([160]) from checkpoint, the shape in current model is torch.Size([60]).\n\tsize mismatch for dense2.1.bn1.running_var: copying a param with shape torch.Size([160]) from checkpoint, the shape in current model is torch.Size([60]).\n\tsize mismatch for dense2.1.conv1.weight: copying a param with shape torch.Size([128, 160, 1, 1]) from checkpoint, the shape in current model is torch.Size([48, 60, 1, 1]).\n\tsize mismatch for dense2.1.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense2.1.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense2.1.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense2.1.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense2.1.conv2.weight: copying a param with shape torch.Size([32, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([12, 48, 3, 3]).\n\tsize mismatch for dense2.2.bn1.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([72]).\n\tsize mismatch for dense2.2.bn1.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([72]).\n\tsize mismatch for dense2.2.bn1.running_mean: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([72]).\n\tsize mismatch for dense2.2.bn1.running_var: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([72]).\n\tsize mismatch for dense2.2.conv1.weight: copying a param with shape torch.Size([128, 192, 1, 1]) from checkpoint, the shape in current model is torch.Size([48, 72, 1, 1]).\n\tsize mismatch for dense2.2.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense2.2.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense2.2.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense2.2.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense2.2.conv2.weight: copying a param with shape torch.Size([32, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([12, 48, 3, 3]).\n\tsize mismatch for dense2.3.bn1.weight: copying a param with shape torch.Size([224]) from checkpoint, the shape in current model is torch.Size([84]).\n\tsize mismatch for dense2.3.bn1.bias: copying a param with shape torch.Size([224]) from checkpoint, the shape in current model is torch.Size([84]).\n\tsize mismatch for dense2.3.bn1.running_mean: copying a param with shape torch.Size([224]) from checkpoint, the shape in current model is torch.Size([84]).\n\tsize mismatch for dense2.3.bn1.running_var: copying a param with shape torch.Size([224]) from checkpoint, the shape in current model is torch.Size([84]).\n\tsize mismatch for dense2.3.conv1.weight: copying a param with shape torch.Size([128, 224, 1, 1]) from checkpoint, the shape in current model is torch.Size([48, 84, 1, 1]).\n\tsize mismatch for dense2.3.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense2.3.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense2.3.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense2.3.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense2.3.conv2.weight: copying a param with shape torch.Size([32, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([12, 48, 3, 3]).\n\tsize mismatch for dense2.4.bn1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([96]).\n\tsize mismatch for dense2.4.bn1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([96]).\n\tsize mismatch for dense2.4.bn1.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([96]).\n\tsize mismatch for dense2.4.bn1.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([96]).\n\tsize mismatch for dense2.4.conv1.weight: copying a param with shape torch.Size([128, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([48, 96, 1, 1]).\n\tsize mismatch for dense2.4.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense2.4.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense2.4.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense2.4.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense2.4.conv2.weight: copying a param with shape torch.Size([32, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([12, 48, 3, 3]).\n\tsize mismatch for dense2.5.bn1.weight: copying a param with shape torch.Size([288]) from checkpoint, the shape in current model is torch.Size([108]).\n\tsize mismatch for dense2.5.bn1.bias: copying a param with shape torch.Size([288]) from checkpoint, the shape in current model is torch.Size([108]).\n\tsize mismatch for dense2.5.bn1.running_mean: copying a param with shape torch.Size([288]) from checkpoint, the shape in current model is torch.Size([108]).\n\tsize mismatch for dense2.5.bn1.running_var: copying a param with shape torch.Size([288]) from checkpoint, the shape in current model is torch.Size([108]).\n\tsize mismatch for dense2.5.conv1.weight: copying a param with shape torch.Size([128, 288, 1, 1]) from checkpoint, the shape in current model is torch.Size([48, 108, 1, 1]).\n\tsize mismatch for dense2.5.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense2.5.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense2.5.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense2.5.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense2.5.conv2.weight: copying a param with shape torch.Size([32, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([12, 48, 3, 3]).\n\tsize mismatch for dense2.6.bn1.weight: copying a param with shape torch.Size([320]) from checkpoint, the shape in current model is torch.Size([120]).\n\tsize mismatch for dense2.6.bn1.bias: copying a param with shape torch.Size([320]) from checkpoint, the shape in current model is torch.Size([120]).\n\tsize mismatch for dense2.6.bn1.running_mean: copying a param with shape torch.Size([320]) from checkpoint, the shape in current model is torch.Size([120]).\n\tsize mismatch for dense2.6.bn1.running_var: copying a param with shape torch.Size([320]) from checkpoint, the shape in current model is torch.Size([120]).\n\tsize mismatch for dense2.6.conv1.weight: copying a param with shape torch.Size([128, 320, 1, 1]) from checkpoint, the shape in current model is torch.Size([48, 120, 1, 1]).\n\tsize mismatch for dense2.6.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense2.6.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense2.6.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense2.6.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense2.6.conv2.weight: copying a param with shape torch.Size([32, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([12, 48, 3, 3]).\n\tsize mismatch for dense2.7.bn1.weight: copying a param with shape torch.Size([352]) from checkpoint, the shape in current model is torch.Size([132]).\n\tsize mismatch for dense2.7.bn1.bias: copying a param with shape torch.Size([352]) from checkpoint, the shape in current model is torch.Size([132]).\n\tsize mismatch for dense2.7.bn1.running_mean: copying a param with shape torch.Size([352]) from checkpoint, the shape in current model is torch.Size([132]).\n\tsize mismatch for dense2.7.bn1.running_var: copying a param with shape torch.Size([352]) from checkpoint, the shape in current model is torch.Size([132]).\n\tsize mismatch for dense2.7.conv1.weight: copying a param with shape torch.Size([128, 352, 1, 1]) from checkpoint, the shape in current model is torch.Size([48, 132, 1, 1]).\n\tsize mismatch for dense2.7.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense2.7.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense2.7.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense2.7.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense2.7.conv2.weight: copying a param with shape torch.Size([32, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([12, 48, 3, 3]).\n\tsize mismatch for dense2.8.bn1.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([144]).\n\tsize mismatch for dense2.8.bn1.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([144]).\n\tsize mismatch for dense2.8.bn1.running_mean: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([144]).\n\tsize mismatch for dense2.8.bn1.running_var: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([144]).\n\tsize mismatch for dense2.8.conv1.weight: copying a param with shape torch.Size([128, 384, 1, 1]) from checkpoint, the shape in current model is torch.Size([48, 144, 1, 1]).\n\tsize mismatch for dense2.8.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense2.8.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense2.8.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense2.8.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense2.8.conv2.weight: copying a param with shape torch.Size([32, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([12, 48, 3, 3]).\n\tsize mismatch for dense2.9.bn1.weight: copying a param with shape torch.Size([416]) from checkpoint, the shape in current model is torch.Size([156]).\n\tsize mismatch for dense2.9.bn1.bias: copying a param with shape torch.Size([416]) from checkpoint, the shape in current model is torch.Size([156]).\n\tsize mismatch for dense2.9.bn1.running_mean: copying a param with shape torch.Size([416]) from checkpoint, the shape in current model is torch.Size([156]).\n\tsize mismatch for dense2.9.bn1.running_var: copying a param with shape torch.Size([416]) from checkpoint, the shape in current model is torch.Size([156]).\n\tsize mismatch for dense2.9.conv1.weight: copying a param with shape torch.Size([128, 416, 1, 1]) from checkpoint, the shape in current model is torch.Size([48, 156, 1, 1]).\n\tsize mismatch for dense2.9.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense2.9.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense2.9.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense2.9.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense2.9.conv2.weight: copying a param with shape torch.Size([32, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([12, 48, 3, 3]).\n\tsize mismatch for dense2.10.bn1.weight: copying a param with shape torch.Size([448]) from checkpoint, the shape in current model is torch.Size([168]).\n\tsize mismatch for dense2.10.bn1.bias: copying a param with shape torch.Size([448]) from checkpoint, the shape in current model is torch.Size([168]).\n\tsize mismatch for dense2.10.bn1.running_mean: copying a param with shape torch.Size([448]) from checkpoint, the shape in current model is torch.Size([168]).\n\tsize mismatch for dense2.10.bn1.running_var: copying a param with shape torch.Size([448]) from checkpoint, the shape in current model is torch.Size([168]).\n\tsize mismatch for dense2.10.conv1.weight: copying a param with shape torch.Size([128, 448, 1, 1]) from checkpoint, the shape in current model is torch.Size([48, 168, 1, 1]).\n\tsize mismatch for dense2.10.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense2.10.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense2.10.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense2.10.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense2.10.conv2.weight: copying a param with shape torch.Size([32, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([12, 48, 3, 3]).\n\tsize mismatch for dense2.11.bn1.weight: copying a param with shape torch.Size([480]) from checkpoint, the shape in current model is torch.Size([180]).\n\tsize mismatch for dense2.11.bn1.bias: copying a param with shape torch.Size([480]) from checkpoint, the shape in current model is torch.Size([180]).\n\tsize mismatch for dense2.11.bn1.running_mean: copying a param with shape torch.Size([480]) from checkpoint, the shape in current model is torch.Size([180]).\n\tsize mismatch for dense2.11.bn1.running_var: copying a param with shape torch.Size([480]) from checkpoint, the shape in current model is torch.Size([180]).\n\tsize mismatch for dense2.11.conv1.weight: copying a param with shape torch.Size([128, 480, 1, 1]) from checkpoint, the shape in current model is torch.Size([48, 180, 1, 1]).\n\tsize mismatch for dense2.11.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense2.11.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense2.11.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense2.11.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense2.11.conv2.weight: copying a param with shape torch.Size([32, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([12, 48, 3, 3]).\n\tsize mismatch for trans2.bn.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for trans2.bn.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for trans2.bn.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for trans2.bn.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for trans2.conv.weight: copying a param with shape torch.Size([256, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([96, 192, 1, 1]).\n\tsize mismatch for dense3.0.bn1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([96]).\n\tsize mismatch for dense3.0.bn1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([96]).\n\tsize mismatch for dense3.0.bn1.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([96]).\n\tsize mismatch for dense3.0.bn1.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([96]).\n\tsize mismatch for dense3.0.conv1.weight: copying a param with shape torch.Size([128, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([48, 96, 1, 1]).\n\tsize mismatch for dense3.0.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.0.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.0.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.0.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.0.conv2.weight: copying a param with shape torch.Size([32, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([12, 48, 3, 3]).\n\tsize mismatch for dense3.1.bn1.weight: copying a param with shape torch.Size([288]) from checkpoint, the shape in current model is torch.Size([108]).\n\tsize mismatch for dense3.1.bn1.bias: copying a param with shape torch.Size([288]) from checkpoint, the shape in current model is torch.Size([108]).\n\tsize mismatch for dense3.1.bn1.running_mean: copying a param with shape torch.Size([288]) from checkpoint, the shape in current model is torch.Size([108]).\n\tsize mismatch for dense3.1.bn1.running_var: copying a param with shape torch.Size([288]) from checkpoint, the shape in current model is torch.Size([108]).\n\tsize mismatch for dense3.1.conv1.weight: copying a param with shape torch.Size([128, 288, 1, 1]) from checkpoint, the shape in current model is torch.Size([48, 108, 1, 1]).\n\tsize mismatch for dense3.1.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.1.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.1.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.1.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.1.conv2.weight: copying a param with shape torch.Size([32, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([12, 48, 3, 3]).\n\tsize mismatch for dense3.2.bn1.weight: copying a param with shape torch.Size([320]) from checkpoint, the shape in current model is torch.Size([120]).\n\tsize mismatch for dense3.2.bn1.bias: copying a param with shape torch.Size([320]) from checkpoint, the shape in current model is torch.Size([120]).\n\tsize mismatch for dense3.2.bn1.running_mean: copying a param with shape torch.Size([320]) from checkpoint, the shape in current model is torch.Size([120]).\n\tsize mismatch for dense3.2.bn1.running_var: copying a param with shape torch.Size([320]) from checkpoint, the shape in current model is torch.Size([120]).\n\tsize mismatch for dense3.2.conv1.weight: copying a param with shape torch.Size([128, 320, 1, 1]) from checkpoint, the shape in current model is torch.Size([48, 120, 1, 1]).\n\tsize mismatch for dense3.2.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.2.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.2.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.2.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.2.conv2.weight: copying a param with shape torch.Size([32, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([12, 48, 3, 3]).\n\tsize mismatch for dense3.3.bn1.weight: copying a param with shape torch.Size([352]) from checkpoint, the shape in current model is torch.Size([132]).\n\tsize mismatch for dense3.3.bn1.bias: copying a param with shape torch.Size([352]) from checkpoint, the shape in current model is torch.Size([132]).\n\tsize mismatch for dense3.3.bn1.running_mean: copying a param with shape torch.Size([352]) from checkpoint, the shape in current model is torch.Size([132]).\n\tsize mismatch for dense3.3.bn1.running_var: copying a param with shape torch.Size([352]) from checkpoint, the shape in current model is torch.Size([132]).\n\tsize mismatch for dense3.3.conv1.weight: copying a param with shape torch.Size([128, 352, 1, 1]) from checkpoint, the shape in current model is torch.Size([48, 132, 1, 1]).\n\tsize mismatch for dense3.3.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.3.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.3.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.3.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.3.conv2.weight: copying a param with shape torch.Size([32, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([12, 48, 3, 3]).\n\tsize mismatch for dense3.4.bn1.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([144]).\n\tsize mismatch for dense3.4.bn1.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([144]).\n\tsize mismatch for dense3.4.bn1.running_mean: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([144]).\n\tsize mismatch for dense3.4.bn1.running_var: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([144]).\n\tsize mismatch for dense3.4.conv1.weight: copying a param with shape torch.Size([128, 384, 1, 1]) from checkpoint, the shape in current model is torch.Size([48, 144, 1, 1]).\n\tsize mismatch for dense3.4.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.4.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.4.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.4.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.4.conv2.weight: copying a param with shape torch.Size([32, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([12, 48, 3, 3]).\n\tsize mismatch for dense3.5.bn1.weight: copying a param with shape torch.Size([416]) from checkpoint, the shape in current model is torch.Size([156]).\n\tsize mismatch for dense3.5.bn1.bias: copying a param with shape torch.Size([416]) from checkpoint, the shape in current model is torch.Size([156]).\n\tsize mismatch for dense3.5.bn1.running_mean: copying a param with shape torch.Size([416]) from checkpoint, the shape in current model is torch.Size([156]).\n\tsize mismatch for dense3.5.bn1.running_var: copying a param with shape torch.Size([416]) from checkpoint, the shape in current model is torch.Size([156]).\n\tsize mismatch for dense3.5.conv1.weight: copying a param with shape torch.Size([128, 416, 1, 1]) from checkpoint, the shape in current model is torch.Size([48, 156, 1, 1]).\n\tsize mismatch for dense3.5.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.5.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.5.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.5.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.5.conv2.weight: copying a param with shape torch.Size([32, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([12, 48, 3, 3]).\n\tsize mismatch for dense3.6.bn1.weight: copying a param with shape torch.Size([448]) from checkpoint, the shape in current model is torch.Size([168]).\n\tsize mismatch for dense3.6.bn1.bias: copying a param with shape torch.Size([448]) from checkpoint, the shape in current model is torch.Size([168]).\n\tsize mismatch for dense3.6.bn1.running_mean: copying a param with shape torch.Size([448]) from checkpoint, the shape in current model is torch.Size([168]).\n\tsize mismatch for dense3.6.bn1.running_var: copying a param with shape torch.Size([448]) from checkpoint, the shape in current model is torch.Size([168]).\n\tsize mismatch for dense3.6.conv1.weight: copying a param with shape torch.Size([128, 448, 1, 1]) from checkpoint, the shape in current model is torch.Size([48, 168, 1, 1]).\n\tsize mismatch for dense3.6.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.6.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.6.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.6.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.6.conv2.weight: copying a param with shape torch.Size([32, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([12, 48, 3, 3]).\n\tsize mismatch for dense3.7.bn1.weight: copying a param with shape torch.Size([480]) from checkpoint, the shape in current model is torch.Size([180]).\n\tsize mismatch for dense3.7.bn1.bias: copying a param with shape torch.Size([480]) from checkpoint, the shape in current model is torch.Size([180]).\n\tsize mismatch for dense3.7.bn1.running_mean: copying a param with shape torch.Size([480]) from checkpoint, the shape in current model is torch.Size([180]).\n\tsize mismatch for dense3.7.bn1.running_var: copying a param with shape torch.Size([480]) from checkpoint, the shape in current model is torch.Size([180]).\n\tsize mismatch for dense3.7.conv1.weight: copying a param with shape torch.Size([128, 480, 1, 1]) from checkpoint, the shape in current model is torch.Size([48, 180, 1, 1]).\n\tsize mismatch for dense3.7.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.7.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.7.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.7.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.7.conv2.weight: copying a param with shape torch.Size([32, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([12, 48, 3, 3]).\n\tsize mismatch for dense3.8.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for dense3.8.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for dense3.8.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for dense3.8.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for dense3.8.conv1.weight: copying a param with shape torch.Size([128, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([48, 192, 1, 1]).\n\tsize mismatch for dense3.8.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.8.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.8.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.8.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.8.conv2.weight: copying a param with shape torch.Size([32, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([12, 48, 3, 3]).\n\tsize mismatch for dense3.9.bn1.weight: copying a param with shape torch.Size([544]) from checkpoint, the shape in current model is torch.Size([204]).\n\tsize mismatch for dense3.9.bn1.bias: copying a param with shape torch.Size([544]) from checkpoint, the shape in current model is torch.Size([204]).\n\tsize mismatch for dense3.9.bn1.running_mean: copying a param with shape torch.Size([544]) from checkpoint, the shape in current model is torch.Size([204]).\n\tsize mismatch for dense3.9.bn1.running_var: copying a param with shape torch.Size([544]) from checkpoint, the shape in current model is torch.Size([204]).\n\tsize mismatch for dense3.9.conv1.weight: copying a param with shape torch.Size([128, 544, 1, 1]) from checkpoint, the shape in current model is torch.Size([48, 204, 1, 1]).\n\tsize mismatch for dense3.9.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.9.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.9.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.9.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.9.conv2.weight: copying a param with shape torch.Size([32, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([12, 48, 3, 3]).\n\tsize mismatch for dense3.10.bn1.weight: copying a param with shape torch.Size([576]) from checkpoint, the shape in current model is torch.Size([216]).\n\tsize mismatch for dense3.10.bn1.bias: copying a param with shape torch.Size([576]) from checkpoint, the shape in current model is torch.Size([216]).\n\tsize mismatch for dense3.10.bn1.running_mean: copying a param with shape torch.Size([576]) from checkpoint, the shape in current model is torch.Size([216]).\n\tsize mismatch for dense3.10.bn1.running_var: copying a param with shape torch.Size([576]) from checkpoint, the shape in current model is torch.Size([216]).\n\tsize mismatch for dense3.10.conv1.weight: copying a param with shape torch.Size([128, 576, 1, 1]) from checkpoint, the shape in current model is torch.Size([48, 216, 1, 1]).\n\tsize mismatch for dense3.10.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.10.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.10.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.10.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.10.conv2.weight: copying a param with shape torch.Size([32, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([12, 48, 3, 3]).\n\tsize mismatch for dense3.11.bn1.weight: copying a param with shape torch.Size([608]) from checkpoint, the shape in current model is torch.Size([228]).\n\tsize mismatch for dense3.11.bn1.bias: copying a param with shape torch.Size([608]) from checkpoint, the shape in current model is torch.Size([228]).\n\tsize mismatch for dense3.11.bn1.running_mean: copying a param with shape torch.Size([608]) from checkpoint, the shape in current model is torch.Size([228]).\n\tsize mismatch for dense3.11.bn1.running_var: copying a param with shape torch.Size([608]) from checkpoint, the shape in current model is torch.Size([228]).\n\tsize mismatch for dense3.11.conv1.weight: copying a param with shape torch.Size([128, 608, 1, 1]) from checkpoint, the shape in current model is torch.Size([48, 228, 1, 1]).\n\tsize mismatch for dense3.11.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.11.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.11.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.11.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.11.conv2.weight: copying a param with shape torch.Size([32, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([12, 48, 3, 3]).\n\tsize mismatch for dense3.12.bn1.weight: copying a param with shape torch.Size([640]) from checkpoint, the shape in current model is torch.Size([240]).\n\tsize mismatch for dense3.12.bn1.bias: copying a param with shape torch.Size([640]) from checkpoint, the shape in current model is torch.Size([240]).\n\tsize mismatch for dense3.12.bn1.running_mean: copying a param with shape torch.Size([640]) from checkpoint, the shape in current model is torch.Size([240]).\n\tsize mismatch for dense3.12.bn1.running_var: copying a param with shape torch.Size([640]) from checkpoint, the shape in current model is torch.Size([240]).\n\tsize mismatch for dense3.12.conv1.weight: copying a param with shape torch.Size([128, 640, 1, 1]) from checkpoint, the shape in current model is torch.Size([48, 240, 1, 1]).\n\tsize mismatch for dense3.12.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.12.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.12.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.12.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.12.conv2.weight: copying a param with shape torch.Size([32, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([12, 48, 3, 3]).\n\tsize mismatch for dense3.13.bn1.weight: copying a param with shape torch.Size([672]) from checkpoint, the shape in current model is torch.Size([252]).\n\tsize mismatch for dense3.13.bn1.bias: copying a param with shape torch.Size([672]) from checkpoint, the shape in current model is torch.Size([252]).\n\tsize mismatch for dense3.13.bn1.running_mean: copying a param with shape torch.Size([672]) from checkpoint, the shape in current model is torch.Size([252]).\n\tsize mismatch for dense3.13.bn1.running_var: copying a param with shape torch.Size([672]) from checkpoint, the shape in current model is torch.Size([252]).\n\tsize mismatch for dense3.13.conv1.weight: copying a param with shape torch.Size([128, 672, 1, 1]) from checkpoint, the shape in current model is torch.Size([48, 252, 1, 1]).\n\tsize mismatch for dense3.13.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.13.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.13.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.13.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.13.conv2.weight: copying a param with shape torch.Size([32, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([12, 48, 3, 3]).\n\tsize mismatch for dense3.14.bn1.weight: copying a param with shape torch.Size([704]) from checkpoint, the shape in current model is torch.Size([264]).\n\tsize mismatch for dense3.14.bn1.bias: copying a param with shape torch.Size([704]) from checkpoint, the shape in current model is torch.Size([264]).\n\tsize mismatch for dense3.14.bn1.running_mean: copying a param with shape torch.Size([704]) from checkpoint, the shape in current model is torch.Size([264]).\n\tsize mismatch for dense3.14.bn1.running_var: copying a param with shape torch.Size([704]) from checkpoint, the shape in current model is torch.Size([264]).\n\tsize mismatch for dense3.14.conv1.weight: copying a param with shape torch.Size([128, 704, 1, 1]) from checkpoint, the shape in current model is torch.Size([48, 264, 1, 1]).\n\tsize mismatch for dense3.14.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.14.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.14.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.14.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.14.conv2.weight: copying a param with shape torch.Size([32, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([12, 48, 3, 3]).\n\tsize mismatch for dense3.15.bn1.weight: copying a param with shape torch.Size([736]) from checkpoint, the shape in current model is torch.Size([276]).\n\tsize mismatch for dense3.15.bn1.bias: copying a param with shape torch.Size([736]) from checkpoint, the shape in current model is torch.Size([276]).\n\tsize mismatch for dense3.15.bn1.running_mean: copying a param with shape torch.Size([736]) from checkpoint, the shape in current model is torch.Size([276]).\n\tsize mismatch for dense3.15.bn1.running_var: copying a param with shape torch.Size([736]) from checkpoint, the shape in current model is torch.Size([276]).\n\tsize mismatch for dense3.15.conv1.weight: copying a param with shape torch.Size([128, 736, 1, 1]) from checkpoint, the shape in current model is torch.Size([48, 276, 1, 1]).\n\tsize mismatch for dense3.15.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.15.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.15.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.15.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.15.conv2.weight: copying a param with shape torch.Size([32, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([12, 48, 3, 3]).\n\tsize mismatch for dense3.16.bn1.weight: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([288]).\n\tsize mismatch for dense3.16.bn1.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([288]).\n\tsize mismatch for dense3.16.bn1.running_mean: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([288]).\n\tsize mismatch for dense3.16.bn1.running_var: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([288]).\n\tsize mismatch for dense3.16.conv1.weight: copying a param with shape torch.Size([128, 768, 1, 1]) from checkpoint, the shape in current model is torch.Size([48, 288, 1, 1]).\n\tsize mismatch for dense3.16.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.16.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.16.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.16.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.16.conv2.weight: copying a param with shape torch.Size([32, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([12, 48, 3, 3]).\n\tsize mismatch for dense3.17.bn1.weight: copying a param with shape torch.Size([800]) from checkpoint, the shape in current model is torch.Size([300]).\n\tsize mismatch for dense3.17.bn1.bias: copying a param with shape torch.Size([800]) from checkpoint, the shape in current model is torch.Size([300]).\n\tsize mismatch for dense3.17.bn1.running_mean: copying a param with shape torch.Size([800]) from checkpoint, the shape in current model is torch.Size([300]).\n\tsize mismatch for dense3.17.bn1.running_var: copying a param with shape torch.Size([800]) from checkpoint, the shape in current model is torch.Size([300]).\n\tsize mismatch for dense3.17.conv1.weight: copying a param with shape torch.Size([128, 800, 1, 1]) from checkpoint, the shape in current model is torch.Size([48, 300, 1, 1]).\n\tsize mismatch for dense3.17.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.17.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.17.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.17.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.17.conv2.weight: copying a param with shape torch.Size([32, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([12, 48, 3, 3]).\n\tsize mismatch for dense3.18.bn1.weight: copying a param with shape torch.Size([832]) from checkpoint, the shape in current model is torch.Size([312]).\n\tsize mismatch for dense3.18.bn1.bias: copying a param with shape torch.Size([832]) from checkpoint, the shape in current model is torch.Size([312]).\n\tsize mismatch for dense3.18.bn1.running_mean: copying a param with shape torch.Size([832]) from checkpoint, the shape in current model is torch.Size([312]).\n\tsize mismatch for dense3.18.bn1.running_var: copying a param with shape torch.Size([832]) from checkpoint, the shape in current model is torch.Size([312]).\n\tsize mismatch for dense3.18.conv1.weight: copying a param with shape torch.Size([128, 832, 1, 1]) from checkpoint, the shape in current model is torch.Size([48, 312, 1, 1]).\n\tsize mismatch for dense3.18.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.18.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.18.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.18.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.18.conv2.weight: copying a param with shape torch.Size([32, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([12, 48, 3, 3]).\n\tsize mismatch for dense3.19.bn1.weight: copying a param with shape torch.Size([864]) from checkpoint, the shape in current model is torch.Size([324]).\n\tsize mismatch for dense3.19.bn1.bias: copying a param with shape torch.Size([864]) from checkpoint, the shape in current model is torch.Size([324]).\n\tsize mismatch for dense3.19.bn1.running_mean: copying a param with shape torch.Size([864]) from checkpoint, the shape in current model is torch.Size([324]).\n\tsize mismatch for dense3.19.bn1.running_var: copying a param with shape torch.Size([864]) from checkpoint, the shape in current model is torch.Size([324]).\n\tsize mismatch for dense3.19.conv1.weight: copying a param with shape torch.Size([128, 864, 1, 1]) from checkpoint, the shape in current model is torch.Size([48, 324, 1, 1]).\n\tsize mismatch for dense3.19.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.19.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.19.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.19.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.19.conv2.weight: copying a param with shape torch.Size([32, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([12, 48, 3, 3]).\n\tsize mismatch for dense3.20.bn1.weight: copying a param with shape torch.Size([896]) from checkpoint, the shape in current model is torch.Size([336]).\n\tsize mismatch for dense3.20.bn1.bias: copying a param with shape torch.Size([896]) from checkpoint, the shape in current model is torch.Size([336]).\n\tsize mismatch for dense3.20.bn1.running_mean: copying a param with shape torch.Size([896]) from checkpoint, the shape in current model is torch.Size([336]).\n\tsize mismatch for dense3.20.bn1.running_var: copying a param with shape torch.Size([896]) from checkpoint, the shape in current model is torch.Size([336]).\n\tsize mismatch for dense3.20.conv1.weight: copying a param with shape torch.Size([128, 896, 1, 1]) from checkpoint, the shape in current model is torch.Size([48, 336, 1, 1]).\n\tsize mismatch for dense3.20.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.20.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.20.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.20.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.20.conv2.weight: copying a param with shape torch.Size([32, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([12, 48, 3, 3]).\n\tsize mismatch for dense3.21.bn1.weight: copying a param with shape torch.Size([928]) from checkpoint, the shape in current model is torch.Size([348]).\n\tsize mismatch for dense3.21.bn1.bias: copying a param with shape torch.Size([928]) from checkpoint, the shape in current model is torch.Size([348]).\n\tsize mismatch for dense3.21.bn1.running_mean: copying a param with shape torch.Size([928]) from checkpoint, the shape in current model is torch.Size([348]).\n\tsize mismatch for dense3.21.bn1.running_var: copying a param with shape torch.Size([928]) from checkpoint, the shape in current model is torch.Size([348]).\n\tsize mismatch for dense3.21.conv1.weight: copying a param with shape torch.Size([128, 928, 1, 1]) from checkpoint, the shape in current model is torch.Size([48, 348, 1, 1]).\n\tsize mismatch for dense3.21.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.21.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.21.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.21.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.21.conv2.weight: copying a param with shape torch.Size([32, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([12, 48, 3, 3]).\n\tsize mismatch for dense3.22.bn1.weight: copying a param with shape torch.Size([960]) from checkpoint, the shape in current model is torch.Size([360]).\n\tsize mismatch for dense3.22.bn1.bias: copying a param with shape torch.Size([960]) from checkpoint, the shape in current model is torch.Size([360]).\n\tsize mismatch for dense3.22.bn1.running_mean: copying a param with shape torch.Size([960]) from checkpoint, the shape in current model is torch.Size([360]).\n\tsize mismatch for dense3.22.bn1.running_var: copying a param with shape torch.Size([960]) from checkpoint, the shape in current model is torch.Size([360]).\n\tsize mismatch for dense3.22.conv1.weight: copying a param with shape torch.Size([128, 960, 1, 1]) from checkpoint, the shape in current model is torch.Size([48, 360, 1, 1]).\n\tsize mismatch for dense3.22.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.22.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.22.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.22.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.22.conv2.weight: copying a param with shape torch.Size([32, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([12, 48, 3, 3]).\n\tsize mismatch for dense3.23.bn1.weight: copying a param with shape torch.Size([992]) from checkpoint, the shape in current model is torch.Size([372]).\n\tsize mismatch for dense3.23.bn1.bias: copying a param with shape torch.Size([992]) from checkpoint, the shape in current model is torch.Size([372]).\n\tsize mismatch for dense3.23.bn1.running_mean: copying a param with shape torch.Size([992]) from checkpoint, the shape in current model is torch.Size([372]).\n\tsize mismatch for dense3.23.bn1.running_var: copying a param with shape torch.Size([992]) from checkpoint, the shape in current model is torch.Size([372]).\n\tsize mismatch for dense3.23.conv1.weight: copying a param with shape torch.Size([128, 992, 1, 1]) from checkpoint, the shape in current model is torch.Size([48, 372, 1, 1]).\n\tsize mismatch for dense3.23.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.23.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.23.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.23.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense3.23.conv2.weight: copying a param with shape torch.Size([32, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([12, 48, 3, 3]).\n\tsize mismatch for trans3.bn.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for trans3.bn.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for trans3.bn.running_mean: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for trans3.bn.running_var: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for trans3.conv.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([192, 384, 1, 1]).\n\tsize mismatch for dense4.0.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for dense4.0.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for dense4.0.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for dense4.0.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for dense4.0.conv1.weight: copying a param with shape torch.Size([128, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([48, 192, 1, 1]).\n\tsize mismatch for dense4.0.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense4.0.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense4.0.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense4.0.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense4.0.conv2.weight: copying a param with shape torch.Size([32, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([12, 48, 3, 3]).\n\tsize mismatch for dense4.1.bn1.weight: copying a param with shape torch.Size([544]) from checkpoint, the shape in current model is torch.Size([204]).\n\tsize mismatch for dense4.1.bn1.bias: copying a param with shape torch.Size([544]) from checkpoint, the shape in current model is torch.Size([204]).\n\tsize mismatch for dense4.1.bn1.running_mean: copying a param with shape torch.Size([544]) from checkpoint, the shape in current model is torch.Size([204]).\n\tsize mismatch for dense4.1.bn1.running_var: copying a param with shape torch.Size([544]) from checkpoint, the shape in current model is torch.Size([204]).\n\tsize mismatch for dense4.1.conv1.weight: copying a param with shape torch.Size([128, 544, 1, 1]) from checkpoint, the shape in current model is torch.Size([48, 204, 1, 1]).\n\tsize mismatch for dense4.1.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense4.1.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense4.1.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense4.1.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense4.1.conv2.weight: copying a param with shape torch.Size([32, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([12, 48, 3, 3]).\n\tsize mismatch for dense4.2.bn1.weight: copying a param with shape torch.Size([576]) from checkpoint, the shape in current model is torch.Size([216]).\n\tsize mismatch for dense4.2.bn1.bias: copying a param with shape torch.Size([576]) from checkpoint, the shape in current model is torch.Size([216]).\n\tsize mismatch for dense4.2.bn1.running_mean: copying a param with shape torch.Size([576]) from checkpoint, the shape in current model is torch.Size([216]).\n\tsize mismatch for dense4.2.bn1.running_var: copying a param with shape torch.Size([576]) from checkpoint, the shape in current model is torch.Size([216]).\n\tsize mismatch for dense4.2.conv1.weight: copying a param with shape torch.Size([128, 576, 1, 1]) from checkpoint, the shape in current model is torch.Size([48, 216, 1, 1]).\n\tsize mismatch for dense4.2.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense4.2.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense4.2.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense4.2.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense4.2.conv2.weight: copying a param with shape torch.Size([32, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([12, 48, 3, 3]).\n\tsize mismatch for dense4.3.bn1.weight: copying a param with shape torch.Size([608]) from checkpoint, the shape in current model is torch.Size([228]).\n\tsize mismatch for dense4.3.bn1.bias: copying a param with shape torch.Size([608]) from checkpoint, the shape in current model is torch.Size([228]).\n\tsize mismatch for dense4.3.bn1.running_mean: copying a param with shape torch.Size([608]) from checkpoint, the shape in current model is torch.Size([228]).\n\tsize mismatch for dense4.3.bn1.running_var: copying a param with shape torch.Size([608]) from checkpoint, the shape in current model is torch.Size([228]).\n\tsize mismatch for dense4.3.conv1.weight: copying a param with shape torch.Size([128, 608, 1, 1]) from checkpoint, the shape in current model is torch.Size([48, 228, 1, 1]).\n\tsize mismatch for dense4.3.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense4.3.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense4.3.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense4.3.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense4.3.conv2.weight: copying a param with shape torch.Size([32, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([12, 48, 3, 3]).\n\tsize mismatch for dense4.4.bn1.weight: copying a param with shape torch.Size([640]) from checkpoint, the shape in current model is torch.Size([240]).\n\tsize mismatch for dense4.4.bn1.bias: copying a param with shape torch.Size([640]) from checkpoint, the shape in current model is torch.Size([240]).\n\tsize mismatch for dense4.4.bn1.running_mean: copying a param with shape torch.Size([640]) from checkpoint, the shape in current model is torch.Size([240]).\n\tsize mismatch for dense4.4.bn1.running_var: copying a param with shape torch.Size([640]) from checkpoint, the shape in current model is torch.Size([240]).\n\tsize mismatch for dense4.4.conv1.weight: copying a param with shape torch.Size([128, 640, 1, 1]) from checkpoint, the shape in current model is torch.Size([48, 240, 1, 1]).\n\tsize mismatch for dense4.4.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense4.4.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense4.4.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense4.4.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense4.4.conv2.weight: copying a param with shape torch.Size([32, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([12, 48, 3, 3]).\n\tsize mismatch for dense4.5.bn1.weight: copying a param with shape torch.Size([672]) from checkpoint, the shape in current model is torch.Size([252]).\n\tsize mismatch for dense4.5.bn1.bias: copying a param with shape torch.Size([672]) from checkpoint, the shape in current model is torch.Size([252]).\n\tsize mismatch for dense4.5.bn1.running_mean: copying a param with shape torch.Size([672]) from checkpoint, the shape in current model is torch.Size([252]).\n\tsize mismatch for dense4.5.bn1.running_var: copying a param with shape torch.Size([672]) from checkpoint, the shape in current model is torch.Size([252]).\n\tsize mismatch for dense4.5.conv1.weight: copying a param with shape torch.Size([128, 672, 1, 1]) from checkpoint, the shape in current model is torch.Size([48, 252, 1, 1]).\n\tsize mismatch for dense4.5.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense4.5.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense4.5.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense4.5.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense4.5.conv2.weight: copying a param with shape torch.Size([32, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([12, 48, 3, 3]).\n\tsize mismatch for dense4.6.bn1.weight: copying a param with shape torch.Size([704]) from checkpoint, the shape in current model is torch.Size([264]).\n\tsize mismatch for dense4.6.bn1.bias: copying a param with shape torch.Size([704]) from checkpoint, the shape in current model is torch.Size([264]).\n\tsize mismatch for dense4.6.bn1.running_mean: copying a param with shape torch.Size([704]) from checkpoint, the shape in current model is torch.Size([264]).\n\tsize mismatch for dense4.6.bn1.running_var: copying a param with shape torch.Size([704]) from checkpoint, the shape in current model is torch.Size([264]).\n\tsize mismatch for dense4.6.conv1.weight: copying a param with shape torch.Size([128, 704, 1, 1]) from checkpoint, the shape in current model is torch.Size([48, 264, 1, 1]).\n\tsize mismatch for dense4.6.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense4.6.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense4.6.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense4.6.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense4.6.conv2.weight: copying a param with shape torch.Size([32, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([12, 48, 3, 3]).\n\tsize mismatch for dense4.7.bn1.weight: copying a param with shape torch.Size([736]) from checkpoint, the shape in current model is torch.Size([276]).\n\tsize mismatch for dense4.7.bn1.bias: copying a param with shape torch.Size([736]) from checkpoint, the shape in current model is torch.Size([276]).\n\tsize mismatch for dense4.7.bn1.running_mean: copying a param with shape torch.Size([736]) from checkpoint, the shape in current model is torch.Size([276]).\n\tsize mismatch for dense4.7.bn1.running_var: copying a param with shape torch.Size([736]) from checkpoint, the shape in current model is torch.Size([276]).\n\tsize mismatch for dense4.7.conv1.weight: copying a param with shape torch.Size([128, 736, 1, 1]) from checkpoint, the shape in current model is torch.Size([48, 276, 1, 1]).\n\tsize mismatch for dense4.7.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense4.7.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense4.7.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense4.7.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense4.7.conv2.weight: copying a param with shape torch.Size([32, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([12, 48, 3, 3]).\n\tsize mismatch for dense4.8.bn1.weight: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([288]).\n\tsize mismatch for dense4.8.bn1.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([288]).\n\tsize mismatch for dense4.8.bn1.running_mean: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([288]).\n\tsize mismatch for dense4.8.bn1.running_var: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([288]).\n\tsize mismatch for dense4.8.conv1.weight: copying a param with shape torch.Size([128, 768, 1, 1]) from checkpoint, the shape in current model is torch.Size([48, 288, 1, 1]).\n\tsize mismatch for dense4.8.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense4.8.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense4.8.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense4.8.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense4.8.conv2.weight: copying a param with shape torch.Size([32, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([12, 48, 3, 3]).\n\tsize mismatch for dense4.9.bn1.weight: copying a param with shape torch.Size([800]) from checkpoint, the shape in current model is torch.Size([300]).\n\tsize mismatch for dense4.9.bn1.bias: copying a param with shape torch.Size([800]) from checkpoint, the shape in current model is torch.Size([300]).\n\tsize mismatch for dense4.9.bn1.running_mean: copying a param with shape torch.Size([800]) from checkpoint, the shape in current model is torch.Size([300]).\n\tsize mismatch for dense4.9.bn1.running_var: copying a param with shape torch.Size([800]) from checkpoint, the shape in current model is torch.Size([300]).\n\tsize mismatch for dense4.9.conv1.weight: copying a param with shape torch.Size([128, 800, 1, 1]) from checkpoint, the shape in current model is torch.Size([48, 300, 1, 1]).\n\tsize mismatch for dense4.9.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense4.9.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense4.9.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense4.9.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense4.9.conv2.weight: copying a param with shape torch.Size([32, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([12, 48, 3, 3]).\n\tsize mismatch for dense4.10.bn1.weight: copying a param with shape torch.Size([832]) from checkpoint, the shape in current model is torch.Size([312]).\n\tsize mismatch for dense4.10.bn1.bias: copying a param with shape torch.Size([832]) from checkpoint, the shape in current model is torch.Size([312]).\n\tsize mismatch for dense4.10.bn1.running_mean: copying a param with shape torch.Size([832]) from checkpoint, the shape in current model is torch.Size([312]).\n\tsize mismatch for dense4.10.bn1.running_var: copying a param with shape torch.Size([832]) from checkpoint, the shape in current model is torch.Size([312]).\n\tsize mismatch for dense4.10.conv1.weight: copying a param with shape torch.Size([128, 832, 1, 1]) from checkpoint, the shape in current model is torch.Size([48, 312, 1, 1]).\n\tsize mismatch for dense4.10.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense4.10.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense4.10.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense4.10.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense4.10.conv2.weight: copying a param with shape torch.Size([32, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([12, 48, 3, 3]).\n\tsize mismatch for dense4.11.bn1.weight: copying a param with shape torch.Size([864]) from checkpoint, the shape in current model is torch.Size([324]).\n\tsize mismatch for dense4.11.bn1.bias: copying a param with shape torch.Size([864]) from checkpoint, the shape in current model is torch.Size([324]).\n\tsize mismatch for dense4.11.bn1.running_mean: copying a param with shape torch.Size([864]) from checkpoint, the shape in current model is torch.Size([324]).\n\tsize mismatch for dense4.11.bn1.running_var: copying a param with shape torch.Size([864]) from checkpoint, the shape in current model is torch.Size([324]).\n\tsize mismatch for dense4.11.conv1.weight: copying a param with shape torch.Size([128, 864, 1, 1]) from checkpoint, the shape in current model is torch.Size([48, 324, 1, 1]).\n\tsize mismatch for dense4.11.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense4.11.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense4.11.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense4.11.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense4.11.conv2.weight: copying a param with shape torch.Size([32, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([12, 48, 3, 3]).\n\tsize mismatch for dense4.12.bn1.weight: copying a param with shape torch.Size([896]) from checkpoint, the shape in current model is torch.Size([336]).\n\tsize mismatch for dense4.12.bn1.bias: copying a param with shape torch.Size([896]) from checkpoint, the shape in current model is torch.Size([336]).\n\tsize mismatch for dense4.12.bn1.running_mean: copying a param with shape torch.Size([896]) from checkpoint, the shape in current model is torch.Size([336]).\n\tsize mismatch for dense4.12.bn1.running_var: copying a param with shape torch.Size([896]) from checkpoint, the shape in current model is torch.Size([336]).\n\tsize mismatch for dense4.12.conv1.weight: copying a param with shape torch.Size([128, 896, 1, 1]) from checkpoint, the shape in current model is torch.Size([48, 336, 1, 1]).\n\tsize mismatch for dense4.12.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense4.12.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense4.12.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense4.12.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense4.12.conv2.weight: copying a param with shape torch.Size([32, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([12, 48, 3, 3]).\n\tsize mismatch for dense4.13.bn1.weight: copying a param with shape torch.Size([928]) from checkpoint, the shape in current model is torch.Size([348]).\n\tsize mismatch for dense4.13.bn1.bias: copying a param with shape torch.Size([928]) from checkpoint, the shape in current model is torch.Size([348]).\n\tsize mismatch for dense4.13.bn1.running_mean: copying a param with shape torch.Size([928]) from checkpoint, the shape in current model is torch.Size([348]).\n\tsize mismatch for dense4.13.bn1.running_var: copying a param with shape torch.Size([928]) from checkpoint, the shape in current model is torch.Size([348]).\n\tsize mismatch for dense4.13.conv1.weight: copying a param with shape torch.Size([128, 928, 1, 1]) from checkpoint, the shape in current model is torch.Size([48, 348, 1, 1]).\n\tsize mismatch for dense4.13.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense4.13.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense4.13.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense4.13.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense4.13.conv2.weight: copying a param with shape torch.Size([32, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([12, 48, 3, 3]).\n\tsize mismatch for dense4.14.bn1.weight: copying a param with shape torch.Size([960]) from checkpoint, the shape in current model is torch.Size([360]).\n\tsize mismatch for dense4.14.bn1.bias: copying a param with shape torch.Size([960]) from checkpoint, the shape in current model is torch.Size([360]).\n\tsize mismatch for dense4.14.bn1.running_mean: copying a param with shape torch.Size([960]) from checkpoint, the shape in current model is torch.Size([360]).\n\tsize mismatch for dense4.14.bn1.running_var: copying a param with shape torch.Size([960]) from checkpoint, the shape in current model is torch.Size([360]).\n\tsize mismatch for dense4.14.conv1.weight: copying a param with shape torch.Size([128, 960, 1, 1]) from checkpoint, the shape in current model is torch.Size([48, 360, 1, 1]).\n\tsize mismatch for dense4.14.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense4.14.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense4.14.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense4.14.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense4.14.conv2.weight: copying a param with shape torch.Size([32, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([12, 48, 3, 3]).\n\tsize mismatch for dense4.15.bn1.weight: copying a param with shape torch.Size([992]) from checkpoint, the shape in current model is torch.Size([372]).\n\tsize mismatch for dense4.15.bn1.bias: copying a param with shape torch.Size([992]) from checkpoint, the shape in current model is torch.Size([372]).\n\tsize mismatch for dense4.15.bn1.running_mean: copying a param with shape torch.Size([992]) from checkpoint, the shape in current model is torch.Size([372]).\n\tsize mismatch for dense4.15.bn1.running_var: copying a param with shape torch.Size([992]) from checkpoint, the shape in current model is torch.Size([372]).\n\tsize mismatch for dense4.15.conv1.weight: copying a param with shape torch.Size([128, 992, 1, 1]) from checkpoint, the shape in current model is torch.Size([48, 372, 1, 1]).\n\tsize mismatch for dense4.15.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense4.15.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense4.15.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense4.15.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for dense4.15.conv2.weight: copying a param with shape torch.Size([32, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([12, 48, 3, 3]).\n\tsize mismatch for bn.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for bn.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for bn.running_mean: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for bn.running_var: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for linear.weight: copying a param with shape torch.Size([10, 1024]) from checkpoint, the shape in current model is torch.Size([10, 384])."
     ]
    }
   ],
   "source": [
    "#pas à exécuter créer un modèle\n",
    "if torch.cuda.is_available():\n",
    "    loaded_cpt=torch.load('models\\\\model_121.pt')\n",
    "else:\n",
    "    loaded_cpt=torch.load('models\\\\model_121.pt', map_location=torch.device('cpu'))\n",
    "model_quant.load_state_dict(loaded_cpt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vWtt8NdggeBD"
   },
   "source": [
    "Une autre méthode consiste à quantizer un modèle déjà performant post-training. Pour cela on modifie le state_dict du modèle pour rajouter les paramètres dont on a besoin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 395
    },
    "id": "7SnDPgFZHfG_",
    "outputId": "2bbd26ed-be56-40ad-bf0c-222d9974b140"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    loaded_cpt=torch.load('models\\\\Densenet_cifar_trained.pt')\n",
    "else:\n",
    "    loaded_cpt=torch.load('models\\\\Densenet_cifar_trained.pt', map_location=torch.device('cpu'))\n",
    "loaded_cpt_clone = loaded_cpt.copy()\n",
    "for key in loaded_cpt.keys():\n",
    "    if \"conv\" in key:\n",
    "        if key.startswith(\"conv\") == False:\n",
    "            loaded_cpt_clone[key.replace(\"weight\",\"act_alpha\")] = torch.nn.Parameter(torch.tensor(8.0))\n",
    "            loaded_cpt_clone[key.replace(\"weight\",\"weight_quant.wgt_alpha\")] = Parameter(torch.tensor(3.0))\n",
    "model_quant.load_state_dict(loaded_cpt_clone)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aMhprKFTgeBD"
   },
   "source": [
    "Un fine tuning est nécessaire mais cela est moins long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WOYXEGREKP6I",
    "outputId": "ac16cfe7-2bdf-4f1c-a23f-13602c2fe680"
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(),lr=0.1, momentum=0.9,weight_decay=1e-4) \n",
    "scheduler = MultiStepLR(optimizer, milestones=[90, 110], gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zZrwyXzAgeBE"
   },
   "outputs": [],
   "source": [
    "train_losses, valid_losses, train_acc, valid_acc = training(trainloader, validloader, model_quant, criterion, optimizer,120,scheduler,'models\\\\densenet_quantized.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Htr1Monhaoq7",
    "outputId": "51cb4f78-d93f-43ce-c072-8eba6b9b3e42"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-0.3000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[ 2.4000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[-0.3000]]],\n",
      "\n",
      "\n",
      "        [[[-0.3000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[-2.4000]],\n",
      "\n",
      "         [[ 3.0000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[-1.8000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[-1.2000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.6000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[ 2.4000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[-0.3000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.9000]],\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[ 1.8000]]],\n",
      "\n",
      "\n",
      "        [[[-0.3000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[-1.8000]],\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         [[-2.4000]],\n",
      "\n",
      "         [[ 1.8000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[-0.3000]]],\n",
      "\n",
      "\n",
      "        [[[-0.6000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[-1.8000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[-3.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         [[-1.8000]]],\n",
      "\n",
      "\n",
      "        [[[-0.6000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[-3.0000]],\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[-2.4000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[-0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.6000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 1.8000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[ 0.3000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.9000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[-2.4000]],\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[-1.8000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[-0.3000]]],\n",
      "\n",
      "\n",
      "        [[[-0.0000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[ 1.8000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[-1.2000]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[-1.8000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[ 2.4000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[-1.8000]],\n",
      "\n",
      "         [[ 0.3000]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2000]],\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         [[ 2.4000]],\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         [[-1.8000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[ 0.3000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.9000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         [[-0.6000]]],\n",
      "\n",
      "\n",
      "        [[[-0.0000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         [[-1.8000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[-3.0000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 0.9000]]],\n",
      "\n",
      "\n",
      "        [[[ 1.8000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[ 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[-0.3000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         [[-1.8000]],\n",
      "\n",
      "         [[ 2.4000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.9000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.6000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         [[ 1.8000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[-2.4000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[-0.9000]]],\n",
      "\n",
      "\n",
      "        [[[-1.2000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[-0.6000]]],\n",
      "\n",
      "\n",
      "        [[[-0.0000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[ 1.8000]],\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         [[-1.8000]]],\n",
      "\n",
      "\n",
      "        [[[-0.3000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[-0.9000]]],\n",
      "\n",
      "\n",
      "        [[[-0.6000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[-1.8000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[ 2.4000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[-0.6000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.6000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 3.0000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[ 1.2000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[ 3.0000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[ 0.3000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[ 3.0000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[ 0.9000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[ 1.8000]],\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[-1.8000]],\n",
      "\n",
      "         [[-0.3000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 3.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 0.3000]]],\n",
      "\n",
      "\n",
      "        [[[-0.3000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[-3.0000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[ 2.4000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[-1.8000]],\n",
      "\n",
      "         [[-1.8000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[-0.9000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[-2.4000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[-1.8000]],\n",
      "\n",
      "         [[-1.8000]],\n",
      "\n",
      "         [[ 0.3000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3000]],\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         [[ 1.8000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[ 1.8000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         [[-0.3000]]],\n",
      "\n",
      "\n",
      "        [[[-0.0000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[-1.8000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[ 1.8000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[-0.6000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 2.4000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[-0.9000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[ 2.4000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[-1.8000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[-1.8000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[-1.8000]]]], device='cuda:0', grad_fn=<_pqBackward>)\n",
      "tensor([[[[ 0.3000,  1.2000,  0.3000],\n",
      "          [ 1.2000,  0.9000,  1.8000],\n",
      "          [ 0.9000,  3.0000,  0.3000]],\n",
      "\n",
      "         [[ 1.2000,  2.4000,  0.3000],\n",
      "          [ 0.3000, -3.0000,  1.2000],\n",
      "          [ 0.6000,  3.0000, -1.8000]],\n",
      "\n",
      "         [[-0.6000, -0.9000, -0.6000],\n",
      "          [ 0.9000,  1.2000, -0.3000],\n",
      "          [ 0.3000, -1.2000, -0.6000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.6000,  0.3000,  0.0000],\n",
      "          [ 0.6000,  0.6000,  0.9000],\n",
      "          [-0.3000,  0.6000,  0.0000]],\n",
      "\n",
      "         [[ 0.9000,  0.0000, -0.3000],\n",
      "          [-0.3000, -1.8000,  0.3000],\n",
      "          [-1.8000,  3.0000, -2.4000]],\n",
      "\n",
      "         [[ 1.2000,  1.8000, -0.6000],\n",
      "          [ 0.0000, -2.4000,  2.4000],\n",
      "          [ 0.6000,  1.8000, -0.6000]]],\n",
      "\n",
      "\n",
      "        [[[ 1.8000,  1.2000, -0.3000],\n",
      "          [ 0.6000,  1.2000,  0.3000],\n",
      "          [-0.3000, -0.3000,  1.2000]],\n",
      "\n",
      "         [[ 0.3000, -1.2000,  0.3000],\n",
      "          [ 0.3000, -3.0000, -1.8000],\n",
      "          [ 1.8000,  1.2000,  1.2000]],\n",
      "\n",
      "         [[-0.9000, -0.3000,  0.9000],\n",
      "          [ 0.0000,  0.9000,  0.9000],\n",
      "          [-0.0000,  0.0000, -1.2000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3000,  0.6000,  1.8000],\n",
      "          [ 0.0000,  0.6000,  0.6000],\n",
      "          [ 0.9000,  1.2000, -0.6000]],\n",
      "\n",
      "         [[ 0.0000, -0.9000,  0.0000],\n",
      "          [ 0.0000, -0.6000, -0.9000],\n",
      "          [-0.3000, -0.0000,  0.0000]],\n",
      "\n",
      "         [[ 0.0000, -0.0000, -0.3000],\n",
      "          [-0.6000, -0.9000,  0.3000],\n",
      "          [-0.3000, -0.3000,  0.3000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.9000, -1.2000, -0.9000],\n",
      "          [ 0.9000,  0.3000,  1.2000],\n",
      "          [ 0.0000, -1.2000, -0.6000]],\n",
      "\n",
      "         [[-0.6000, -1.8000, -0.6000],\n",
      "          [ 3.0000,  0.6000, -3.0000],\n",
      "          [-0.9000, -0.0000, -0.3000]],\n",
      "\n",
      "         [[-0.0000,  0.6000,  0.3000],\n",
      "          [-0.9000, -0.3000,  0.3000],\n",
      "          [ 0.0000, -0.0000,  0.3000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.8000,  0.3000, -1.2000],\n",
      "          [-1.8000, -0.9000, -1.8000],\n",
      "          [-1.2000, -0.6000, -1.2000]],\n",
      "\n",
      "         [[-0.6000,  0.0000,  0.0000],\n",
      "          [ 0.0000, -0.3000, -2.4000],\n",
      "          [-0.6000, -0.3000, -0.3000]],\n",
      "\n",
      "         [[ 0.9000, -0.6000,  0.6000],\n",
      "          [ 2.4000,  0.9000, -0.3000],\n",
      "          [-0.0000,  0.0000,  1.2000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.6000,  0.6000,  0.0000],\n",
      "          [-0.6000,  0.6000, -0.3000],\n",
      "          [-0.6000, -0.3000, -0.3000]],\n",
      "\n",
      "         [[-1.2000,  2.4000, -0.3000],\n",
      "          [ 0.9000,  1.2000,  0.6000],\n",
      "          [-2.4000,  0.3000, -0.0000]],\n",
      "\n",
      "         [[ 0.6000, -0.0000, -0.9000],\n",
      "          [ 0.6000,  0.0000, -0.3000],\n",
      "          [ 0.9000,  0.3000,  0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3000,  0.3000, -0.9000],\n",
      "          [ 0.0000,  0.3000, -1.2000],\n",
      "          [ 0.3000,  0.9000, -1.2000]],\n",
      "\n",
      "         [[-1.8000, -0.0000, -1.2000],\n",
      "          [ 1.8000,  0.9000, -0.3000],\n",
      "          [-0.3000,  0.6000, -0.6000]],\n",
      "\n",
      "         [[-0.9000,  0.9000,  0.3000],\n",
      "          [-0.0000,  0.6000,  0.9000],\n",
      "          [-1.2000, -0.6000,  0.9000]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2000,  0.0000,  0.6000],\n",
      "          [-0.6000, -0.9000,  0.9000],\n",
      "          [ 0.3000,  0.3000,  0.3000]],\n",
      "\n",
      "         [[-1.8000, -2.4000, -1.8000],\n",
      "          [-1.2000,  3.0000,  1.8000],\n",
      "          [ 0.6000, -0.3000, -0.6000]],\n",
      "\n",
      "         [[ 0.3000,  0.6000,  0.3000],\n",
      "          [ 0.6000, -0.0000, -0.3000],\n",
      "          [-0.6000, -0.3000,  0.6000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.6000,  0.6000,  0.3000],\n",
      "          [ 0.6000, -0.3000, -0.6000],\n",
      "          [ 0.6000, -0.3000,  1.2000]],\n",
      "\n",
      "         [[-0.6000, -0.9000, -0.3000],\n",
      "          [-0.0000,  1.8000,  0.3000],\n",
      "          [ 0.9000, -0.6000, -0.9000]],\n",
      "\n",
      "         [[-0.3000, -0.3000,  0.3000],\n",
      "          [-1.8000,  1.8000,  0.6000],\n",
      "          [-0.3000, -0.0000, -0.6000]]],\n",
      "\n",
      "\n",
      "        [[[-0.6000,  1.8000, -0.6000],\n",
      "          [-0.6000,  1.2000, -0.6000],\n",
      "          [-0.3000,  0.9000, -1.2000]],\n",
      "\n",
      "         [[ 0.9000, -0.9000,  1.8000],\n",
      "          [-0.0000, -0.9000,  0.0000],\n",
      "          [ 2.4000,  0.9000,  2.4000]],\n",
      "\n",
      "         [[ 0.3000,  0.6000,  0.9000],\n",
      "          [ 1.2000,  0.6000,  1.2000],\n",
      "          [-0.3000, -0.0000,  0.3000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0000,  0.9000, -0.0000],\n",
      "          [-0.3000,  0.6000, -0.6000],\n",
      "          [-0.3000,  0.6000, -0.3000]],\n",
      "\n",
      "         [[ 0.3000, -0.0000,  1.2000],\n",
      "          [-0.3000, -0.3000,  0.3000],\n",
      "          [-0.3000, -0.6000,  0.0000]],\n",
      "\n",
      "         [[ 0.9000,  1.2000,  0.9000],\n",
      "          [-0.0000,  0.0000, -0.3000],\n",
      "          [ 0.9000,  0.9000,  0.6000]]]], device='cuda:0',\n",
      "       grad_fn=<_pqBackward>)\n",
      "tensor([[[[-0.0000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[ 1.8000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[-0.3000]]],\n",
      "\n",
      "\n",
      "        [[[ 1.8000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         [[-1.8000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 0.3000]]],\n",
      "\n",
      "\n",
      "        [[[-1.8000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[-2.4000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[-2.4000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[ 3.0000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[-0.0000]]],\n",
      "\n",
      "\n",
      "        [[[-0.9000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 1.8000]],\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[-3.0000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         [[ 1.8000]],\n",
      "\n",
      "         [[-2.4000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.6000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[-3.0000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[-3.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 1.8000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[-1.8000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[-0.3000]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[ 2.4000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.6000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[-1.8000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 1.8000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[-3.0000]],\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         [[ 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[-0.0000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[-1.8000]],\n",
      "\n",
      "         [[-3.0000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[-1.8000]],\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 1.2000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[ 1.8000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[-3.0000]],\n",
      "\n",
      "         [[-1.8000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 1.8000]],\n",
      "\n",
      "         [[-1.8000]],\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         [[-2.4000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         [[ 0.3000]]],\n",
      "\n",
      "\n",
      "        [[[-3.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[ 1.8000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         [[ 3.0000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[-1.8000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.9000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         [[-2.4000]],\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[-3.0000]],\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[-1.8000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 0.3000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.6000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[-2.4000]],\n",
      "\n",
      "         [[ 1.8000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[-3.0000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[ 2.4000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[ 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 1.8000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[-1.8000]],\n",
      "\n",
      "         [[-1.8000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[-1.8000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         [[-1.8000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[-0.9000]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[-2.4000]],\n",
      "\n",
      "         [[-1.8000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[-2.4000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 0.9000]]],\n",
      "\n",
      "\n",
      "        [[[-0.6000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         [[-1.8000]],\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[-1.8000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[ 1.8000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         [[ 1.8000]],\n",
      "\n",
      "         [[-1.8000]]],\n",
      "\n",
      "\n",
      "        [[[ 3.0000]],\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         [[-2.4000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[-3.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[ 0.9000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.6000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[-2.4000]],\n",
      "\n",
      "         [[ 1.8000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[-2.4000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[-2.4000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[ 1.8000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[ 0.3000]]],\n",
      "\n",
      "\n",
      "        [[[-0.6000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 1.8000]],\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 2.4000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[-3.0000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[-0.3000]]],\n",
      "\n",
      "\n",
      "        [[[-0.3000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[ 1.8000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 2.4000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[-3.0000]],\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         [[-0.3000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[-0.6000]]],\n",
      "\n",
      "\n",
      "        [[[-0.9000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.6000]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[ 1.8000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 1.2000]]],\n",
      "\n",
      "\n",
      "        [[[-2.4000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         [[ 1.8000]],\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         [[-1.8000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[-1.8000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         [[ 1.8000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[ 0.3000]]],\n",
      "\n",
      "\n",
      "        [[[-0.9000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 2.4000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         [[-0.9000]]],\n",
      "\n",
      "\n",
      "        [[[-0.3000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[-1.2000]]],\n",
      "\n",
      "\n",
      "        [[[-1.2000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[ 2.4000]],\n",
      "\n",
      "         [[-2.4000]],\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[ 0.6000]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[-1.8000]],\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 0.6000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[-1.8000]],\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         [[-1.8000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[ 1.8000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[-3.0000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[ 1.8000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[-0.3000]]],\n",
      "\n",
      "\n",
      "        [[[ 2.4000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[-2.4000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         [[ 1.8000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[-1.8000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         [[-1.8000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[ 1.8000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[-0.6000]]],\n",
      "\n",
      "\n",
      "        [[[-1.8000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         [[-1.8000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[ 1.8000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[-1.8000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 1.2000]]]], device='cuda:0', grad_fn=<_pqBackward>)\n",
      "tensor([[[[-0.9000,  0.9000, -0.6000],\n",
      "          [-1.2000,  0.6000, -0.9000],\n",
      "          [-1.2000,  0.3000, -1.2000]],\n",
      "\n",
      "         [[-0.0000,  0.6000, -0.3000],\n",
      "          [-0.3000,  1.8000,  0.3000],\n",
      "          [ 0.3000,  0.3000,  0.9000]],\n",
      "\n",
      "         [[ 1.2000, -1.8000,  1.8000],\n",
      "          [ 2.4000, -3.0000,  3.0000],\n",
      "          [-0.3000, -0.6000,  0.6000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3000,  0.0000, -1.2000],\n",
      "          [ 0.3000, -0.6000, -1.2000],\n",
      "          [ 0.6000,  0.0000, -0.6000]],\n",
      "\n",
      "         [[-1.2000,  1.2000, -0.6000],\n",
      "          [-1.2000,  0.9000, -0.9000],\n",
      "          [-1.8000,  0.6000, -0.9000]],\n",
      "\n",
      "         [[-0.0000, -1.8000,  0.0000],\n",
      "          [-1.2000, -0.3000, -0.0000],\n",
      "          [-1.2000, -0.6000, -0.3000]]],\n",
      "\n",
      "\n",
      "        [[[-0.3000, -0.6000, -0.3000],\n",
      "          [-0.6000, -0.3000, -0.3000],\n",
      "          [-0.6000, -0.6000, -0.6000]],\n",
      "\n",
      "         [[ 0.0000,  0.6000,  0.6000],\n",
      "          [-0.0000,  0.3000,  0.3000],\n",
      "          [-0.3000, -0.0000, -0.3000]],\n",
      "\n",
      "         [[-0.3000, -0.0000, -0.6000],\n",
      "          [-0.0000, -0.6000, -0.9000],\n",
      "          [ 0.3000, -0.3000, -0.3000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0000, -0.0000, -0.0000],\n",
      "          [ 0.0000, -0.0000, -0.0000],\n",
      "          [-0.3000, -0.3000, -0.6000]],\n",
      "\n",
      "         [[-0.6000, -0.6000, -0.6000],\n",
      "          [-0.6000, -0.6000, -0.6000],\n",
      "          [-0.9000, -0.6000, -0.6000]],\n",
      "\n",
      "         [[ 1.2000,  1.2000,  1.2000],\n",
      "          [ 0.6000,  0.9000,  0.9000],\n",
      "          [-0.9000, -0.9000, -0.9000]]],\n",
      "\n",
      "\n",
      "        [[[-0.3000,  0.6000,  0.3000],\n",
      "          [-0.3000,  0.6000,  0.3000],\n",
      "          [ 0.3000,  0.9000,  0.3000]],\n",
      "\n",
      "         [[-1.2000,  1.2000, -0.0000],\n",
      "          [-1.2000, -1.2000, -0.3000],\n",
      "          [ 2.4000,  0.3000,  0.3000]],\n",
      "\n",
      "         [[ 0.6000, -2.4000, -0.3000],\n",
      "          [ 0.9000,  0.9000,  0.9000],\n",
      "          [-0.9000,  1.8000, -0.6000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.6000,  1.8000, -0.6000],\n",
      "          [-0.0000, -0.9000, -0.3000],\n",
      "          [-0.9000, -2.4000, -1.2000]],\n",
      "\n",
      "         [[-0.0000,  0.3000, -0.6000],\n",
      "          [-0.0000,  0.3000, -0.3000],\n",
      "          [ 0.0000,  0.6000,  0.3000]],\n",
      "\n",
      "         [[-0.3000, -1.8000, -1.8000],\n",
      "          [-1.8000, -0.0000, -2.4000],\n",
      "          [-1.2000, -0.6000, -0.9000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.6000, -1.2000, -0.0000],\n",
      "          [-0.9000, -0.9000, -0.0000],\n",
      "          [-0.3000, -0.9000,  0.3000]],\n",
      "\n",
      "         [[-0.6000,  2.4000, -0.0000],\n",
      "          [ 1.2000, -2.4000,  0.6000],\n",
      "          [ 0.3000, -0.3000,  0.3000]],\n",
      "\n",
      "         [[ 0.9000, -3.0000,  1.8000],\n",
      "          [-3.0000,  3.0000, -3.0000],\n",
      "          [-1.2000,  0.0000, -1.8000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.2000,  1.2000,  0.0000],\n",
      "          [ 1.8000, -2.4000,  1.8000],\n",
      "          [ 1.2000,  0.0000,  0.9000]],\n",
      "\n",
      "         [[-0.3000, -1.8000, -0.6000],\n",
      "          [-0.6000, -1.2000, -0.3000],\n",
      "          [-0.0000, -0.9000,  0.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.0000, -0.6000],\n",
      "          [-0.9000,  0.6000, -1.8000],\n",
      "          [ 0.9000, -0.6000, -0.0000]]],\n",
      "\n",
      "\n",
      "        [[[-0.9000, -0.0000,  0.3000],\n",
      "          [-0.3000,  0.0000,  0.3000],\n",
      "          [-0.3000, -0.3000, -0.0000]],\n",
      "\n",
      "         [[ 0.9000, -0.3000,  0.6000],\n",
      "          [ 0.9000,  0.9000, -0.9000],\n",
      "          [-0.3000,  0.6000, -0.0000]],\n",
      "\n",
      "         [[-0.9000,  3.0000,  0.0000],\n",
      "          [ 1.8000, -0.3000, -1.8000],\n",
      "          [ 0.6000, -2.4000, -1.8000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.6000, -0.6000,  1.2000],\n",
      "          [-1.2000,  1.8000,  0.3000],\n",
      "          [ 0.9000,  2.4000, -0.9000]],\n",
      "\n",
      "         [[-0.9000, -0.3000,  0.6000],\n",
      "          [-0.6000, -0.3000, -0.0000],\n",
      "          [-0.6000, -0.3000, -0.6000]],\n",
      "\n",
      "         [[-0.3000,  0.6000, -1.2000],\n",
      "          [-0.6000,  0.3000,  1.2000],\n",
      "          [-0.6000,  0.6000,  0.6000]]],\n",
      "\n",
      "\n",
      "        [[[-0.3000, -0.3000, -0.0000],\n",
      "          [-0.3000,  0.3000,  0.0000],\n",
      "          [ 0.3000, -0.6000, -0.3000]],\n",
      "\n",
      "         [[ 0.0000, -0.9000, -0.3000],\n",
      "          [ 1.2000,  2.4000,  1.2000],\n",
      "          [-1.2000, -1.8000, -1.8000]],\n",
      "\n",
      "         [[ 0.0000, -0.9000,  0.6000],\n",
      "          [-0.9000, -0.9000, -0.6000],\n",
      "          [ 1.2000,  2.4000,  1.8000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.2000, -3.0000, -1.8000],\n",
      "          [ 0.3000,  2.4000,  1.2000],\n",
      "          [ 0.9000,  0.9000,  0.0000]],\n",
      "\n",
      "         [[-0.6000, -0.3000, -0.0000],\n",
      "          [-0.6000,  0.0000,  0.3000],\n",
      "          [ 0.3000, -0.3000, -0.6000]],\n",
      "\n",
      "         [[ 0.0000,  1.8000,  0.0000],\n",
      "          [-0.0000, -0.9000,  0.6000],\n",
      "          [-0.6000, -0.9000, -1.2000]]]], device='cuda:0',\n",
      "       grad_fn=<_pqBackward>)\n",
      "tensor([[[[ 0.3000]],\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         [[ 1.8000]],\n",
      "\n",
      "         [[-0.6000]]],\n",
      "\n",
      "\n",
      "        [[[-0.0000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[-0.3000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.6000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[-0.9000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 1.8000]],\n",
      "\n",
      "         [[ 1.8000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[-0.6000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.9000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[ 1.8000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[-1.2000]]],\n",
      "\n",
      "\n",
      "        [[[-0.3000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[ 1.8000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.8000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[ 0.3000]]]], device='cuda:0', grad_fn=<_pqBackward>)\n",
      "tensor([[[[-0.3000, -0.9000, -0.6000],\n",
      "          [ 0.6000, -0.6000, -1.2000],\n",
      "          [ 1.2000,  0.3000, -0.0000]],\n",
      "\n",
      "         [[ 0.3000, -0.0000, -1.2000],\n",
      "          [ 0.3000, -0.3000, -0.9000],\n",
      "          [-0.0000, -0.3000,  0.6000]],\n",
      "\n",
      "         [[-0.9000, -0.6000, -0.6000],\n",
      "          [ 0.6000,  1.8000,  0.9000],\n",
      "          [-0.6000,  0.3000,  0.3000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3000,  0.9000,  0.3000],\n",
      "          [ 0.3000, -0.9000, -0.9000],\n",
      "          [ 1.8000, -0.3000, -1.2000]],\n",
      "\n",
      "         [[ 0.3000, -0.3000, -0.3000],\n",
      "          [ 0.0000,  0.0000, -0.3000],\n",
      "          [-0.6000, -0.0000,  0.6000]],\n",
      "\n",
      "         [[-0.6000, -0.9000,  0.0000],\n",
      "          [-0.0000, -0.0000,  0.3000],\n",
      "          [ 0.6000,  0.3000, -0.0000]]],\n",
      "\n",
      "\n",
      "        [[[-0.3000,  0.6000,  0.3000],\n",
      "          [ 0.9000,  0.9000,  0.3000],\n",
      "          [ 0.0000, -0.3000, -0.6000]],\n",
      "\n",
      "         [[ 0.0000, -0.0000, -0.0000],\n",
      "          [-0.0000, -0.3000, -0.6000],\n",
      "          [ 0.3000, -0.3000, -0.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.3000, -0.0000],\n",
      "          [-0.3000,  0.3000,  0.6000],\n",
      "          [-0.3000,  0.3000,  0.3000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3000,  0.3000,  0.6000],\n",
      "          [-0.3000,  0.3000,  0.6000],\n",
      "          [-0.9000,  0.3000,  0.9000]],\n",
      "\n",
      "         [[-0.6000,  0.3000,  0.9000],\n",
      "          [-0.6000, -0.6000,  0.0000],\n",
      "          [ 0.0000, -0.6000, -0.6000]],\n",
      "\n",
      "         [[ 0.6000, -0.3000, -0.3000],\n",
      "          [ 0.6000,  0.3000, -0.6000],\n",
      "          [-0.3000,  0.0000, -0.9000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000, -0.3000, -0.0000],\n",
      "          [-0.3000, -0.6000,  0.6000],\n",
      "          [ 0.3000,  0.9000,  0.3000]],\n",
      "\n",
      "         [[ 0.9000, -1.2000, -0.0000],\n",
      "          [-0.3000, -0.3000,  1.2000],\n",
      "          [-0.9000,  0.0000, -0.3000]],\n",
      "\n",
      "         [[-1.2000, -0.0000,  1.2000],\n",
      "          [ 0.9000,  0.3000, -0.6000],\n",
      "          [ 0.9000, -0.3000, -2.4000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.8000,  1.8000,  0.9000],\n",
      "          [-0.6000, -0.3000, -0.6000],\n",
      "          [-0.0000, -1.2000,  0.3000]],\n",
      "\n",
      "         [[-1.2000,  0.3000, -0.3000],\n",
      "          [ 0.9000,  0.6000, -0.9000],\n",
      "          [ 0.3000, -0.9000, -0.6000]],\n",
      "\n",
      "         [[-0.6000,  0.9000,  1.2000],\n",
      "          [-0.3000,  1.8000,  0.3000],\n",
      "          [ 1.2000, -0.0000, -1.8000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 1.2000,  1.8000,  0.3000],\n",
      "          [ 0.9000,  0.6000,  0.3000],\n",
      "          [ 0.3000, -0.0000,  0.3000]],\n",
      "\n",
      "         [[ 0.9000,  1.8000, -0.3000],\n",
      "          [-0.3000, -0.3000, -0.3000],\n",
      "          [-0.3000, -1.2000,  0.3000]],\n",
      "\n",
      "         [[-0.6000, -0.3000,  0.3000],\n",
      "          [-0.3000,  1.2000,  1.8000],\n",
      "          [-1.8000, -0.0000,  0.3000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0000, -1.2000,  0.9000],\n",
      "          [ 0.6000, -0.9000, -1.8000],\n",
      "          [ 0.3000,  0.3000, -0.9000]],\n",
      "\n",
      "         [[-0.9000, -0.9000, -0.3000],\n",
      "          [-0.6000,  1.2000, -0.6000],\n",
      "          [-0.9000,  0.0000,  0.6000]],\n",
      "\n",
      "         [[ 1.2000,  0.0000,  0.3000],\n",
      "          [ 0.0000,  0.3000,  0.3000],\n",
      "          [ 0.6000,  0.3000, -0.6000]]],\n",
      "\n",
      "\n",
      "        [[[-0.6000, -1.2000, -0.6000],\n",
      "          [ 1.2000,  0.9000,  0.3000],\n",
      "          [ 1.2000,  1.8000,  1.2000]],\n",
      "\n",
      "         [[-0.6000, -0.6000,  0.0000],\n",
      "          [-0.9000, -0.6000, -0.6000],\n",
      "          [-0.0000,  0.6000, -0.0000]],\n",
      "\n",
      "         [[ 0.0000, -0.3000, -0.3000],\n",
      "          [-0.3000, -0.0000,  0.0000],\n",
      "          [ 0.0000,  0.6000,  1.2000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0000, -0.0000,  0.9000],\n",
      "          [ 0.6000, -0.9000,  0.3000],\n",
      "          [ 0.0000,  0.6000, -0.6000]],\n",
      "\n",
      "         [[ 0.0000, -1.2000, -0.3000],\n",
      "          [-0.6000, -0.9000, -0.9000],\n",
      "          [ 1.2000,  1.8000,  1.8000]],\n",
      "\n",
      "         [[-0.6000,  0.6000,  1.8000],\n",
      "          [-0.6000,  0.3000,  0.3000],\n",
      "          [-0.6000, -0.9000, -0.3000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3000, -0.9000, -0.9000],\n",
      "          [-0.9000, -0.0000, -0.9000],\n",
      "          [-0.0000, -0.3000,  0.0000]],\n",
      "\n",
      "         [[ 0.3000, -0.3000,  0.0000],\n",
      "          [-0.6000,  0.6000, -0.6000],\n",
      "          [ 0.3000,  0.0000,  0.3000]],\n",
      "\n",
      "         [[ 0.0000, -0.3000, -0.9000],\n",
      "          [ 0.6000, -1.8000,  0.6000],\n",
      "          [-0.9000,  0.9000,  0.9000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3000,  1.8000, -0.9000],\n",
      "          [ 1.2000, -1.8000,  1.8000],\n",
      "          [ 0.3000,  3.0000, -1.8000]],\n",
      "\n",
      "         [[ 0.3000,  0.3000,  0.6000],\n",
      "          [ 0.6000,  0.0000,  0.6000],\n",
      "          [-0.6000,  1.8000,  0.9000]],\n",
      "\n",
      "         [[-0.3000,  0.3000,  0.3000],\n",
      "          [ 0.3000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.3000, -0.3000]]]], device='cuda:0',\n",
      "       grad_fn=<_pqBackward>)\n",
      "tensor([[[[-1.2000]],\n",
      "\n",
      "         [[ 1.8000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[ 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.9000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[ 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[-0.0000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.3000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 3.0000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.8000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[-0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.6000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 0.3000]]]], device='cuda:0', grad_fn=<_pqBackward>)\n",
      "tensor([[[[ 1.8000,  0.3000,  0.3000],\n",
      "          [ 0.3000,  0.0000,  0.9000],\n",
      "          [ 0.9000, -1.2000, -1.2000]],\n",
      "\n",
      "         [[-0.9000,  1.2000, -0.9000],\n",
      "          [ 0.6000,  0.0000,  1.2000],\n",
      "          [ 0.9000,  1.8000,  0.3000]],\n",
      "\n",
      "         [[ 1.2000, -1.2000, -0.3000],\n",
      "          [ 0.9000,  0.3000,  0.6000],\n",
      "          [ 1.8000,  0.0000, -1.2000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3000,  1.8000, -0.0000],\n",
      "          [ 0.6000,  0.0000,  1.8000],\n",
      "          [ 1.2000,  1.2000,  0.3000]],\n",
      "\n",
      "         [[ 0.6000, -0.9000, -0.6000],\n",
      "          [ 0.0000,  0.6000, -0.6000],\n",
      "          [-0.3000, -0.3000,  0.3000]],\n",
      "\n",
      "         [[ 3.0000,  1.8000,  2.4000],\n",
      "          [ 0.6000, -0.3000, -0.6000],\n",
      "          [ 3.0000,  3.0000,  0.9000]]],\n",
      "\n",
      "\n",
      "        [[[-0.3000,  0.3000,  0.3000],\n",
      "          [ 0.6000,  0.9000, -0.3000],\n",
      "          [-0.3000, -0.6000, -1.2000]],\n",
      "\n",
      "         [[ 0.3000,  0.0000, -0.3000],\n",
      "          [-0.0000,  0.3000, -0.9000],\n",
      "          [-1.2000, -0.6000, -0.9000]],\n",
      "\n",
      "         [[ 0.6000,  1.2000,  0.3000],\n",
      "          [ 1.8000,  1.8000,  1.2000],\n",
      "          [ 0.6000,  0.9000,  0.3000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.6000, -0.0000, -0.6000],\n",
      "          [-0.0000,  0.3000, -0.9000],\n",
      "          [-0.9000, -0.9000, -0.9000]],\n",
      "\n",
      "         [[ 0.0000,  0.3000,  0.3000],\n",
      "          [-0.3000, -0.6000, -0.3000],\n",
      "          [-0.3000, -0.6000, -0.6000]],\n",
      "\n",
      "         [[ 0.6000,  0.6000,  1.2000],\n",
      "          [ 0.6000,  0.0000,  0.0000],\n",
      "          [ 0.0000, -1.2000, -1.2000]]],\n",
      "\n",
      "\n",
      "        [[[-0.3000, -0.3000,  0.6000],\n",
      "          [ 0.3000,  1.2000,  0.9000],\n",
      "          [ 1.8000,  0.6000,  1.8000]],\n",
      "\n",
      "         [[-1.2000, -1.8000, -1.8000],\n",
      "          [-0.6000, -0.6000, -3.0000],\n",
      "          [ 1.2000,  0.3000,  0.9000]],\n",
      "\n",
      "         [[-0.3000, -1.8000,  0.9000],\n",
      "          [ 1.2000,  1.2000,  0.3000],\n",
      "          [ 2.4000,  2.4000,  2.4000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.2000, -1.8000, -1.8000],\n",
      "          [-0.9000, -1.2000, -3.0000],\n",
      "          [ 0.6000, -0.3000,  0.0000]],\n",
      "\n",
      "         [[-0.9000, -0.6000, -0.9000],\n",
      "          [-0.6000,  0.9000,  0.0000],\n",
      "          [-0.3000,  0.3000,  0.6000]],\n",
      "\n",
      "         [[-0.9000, -0.0000, -0.6000],\n",
      "          [-0.0000,  0.9000,  0.9000],\n",
      "          [ 0.6000,  1.2000,  1.8000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.3000,  0.6000, -0.6000],\n",
      "          [-0.0000,  0.9000,  0.0000],\n",
      "          [-0.6000, -0.6000, -1.8000]],\n",
      "\n",
      "         [[-0.6000,  0.0000, -0.3000],\n",
      "          [ 0.3000,  0.3000, -0.3000],\n",
      "          [-0.0000, -0.3000,  0.3000]],\n",
      "\n",
      "         [[-0.3000, -0.6000, -1.8000],\n",
      "          [-1.2000, -0.6000, -0.6000],\n",
      "          [-1.2000, -1.8000, -1.8000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0000,  0.3000, -0.3000],\n",
      "          [ 0.6000,  0.3000, -0.3000],\n",
      "          [-0.0000, -0.0000,  0.6000]],\n",
      "\n",
      "         [[-0.9000, -0.3000, -0.3000],\n",
      "          [ 0.3000,  0.6000,  0.3000],\n",
      "          [-1.8000, -1.8000, -1.2000]],\n",
      "\n",
      "         [[ 1.2000,  1.2000,  2.4000],\n",
      "          [ 0.0000, -2.4000, -1.2000],\n",
      "          [ 1.2000,  0.9000, -0.3000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.6000,  0.3000,  0.6000],\n",
      "          [ 0.0000, -0.3000, -1.2000],\n",
      "          [ 0.3000, -0.6000, -0.3000]],\n",
      "\n",
      "         [[ 0.9000, -0.3000,  0.9000],\n",
      "          [-0.0000, -0.6000, -0.9000],\n",
      "          [ 0.3000, -0.9000, -0.6000]],\n",
      "\n",
      "         [[ 0.9000,  0.6000, -0.0000],\n",
      "          [ 0.6000,  1.2000,  0.3000],\n",
      "          [ 0.6000,  0.0000,  0.9000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.9000, -0.3000,  0.6000],\n",
      "          [-0.3000, -0.9000, -0.9000],\n",
      "          [-0.3000, -1.8000, -1.2000]],\n",
      "\n",
      "         [[-0.9000, -0.0000, -0.6000],\n",
      "          [-1.2000, -0.6000, -1.2000],\n",
      "          [ 0.6000,  1.2000,  0.3000]],\n",
      "\n",
      "         [[ 0.3000,  0.3000, -0.3000],\n",
      "          [ 1.2000,  0.9000, -0.3000],\n",
      "          [-0.3000, -0.3000, -0.6000]]],\n",
      "\n",
      "\n",
      "        [[[ 1.8000,  1.2000,  0.9000],\n",
      "          [ 0.9000, -1.2000, -0.9000],\n",
      "          [ 0.6000,  0.0000, -0.0000]],\n",
      "\n",
      "         [[ 1.8000,  2.4000,  0.9000],\n",
      "          [ 0.3000,  0.3000, -0.9000],\n",
      "          [-0.6000, -1.2000, -1.8000]],\n",
      "\n",
      "         [[ 1.2000,  1.8000,  1.8000],\n",
      "          [ 0.3000,  0.3000, -0.6000],\n",
      "          [ 0.6000,  0.0000, -0.3000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.2000,  2.4000,  0.3000],\n",
      "          [ 0.3000,  0.6000, -0.9000],\n",
      "          [-1.2000, -1.8000, -1.2000]],\n",
      "\n",
      "         [[ 0.9000,  0.6000,  0.3000],\n",
      "          [ 0.0000, -0.3000, -0.6000],\n",
      "          [-0.3000,  0.3000, -0.3000]],\n",
      "\n",
      "         [[-0.9000,  0.9000,  0.3000],\n",
      "          [ 1.8000, -0.0000, -0.9000],\n",
      "          [ 0.9000, -0.0000, -2.4000]]]], device='cuda:0',\n",
      "       grad_fn=<_pqBackward>)\n",
      "tensor([[[[ 0.6000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[-0.3000]]],\n",
      "\n",
      "\n",
      "        [[[-1.2000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[-1.8000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[-1.2000]]],\n",
      "\n",
      "\n",
      "        [[[-1.8000]],\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.4000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[ 0.0000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-1.2000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[-1.8000]]],\n",
      "\n",
      "\n",
      "        [[[-1.2000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.3000]]],\n",
      "\n",
      "\n",
      "        [[[-1.2000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[-0.0000]]]], device='cuda:0', grad_fn=<_pqBackward>)\n",
      "tensor([[[[ 1.8000,  0.6000, -0.9000],\n",
      "          [-0.3000,  1.2000,  0.9000],\n",
      "          [-1.8000, -1.2000, -0.3000]],\n",
      "\n",
      "         [[-0.6000, -0.6000, -1.8000],\n",
      "          [ 0.0000, -0.3000, -0.3000],\n",
      "          [ 1.2000,  0.3000, -0.6000]],\n",
      "\n",
      "         [[ 3.0000, -0.3000, -2.4000],\n",
      "          [-0.3000,  2.4000, -0.6000],\n",
      "          [-2.4000, -0.3000,  1.2000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.6000, -0.6000,  0.6000],\n",
      "          [ 1.8000,  0.3000, -0.6000],\n",
      "          [ 0.6000,  1.2000, -0.6000]],\n",
      "\n",
      "         [[ 0.6000,  0.6000, -1.8000],\n",
      "          [-0.9000,  0.9000,  0.6000],\n",
      "          [-0.3000, -0.9000,  0.3000]],\n",
      "\n",
      "         [[ 0.0000, -0.9000,  0.0000],\n",
      "          [ 0.3000, -0.3000,  0.3000],\n",
      "          [ 1.2000,  0.6000,  0.3000]]],\n",
      "\n",
      "\n",
      "        [[[-0.3000,  0.9000,  1.2000],\n",
      "          [-0.9000, -0.0000,  0.9000],\n",
      "          [-1.2000, -1.2000,  0.3000]],\n",
      "\n",
      "         [[ 0.0000, -0.9000, -0.9000],\n",
      "          [ 0.0000, -0.6000, -0.9000],\n",
      "          [ 0.3000, -0.6000, -1.2000]],\n",
      "\n",
      "         [[ 0.9000,  0.3000, -1.2000],\n",
      "          [ 1.8000, -0.3000, -0.9000],\n",
      "          [-0.3000,  0.9000,  0.3000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3000, -1.2000, -1.8000],\n",
      "          [-0.6000,  0.3000, -0.3000],\n",
      "          [-0.3000, -0.3000, -1.2000]],\n",
      "\n",
      "         [[-0.3000,  1.2000,  0.9000],\n",
      "          [ 0.6000, -0.6000,  0.3000],\n",
      "          [-0.0000,  0.6000, -0.3000]],\n",
      "\n",
      "         [[-1.8000, -1.2000, -1.8000],\n",
      "          [ 0.0000, -0.6000, -0.6000],\n",
      "          [ 1.2000,  1.2000,  1.2000]]],\n",
      "\n",
      "\n",
      "        [[[-1.2000, -1.2000, -0.0000],\n",
      "          [ 0.3000,  0.6000,  0.9000],\n",
      "          [ 1.8000,  1.8000,  1.2000]],\n",
      "\n",
      "         [[-2.4000, -0.9000,  0.3000],\n",
      "          [-0.6000,  0.3000,  0.0000],\n",
      "          [ 0.0000, -0.6000,  0.3000]],\n",
      "\n",
      "         [[-1.8000, -2.4000, -0.3000],\n",
      "          [-1.2000, -0.3000, -0.9000],\n",
      "          [ 1.8000,  1.8000,  0.6000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.6000, -1.2000, -0.0000],\n",
      "          [-1.2000, -0.6000,  1.8000],\n",
      "          [-1.8000,  0.9000,  1.2000]],\n",
      "\n",
      "         [[-0.6000,  1.2000,  0.9000],\n",
      "          [ 0.9000,  0.3000, -1.2000],\n",
      "          [-1.2000, -1.2000, -0.6000]],\n",
      "\n",
      "         [[-1.2000, -1.2000, -0.6000],\n",
      "          [-1.2000, -0.3000, -0.0000],\n",
      "          [ 0.3000,  0.6000, -0.0000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.6000,  0.0000, -0.3000],\n",
      "          [ 0.9000,  0.3000, -1.2000],\n",
      "          [-1.2000, -1.2000, -2.4000]],\n",
      "\n",
      "         [[ 0.6000,  0.9000,  1.2000],\n",
      "          [ 0.9000,  1.2000,  0.9000],\n",
      "          [ 1.8000,  0.6000, -1.2000]],\n",
      "\n",
      "         [[ 0.3000,  0.0000, -0.6000],\n",
      "          [ 2.4000,  3.0000,  0.9000],\n",
      "          [-0.9000, -0.6000, -0.6000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.9000,  1.2000,  0.3000],\n",
      "          [ 0.3000,  1.2000, -0.3000],\n",
      "          [ 1.8000,  0.9000, -0.3000]],\n",
      "\n",
      "         [[-0.9000, -0.3000,  0.3000],\n",
      "          [-1.2000,  0.9000,  0.9000],\n",
      "          [-1.2000, -0.3000,  0.3000]],\n",
      "\n",
      "         [[ 1.8000,  1.2000, -0.0000],\n",
      "          [-0.9000, -0.9000, -0.9000],\n",
      "          [-1.2000, -0.9000, -0.6000]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2000,  1.2000, -1.2000],\n",
      "          [ 1.8000,  0.6000, -1.8000],\n",
      "          [ 0.9000,  0.3000, -1.8000]],\n",
      "\n",
      "         [[-1.2000, -1.8000, -1.8000],\n",
      "          [ 0.0000, -0.3000,  0.3000],\n",
      "          [ 0.6000,  1.2000,  1.2000]],\n",
      "\n",
      "         [[ 0.9000,  0.6000, -1.8000],\n",
      "          [ 2.4000,  0.0000, -2.4000],\n",
      "          [ 1.8000,  0.3000, -2.4000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.9000, -0.9000, -0.6000],\n",
      "          [-1.2000, -0.3000,  0.6000],\n",
      "          [-0.9000,  0.6000,  1.8000]],\n",
      "\n",
      "         [[ 0.0000, -0.6000,  0.3000],\n",
      "          [-0.6000,  0.3000,  0.0000],\n",
      "          [-0.6000, -0.3000, -0.6000]],\n",
      "\n",
      "         [[-0.0000, -0.3000, -0.9000],\n",
      "          [ 0.9000, -0.0000, -0.9000],\n",
      "          [ 0.9000,  0.3000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[-0.9000, -0.3000,  0.9000],\n",
      "          [-1.2000,  0.6000,  1.2000],\n",
      "          [-0.9000,  1.8000,  1.2000]],\n",
      "\n",
      "         [[-0.6000, -0.6000, -0.0000],\n",
      "          [ 1.2000, -0.0000, -0.3000],\n",
      "          [-0.3000, -1.2000, -0.6000]],\n",
      "\n",
      "         [[-0.9000,  0.9000,  1.2000],\n",
      "          [-3.0000,  2.4000, -1.8000],\n",
      "          [-1.8000,  0.6000, -3.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3000,  0.0000, -0.0000],\n",
      "          [ 0.0000, -0.0000, -0.3000],\n",
      "          [ 0.6000, -1.2000, -0.0000]],\n",
      "\n",
      "         [[-1.2000,  1.2000,  0.0000],\n",
      "          [-0.0000,  1.2000, -0.0000],\n",
      "          [-0.6000, -0.0000, -0.9000]],\n",
      "\n",
      "         [[-0.3000, -0.3000, -0.0000],\n",
      "          [-0.6000,  0.3000,  0.6000],\n",
      "          [-1.2000, -0.0000,  0.0000]]]], device='cuda:0',\n",
      "       grad_fn=<_pqBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-0.9000]],\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.6000]]],\n",
      "\n",
      "\n",
      "        [[[-2.4000]],\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         [[ 1.8000]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2000]],\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[-0.3000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.9000]],\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         [[ 1.8000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[ 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.6000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[-1.2000]]],\n",
      "\n",
      "\n",
      "        [[[ 1.8000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 0.3000]]]], device='cuda:0', grad_fn=<_pqBackward>)\n",
      "tensor([[[[ 0.0000,  0.3000,  0.6000],\n",
      "          [-0.3000, -0.0000,  0.0000],\n",
      "          [-0.6000, -0.9000, -1.2000]],\n",
      "\n",
      "         [[-0.6000,  0.6000,  0.0000],\n",
      "          [-0.9000, -0.3000, -0.9000],\n",
      "          [ 0.3000,  1.2000, -0.0000]],\n",
      "\n",
      "         [[-0.0000, -0.6000, -0.3000],\n",
      "          [ 0.6000,  1.2000,  1.2000],\n",
      "          [ 0.6000,  0.0000, -0.6000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.6000,  0.3000,  0.3000],\n",
      "          [ 0.0000,  0.3000, -0.3000],\n",
      "          [-0.3000, -1.2000, -0.9000]],\n",
      "\n",
      "         [[ 0.0000, -0.3000,  0.3000],\n",
      "          [ 0.0000, -0.0000,  0.0000],\n",
      "          [ 0.3000,  0.6000,  1.2000]],\n",
      "\n",
      "         [[-1.8000, -1.8000, -1.8000],\n",
      "          [ 1.8000,  3.0000,  2.4000],\n",
      "          [-1.2000, -1.8000, -1.8000]]],\n",
      "\n",
      "\n",
      "        [[[-0.6000, -1.2000, -1.2000],\n",
      "          [-0.3000,  0.6000, -0.3000],\n",
      "          [-1.2000, -0.0000,  1.2000]],\n",
      "\n",
      "         [[-2.4000, -1.2000, -1.8000],\n",
      "          [-1.2000, -1.2000, -1.2000],\n",
      "          [ 3.0000,  3.0000,  3.0000]],\n",
      "\n",
      "         [[ 0.3000,  0.6000,  0.6000],\n",
      "          [-0.6000, -0.0000, -1.2000],\n",
      "          [-0.9000, -1.2000, -0.6000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3000, -0.3000, -0.9000],\n",
      "          [-0.3000, -0.3000, -0.9000],\n",
      "          [ 0.9000, -0.0000, -0.0000]],\n",
      "\n",
      "         [[ 1.2000, -0.3000,  0.9000],\n",
      "          [ 0.9000,  0.6000,  0.9000],\n",
      "          [ 1.8000,  1.8000,  1.8000]],\n",
      "\n",
      "         [[ 0.6000, -1.2000,  0.3000],\n",
      "          [-0.6000,  0.6000,  0.6000],\n",
      "          [ 1.8000,  1.8000,  1.8000]]],\n",
      "\n",
      "\n",
      "        [[[-0.0000,  0.3000,  0.3000],\n",
      "          [-0.3000,  0.6000, -0.0000],\n",
      "          [ 0.0000,  1.2000, -1.2000]],\n",
      "\n",
      "         [[-0.6000, -0.6000, -0.6000],\n",
      "          [ 0.6000, -0.6000, -0.9000],\n",
      "          [ 0.6000, -1.2000, -1.2000]],\n",
      "\n",
      "         [[ 0.9000,  0.0000, -1.2000],\n",
      "          [ 1.2000,  0.3000, -0.9000],\n",
      "          [ 1.8000,  0.3000, -0.3000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.8000, -0.9000, -0.9000],\n",
      "          [ 3.0000, -0.0000, -0.9000],\n",
      "          [ 3.0000,  1.2000, -1.2000]],\n",
      "\n",
      "         [[-1.2000, -0.3000,  0.3000],\n",
      "          [-0.3000, -0.3000, -0.0000],\n",
      "          [-1.2000, -1.2000,  0.0000]],\n",
      "\n",
      "         [[-2.4000, -1.2000,  0.6000],\n",
      "          [-0.3000,  0.3000,  0.3000],\n",
      "          [ 1.2000,  0.9000,  0.3000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 2.4000,  2.4000, -1.2000],\n",
      "          [ 0.3000,  0.9000,  2.4000],\n",
      "          [ 0.6000, -0.0000, -1.2000]],\n",
      "\n",
      "         [[-0.0000, -1.8000, -0.3000],\n",
      "          [ 0.3000,  1.8000, -0.9000],\n",
      "          [-0.9000,  0.9000,  1.8000]],\n",
      "\n",
      "         [[ 0.0000, -0.3000,  0.3000],\n",
      "          [-0.3000, -0.3000,  0.3000],\n",
      "          [ 0.6000,  1.2000, -0.6000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.8000,  0.6000, -0.9000],\n",
      "          [-1.2000,  1.2000,  0.3000],\n",
      "          [ 0.6000, -1.8000,  0.3000]],\n",
      "\n",
      "         [[-0.0000,  1.8000,  0.6000],\n",
      "          [-0.3000, -0.0000,  1.2000],\n",
      "          [ 0.9000,  0.3000,  0.6000]],\n",
      "\n",
      "         [[ 0.3000,  2.4000, -2.4000],\n",
      "          [-2.4000, -0.6000,  1.8000],\n",
      "          [ 3.0000, -0.3000, -1.8000]]],\n",
      "\n",
      "\n",
      "        [[[-0.6000,  0.0000, -0.3000],\n",
      "          [ 0.6000,  0.9000,  0.0000],\n",
      "          [ 0.3000,  0.0000, -0.0000]],\n",
      "\n",
      "         [[ 0.3000, -1.2000, -0.6000],\n",
      "          [ 0.3000, -0.9000, -2.4000],\n",
      "          [ 0.9000,  1.8000, -0.6000]],\n",
      "\n",
      "         [[-0.6000, -1.2000,  0.9000],\n",
      "          [ 0.6000, -0.6000,  1.8000],\n",
      "          [ 0.3000, -0.9000,  0.6000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.2000, -2.4000, -1.8000],\n",
      "          [ 1.2000, -0.6000, -1.2000],\n",
      "          [ 1.2000,  0.6000,  0.9000]],\n",
      "\n",
      "         [[ 1.8000,  0.6000, -0.3000],\n",
      "          [ 0.0000,  1.2000, -0.3000],\n",
      "          [-0.0000,  0.3000, -0.0000]],\n",
      "\n",
      "         [[-0.6000,  0.3000,  0.3000],\n",
      "          [-0.3000, -0.0000,  0.3000],\n",
      "          [-0.9000, -0.9000,  1.2000]]],\n",
      "\n",
      "\n",
      "        [[[ 1.8000,  0.9000,  1.2000],\n",
      "          [ 1.8000,  0.3000,  0.9000],\n",
      "          [-0.6000, -1.2000,  1.2000]],\n",
      "\n",
      "         [[-0.3000,  0.6000,  0.0000],\n",
      "          [ 0.6000,  0.9000,  0.6000],\n",
      "          [ 0.3000,  1.2000, -0.6000]],\n",
      "\n",
      "         [[-0.6000,  0.0000,  0.6000],\n",
      "          [-0.0000, -0.3000,  0.3000],\n",
      "          [-0.6000, -0.3000, -0.6000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.6000,  1.8000, -0.9000],\n",
      "          [-0.3000,  0.6000,  0.3000],\n",
      "          [-0.3000, -0.3000,  1.2000]],\n",
      "\n",
      "         [[ 0.0000, -0.6000, -0.0000],\n",
      "          [ 0.6000, -0.3000, -0.3000],\n",
      "          [-0.0000, -0.6000, -0.0000]],\n",
      "\n",
      "         [[ 0.9000, -1.8000,  0.3000],\n",
      "          [ 1.8000,  0.9000, -0.3000],\n",
      "          [-0.6000,  0.3000,  0.3000]]]], device='cuda:0',\n",
      "       grad_fn=<_pqBackward>)\n",
      "tensor([[[[-0.3000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[-2.4000]],\n",
      "\n",
      "         [[-0.9000]]],\n",
      "\n",
      "\n",
      "        [[[ 3.0000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[-0.3000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.6000]],\n",
      "\n",
      "         [[-1.8000]],\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.8000]],\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         [[-0.3000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[-0.3000]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2000]],\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[ 1.8000]],\n",
      "\n",
      "         [[ 1.2000]]],\n",
      "\n",
      "\n",
      "        [[[-0.0000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[-3.0000]],\n",
      "\n",
      "         [[ 3.0000]]]], device='cuda:0', grad_fn=<_pqBackward>)\n",
      "tensor([[[[ 0.6000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         [[-0.3000]]],\n",
      "\n",
      "\n",
      "        [[[ 1.8000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[ 0.6000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[-0.6000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.9000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[-0.6000]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.4000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[ 2.4000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.6000]],\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[-0.0000]]]], device='cuda:0', grad_fn=<_pqBackward>)\n",
      "tensor([[[[-0.6000, -0.9000,  0.3000],\n",
      "          [ 0.3000, -1.2000, -0.0000],\n",
      "          [ 0.9000,  0.3000,  0.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.9000,  0.0000],\n",
      "          [ 0.3000,  1.8000,  0.6000],\n",
      "          [-0.3000, -2.4000, -1.2000]],\n",
      "\n",
      "         [[-0.6000, -0.9000, -0.6000],\n",
      "          [-0.0000, -0.6000, -0.0000],\n",
      "          [ 0.9000,  0.9000,  0.3000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3000, -1.2000,  0.3000],\n",
      "          [-0.0000, -1.2000, -0.3000],\n",
      "          [ 1.8000,  1.8000,  0.9000]],\n",
      "\n",
      "         [[ 0.9000,  0.9000, -0.0000],\n",
      "          [ 0.0000,  0.0000, -0.6000],\n",
      "          [-0.3000, -1.2000, -0.9000]],\n",
      "\n",
      "         [[-0.6000, -0.6000,  0.0000],\n",
      "          [-0.0000,  0.3000, -0.3000],\n",
      "          [ 0.0000,  0.6000, -0.3000]]],\n",
      "\n",
      "\n",
      "        [[[-0.6000, -0.9000, -0.6000],\n",
      "          [-0.9000,  0.3000, -1.2000],\n",
      "          [-0.6000, -0.3000, -0.9000]],\n",
      "\n",
      "         [[-0.6000, -1.2000, -0.3000],\n",
      "          [ 1.2000, -1.2000,  1.2000],\n",
      "          [ 1.2000, -1.8000, -0.6000]],\n",
      "\n",
      "         [[-0.9000, -0.3000, -0.9000],\n",
      "          [-0.3000,  0.3000, -0.6000],\n",
      "          [-0.3000, -0.0000, -0.3000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.6000, -0.3000, -0.3000],\n",
      "          [ 0.6000,  1.2000, -0.3000],\n",
      "          [ 0.3000, -0.3000, -1.8000]],\n",
      "\n",
      "         [[-0.0000, -1.8000, -1.2000],\n",
      "          [ 0.9000, -1.2000,  0.3000],\n",
      "          [-1.2000, -2.4000, -0.6000]],\n",
      "\n",
      "         [[-0.6000, -0.3000, -0.3000],\n",
      "          [-0.3000, -0.3000,  0.6000],\n",
      "          [ 0.3000,  0.0000,  0.6000]]],\n",
      "\n",
      "\n",
      "        [[[-0.3000, -0.6000, -0.6000],\n",
      "          [-1.8000, -1.2000, -1.2000],\n",
      "          [-0.9000, -0.3000, -0.6000]],\n",
      "\n",
      "         [[-0.6000, -0.3000, -0.3000],\n",
      "          [-1.8000, -1.2000, -0.9000],\n",
      "          [-0.6000, -0.9000, -0.3000]],\n",
      "\n",
      "         [[-0.6000, -0.3000, -0.0000],\n",
      "          [-0.3000,  0.3000,  0.3000],\n",
      "          [-0.6000, -0.3000, -0.6000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.6000, -0.9000, -0.6000],\n",
      "          [-0.3000, -0.0000, -0.9000],\n",
      "          [-0.9000, -0.6000, -1.2000]],\n",
      "\n",
      "         [[ 0.6000,  0.3000,  0.6000],\n",
      "          [-0.6000, -0.3000,  0.6000],\n",
      "          [-1.2000, -0.0000,  0.6000]],\n",
      "\n",
      "         [[-0.9000, -0.6000, -0.3000],\n",
      "          [-0.3000,  0.3000,  0.9000],\n",
      "          [ 0.0000,  0.6000,  0.3000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.6000, -0.0000, -0.0000],\n",
      "          [-0.3000, -1.2000, -0.9000],\n",
      "          [ 0.3000, -0.3000, -0.6000]],\n",
      "\n",
      "         [[-0.3000, -0.3000, -0.3000],\n",
      "          [ 0.6000,  0.0000,  0.9000],\n",
      "          [-0.6000, -0.9000, -0.9000]],\n",
      "\n",
      "         [[ 0.6000,  0.6000,  0.3000],\n",
      "          [-0.6000, -0.9000, -0.6000],\n",
      "          [-0.6000, -0.6000, -0.6000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0000,  0.3000,  0.3000],\n",
      "          [-0.6000, -0.9000, -0.3000],\n",
      "          [ 0.3000, -0.3000, -0.3000]],\n",
      "\n",
      "         [[-0.0000,  1.2000,  0.3000],\n",
      "          [ 0.6000,  0.0000, -0.0000],\n",
      "          [-0.6000, -1.2000, -0.0000]],\n",
      "\n",
      "         [[ 1.2000,  1.2000,  1.2000],\n",
      "          [-0.3000, -0.9000, -0.9000],\n",
      "          [-0.9000, -0.9000, -0.9000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.6000, -0.3000, -0.3000],\n",
      "          [-0.3000,  1.2000, -0.9000],\n",
      "          [-0.6000, -0.6000, -0.9000]],\n",
      "\n",
      "         [[ 0.9000, -0.0000,  1.2000],\n",
      "          [ 1.8000, -0.6000,  1.2000],\n",
      "          [ 0.3000,  0.0000,  0.3000]],\n",
      "\n",
      "         [[-0.0000,  0.3000, -0.3000],\n",
      "          [-0.0000,  1.2000, -0.6000],\n",
      "          [-0.3000, -0.0000, -0.6000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.8000,  0.0000, -1.2000],\n",
      "          [-1.2000,  2.4000, -0.6000],\n",
      "          [-0.9000,  0.6000, -1.2000]],\n",
      "\n",
      "         [[ 1.2000,  0.3000, -0.0000],\n",
      "          [ 0.9000, -1.2000, -0.3000],\n",
      "          [ 0.6000, -0.3000,  0.6000]],\n",
      "\n",
      "         [[-0.9000,  1.2000,  0.3000],\n",
      "          [ 0.3000,  0.0000, -0.0000],\n",
      "          [ 0.3000, -0.3000, -0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3000,  0.9000,  0.6000],\n",
      "          [-1.8000, -0.9000,  3.0000],\n",
      "          [-0.3000, -0.9000,  0.0000]],\n",
      "\n",
      "         [[ 0.3000,  0.0000, -0.9000],\n",
      "          [ 1.8000,  0.3000, -1.2000],\n",
      "          [ 1.2000, -0.6000, -1.2000]],\n",
      "\n",
      "         [[ 0.6000,  0.9000,  0.3000],\n",
      "          [-1.2000, -0.3000,  2.4000],\n",
      "          [-0.6000, -0.3000,  0.9000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0000,  1.2000,  0.0000],\n",
      "          [-3.0000, -0.3000,  3.0000],\n",
      "          [-1.2000, -0.0000,  1.8000]],\n",
      "\n",
      "         [[ 0.3000,  0.0000,  0.0000],\n",
      "          [ 0.6000,  0.3000, -0.9000],\n",
      "          [ 1.2000,  0.9000, -0.6000]],\n",
      "\n",
      "         [[-0.9000, -0.0000,  1.2000],\n",
      "          [-0.6000,  0.0000,  1.2000],\n",
      "          [-0.3000, -0.3000,  0.6000]]]], device='cuda:0',\n",
      "       grad_fn=<_pqBackward>)\n",
      "tensor([[[[-0.0000]],\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[-1.8000]],\n",
      "\n",
      "         [[-0.6000]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[-0.9000]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.8000]],\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         [[-0.6000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.6000]],\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[ 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[-0.9000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.8000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[-1.8000]]],\n",
      "\n",
      "\n",
      "        [[[-0.6000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[-0.6000]]]], device='cuda:0', grad_fn=<_pqBackward>)\n",
      "tensor([[[[ 0.3000,  0.3000, -0.6000],\n",
      "          [ 0.3000,  0.9000,  0.9000],\n",
      "          [ 0.0000,  0.9000,  1.2000]],\n",
      "\n",
      "         [[ 0.6000,  0.6000, -0.6000],\n",
      "          [-0.3000, -1.2000, -0.6000],\n",
      "          [ 0.6000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.3000, -0.3000],\n",
      "          [ 0.9000,  0.3000,  0.3000],\n",
      "          [ 0.3000, -0.0000,  0.6000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3000,  0.6000,  1.2000],\n",
      "          [ 0.3000,  0.6000,  0.0000],\n",
      "          [-0.6000,  0.0000, -0.0000]],\n",
      "\n",
      "         [[-1.2000, -1.2000, -1.2000],\n",
      "          [ 0.6000,  1.2000,  0.3000],\n",
      "          [-0.3000,  1.2000,  1.2000]],\n",
      "\n",
      "         [[-1.2000, -3.0000, -1.2000],\n",
      "          [ 1.2000,  1.8000,  1.2000],\n",
      "          [ 0.6000,  1.8000,  1.8000]]],\n",
      "\n",
      "\n",
      "        [[[-0.6000, -0.9000, -0.9000],\n",
      "          [ 0.0000, -0.6000, -0.9000],\n",
      "          [ 1.8000,  2.4000,  1.2000]],\n",
      "\n",
      "         [[-0.0000,  0.3000,  1.8000],\n",
      "          [-0.9000, -1.2000,  0.9000],\n",
      "          [-0.6000, -0.6000,  0.3000]],\n",
      "\n",
      "         [[ 0.6000,  0.0000,  0.6000],\n",
      "          [-0.9000, -0.6000, -0.9000],\n",
      "          [ 0.0000,  0.0000, -0.3000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.9000, -0.3000,  0.6000],\n",
      "          [ 0.6000,  0.9000,  0.6000],\n",
      "          [-0.6000, -0.0000, -0.3000]],\n",
      "\n",
      "         [[-0.0000, -0.9000, -0.6000],\n",
      "          [-0.0000,  0.3000, -0.3000],\n",
      "          [-0.3000,  1.8000,  1.8000]],\n",
      "\n",
      "         [[ 1.8000,  1.2000,  1.2000],\n",
      "          [-0.3000,  0.6000,  0.6000],\n",
      "          [-2.4000, -0.9000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.3000, -1.2000],\n",
      "          [ 0.9000, -0.6000, -1.8000],\n",
      "          [-0.0000, -0.6000, -0.0000]],\n",
      "\n",
      "         [[-0.9000,  0.3000,  1.2000],\n",
      "          [-1.8000,  0.9000,  2.4000],\n",
      "          [ 0.3000,  0.9000,  0.3000]],\n",
      "\n",
      "         [[-1.2000, -1.2000, -0.6000],\n",
      "          [-0.0000,  0.6000,  0.9000],\n",
      "          [ 0.0000,  0.3000,  1.2000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.8000, -0.0000,  1.8000],\n",
      "          [-0.6000,  0.6000,  0.6000],\n",
      "          [ 0.3000,  1.2000,  1.2000]],\n",
      "\n",
      "         [[ 1.8000, -0.6000, -0.3000],\n",
      "          [ 1.8000, -0.9000, -1.8000],\n",
      "          [ 1.2000,  1.2000, -0.6000]],\n",
      "\n",
      "         [[-0.0000, -0.6000,  0.9000],\n",
      "          [ 0.6000,  0.3000,  0.6000],\n",
      "          [-1.2000,  0.3000, -0.3000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.9000,  1.2000,  0.3000],\n",
      "          [ 0.3000,  0.3000,  1.2000],\n",
      "          [-0.9000, -0.6000, -0.3000]],\n",
      "\n",
      "         [[-0.3000,  0.9000,  0.0000],\n",
      "          [-0.0000,  1.2000,  0.9000],\n",
      "          [-1.2000,  1.8000, -0.3000]],\n",
      "\n",
      "         [[ 0.3000,  0.9000,  1.8000],\n",
      "          [-0.6000,  1.2000,  3.0000],\n",
      "          [-2.4000,  0.6000,  0.9000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3000, -0.0000,  0.0000],\n",
      "          [ 0.3000,  0.0000,  0.6000],\n",
      "          [-0.3000, -0.9000,  0.9000]],\n",
      "\n",
      "         [[ 0.6000,  1.8000,  0.6000],\n",
      "          [-0.6000,  0.3000,  1.2000],\n",
      "          [-0.6000, -0.6000,  1.2000]],\n",
      "\n",
      "         [[ 2.4000,  0.6000, -1.2000],\n",
      "          [ 1.2000, -0.3000, -1.2000],\n",
      "          [-0.3000, -0.6000, -1.2000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.6000, -0.6000, -1.2000],\n",
      "          [ 0.6000, -0.0000, -0.9000],\n",
      "          [ 0.0000, -0.6000, -0.9000]],\n",
      "\n",
      "         [[ 0.3000,  1.8000,  2.4000],\n",
      "          [-0.6000, -0.3000,  1.8000],\n",
      "          [ 0.3000,  0.3000,  1.2000]],\n",
      "\n",
      "         [[ 0.3000, -0.3000,  0.0000],\n",
      "          [-0.9000, -1.2000, -0.3000],\n",
      "          [ 0.0000, -0.6000, -0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.6000, -0.0000, -1.2000],\n",
      "          [-0.3000,  0.6000, -1.2000],\n",
      "          [-0.9000, -0.3000, -1.8000]],\n",
      "\n",
      "         [[-0.9000, -0.6000, -1.8000],\n",
      "          [-0.3000,  1.2000, -0.3000],\n",
      "          [-1.2000, -0.3000, -0.9000]],\n",
      "\n",
      "         [[-0.6000, -0.6000, -0.3000],\n",
      "          [-0.3000, -0.3000,  0.9000],\n",
      "          [-1.8000, -1.2000, -1.2000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3000,  0.6000, -0.3000],\n",
      "          [-0.6000, -0.3000, -0.3000],\n",
      "          [-0.6000, -0.6000, -0.0000]],\n",
      "\n",
      "         [[-0.0000,  0.6000,  0.9000],\n",
      "          [ 0.6000,  0.6000,  0.9000],\n",
      "          [ 0.6000,  0.9000, -0.0000]],\n",
      "\n",
      "         [[ 0.9000,  0.9000,  0.6000],\n",
      "          [ 0.0000,  0.6000, -0.3000],\n",
      "          [-0.9000,  0.0000, -0.3000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.6000,  0.6000, -0.0000],\n",
      "          [ 0.6000,  1.2000,  0.3000],\n",
      "          [-0.6000, -0.0000, -0.6000]],\n",
      "\n",
      "         [[-0.3000, -0.3000, -0.9000],\n",
      "          [ 0.3000,  1.2000,  0.3000],\n",
      "          [-0.0000,  0.6000,  0.3000]],\n",
      "\n",
      "         [[ 0.3000,  0.3000, -0.0000],\n",
      "          [ 0.3000, -0.3000,  0.0000],\n",
      "          [-0.3000, -0.9000, -0.6000]]]], device='cuda:0',\n",
      "       grad_fn=<_pqBackward>)\n",
      "tensor([[[[ 0.9000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.8000]],\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         [[-0.9000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.6000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[-0.3000]]],\n",
      "\n",
      "\n",
      "        [[[-0.3000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.4000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 1.2000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.9000]],\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[-0.3000]]],\n",
      "\n",
      "\n",
      "        [[[-0.3000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.8000]],\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         [[ 1.2000]]],\n",
      "\n",
      "\n",
      "        [[[-1.2000]],\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[ 1.8000]],\n",
      "\n",
      "         [[ 1.2000]]]], device='cuda:0', grad_fn=<_pqBackward>)\n",
      "tensor([[[[-0.9000,  0.3000,  0.9000],\n",
      "          [-1.8000, -1.2000,  3.0000],\n",
      "          [-0.3000, -1.2000,  1.2000]],\n",
      "\n",
      "         [[ 0.3000, -0.3000, -0.9000],\n",
      "          [-0.6000, -0.3000,  1.8000],\n",
      "          [ 0.0000, -0.3000,  0.6000]],\n",
      "\n",
      "         [[-0.6000,  0.0000, -0.3000],\n",
      "          [ 1.2000,  1.2000, -2.4000],\n",
      "          [ 0.6000,  2.4000, -0.9000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.6000, -0.3000, -1.8000],\n",
      "          [ 1.8000,  0.9000, -1.8000],\n",
      "          [ 0.6000,  1.2000, -0.6000]],\n",
      "\n",
      "         [[ 0.6000, -0.0000, -1.2000],\n",
      "          [ 2.4000,  1.8000, -3.0000],\n",
      "          [ 0.3000,  3.0000, -0.9000]],\n",
      "\n",
      "         [[ 0.3000,  0.3000, -0.3000],\n",
      "          [ 0.6000,  1.8000, -1.8000],\n",
      "          [-0.6000,  1.8000, -0.9000]]],\n",
      "\n",
      "\n",
      "        [[[-0.6000, -0.6000,  0.9000],\n",
      "          [-1.8000, -1.2000,  1.2000],\n",
      "          [-0.9000,  0.3000,  1.8000]],\n",
      "\n",
      "         [[ 0.0000,  0.0000, -0.9000],\n",
      "          [ 0.3000, -0.0000, -1.2000],\n",
      "          [ 0.6000,  1.2000, -0.3000]],\n",
      "\n",
      "         [[ 0.9000,  0.9000, -1.2000],\n",
      "          [ 1.8000, -0.0000, -1.8000],\n",
      "          [ 0.6000,  0.3000, -0.3000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.2000, -0.0000, -0.9000],\n",
      "          [ 1.8000, -0.9000, -0.9000],\n",
      "          [ 0.9000, -0.6000, -0.3000]],\n",
      "\n",
      "         [[ 1.2000, -0.0000, -1.2000],\n",
      "          [ 3.0000, -0.6000, -1.8000],\n",
      "          [ 0.6000, -0.9000, -0.3000]],\n",
      "\n",
      "         [[ 1.2000, -0.3000, -1.2000],\n",
      "          [-0.3000,  0.0000, -0.3000],\n",
      "          [-1.2000, -0.6000,  0.9000]]],\n",
      "\n",
      "\n",
      "        [[[-1.2000, -0.6000, -0.0000],\n",
      "          [ 0.0000,  0.3000,  0.0000],\n",
      "          [ 0.9000,  0.0000, -0.0000]],\n",
      "\n",
      "         [[-0.3000, -0.3000, -0.6000],\n",
      "          [ 0.0000, -0.3000, -0.0000],\n",
      "          [ 0.9000, -0.6000,  0.9000]],\n",
      "\n",
      "         [[ 0.0000, -0.6000,  0.3000],\n",
      "          [ 0.3000, -1.2000,  0.6000],\n",
      "          [ 0.3000, -0.9000,  1.2000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0000, -0.6000,  0.3000],\n",
      "          [-0.3000, -0.6000,  0.0000],\n",
      "          [ 0.3000,  0.0000,  0.3000]],\n",
      "\n",
      "         [[-0.3000, -0.6000,  0.0000],\n",
      "          [ 0.3000, -0.6000,  0.9000],\n",
      "          [ 0.9000,  0.3000,  1.2000]],\n",
      "\n",
      "         [[ 2.4000,  2.4000,  1.2000],\n",
      "          [-0.6000, -1.2000, -0.6000],\n",
      "          [-1.8000, -3.0000, -1.8000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.3000, -0.3000, -0.3000],\n",
      "          [ 1.8000, -0.3000, -1.2000],\n",
      "          [ 0.6000, -0.3000, -0.6000]],\n",
      "\n",
      "         [[-0.0000,  0.3000,  0.3000],\n",
      "          [ 0.3000,  0.0000,  0.0000],\n",
      "          [ 0.3000, -0.3000, -0.0000]],\n",
      "\n",
      "         [[-1.2000,  0.3000,  0.3000],\n",
      "          [-1.2000,  1.2000,  1.8000],\n",
      "          [-0.6000,  1.2000,  0.3000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.9000,  0.3000,  1.2000],\n",
      "          [-1.2000,  0.3000,  3.0000],\n",
      "          [-0.9000, -0.3000,  0.9000]],\n",
      "\n",
      "         [[-1.8000, -0.0000,  1.2000],\n",
      "          [-2.4000,  0.6000,  3.0000],\n",
      "          [-0.3000,  0.9000,  1.2000]],\n",
      "\n",
      "         [[-1.2000, -0.9000, -0.6000],\n",
      "          [-1.2000,  0.3000,  0.9000],\n",
      "          [-1.2000, -0.3000,  0.6000]]],\n",
      "\n",
      "\n",
      "        [[[-0.6000,  0.6000,  0.0000],\n",
      "          [ 0.6000,  0.3000, -0.3000],\n",
      "          [ 0.9000,  0.6000,  0.6000]],\n",
      "\n",
      "         [[ 0.3000,  0.6000,  0.0000],\n",
      "          [ 0.0000, -0.3000, -0.9000],\n",
      "          [-0.3000, -0.3000, -0.6000]],\n",
      "\n",
      "         [[-1.8000, -1.2000, -0.9000],\n",
      "          [-0.6000,  0.9000,  0.6000],\n",
      "          [ 0.0000,  0.6000,  0.6000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3000,  0.6000, -0.3000],\n",
      "          [ 0.0000,  0.3000, -0.3000],\n",
      "          [ 0.0000,  0.3000,  0.6000]],\n",
      "\n",
      "         [[-1.2000, -1.2000, -1.2000],\n",
      "          [ 0.3000,  1.2000,  0.6000],\n",
      "          [ 1.8000,  2.4000,  1.8000]],\n",
      "\n",
      "         [[-0.6000, -0.9000, -1.2000],\n",
      "          [ 0.3000,  1.8000,  1.2000],\n",
      "          [ 0.3000,  1.2000,  0.9000]]],\n",
      "\n",
      "\n",
      "        [[[-0.3000, -1.2000,  0.6000],\n",
      "          [-0.9000, -0.6000, -0.0000],\n",
      "          [ 0.9000,  3.0000,  1.2000]],\n",
      "\n",
      "         [[-0.0000, -0.9000, -0.0000],\n",
      "          [ 0.0000, -0.6000, -0.0000],\n",
      "          [ 0.6000,  1.2000,  0.0000]],\n",
      "\n",
      "         [[ 0.9000,  3.0000,  0.9000],\n",
      "          [ 0.6000, -0.3000, -0.9000],\n",
      "          [-0.9000, -2.4000, -0.3000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3000,  1.8000,  0.3000],\n",
      "          [ 0.6000, -0.0000, -0.9000],\n",
      "          [-0.9000, -1.2000, -0.6000]],\n",
      "\n",
      "         [[ 1.2000,  3.0000,  1.2000],\n",
      "          [-0.3000, -0.3000, -1.2000],\n",
      "          [-1.2000, -3.0000, -0.6000]],\n",
      "\n",
      "         [[ 0.0000,  1.8000, -0.6000],\n",
      "          [-0.9000, -0.9000, -1.8000],\n",
      "          [-0.3000, -2.4000, -1.2000]]]], device='cuda:0',\n",
      "       grad_fn=<_pqBackward>)\n",
      "tensor([[[[ 0.9000]],\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[-0.3000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.6000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[-0.9000]]],\n",
      "\n",
      "\n",
      "        [[[-0.3000]],\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         [[ 0.3000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 1.8000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[-1.8000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[-1.2000]]],\n",
      "\n",
      "\n",
      "        [[[-1.2000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.4000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[-0.0000]]],\n",
      "\n",
      "\n",
      "        [[[-1.8000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.8000]],\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         [[-1.8000]]]], device='cuda:0', grad_fn=<_pqBackward>)\n",
      "tensor([[[[-0.0000, -0.9000, -0.9000],\n",
      "          [-0.3000, -1.2000, -0.0000],\n",
      "          [ 0.6000,  0.0000,  0.6000]],\n",
      "\n",
      "         [[-0.9000,  0.6000,  1.2000],\n",
      "          [-0.6000,  0.9000,  0.6000],\n",
      "          [ 0.6000,  1.8000,  0.3000]],\n",
      "\n",
      "         [[-1.8000, -3.0000, -0.9000],\n",
      "          [-1.8000, -1.2000,  1.2000],\n",
      "          [ 0.6000,  1.8000,  2.4000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.9000,  0.0000,  0.0000],\n",
      "          [ 0.3000,  0.6000,  0.3000],\n",
      "          [ 0.3000,  1.2000,  0.0000]],\n",
      "\n",
      "         [[-0.6000,  0.9000, -0.3000],\n",
      "          [ 0.3000,  0.6000, -0.3000],\n",
      "          [ 0.3000, -0.3000, -0.6000]],\n",
      "\n",
      "         [[ 0.9000, -0.9000, -1.8000],\n",
      "          [-1.8000, -2.4000,  0.6000],\n",
      "          [-0.9000,  0.6000,  1.8000]]],\n",
      "\n",
      "\n",
      "        [[[-0.3000, -0.0000,  0.9000],\n",
      "          [-0.9000, -0.9000,  0.6000],\n",
      "          [ 0.6000, -0.3000,  0.3000]],\n",
      "\n",
      "         [[ 0.3000,  0.3000, -0.9000],\n",
      "          [ 0.3000,  0.3000, -0.6000],\n",
      "          [-0.3000, -1.2000,  0.3000]],\n",
      "\n",
      "         [[ 1.8000,  0.0000, -0.3000],\n",
      "          [ 1.8000, -2.4000, -0.9000],\n",
      "          [-0.9000, -1.8000,  0.6000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0000, -0.6000, -0.6000],\n",
      "          [ 0.9000,  0.6000,  0.9000],\n",
      "          [ 1.2000, -0.3000, -0.3000]],\n",
      "\n",
      "         [[-1.2000, -0.9000,  0.0000],\n",
      "          [-1.2000,  0.9000,  0.0000],\n",
      "          [ 0.0000,  1.2000, -0.6000]],\n",
      "\n",
      "         [[-1.2000,  0.3000, -0.6000],\n",
      "          [ 1.2000,  1.2000, -0.3000],\n",
      "          [-0.6000,  0.0000,  1.2000]]],\n",
      "\n",
      "\n",
      "        [[[-0.6000,  0.3000,  1.8000],\n",
      "          [-0.9000,  1.2000,  1.2000],\n",
      "          [-1.2000,  0.3000,  0.3000]],\n",
      "\n",
      "         [[-0.9000,  0.6000, -0.9000],\n",
      "          [-0.9000, -0.6000,  0.3000],\n",
      "          [-0.0000, -0.6000, -0.9000]],\n",
      "\n",
      "         [[-0.3000, -3.0000,  1.2000],\n",
      "          [ 1.8000, -1.8000,  0.0000],\n",
      "          [ 2.4000, -0.6000,  0.3000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.2000, -0.6000, -0.9000],\n",
      "          [ 0.9000,  1.2000, -0.3000],\n",
      "          [-0.6000,  0.6000, -0.9000]],\n",
      "\n",
      "         [[ 0.6000,  1.2000,  0.9000],\n",
      "          [-0.6000,  0.0000,  0.3000],\n",
      "          [-0.6000, -1.8000, -0.6000]],\n",
      "\n",
      "         [[-1.2000, -0.6000,  0.6000],\n",
      "          [-0.9000, -0.3000, -0.0000],\n",
      "          [ 1.2000, -0.0000, -0.6000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.3000, -0.6000, -0.3000],\n",
      "          [-1.2000, -0.6000,  0.0000],\n",
      "          [-1.2000, -0.0000,  0.0000]],\n",
      "\n",
      "         [[ 1.2000,  1.8000,  0.6000],\n",
      "          [ 1.8000, -0.3000, -0.9000],\n",
      "          [ 1.2000, -0.6000, -1.2000]],\n",
      "\n",
      "         [[-0.0000, -1.2000, -1.8000],\n",
      "          [-1.2000, -0.6000,  0.0000],\n",
      "          [ 0.0000,  1.2000,  0.6000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.2000,  0.6000, -0.9000],\n",
      "          [ 0.3000, -0.9000, -1.2000],\n",
      "          [-0.6000, -0.9000, -0.9000]],\n",
      "\n",
      "         [[ 1.2000,  1.2000,  1.8000],\n",
      "          [ 1.2000,  0.0000,  0.3000],\n",
      "          [ 0.6000, -0.9000, -0.6000]],\n",
      "\n",
      "         [[-0.0000,  0.3000,  0.9000],\n",
      "          [ 0.6000, -0.6000, -0.0000],\n",
      "          [ 0.9000, -0.9000,  0.9000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3000,  0.3000, -1.2000],\n",
      "          [-1.2000, -0.3000,  0.3000],\n",
      "          [-1.2000, -0.6000,  1.2000]],\n",
      "\n",
      "         [[ 0.6000, -0.3000, -1.2000],\n",
      "          [ 1.2000,  0.6000,  0.3000],\n",
      "          [-0.6000, -0.6000,  0.3000]],\n",
      "\n",
      "         [[-0.6000, -2.4000,  0.9000],\n",
      "          [-1.8000, -2.4000,  2.4000],\n",
      "          [-1.2000, -0.9000,  3.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3000, -1.2000, -0.9000],\n",
      "          [ 0.9000,  0.9000,  0.9000],\n",
      "          [-0.9000,  0.9000,  0.9000]],\n",
      "\n",
      "         [[-0.9000,  0.9000,  0.6000],\n",
      "          [-0.0000, -0.0000, -0.3000],\n",
      "          [-0.6000, -0.6000,  0.0000]],\n",
      "\n",
      "         [[ 0.6000, -0.9000, -0.0000],\n",
      "          [ 1.8000,  1.8000, -0.9000],\n",
      "          [ 1.2000,  1.2000, -1.8000]]],\n",
      "\n",
      "\n",
      "        [[[-0.6000, -0.9000, -0.9000],\n",
      "          [ 2.4000,  0.3000, -0.3000],\n",
      "          [ 1.8000,  1.8000, -1.2000]],\n",
      "\n",
      "         [[ 0.3000,  0.0000,  0.9000],\n",
      "          [-0.3000,  0.3000,  1.2000],\n",
      "          [-0.9000,  0.6000,  1.2000]],\n",
      "\n",
      "         [[-0.0000, -0.9000,  0.6000],\n",
      "          [ 0.3000, -0.9000,  0.0000],\n",
      "          [ 1.2000,  0.6000,  0.9000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.8000,  2.4000,  2.4000],\n",
      "          [ 0.0000,  0.3000,  1.2000],\n",
      "          [-0.3000,  0.0000,  0.3000]],\n",
      "\n",
      "         [[ 0.9000,  3.0000,  1.2000],\n",
      "          [-0.9000,  1.2000, -0.0000],\n",
      "          [-1.2000, -0.3000, -0.9000]],\n",
      "\n",
      "         [[-1.2000, -0.9000,  1.2000],\n",
      "          [-1.8000,  0.3000,  2.4000],\n",
      "          [-1.8000,  0.3000,  1.8000]]]], device='cuda:0',\n",
      "       grad_fn=<_pqBackward>)\n",
      "tensor([[[[ 0.6000]],\n",
      "\n",
      "         [[-2.4000]],\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[-0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.6000]],\n",
      "\n",
      "         [[-1.8000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         [[ 0.6000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[ 0.6000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.6000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[-0.0000]]],\n",
      "\n",
      "\n",
      "        [[[-1.2000]],\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         [[-2.4000]]],\n",
      "\n",
      "\n",
      "        [[[-0.6000]],\n",
      "\n",
      "         [[ 1.8000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[-1.2000]]]], device='cuda:0', grad_fn=<_pqBackward>)\n",
      "tensor([[[[-0.9000,  0.3000,  0.3000],\n",
      "          [-0.0000,  0.0000, -0.3000],\n",
      "          [ 0.9000,  0.3000, -1.8000]],\n",
      "\n",
      "         [[-0.9000, -0.3000, -0.6000],\n",
      "          [-0.9000,  0.0000,  0.0000],\n",
      "          [-0.3000, -0.0000,  0.3000]],\n",
      "\n",
      "         [[ 0.6000,  0.9000,  0.6000],\n",
      "          [-0.0000, -0.6000,  0.6000],\n",
      "          [ 0.3000, -1.2000, -1.2000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.8000, -0.3000, -0.9000],\n",
      "          [ 0.0000,  0.9000, -0.9000],\n",
      "          [-1.8000, -0.6000,  0.3000]],\n",
      "\n",
      "         [[-0.9000, -1.2000, -1.2000],\n",
      "          [ 0.3000,  1.2000, -0.0000],\n",
      "          [ 0.0000,  1.2000,  0.9000]],\n",
      "\n",
      "         [[-3.0000, -2.4000, -0.9000],\n",
      "          [-1.8000,  0.6000,  3.0000],\n",
      "          [ 1.8000,  2.4000,  1.8000]]],\n",
      "\n",
      "\n",
      "        [[[-1.2000, -0.9000, -0.9000],\n",
      "          [-0.3000, -0.9000, -1.8000],\n",
      "          [-0.3000, -0.9000, -1.8000]],\n",
      "\n",
      "         [[-0.3000,  0.0000,  0.3000],\n",
      "          [-1.2000, -1.2000,  0.3000],\n",
      "          [-0.3000, -0.3000,  1.2000]],\n",
      "\n",
      "         [[-0.0000,  0.3000,  0.6000],\n",
      "          [ 0.3000, -0.0000, -0.3000],\n",
      "          [ 2.4000,  1.2000,  1.8000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.2000,  0.3000,  0.6000],\n",
      "          [ 0.9000,  0.3000,  0.6000],\n",
      "          [ 0.3000, -1.2000, -1.8000]],\n",
      "\n",
      "         [[-0.0000,  0.0000, -0.3000],\n",
      "          [ 0.0000,  0.6000,  0.0000],\n",
      "          [ 1.2000,  0.6000, -0.3000]],\n",
      "\n",
      "         [[ 2.4000, -0.6000, -1.2000],\n",
      "          [ 0.3000, -0.9000, -0.6000],\n",
      "          [-0.9000,  0.3000,  1.2000]]],\n",
      "\n",
      "\n",
      "        [[[-0.9000, -1.8000, -1.2000],\n",
      "          [-1.2000, -1.2000,  0.9000],\n",
      "          [-0.3000,  0.6000,  2.4000]],\n",
      "\n",
      "         [[-0.6000, -2.4000, -1.8000],\n",
      "          [-0.6000, -1.2000, -0.0000],\n",
      "          [-0.9000, -0.0000, -0.3000]],\n",
      "\n",
      "         [[ 0.0000,  0.6000, -0.3000],\n",
      "          [ 1.8000,  1.8000,  0.6000],\n",
      "          [ 1.2000, -0.6000, -0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.9000,  0.9000, -0.0000],\n",
      "          [-0.9000, -0.0000,  0.6000],\n",
      "          [ 0.9000, -0.0000, -1.2000]],\n",
      "\n",
      "         [[ 1.8000,  1.8000,  1.2000],\n",
      "          [-0.0000, -0.9000, -0.6000],\n",
      "          [ 0.6000,  0.3000, -0.9000]],\n",
      "\n",
      "         [[-0.3000, -0.6000,  0.6000],\n",
      "          [ 1.2000,  0.3000,  0.0000],\n",
      "          [-0.6000, -0.9000,  1.2000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.6000, -0.3000,  1.2000],\n",
      "          [ 0.6000,  0.6000,  1.2000],\n",
      "          [ 1.8000, -0.3000, -0.6000]],\n",
      "\n",
      "         [[ 1.2000,  0.3000,  0.3000],\n",
      "          [ 0.3000, -0.3000,  0.0000],\n",
      "          [ 0.3000, -0.3000,  0.6000]],\n",
      "\n",
      "         [[-0.3000, -0.3000, -0.9000],\n",
      "          [ 0.9000,  0.6000,  0.0000],\n",
      "          [ 0.3000, -0.0000, -0.9000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.9000, -0.3000, -0.6000],\n",
      "          [-0.6000,  0.9000,  0.3000],\n",
      "          [ 0.6000,  0.9000,  0.0000]],\n",
      "\n",
      "         [[ 0.9000,  0.0000,  0.3000],\n",
      "          [-0.3000, -0.6000,  0.3000],\n",
      "          [-0.3000,  1.2000,  1.8000]],\n",
      "\n",
      "         [[ 1.8000,  1.8000, -0.3000],\n",
      "          [ 0.6000, -0.0000, -1.2000],\n",
      "          [-0.9000, -1.8000, -1.2000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.6000, -0.3000, -0.9000],\n",
      "          [-0.3000, -0.3000,  1.8000],\n",
      "          [-0.3000,  0.0000,  0.3000]],\n",
      "\n",
      "         [[-0.9000, -1.2000, -1.8000],\n",
      "          [-1.2000, -0.6000,  0.6000],\n",
      "          [ 0.3000,  0.9000,  1.8000]],\n",
      "\n",
      "         [[-0.6000, -0.3000, -1.8000],\n",
      "          [-0.6000, -1.2000, -1.8000],\n",
      "          [ 0.6000, -0.0000,  1.2000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3000, -1.2000, -1.8000],\n",
      "          [ 2.4000,  0.3000, -0.9000],\n",
      "          [ 1.2000,  0.3000, -0.9000]],\n",
      "\n",
      "         [[ 0.6000,  1.8000,  0.3000],\n",
      "          [-0.9000, -0.6000,  0.3000],\n",
      "          [-0.9000, -1.2000,  0.0000]],\n",
      "\n",
      "         [[ 1.2000, -0.0000, -0.6000],\n",
      "          [ 0.0000,  0.3000, -1.2000],\n",
      "          [ 0.3000, -1.8000, -0.9000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.6000, -0.3000,  0.9000],\n",
      "          [-0.0000,  0.3000,  0.3000],\n",
      "          [-0.3000,  0.9000, -0.6000]],\n",
      "\n",
      "         [[-0.0000, -0.3000, -1.2000],\n",
      "          [-0.9000,  0.6000,  0.3000],\n",
      "          [-0.3000,  0.3000, -0.0000]],\n",
      "\n",
      "         [[-0.9000,  0.3000,  0.6000],\n",
      "          [-0.6000,  0.6000,  0.9000],\n",
      "          [-1.8000, -0.6000, -0.3000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.8000,  1.8000,  0.6000],\n",
      "          [-0.9000,  0.3000,  0.9000],\n",
      "          [-1.2000, -2.4000, -0.6000]],\n",
      "\n",
      "         [[-0.0000, -0.0000,  0.3000],\n",
      "          [-0.6000, -0.9000,  0.9000],\n",
      "          [-0.3000, -0.3000, -0.9000]],\n",
      "\n",
      "         [[-1.2000, -2.4000, -0.6000],\n",
      "          [ 0.9000, -1.2000, -0.3000],\n",
      "          [ 3.0000,  1.8000, -0.6000]]]], device='cuda:0',\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       grad_fn=<_pqBackward>)\n",
      "tensor([[[[ 1.2000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[-0.9000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.6000]],\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[-0.3000]]],\n",
      "\n",
      "\n",
      "        [[[-0.3000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[-0.3000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[ 0.3000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.9000]],\n",
      "\n",
      "         [[-1.8000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 0.3000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[ 0.3000]]]], device='cuda:0', grad_fn=<_pqBackward>)\n",
      "tensor([[[[ 0.9000, -0.6000, -0.9000],\n",
      "          [ 0.9000, -0.6000, -0.9000],\n",
      "          [ 0.6000, -0.9000, -1.8000]],\n",
      "\n",
      "         [[ 1.2000,  0.3000,  0.0000],\n",
      "          [ 2.4000,  1.8000, -0.0000],\n",
      "          [ 0.3000,  2.4000, -0.3000]],\n",
      "\n",
      "         [[-1.2000, -0.9000, -1.2000],\n",
      "          [-0.6000, -0.6000, -1.8000],\n",
      "          [-1.2000, -0.9000, -1.8000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.8000, -0.6000, -0.6000],\n",
      "          [-0.0000,  1.2000, -0.6000],\n",
      "          [ 0.9000,  3.0000,  0.0000]],\n",
      "\n",
      "         [[-0.6000, -0.6000,  0.3000],\n",
      "          [ 1.2000,  1.2000,  0.6000],\n",
      "          [ 0.9000,  0.6000,  0.9000]],\n",
      "\n",
      "         [[-0.6000,  0.9000, -1.8000],\n",
      "          [ 1.2000,  1.8000, -0.6000],\n",
      "          [ 0.6000,  0.9000, -0.6000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3000,  1.8000,  1.8000],\n",
      "          [-0.3000,  0.6000, -0.0000],\n",
      "          [ 0.3000, -1.2000, -2.4000]],\n",
      "\n",
      "         [[-0.6000,  2.4000,  2.4000],\n",
      "          [ 1.2000,  0.6000,  0.6000],\n",
      "          [ 0.9000, -0.9000, -0.3000]],\n",
      "\n",
      "         [[-1.2000, -0.9000,  0.6000],\n",
      "          [-0.6000, -0.3000,  0.3000],\n",
      "          [-0.6000,  0.6000, -0.3000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.2000, -0.3000,  0.3000],\n",
      "          [ 0.3000, -0.6000, -0.6000],\n",
      "          [ 0.3000, -0.6000, -0.6000]],\n",
      "\n",
      "         [[-0.0000, -0.3000,  1.8000],\n",
      "          [-1.2000, -0.3000,  1.8000],\n",
      "          [ 0.0000,  0.9000,  0.0000]],\n",
      "\n",
      "         [[ 1.2000,  0.6000,  1.2000],\n",
      "          [-0.6000, -1.2000, -0.6000],\n",
      "          [-1.8000, -1.2000, -0.6000]]],\n",
      "\n",
      "\n",
      "        [[[-0.6000,  1.8000,  0.3000],\n",
      "          [-0.0000,  0.6000, -0.9000],\n",
      "          [ 0.0000, -0.9000, -0.0000]],\n",
      "\n",
      "         [[ 1.2000, -0.6000, -1.2000],\n",
      "          [ 0.6000, -0.6000,  0.3000],\n",
      "          [-1.2000,  0.3000,  1.2000]],\n",
      "\n",
      "         [[ 0.3000,  0.3000,  1.8000],\n",
      "          [-0.3000,  0.6000,  0.6000],\n",
      "          [-0.0000,  0.6000, -0.6000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3000, -1.2000, -0.9000],\n",
      "          [-0.6000,  0.3000,  0.6000],\n",
      "          [-0.3000,  1.2000,  0.9000]],\n",
      "\n",
      "         [[-1.2000,  0.3000,  0.6000],\n",
      "          [-0.3000,  0.9000, -0.3000],\n",
      "          [ 0.9000, -1.2000, -1.8000]],\n",
      "\n",
      "         [[-0.3000, -0.3000, -0.3000],\n",
      "          [-0.3000, -0.9000, -0.9000],\n",
      "          [-1.2000, -1.2000, -0.3000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.6000,  1.2000,  0.6000],\n",
      "          [-0.3000,  1.2000,  1.2000],\n",
      "          [-1.2000, -0.6000, -0.0000]],\n",
      "\n",
      "         [[ 2.4000,  0.0000,  0.0000],\n",
      "          [ 2.4000, -0.6000, -0.3000],\n",
      "          [ 0.6000, -0.6000, -0.3000]],\n",
      "\n",
      "         [[ 1.2000,  1.2000, -0.6000],\n",
      "          [ 1.8000, -0.0000, -0.3000],\n",
      "          [ 0.0000, -0.3000, -0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.6000, -0.9000,  0.0000],\n",
      "          [-0.3000, -1.8000,  1.2000],\n",
      "          [-0.6000, -0.9000,  1.2000]],\n",
      "\n",
      "         [[-0.6000,  1.8000,  1.2000],\n",
      "          [-1.2000,  0.6000,  1.2000],\n",
      "          [-2.4000, -0.9000,  0.3000]],\n",
      "\n",
      "         [[ 0.6000,  0.3000, -1.2000],\n",
      "          [ 1.8000,  0.3000, -0.3000],\n",
      "          [-0.3000, -0.9000, -0.9000]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2000, -0.0000, -0.9000],\n",
      "          [-0.3000, -1.8000, -0.0000],\n",
      "          [-0.3000,  0.3000,  1.2000]],\n",
      "\n",
      "         [[-1.2000, -0.3000,  0.9000],\n",
      "          [-1.2000, -0.9000,  0.3000],\n",
      "          [-0.9000,  0.0000, -0.3000]],\n",
      "\n",
      "         [[-0.9000, -0.9000, -0.9000],\n",
      "          [-0.0000, -0.6000, -0.6000],\n",
      "          [ 0.0000,  0.3000,  0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3000,  0.3000, -0.6000],\n",
      "          [-0.6000, -0.3000, -0.3000],\n",
      "          [ 1.2000,  1.8000,  1.2000]],\n",
      "\n",
      "         [[ 1.8000,  0.3000, -0.6000],\n",
      "          [ 1.8000, -0.3000,  0.3000],\n",
      "          [ 1.8000,  0.3000,  0.9000]],\n",
      "\n",
      "         [[-0.6000, -0.3000, -0.9000],\n",
      "          [-0.9000, -0.6000, -0.6000],\n",
      "          [-0.3000, -1.2000, -0.3000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.9000, -0.9000, -0.9000],\n",
      "          [ 1.2000, -0.3000, -1.2000],\n",
      "          [ 0.6000, -0.9000, -0.9000]],\n",
      "\n",
      "         [[ 0.3000,  0.0000, -1.2000],\n",
      "          [ 0.9000, -0.0000, -1.2000],\n",
      "          [ 0.9000,  0.3000, -1.2000]],\n",
      "\n",
      "         [[-0.9000, -0.3000,  0.9000],\n",
      "          [ 0.9000,  0.6000,  1.8000],\n",
      "          [ 0.9000, -0.9000, -0.9000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0000,  0.3000, -0.6000],\n",
      "          [-0.6000,  1.2000, -0.9000],\n",
      "          [-0.0000,  1.8000,  0.3000]],\n",
      "\n",
      "         [[ 0.9000, -1.2000, -0.6000],\n",
      "          [ 0.9000,  0.3000, -0.9000],\n",
      "          [ 1.2000, -0.6000, -1.2000]],\n",
      "\n",
      "         [[-1.8000, -0.6000,  0.9000],\n",
      "          [-0.9000,  0.3000,  3.0000],\n",
      "          [-0.6000, -1.2000,  0.0000]]]], device='cuda:0',\n",
      "       grad_fn=<_pqBackward>)\n",
      "tensor([[[[ 1.2000]],\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[-2.4000]]],\n",
      "\n",
      "\n",
      "        [[[-0.9000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.4000]],\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         [[-2.4000]]],\n",
      "\n",
      "\n",
      "        [[[-0.3000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[-1.8000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.6000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         [[ 2.4000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3000]],\n",
      "\n",
      "         [[-1.8000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[-0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[ 0.9000]]]], device='cuda:0', grad_fn=<_pqBackward>)\n",
      "tensor([[[[-0.3000, -0.3000,  0.3000],\n",
      "          [-0.3000, -0.9000, -1.2000],\n",
      "          [-0.3000,  0.6000, -0.6000]],\n",
      "\n",
      "         [[ 2.4000,  2.4000,  2.4000],\n",
      "          [ 0.3000, -0.0000,  0.9000],\n",
      "          [ 0.6000, -0.3000,  0.9000]],\n",
      "\n",
      "         [[ 0.3000,  0.9000,  1.8000],\n",
      "          [-1.8000, -0.0000,  0.3000],\n",
      "          [-1.2000,  0.0000, -0.9000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.8000,  1.8000,  1.2000],\n",
      "          [ 1.2000,  1.8000,  1.8000],\n",
      "          [-0.9000, -0.9000, -0.3000]],\n",
      "\n",
      "         [[ 0.3000,  0.9000,  1.2000],\n",
      "          [-0.0000,  0.0000,  0.0000],\n",
      "          [-0.3000, -0.3000, -0.0000]],\n",
      "\n",
      "         [[-0.3000, -1.2000, -0.6000],\n",
      "          [ 1.2000,  0.3000, -0.3000],\n",
      "          [ 1.8000,  0.6000,  0.9000]]],\n",
      "\n",
      "\n",
      "        [[[-0.0000, -0.0000, -1.2000],\n",
      "          [-1.2000, -0.9000, -0.3000],\n",
      "          [-1.2000,  0.0000,  0.6000]],\n",
      "\n",
      "         [[-0.3000, -1.2000, -0.9000],\n",
      "          [-1.8000, -1.8000, -0.0000],\n",
      "          [ 0.9000,  0.6000,  2.4000]],\n",
      "\n",
      "         [[-0.0000, -0.6000, -0.9000],\n",
      "          [ 0.0000, -1.2000,  0.9000],\n",
      "          [-0.3000,  0.6000,  1.2000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.6000, -0.0000, -0.3000],\n",
      "          [-1.2000, -0.9000, -1.2000],\n",
      "          [-0.6000, -0.3000, -1.2000]],\n",
      "\n",
      "         [[ 0.3000,  0.6000,  0.3000],\n",
      "          [-1.2000, -0.3000, -1.2000],\n",
      "          [-2.4000, -1.8000, -1.8000]],\n",
      "\n",
      "         [[ 0.3000, -1.2000, -0.0000],\n",
      "          [ 0.3000,  0.3000,  0.6000],\n",
      "          [ 0.6000,  0.3000,  0.3000]]],\n",
      "\n",
      "\n",
      "        [[[ 1.8000,  0.9000,  0.9000],\n",
      "          [ 0.3000, -0.3000, -0.3000],\n",
      "          [-0.6000, -0.9000, -0.3000]],\n",
      "\n",
      "         [[ 1.8000,  2.4000,  2.4000],\n",
      "          [-0.3000, -0.0000, -0.3000],\n",
      "          [-0.9000,  3.0000, -0.3000]],\n",
      "\n",
      "         [[-0.6000, -0.6000,  0.9000],\n",
      "          [-0.9000, -0.0000,  0.9000],\n",
      "          [-1.8000,  1.8000,  0.9000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3000, -0.0000, -0.0000],\n",
      "          [-0.3000,  1.2000, -1.2000],\n",
      "          [-2.4000, -0.3000, -2.4000]],\n",
      "\n",
      "         [[ 0.0000, -0.6000, -0.3000],\n",
      "          [-0.0000, -1.2000, -0.6000],\n",
      "          [ 0.3000,  0.6000, -0.9000]],\n",
      "\n",
      "         [[ 1.8000,  2.4000,  1.2000],\n",
      "          [-0.0000,  0.9000, -0.6000],\n",
      "          [-0.0000, -2.4000, -0.3000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0000, -0.6000,  0.6000],\n",
      "          [-0.9000, -0.6000,  0.9000],\n",
      "          [ 0.0000,  0.3000,  0.0000]],\n",
      "\n",
      "         [[-0.9000, -0.0000, -0.0000],\n",
      "          [-1.2000,  0.3000,  0.6000],\n",
      "          [ 0.9000,  0.6000,  0.3000]],\n",
      "\n",
      "         [[-0.6000, -0.3000, -0.6000],\n",
      "          [ 1.2000, -0.6000, -1.8000],\n",
      "          [ 0.3000, -0.6000, -0.3000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.8000, -1.2000, -0.3000],\n",
      "          [-0.3000,  0.0000,  0.0000],\n",
      "          [ 0.9000,  0.6000, -0.3000]],\n",
      "\n",
      "         [[-1.2000,  1.2000, -0.6000],\n",
      "          [-1.8000, -0.3000,  0.0000],\n",
      "          [-0.3000, -0.9000, -0.6000]],\n",
      "\n",
      "         [[ 0.3000, -0.6000, -0.6000],\n",
      "          [ 1.2000,  0.6000,  0.3000],\n",
      "          [ 0.6000,  1.8000,  1.2000]]],\n",
      "\n",
      "\n",
      "        [[[-0.6000, -0.9000, -0.9000],\n",
      "          [ 0.9000, -0.6000,  0.6000],\n",
      "          [ 1.8000, -1.8000, -1.8000]],\n",
      "\n",
      "         [[ 0.0000,  3.0000, -0.0000],\n",
      "          [ 0.3000,  3.0000, -1.2000],\n",
      "          [-1.8000,  0.9000,  0.0000]],\n",
      "\n",
      "         [[-2.4000, -1.8000, -1.8000],\n",
      "          [ 0.0000, -1.2000,  1.2000],\n",
      "          [-0.9000, -0.9000,  0.9000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.9000,  0.9000, -1.2000],\n",
      "          [-1.8000, -0.9000, -1.2000],\n",
      "          [-0.9000, -0.3000, -0.3000]],\n",
      "\n",
      "         [[ 0.6000,  0.0000,  0.3000],\n",
      "          [-0.9000, -0.3000, -0.6000],\n",
      "          [-0.6000,  0.3000,  0.3000]],\n",
      "\n",
      "         [[-0.3000,  0.3000,  1.8000],\n",
      "          [ 0.0000, -0.0000,  2.4000],\n",
      "          [-0.9000, -0.9000,  0.9000]]],\n",
      "\n",
      "\n",
      "        [[[ 3.0000,  0.6000, -2.4000],\n",
      "          [ 0.6000,  1.8000,  0.9000],\n",
      "          [-1.8000, -1.8000,  0.3000]],\n",
      "\n",
      "         [[ 0.9000,  0.3000, -0.6000],\n",
      "          [ 0.3000,  0.3000, -0.9000],\n",
      "          [-0.6000, -0.9000, -0.9000]],\n",
      "\n",
      "         [[-0.6000,  1.2000,  3.0000],\n",
      "          [-0.9000, -0.0000,  1.2000],\n",
      "          [-1.8000, -0.9000, -0.3000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.2000, -0.3000,  1.2000],\n",
      "          [ 0.9000,  0.0000,  0.3000],\n",
      "          [ 0.3000,  0.0000, -0.3000]],\n",
      "\n",
      "         [[-0.0000, -1.8000,  0.3000],\n",
      "          [ 1.2000, -0.9000, -0.9000],\n",
      "          [ 1.8000,  2.4000,  0.9000]],\n",
      "\n",
      "         [[ 1.2000,  1.8000,  0.6000],\n",
      "          [-0.0000, -0.3000,  0.3000],\n",
      "          [-0.6000,  0.0000, -0.6000]]]], device='cuda:0',\n",
      "       grad_fn=<_pqBackward>)\n",
      "tensor([[[[-0.9000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[-3.0000]]],\n",
      "\n",
      "\n",
      "        [[[-1.2000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[ 0.6000]]],\n",
      "\n",
      "\n",
      "        [[[-0.6000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         [[ 0.6000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-1.2000]],\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[-0.6000]]],\n",
      "\n",
      "\n",
      "        [[[-0.9000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[-3.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[-1.2000]]],\n",
      "\n",
      "\n",
      "        [[[-1.2000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[-1.8000]]]], device='cuda:0', grad_fn=<_pqBackward>)\n",
      "tensor([[[[ 0.6000,  0.6000,  0.9000],\n",
      "          [ 1.2000, -0.3000, -0.6000],\n",
      "          [-0.9000, -0.9000, -0.9000]],\n",
      "\n",
      "         [[ 0.6000, -0.0000, -0.6000],\n",
      "          [ 0.3000,  0.3000,  0.9000],\n",
      "          [-1.2000,  1.8000,  0.3000]],\n",
      "\n",
      "         [[ 0.3000,  1.8000,  1.2000],\n",
      "          [ 2.4000,  0.3000, -1.2000],\n",
      "          [ 1.2000, -1.8000, -1.2000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3000, -1.2000, -1.2000],\n",
      "          [-0.6000,  0.3000, -0.3000],\n",
      "          [ 1.8000,  0.9000,  0.3000]],\n",
      "\n",
      "         [[ 0.6000, -2.4000, -0.6000],\n",
      "          [-1.2000,  0.0000,  1.2000],\n",
      "          [-0.6000,  1.2000, -0.0000]],\n",
      "\n",
      "         [[ 0.3000, -0.3000, -0.6000],\n",
      "          [ 0.0000,  0.9000,  1.8000],\n",
      "          [-0.3000,  0.6000,  0.3000]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2000,  1.8000,  0.3000],\n",
      "          [-0.3000,  0.6000,  0.6000],\n",
      "          [-0.9000,  0.3000,  0.3000]],\n",
      "\n",
      "         [[ 0.9000, -0.3000, -0.9000],\n",
      "          [-1.2000, -0.9000, -0.9000],\n",
      "          [ 0.6000,  1.2000,  1.8000]],\n",
      "\n",
      "         [[-0.6000, -0.6000, -0.0000],\n",
      "          [-0.9000, -0.3000, -0.6000],\n",
      "          [-0.9000,  0.0000,  0.9000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.9000, -0.6000, -1.8000],\n",
      "          [ 0.9000,  0.0000, -0.0000],\n",
      "          [ 1.8000,  0.3000,  1.2000]],\n",
      "\n",
      "         [[-0.0000, -0.6000, -0.6000],\n",
      "          [-0.0000, -1.8000, -1.2000],\n",
      "          [ 0.9000,  0.9000,  0.3000]],\n",
      "\n",
      "         [[-0.3000, -0.9000, -1.2000],\n",
      "          [-0.3000, -1.2000,  0.3000],\n",
      "          [ 1.8000,  1.8000,  2.4000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3000,  0.3000,  1.2000],\n",
      "          [ 0.9000,  1.2000,  1.2000],\n",
      "          [ 2.4000,  2.4000,  1.2000]],\n",
      "\n",
      "         [[-0.6000, -1.2000, -0.6000],\n",
      "          [ 0.3000, -0.3000, -0.3000],\n",
      "          [ 0.9000, -0.3000, -0.0000]],\n",
      "\n",
      "         [[-1.8000, -1.8000, -0.9000],\n",
      "          [-0.9000, -0.0000,  2.4000],\n",
      "          [ 1.2000,  1.8000,  1.8000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.6000, -0.3000, -0.3000],\n",
      "          [ 0.9000,  0.6000,  0.3000],\n",
      "          [ 0.9000, -0.0000, -0.9000]],\n",
      "\n",
      "         [[ 0.9000,  0.9000,  1.8000],\n",
      "          [-0.0000, -0.3000,  0.9000],\n",
      "          [-0.3000, -0.6000,  0.0000]],\n",
      "\n",
      "         [[-0.0000, -0.3000, -0.6000],\n",
      "          [ 0.6000, -0.9000, -0.3000],\n",
      "          [ 0.6000, -1.2000, -0.6000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 1.2000,  1.2000,  1.2000],\n",
      "          [ 0.3000,  1.2000,  0.3000],\n",
      "          [-1.2000, -1.2000, -2.4000]],\n",
      "\n",
      "         [[ 0.6000,  1.2000,  1.2000],\n",
      "          [-0.0000,  0.3000,  0.3000],\n",
      "          [-0.3000, -0.6000, -0.6000]],\n",
      "\n",
      "         [[-0.9000, -1.8000, -0.9000],\n",
      "          [-0.0000, -0.0000,  0.6000],\n",
      "          [ 0.3000,  1.2000,  1.2000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3000,  0.3000,  0.6000],\n",
      "          [ 0.3000,  0.6000, -0.6000],\n",
      "          [ 0.6000,  0.0000, -1.2000]],\n",
      "\n",
      "         [[ 2.4000,  1.8000,  1.2000],\n",
      "          [ 0.3000,  0.3000,  0.3000],\n",
      "          [-1.2000, -1.8000, -0.9000]],\n",
      "\n",
      "         [[ 0.9000,  1.2000,  0.9000],\n",
      "          [ 0.0000,  0.6000,  0.0000],\n",
      "          [-0.9000, -0.9000, -0.6000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.9000,  1.2000, -0.0000],\n",
      "          [-0.6000, -0.3000, -0.6000],\n",
      "          [-0.9000,  0.3000, -0.3000]],\n",
      "\n",
      "         [[ 0.3000, -0.0000,  0.3000],\n",
      "          [ 0.3000, -0.3000, -0.0000],\n",
      "          [ 0.9000, -1.2000,  1.8000]],\n",
      "\n",
      "         [[ 0.6000,  0.6000,  0.6000],\n",
      "          [ 1.2000, -0.3000, -0.3000],\n",
      "          [-1.2000,  0.9000,  0.6000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.8000, -0.6000, -0.9000],\n",
      "          [-1.8000, -1.2000, -1.2000],\n",
      "          [-1.8000,  0.0000,  2.4000]],\n",
      "\n",
      "         [[-0.3000, -1.8000,  0.0000],\n",
      "          [ 1.8000,  0.0000, -0.6000],\n",
      "          [ 0.6000,  0.6000,  0.3000]],\n",
      "\n",
      "         [[-1.2000, -2.4000, -0.6000],\n",
      "          [-1.2000,  0.6000,  1.8000],\n",
      "          [ 0.6000,  0.6000,  1.2000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.6000,  0.9000, -0.3000],\n",
      "          [ 1.2000,  1.2000,  0.0000],\n",
      "          [ 1.8000,  1.2000, -0.6000]],\n",
      "\n",
      "         [[-1.8000, -1.8000,  1.2000],\n",
      "          [-1.2000, -1.2000,  1.2000],\n",
      "          [-2.4000, -0.9000,  0.3000]],\n",
      "\n",
      "         [[ 0.6000,  1.2000, -0.0000],\n",
      "          [ 0.3000,  1.8000, -0.6000],\n",
      "          [ 0.3000,  1.2000,  0.3000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3000, -0.9000,  1.2000],\n",
      "          [-0.0000, -0.9000,  1.2000],\n",
      "          [ 0.0000, -0.3000,  0.6000]],\n",
      "\n",
      "         [[ 0.3000, -1.2000,  1.8000],\n",
      "          [ 0.3000, -0.3000,  1.2000],\n",
      "          [-0.0000,  0.6000,  0.6000]],\n",
      "\n",
      "         [[-1.8000, -0.9000,  1.2000],\n",
      "          [-1.8000, -0.6000,  2.4000],\n",
      "          [-1.8000, -0.0000,  1.2000]]]], device='cuda:0',\n",
      "       grad_fn=<_pqBackward>)\n",
      "tensor([[[[-0.9000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[ 1.8000]],\n",
      "\n",
      "         [[-0.6000]]],\n",
      "\n",
      "\n",
      "        [[[-1.8000]],\n",
      "\n",
      "         [[ 2.4000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 1.2000]]],\n",
      "\n",
      "\n",
      "        [[[-0.6000]],\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[-1.2000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 1.2000]],\n",
      "\n",
      "         [[-1.8000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[ 1.2000]]],\n",
      "\n",
      "\n",
      "        [[[-0.9000]],\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[ 0.6000]]],\n",
      "\n",
      "\n",
      "        [[[-1.8000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.4000]],\n",
      "\n",
      "         [[-3.0000]],\n",
      "\n",
      "         [[ 0.9000]]]], device='cuda:0', grad_fn=<_pqBackward>)\n",
      "tensor([[[[ 0.3000,  1.2000,  0.9000],\n",
      "          [-0.6000, -0.3000,  0.3000],\n",
      "          [-0.6000, -0.9000,  0.3000]],\n",
      "\n",
      "         [[-0.0000,  0.9000, -0.3000],\n",
      "          [-0.3000,  0.3000, -0.6000],\n",
      "          [-0.3000, -0.3000, -0.9000]],\n",
      "\n",
      "         [[-1.8000, -1.2000, -0.3000],\n",
      "          [-0.6000, -0.0000, -0.9000],\n",
      "          [-1.2000, -0.6000, -1.2000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.9000, -0.3000, -1.2000],\n",
      "          [ 0.6000,  0.6000, -0.3000],\n",
      "          [-0.6000, -0.0000, -0.0000]],\n",
      "\n",
      "         [[-0.3000, -0.3000, -1.8000],\n",
      "          [ 0.6000,  0.3000, -0.0000],\n",
      "          [ 0.9000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[ 0.9000,  0.3000,  0.0000],\n",
      "          [-0.0000,  0.3000, -0.9000],\n",
      "          [-0.6000, -0.0000, -1.2000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.6000,  0.6000,  1.2000],\n",
      "          [ 0.3000,  0.3000,  0.3000],\n",
      "          [ 0.0000,  0.3000,  0.0000]],\n",
      "\n",
      "         [[-0.9000, -0.3000,  0.9000],\n",
      "          [-0.9000,  1.2000,  1.8000],\n",
      "          [ 0.0000,  1.2000,  1.8000]],\n",
      "\n",
      "         [[-1.2000, -1.2000, -0.0000],\n",
      "          [-1.2000, -0.6000,  2.4000],\n",
      "          [ 0.0000,  0.6000,  2.4000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.9000,  0.0000, -1.2000],\n",
      "          [ 1.8000, -1.2000, -1.2000],\n",
      "          [ 2.4000, -1.2000, -1.8000]],\n",
      "\n",
      "         [[-1.2000, -0.6000,  0.6000],\n",
      "          [-0.3000, -0.3000,  1.2000],\n",
      "          [-0.0000, -0.0000,  0.3000]],\n",
      "\n",
      "         [[ 0.3000, -0.6000, -0.3000],\n",
      "          [-0.9000, -0.0000,  0.0000],\n",
      "          [-0.6000,  0.0000, -0.3000]]],\n",
      "\n",
      "\n",
      "        [[[-0.6000, -1.8000, -1.8000],\n",
      "          [-0.3000, -1.2000, -1.2000],\n",
      "          [ 0.0000,  0.3000,  0.6000]],\n",
      "\n",
      "         [[-0.9000, -0.0000, -1.2000],\n",
      "          [-1.2000,  0.0000, -0.6000],\n",
      "          [-1.8000, -0.9000, -1.2000]],\n",
      "\n",
      "         [[ 0.9000,  0.3000, -0.3000],\n",
      "          [-0.9000, -0.3000,  0.9000],\n",
      "          [-1.2000, -0.9000,  1.2000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0000, -0.6000,  0.3000],\n",
      "          [-0.6000, -0.6000,  1.2000],\n",
      "          [-1.2000, -0.0000,  1.8000]],\n",
      "\n",
      "         [[ 0.9000, -0.0000,  0.9000],\n",
      "          [ 0.3000, -0.3000, -0.6000],\n",
      "          [ 0.3000,  0.3000, -0.3000]],\n",
      "\n",
      "         [[-0.9000, -0.6000, -1.2000],\n",
      "          [ 0.9000,  0.0000, -0.6000],\n",
      "          [ 1.2000,  0.9000,  1.2000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.3000, -0.9000],\n",
      "          [-0.3000,  0.6000, -0.3000],\n",
      "          [ 2.4000,  1.8000,  2.4000]],\n",
      "\n",
      "         [[-0.3000,  0.6000,  0.6000],\n",
      "          [-1.2000, -0.6000,  0.6000],\n",
      "          [-0.9000, -0.9000, -0.3000]],\n",
      "\n",
      "         [[-0.0000,  0.3000,  0.9000],\n",
      "          [ 0.3000, -0.3000,  1.8000],\n",
      "          [ 0.6000,  0.3000,  0.3000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.6000, -0.6000, -0.0000],\n",
      "          [-0.6000,  0.6000, -0.0000],\n",
      "          [-0.6000, -0.6000, -1.2000]],\n",
      "\n",
      "         [[-0.6000, -0.6000, -0.3000],\n",
      "          [-0.9000, -1.2000, -0.9000],\n",
      "          [ 0.6000, -0.3000, -0.3000]],\n",
      "\n",
      "         [[-0.9000,  0.0000, -0.3000],\n",
      "          [-0.6000, -0.0000,  1.8000],\n",
      "          [ 0.6000,  0.3000,  1.8000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.3000,  0.9000],\n",
      "          [ 0.3000,  1.2000,  1.2000],\n",
      "          [-0.3000,  1.2000,  0.6000]],\n",
      "\n",
      "         [[ 0.9000,  0.3000,  0.0000],\n",
      "          [ 1.2000,  0.6000,  0.3000],\n",
      "          [ 0.9000,  1.2000,  0.0000]],\n",
      "\n",
      "         [[ 0.3000,  0.3000, -0.9000],\n",
      "          [ 0.3000,  0.0000, -0.3000],\n",
      "          [ 1.2000,  0.6000, -0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3000, -0.3000, -1.2000],\n",
      "          [-1.2000, -1.2000, -1.8000],\n",
      "          [-0.6000, -0.3000, -1.2000]],\n",
      "\n",
      "         [[ 0.3000,  0.3000,  0.9000],\n",
      "          [ 0.3000, -0.0000,  0.9000],\n",
      "          [ 0.3000,  1.2000,  1.2000]],\n",
      "\n",
      "         [[ 0.9000,  0.6000,  1.2000],\n",
      "          [ 0.9000,  0.6000,  0.6000],\n",
      "          [ 0.0000, -0.3000, -0.3000]]],\n",
      "\n",
      "\n",
      "        [[[-0.6000, -0.3000, -0.9000],\n",
      "          [-1.8000, -0.9000, -0.6000],\n",
      "          [-0.6000, -0.3000, -1.2000]],\n",
      "\n",
      "         [[ 0.6000,  0.3000,  1.2000],\n",
      "          [-0.3000, -0.6000, -0.3000],\n",
      "          [-0.9000, -0.3000, -0.9000]],\n",
      "\n",
      "         [[ 0.6000,  0.9000,  3.0000],\n",
      "          [-0.6000, -0.3000,  0.9000],\n",
      "          [-0.6000, -0.3000,  0.9000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3000, -0.9000,  0.0000],\n",
      "          [-0.3000, -0.9000,  0.3000],\n",
      "          [ 1.2000, -0.3000,  0.0000]],\n",
      "\n",
      "         [[-1.2000,  0.6000,  0.6000],\n",
      "          [-0.6000,  0.6000,  0.6000],\n",
      "          [ 0.6000, -0.6000, -0.3000]],\n",
      "\n",
      "         [[ 0.3000, -0.9000, -0.9000],\n",
      "          [ 1.8000, -0.0000, -0.6000],\n",
      "          [ 1.8000,  1.8000, -1.8000]]]], device='cuda:0',\n",
      "       grad_fn=<_pqBackward>)\n",
      "tensor([[[[ 0.0000]],\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[ 0.6000]]],\n",
      "\n",
      "\n",
      "        [[[-2.4000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[ 1.8000]]],\n",
      "\n",
      "\n",
      "        [[[-0.6000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[-0.3000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.6000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 1.2000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[ 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[-0.3000]],\n",
      "\n",
      "         [[-1.8000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 1.8000]]]], device='cuda:0', grad_fn=<_pqBackward>)\n",
      "tensor([[[[ 0.3000, -0.3000, -0.9000],\n",
      "          [-0.9000, -0.3000, -0.9000],\n",
      "          [-0.6000, -0.6000,  0.3000]],\n",
      "\n",
      "         [[-0.9000, -1.8000, -1.8000],\n",
      "          [ 0.3000, -0.3000, -0.9000],\n",
      "          [ 0.3000,  0.9000,  2.4000]],\n",
      "\n",
      "         [[-3.0000, -1.8000,  0.3000],\n",
      "          [ 0.6000, -1.2000, -1.2000],\n",
      "          [ 1.8000,  1.8000, -0.9000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.9000, -0.6000,  0.6000],\n",
      "          [ 3.0000,  0.6000,  0.0000],\n",
      "          [ 3.0000,  0.9000, -0.3000]],\n",
      "\n",
      "         [[-2.4000, -0.9000,  3.0000],\n",
      "          [-0.3000, -1.8000,  0.3000],\n",
      "          [ 0.3000,  0.6000, -1.2000]],\n",
      "\n",
      "         [[ 2.4000, -0.0000, -0.9000],\n",
      "          [ 0.6000,  0.9000,  1.8000],\n",
      "          [-1.2000,  0.6000,  2.4000]]],\n",
      "\n",
      "\n",
      "        [[[-2.4000, -0.0000, -1.2000],\n",
      "          [-0.6000, -0.3000, -3.0000],\n",
      "          [ 1.2000,  0.0000, -0.6000]],\n",
      "\n",
      "         [[ 2.4000,  0.3000, -1.8000],\n",
      "          [ 0.6000,  0.6000, -0.9000],\n",
      "          [-0.6000,  0.9000,  0.3000]],\n",
      "\n",
      "         [[-1.8000, -0.0000,  1.2000],\n",
      "          [-2.4000, -1.8000,  0.9000],\n",
      "          [-1.2000, -1.8000, -0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.8000,  1.8000,  2.4000],\n",
      "          [ 0.9000, -0.0000,  1.2000],\n",
      "          [ 1.2000,  0.6000,  0.0000]],\n",
      "\n",
      "         [[ 0.6000, -0.9000,  1.2000],\n",
      "          [ 1.8000,  0.0000,  0.0000],\n",
      "          [-0.3000,  0.9000,  1.2000]],\n",
      "\n",
      "         [[-1.8000, -1.8000, -3.0000],\n",
      "          [-0.3000,  0.6000, -0.9000],\n",
      "          [-0.6000,  1.2000,  0.3000]]],\n",
      "\n",
      "\n",
      "        [[[-0.6000,  1.2000,  0.0000],\n",
      "          [-2.4000,  0.9000,  0.9000],\n",
      "          [-1.2000,  0.3000,  0.6000]],\n",
      "\n",
      "         [[-0.0000, -2.4000, -1.8000],\n",
      "          [ 1.8000, -0.3000, -0.6000],\n",
      "          [ 2.4000,  1.8000,  0.9000]],\n",
      "\n",
      "         [[-0.9000, -0.0000,  0.3000],\n",
      "          [ 0.9000,  1.8000,  2.4000],\n",
      "          [-1.2000, -0.6000,  1.2000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0000,  0.6000, -0.6000],\n",
      "          [-1.2000, -0.0000,  1.8000],\n",
      "          [ 0.3000,  0.3000,  0.6000]],\n",
      "\n",
      "         [[-0.9000, -0.3000,  1.2000],\n",
      "          [-0.0000,  0.3000,  0.3000],\n",
      "          [ 0.3000,  0.0000, -1.8000]],\n",
      "\n",
      "         [[-1.2000, -0.3000, -0.9000],\n",
      "          [-0.0000,  0.6000, -0.6000],\n",
      "          [ 0.6000,  0.3000, -0.3000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.3000, -0.6000, -0.6000],\n",
      "          [-0.6000, -0.3000, -0.3000],\n",
      "          [-1.8000, -0.9000,  0.3000]],\n",
      "\n",
      "         [[ 0.9000,  0.3000,  0.3000],\n",
      "          [ 0.9000,  1.2000, -0.3000],\n",
      "          [ 1.2000,  0.9000, -0.0000]],\n",
      "\n",
      "         [[-0.9000, -0.3000, -0.3000],\n",
      "          [-0.3000,  0.0000, -0.3000],\n",
      "          [-0.6000, -0.6000, -0.9000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.6000, -0.6000, -0.9000],\n",
      "          [-0.9000,  0.0000, -0.9000],\n",
      "          [-0.3000, -0.9000, -0.3000]],\n",
      "\n",
      "         [[-0.6000, -0.3000,  0.3000],\n",
      "          [-0.9000,  0.0000,  0.6000],\n",
      "          [-0.3000, -0.3000,  0.3000]],\n",
      "\n",
      "         [[-0.6000, -0.9000,  0.3000],\n",
      "          [ 0.3000, -1.2000,  0.3000],\n",
      "          [ 0.9000,  0.6000,  1.2000]]],\n",
      "\n",
      "\n",
      "        [[[ 2.4000,  1.8000,  3.0000],\n",
      "          [ 0.9000, -0.6000,  0.6000],\n",
      "          [-0.9000, -1.8000, -0.9000]],\n",
      "\n",
      "         [[ 0.0000, -0.9000, -1.2000],\n",
      "          [ 0.6000,  0.0000,  0.6000],\n",
      "          [-0.3000, -0.9000,  0.6000]],\n",
      "\n",
      "         [[ 0.3000,  0.0000, -0.3000],\n",
      "          [ 1.2000,  1.2000,  1.2000],\n",
      "          [-0.6000, -1.2000, -1.2000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.6000,  0.3000,  1.2000],\n",
      "          [ 1.8000,  0.3000,  0.0000],\n",
      "          [ 1.8000,  0.3000, -0.0000]],\n",
      "\n",
      "         [[-1.8000, -1.2000, -1.8000],\n",
      "          [-2.4000, -1.2000, -1.2000],\n",
      "          [-2.4000, -0.9000, -1.8000]],\n",
      "\n",
      "         [[-0.3000, -0.9000, -0.9000],\n",
      "          [-0.3000, -0.3000,  0.3000],\n",
      "          [ 1.2000,  1.8000,  1.8000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.9000,  0.3000, -0.6000],\n",
      "          [ 2.4000,  1.2000,  0.3000],\n",
      "          [ 3.0000,  2.4000,  3.0000]],\n",
      "\n",
      "         [[-0.0000,  0.6000,  0.6000],\n",
      "          [-0.3000, -0.3000, -0.6000],\n",
      "          [-0.6000, -0.6000, -0.3000]],\n",
      "\n",
      "         [[ 0.3000,  0.6000,  0.9000],\n",
      "          [-0.6000,  0.3000,  0.3000],\n",
      "          [-1.8000, -0.9000,  0.6000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3000, -0.0000,  0.6000],\n",
      "          [ 1.2000,  0.6000,  0.0000],\n",
      "          [-0.6000, -0.9000, -1.2000]],\n",
      "\n",
      "         [[-0.9000,  0.6000,  0.9000],\n",
      "          [-0.6000, -0.3000, -0.6000],\n",
      "          [-0.9000, -0.3000, -0.9000]],\n",
      "\n",
      "         [[ 0.6000,  0.0000,  1.2000],\n",
      "          [-0.3000, -0.9000,  0.9000],\n",
      "          [ 1.2000,  0.6000,  0.6000]]]], device='cuda:0',\n",
      "       grad_fn=<_pqBackward>)\n",
      "tensor([[[[-0.3000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         [[ 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[-0.6000]],\n",
      "\n",
      "         [[ 2.4000]],\n",
      "\n",
      "         [[ 1.8000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[-0.3000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[ 2.4000]],\n",
      "\n",
      "         [[-1.2000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 1.2000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 1.8000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[-1.2000]]],\n",
      "\n",
      "\n",
      "        [[[-0.9000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[-1.8000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[-1.2000]]],\n",
      "\n",
      "\n",
      "        [[[-0.3000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         [[ 0.9000]]]], device='cuda:0', grad_fn=<_pqBackward>)\n",
      "tensor([[[[-1.2000]],\n",
      "\n",
      "         [[ 1.8000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         [[ 3.0000]],\n",
      "\n",
      "         [[-0.9000]]],\n",
      "\n",
      "\n",
      "        [[[-0.6000]],\n",
      "\n",
      "         [[ 2.4000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         [[ 1.8000]]],\n",
      "\n",
      "\n",
      "        [[[-1.2000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         [[ 0.9000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.3000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[-0.9000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.9000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.9000]]],\n",
      "\n",
      "\n",
      "        [[[-1.2000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 1.2000]]]], device='cuda:0', grad_fn=<_pqBackward>)\n",
      "tensor([[[[ 0.0000,  0.6000, -0.3000],\n",
      "          [ 1.8000,  0.3000, -0.3000],\n",
      "          [ 0.0000, -2.4000, -1.2000]],\n",
      "\n",
      "         [[ 0.6000,  0.9000, -0.3000],\n",
      "          [ 0.6000,  0.9000, -1.2000],\n",
      "          [-0.3000, -1.2000, -0.9000]],\n",
      "\n",
      "         [[ 0.6000, -0.0000, -0.0000],\n",
      "          [ 0.6000,  0.6000,  0.6000],\n",
      "          [ 0.9000, -0.0000,  0.6000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.2000,  3.0000,  1.8000],\n",
      "          [-0.0000, -0.6000, -0.6000],\n",
      "          [-0.6000, -1.8000, -0.6000]],\n",
      "\n",
      "         [[ 0.3000, -0.3000,  0.0000],\n",
      "          [ 0.6000,  0.6000,  0.3000],\n",
      "          [ 0.9000,  0.3000,  0.0000]],\n",
      "\n",
      "         [[-0.0000,  0.3000,  0.6000],\n",
      "          [ 0.9000,  0.6000,  0.9000],\n",
      "          [-1.2000, -1.8000, -1.2000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  1.8000,  0.3000],\n",
      "          [-0.3000,  1.2000, -0.3000],\n",
      "          [ 0.6000,  0.0000, -0.0000]],\n",
      "\n",
      "         [[-1.8000, -1.2000, -0.9000],\n",
      "          [-1.2000, -1.2000, -0.9000],\n",
      "          [-0.9000,  0.3000, -1.8000]],\n",
      "\n",
      "         [[ 0.9000,  0.9000,  1.2000],\n",
      "          [-0.6000,  0.6000, -0.3000],\n",
      "          [-1.2000, -1.8000, -1.8000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.6000,  2.4000,  1.8000],\n",
      "          [-0.6000, -0.3000, -0.9000],\n",
      "          [-0.0000, -0.3000, -0.0000]],\n",
      "\n",
      "         [[-0.0000,  1.2000,  0.3000],\n",
      "          [-0.9000, -0.3000,  0.0000],\n",
      "          [-0.3000, -0.0000, -0.3000]],\n",
      "\n",
      "         [[-0.6000, -0.9000, -0.6000],\n",
      "          [ 0.9000,  1.2000,  0.3000],\n",
      "          [-0.6000, -0.3000,  0.3000]]],\n",
      "\n",
      "\n",
      "        [[[-0.6000, -1.2000, -0.9000],\n",
      "          [ 1.8000,  1.8000,  1.2000],\n",
      "          [ 0.6000, -0.6000, -0.3000]],\n",
      "\n",
      "         [[-0.3000, -0.3000, -0.0000],\n",
      "          [ 1.2000,  0.9000,  0.6000],\n",
      "          [ 0.0000,  1.2000,  0.6000]],\n",
      "\n",
      "         [[-0.3000, -0.6000, -0.6000],\n",
      "          [ 0.6000,  0.3000, -0.0000],\n",
      "          [ 0.9000,  0.6000,  0.3000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.6000,  1.2000,  0.6000],\n",
      "          [ 0.6000, -1.2000,  0.3000],\n",
      "          [-0.3000,  0.3000, -0.3000]],\n",
      "\n",
      "         [[-0.6000, -0.3000, -0.0000],\n",
      "          [-0.9000, -0.3000, -0.6000],\n",
      "          [ 0.6000,  0.9000,  0.3000]],\n",
      "\n",
      "         [[ 0.9000,  1.8000,  0.9000],\n",
      "          [ 1.8000,  0.9000,  1.8000],\n",
      "          [-1.2000, -1.8000, -1.2000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.9000,  0.6000,  0.3000],\n",
      "          [ 0.3000,  0.3000, -0.9000],\n",
      "          [-0.3000, -0.3000, -1.8000]],\n",
      "\n",
      "         [[-0.6000, -0.3000, -0.9000],\n",
      "          [-1.8000,  0.6000, -1.2000],\n",
      "          [ 0.3000,  3.0000,  0.3000]],\n",
      "\n",
      "         [[-0.3000, -0.3000, -0.3000],\n",
      "          [-0.3000,  0.3000, -0.9000],\n",
      "          [-0.3000, -0.6000, -0.9000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.8000, -1.2000, -1.8000],\n",
      "          [ 0.3000,  1.2000, -0.3000],\n",
      "          [-0.0000, -0.6000,  0.3000]],\n",
      "\n",
      "         [[ 0.0000, -0.9000, -1.8000],\n",
      "          [ 0.6000, -0.3000, -0.6000],\n",
      "          [ 0.6000,  0.6000, -0.6000]],\n",
      "\n",
      "         [[-0.9000,  0.0000,  0.0000],\n",
      "          [-0.6000,  0.9000, -0.6000],\n",
      "          [ 0.3000, -0.6000, -0.3000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.9000,  0.3000],\n",
      "          [ 0.0000,  0.6000, -1.2000],\n",
      "          [-0.6000,  0.0000,  0.9000]],\n",
      "\n",
      "         [[-0.0000,  0.9000,  1.2000],\n",
      "          [-1.8000,  0.9000,  0.6000],\n",
      "          [-1.8000, -0.9000,  2.4000]],\n",
      "\n",
      "         [[-0.3000,  0.0000,  0.6000],\n",
      "          [-1.2000,  0.6000,  1.2000],\n",
      "          [-0.9000,  0.0000,  0.9000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.4000, -0.0000,  1.8000],\n",
      "          [-3.0000, -0.3000,  1.8000],\n",
      "          [-1.8000, -0.6000,  0.3000]],\n",
      "\n",
      "         [[-0.6000,  0.3000,  0.9000],\n",
      "          [ 0.3000,  0.3000, -0.0000],\n",
      "          [-0.6000, -0.9000, -0.3000]],\n",
      "\n",
      "         [[-0.9000, -0.3000,  0.0000],\n",
      "          [-0.3000,  0.0000,  1.2000],\n",
      "          [-0.6000,  0.6000,  0.9000]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2000,  1.8000,  0.6000],\n",
      "          [-0.3000,  0.3000,  0.6000],\n",
      "          [-2.4000, -1.8000, -0.3000]],\n",
      "\n",
      "         [[ 2.4000,  1.8000,  0.9000],\n",
      "          [ 0.3000, -3.0000, -0.6000],\n",
      "          [ 0.0000, -1.2000, -1.8000]],\n",
      "\n",
      "         [[-0.3000, -0.3000, -0.3000],\n",
      "          [-0.3000, -0.3000, -0.3000],\n",
      "          [ 1.2000,  1.8000,  3.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.9000, -0.6000,  0.6000],\n",
      "          [-0.3000, -0.9000,  0.3000],\n",
      "          [ 0.9000, -0.9000,  3.0000]],\n",
      "\n",
      "         [[ 0.6000, -1.2000, -0.6000],\n",
      "          [ 0.9000,  0.0000,  0.6000],\n",
      "          [ 0.6000, -0.9000, -0.6000]],\n",
      "\n",
      "         [[ 1.8000,  2.4000,  0.9000],\n",
      "          [ 1.2000,  0.6000,  0.6000],\n",
      "          [ 0.9000, -1.2000,  0.0000]]]], device='cuda:0',\n",
      "       grad_fn=<_pqBackward>)\n",
      "tensor([[[[ 1.2000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 0.6000]]],\n",
      "\n",
      "\n",
      "        [[[-0.0000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         [[-1.8000]],\n",
      "\n",
      "         [[-0.3000]]],\n",
      "\n",
      "\n",
      "        [[[ 2.4000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 1.2000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.3000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[ 1.2000]]],\n",
      "\n",
      "\n",
      "        [[[-0.6000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[-0.3000]]],\n",
      "\n",
      "\n",
      "        [[[-0.9000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[-0.9000]]]], device='cuda:0', grad_fn=<_pqBackward>)\n",
      "tensor([[[[ 0.9000,  1.2000,  0.0000],\n",
      "          [ 0.3000, -0.0000,  0.3000],\n",
      "          [ 0.0000, -0.9000, -0.3000]],\n",
      "\n",
      "         [[ 1.2000,  1.2000,  1.2000],\n",
      "          [ 1.2000,  0.6000,  0.6000],\n",
      "          [-0.0000, -0.9000, -0.3000]],\n",
      "\n",
      "         [[ 0.6000, -0.0000,  0.9000],\n",
      "          [ 0.9000, -0.6000,  0.3000],\n",
      "          [ 0.9000, -0.3000,  0.6000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3000,  0.6000, -0.0000],\n",
      "          [-0.6000,  0.3000, -0.3000],\n",
      "          [ 0.0000, -0.3000, -0.3000]],\n",
      "\n",
      "         [[-0.3000, -0.3000, -0.3000],\n",
      "          [-0.6000,  0.0000,  0.3000],\n",
      "          [-1.2000, -1.2000,  0.3000]],\n",
      "\n",
      "         [[ 1.8000, -0.6000, -0.6000],\n",
      "          [ 1.8000, -0.6000, -0.6000],\n",
      "          [ 0.6000, -0.6000, -0.6000]]],\n",
      "\n",
      "\n",
      "        [[[-1.2000,  0.6000, -0.6000],\n",
      "          [-1.8000, -0.6000, -1.2000],\n",
      "          [-0.3000, -0.6000, -0.0000]],\n",
      "\n",
      "         [[-0.3000, -0.9000, -0.6000],\n",
      "          [ 0.0000, -1.2000, -1.2000],\n",
      "          [ 0.3000, -0.6000,  0.6000]],\n",
      "\n",
      "         [[-1.2000, -1.2000, -0.0000],\n",
      "          [-1.8000,  0.3000, -0.6000],\n",
      "          [-1.8000,  1.2000, -1.8000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.9000,  0.9000, -0.0000],\n",
      "          [-0.3000,  0.0000,  0.0000],\n",
      "          [-0.3000, -0.0000, -0.6000]],\n",
      "\n",
      "         [[ 1.2000,  0.0000,  0.3000],\n",
      "          [ 1.2000, -0.0000,  0.3000],\n",
      "          [ 1.2000, -0.0000, -1.8000]],\n",
      "\n",
      "         [[ 0.6000,  0.3000, -0.3000],\n",
      "          [ 0.6000,  0.6000, -0.0000],\n",
      "          [ 1.2000,  0.6000,  0.6000]]],\n",
      "\n",
      "\n",
      "        [[[-1.8000, -3.0000, -1.2000],\n",
      "          [-1.2000,  1.2000, -0.6000],\n",
      "          [-1.8000, -1.2000, -1.2000]],\n",
      "\n",
      "         [[-0.3000,  0.3000,  0.3000],\n",
      "          [-0.9000,  0.3000,  0.3000],\n",
      "          [-0.9000,  0.0000, -0.6000]],\n",
      "\n",
      "         [[ 0.3000,  1.2000, -1.8000],\n",
      "          [-0.3000, -0.3000, -1.8000],\n",
      "          [ 2.4000, -0.0000, -0.6000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.2000, -0.9000,  0.6000],\n",
      "          [-0.9000, -2.4000, -0.9000],\n",
      "          [-0.3000,  0.9000,  0.9000]],\n",
      "\n",
      "         [[ 1.2000,  0.0000, -0.0000],\n",
      "          [-0.9000, -0.9000,  0.0000],\n",
      "          [-0.3000,  0.3000,  1.2000]],\n",
      "\n",
      "         [[-2.4000, -0.6000,  1.2000],\n",
      "          [-1.8000,  0.6000,  1.8000],\n",
      "          [-0.0000, -0.3000,  0.0000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 1.8000, -0.3000, -0.6000],\n",
      "          [ 0.3000, -1.2000, -0.9000],\n",
      "          [ 1.2000, -1.2000, -0.6000]],\n",
      "\n",
      "         [[-0.9000, -0.9000,  1.2000],\n",
      "          [-1.8000, -0.6000,  0.6000],\n",
      "          [-0.3000, -1.2000, -0.3000]],\n",
      "\n",
      "         [[ 0.6000,  0.0000, -0.9000],\n",
      "          [ 3.0000,  1.2000, -3.0000],\n",
      "          [ 1.2000,  0.3000, -1.8000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.9000, -0.6000, -0.6000],\n",
      "          [ 0.3000, -0.0000, -0.6000],\n",
      "          [-0.6000,  0.6000,  0.0000]],\n",
      "\n",
      "         [[ 0.3000, -0.3000,  0.3000],\n",
      "          [ 1.2000,  0.6000,  0.3000],\n",
      "          [-0.3000, -0.0000,  1.2000]],\n",
      "\n",
      "         [[-0.0000, -0.9000,  0.0000],\n",
      "          [ 0.6000,  0.3000,  0.9000],\n",
      "          [ 0.3000,  0.3000, -0.0000]]],\n",
      "\n",
      "\n",
      "        [[[-1.2000, -1.2000,  3.0000],\n",
      "          [-1.2000,  0.0000,  1.2000],\n",
      "          [-0.9000,  0.3000,  0.6000]],\n",
      "\n",
      "         [[ 1.2000,  0.0000,  0.6000],\n",
      "          [ 0.6000,  0.6000,  0.3000],\n",
      "          [-1.2000, -0.3000, -0.3000]],\n",
      "\n",
      "         [[ 1.2000, -1.2000,  0.3000],\n",
      "          [-0.6000,  0.9000,  0.6000],\n",
      "          [-0.6000,  1.8000,  0.3000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0000,  0.3000,  0.3000],\n",
      "          [ 0.9000,  0.3000, -0.9000],\n",
      "          [ 2.4000,  0.6000, -1.2000]],\n",
      "\n",
      "         [[-0.6000, -0.3000, -0.0000],\n",
      "          [ 0.0000,  0.3000, -0.9000],\n",
      "          [ 1.2000,  0.6000, -1.2000]],\n",
      "\n",
      "         [[ 1.2000,  0.9000, -0.3000],\n",
      "          [-0.9000,  0.6000, -0.0000],\n",
      "          [ 0.3000,  0.9000, -0.3000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.6000, -0.9000, -0.3000],\n",
      "          [ 0.3000,  0.6000,  0.0000],\n",
      "          [-0.3000, -0.3000, -0.0000]],\n",
      "\n",
      "         [[-0.3000, -0.3000,  0.6000],\n",
      "          [ 0.3000,  0.3000,  1.2000],\n",
      "          [-0.0000, -1.2000, -0.3000]],\n",
      "\n",
      "         [[ 0.3000, -0.9000,  2.4000],\n",
      "          [-1.2000, -1.8000,  1.8000],\n",
      "          [ 0.3000,  0.6000,  0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.9000, -0.0000, -0.6000],\n",
      "          [ 0.9000,  0.0000, -0.3000],\n",
      "          [ 0.0000, -0.6000, -0.6000]],\n",
      "\n",
      "         [[ 0.6000,  1.2000, -0.9000],\n",
      "          [ 0.3000,  0.3000, -0.6000],\n",
      "          [ 0.0000,  0.3000,  0.6000]],\n",
      "\n",
      "         [[-0.9000, -0.3000,  0.9000],\n",
      "          [-0.6000, -0.3000,  0.3000],\n",
      "          [-0.0000,  0.3000,  0.6000]]]], device='cuda:0',\n",
      "       grad_fn=<_pqBackward>)\n",
      "tensor([[[[-1.2000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[ 3.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[-1.8000]],\n",
      "\n",
      "         [[ 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[-0.6000]],\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[ 1.2000]]],\n",
      "\n",
      "\n",
      "        [[[ 1.8000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.3000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-1.8000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 0.3000]]],\n",
      "\n",
      "\n",
      "        [[[-0.0000]],\n",
      "\n",
      "         [[ 1.8000]],\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[ 0.6000]]],\n",
      "\n",
      "\n",
      "        [[[-0.9000]],\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[ 1.8000]]]], device='cuda:0', grad_fn=<_pqBackward>)\n",
      "tensor([[[[ 0.6000, -0.6000,  0.0000],\n",
      "          [-0.3000,  0.0000, -1.2000],\n",
      "          [-0.6000, -0.6000, -1.2000]],\n",
      "\n",
      "         [[-0.9000,  0.0000, -0.0000],\n",
      "          [-1.2000, -0.0000, -0.9000],\n",
      "          [-0.3000,  0.0000, -0.6000]],\n",
      "\n",
      "         [[ 0.6000,  0.3000,  0.9000],\n",
      "          [-0.6000, -0.6000,  0.3000],\n",
      "          [-0.9000, -0.6000,  0.9000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.2000, -1.2000, -0.6000],\n",
      "          [-1.2000, -0.0000, -1.8000],\n",
      "          [-0.6000,  0.9000, -0.3000]],\n",
      "\n",
      "         [[ 0.3000,  1.2000, -0.6000],\n",
      "          [ 0.6000,  1.2000,  0.6000],\n",
      "          [-0.3000, -0.0000, -0.9000]],\n",
      "\n",
      "         [[-1.2000, -0.9000, -1.2000],\n",
      "          [-1.2000, -1.8000, -1.2000],\n",
      "          [-0.6000, -0.6000, -0.3000]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2000, -0.9000,  0.3000],\n",
      "          [ 1.2000, -1.2000, -0.3000],\n",
      "          [ 1.2000,  0.0000,  0.3000]],\n",
      "\n",
      "         [[ 0.9000, -0.0000,  0.9000],\n",
      "          [-0.3000, -0.0000, -0.6000],\n",
      "          [-0.9000, -0.6000, -0.6000]],\n",
      "\n",
      "         [[-0.3000, -0.3000, -0.3000],\n",
      "          [-1.2000, -0.3000,  1.2000],\n",
      "          [ 0.3000,  0.9000,  0.3000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0000, -0.3000,  1.2000],\n",
      "          [-0.3000, -0.6000,  1.8000],\n",
      "          [ 0.3000, -0.0000,  1.2000]],\n",
      "\n",
      "         [[ 0.6000,  0.3000, -1.8000],\n",
      "          [ 3.0000, -0.3000, -2.4000],\n",
      "          [ 0.9000,  0.6000, -0.9000]],\n",
      "\n",
      "         [[ 0.9000,  0.3000, -0.0000],\n",
      "          [ 0.6000,  0.6000,  0.0000],\n",
      "          [ 0.0000,  0.6000, -0.9000]]],\n",
      "\n",
      "\n",
      "        [[[-2.4000, -0.9000,  0.3000],\n",
      "          [-1.8000,  0.9000,  0.6000],\n",
      "          [-0.0000,  1.8000,  3.0000]],\n",
      "\n",
      "         [[-0.9000, -1.2000,  0.9000],\n",
      "          [-0.3000, -0.9000,  1.2000],\n",
      "          [ 0.3000, -0.6000,  0.3000]],\n",
      "\n",
      "         [[-1.2000, -0.6000,  1.8000],\n",
      "          [-1.8000, -1.2000,  0.3000],\n",
      "          [-0.3000, -0.6000, -0.3000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.2000, -0.6000,  1.8000],\n",
      "          [-1.8000, -0.9000,  1.8000],\n",
      "          [-1.2000, -1.2000,  1.8000]],\n",
      "\n",
      "         [[-0.3000, -1.8000, -1.2000],\n",
      "          [ 1.8000,  1.2000, -0.9000],\n",
      "          [ 0.0000,  0.6000, -1.2000]],\n",
      "\n",
      "         [[-0.3000, -0.3000,  0.6000],\n",
      "          [-0.0000,  0.3000,  0.6000],\n",
      "          [-1.2000, -0.9000, -0.3000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.6000, -2.4000, -1.8000],\n",
      "          [ 0.3000, -0.6000, -1.2000],\n",
      "          [ 2.4000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[ 0.9000,  0.0000,  0.3000],\n",
      "          [ 1.2000,  0.6000,  0.0000],\n",
      "          [ 0.6000,  1.2000,  0.9000]],\n",
      "\n",
      "         [[ 1.2000, -1.2000, -0.3000],\n",
      "          [ 0.3000, -0.3000,  1.2000],\n",
      "          [-0.9000,  0.6000,  1.8000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.6000, -0.9000, -0.6000],\n",
      "          [-0.0000,  0.3000, -0.9000],\n",
      "          [ 0.6000,  1.8000,  0.0000]],\n",
      "\n",
      "         [[-0.0000,  0.6000,  1.2000],\n",
      "          [-0.6000, -1.2000,  0.9000],\n",
      "          [-0.3000, -0.9000, -0.0000]],\n",
      "\n",
      "         [[ 0.6000, -0.9000, -0.9000],\n",
      "          [-0.3000, -0.6000, -0.6000],\n",
      "          [-0.6000,  0.6000, -0.6000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3000,  1.8000,  0.9000],\n",
      "          [-0.0000,  0.6000, -0.3000],\n",
      "          [-0.3000, -0.3000, -0.3000]],\n",
      "\n",
      "         [[-0.3000,  0.0000, -0.3000],\n",
      "          [-0.6000,  0.0000, -0.3000],\n",
      "          [ 0.3000,  0.3000, -0.3000]],\n",
      "\n",
      "         [[ 0.6000,  0.0000,  0.6000],\n",
      "          [ 1.2000,  1.2000,  1.2000],\n",
      "          [ 0.3000,  0.9000,  0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.2000,  0.9000,  0.0000],\n",
      "          [-1.8000, -1.8000, -1.8000],\n",
      "          [-1.2000, -1.2000, -0.9000]],\n",
      "\n",
      "         [[-2.4000, -3.0000, -1.8000],\n",
      "          [ 0.9000,  0.3000,  0.6000],\n",
      "          [ 1.8000,  2.4000,  2.4000]],\n",
      "\n",
      "         [[ 0.3000, -0.0000,  0.6000],\n",
      "          [-0.3000, -0.0000,  0.9000],\n",
      "          [-1.2000,  0.0000, -0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3000, -1.8000,  1.2000],\n",
      "          [-1.8000, -0.3000,  1.2000],\n",
      "          [-1.2000,  0.9000,  1.2000]],\n",
      "\n",
      "         [[-1.2000, -0.9000,  0.3000],\n",
      "          [-0.0000,  0.3000,  0.9000],\n",
      "          [-0.6000, -0.0000,  0.9000]],\n",
      "\n",
      "         [[ 1.2000,  0.3000,  0.9000],\n",
      "          [ 0.6000, -1.8000,  0.3000],\n",
      "          [ 0.9000, -1.2000,  0.3000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3000, -0.9000, -0.3000],\n",
      "          [-0.3000,  0.3000, -1.8000],\n",
      "          [ 0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[-0.6000, -0.9000,  0.3000],\n",
      "          [-2.4000,  0.9000,  1.8000],\n",
      "          [-1.2000,  0.3000,  0.6000]],\n",
      "\n",
      "         [[-0.6000,  0.6000,  1.8000],\n",
      "          [-1.2000,  0.0000,  1.2000],\n",
      "          [ 0.6000, -0.9000, -0.6000]]]], device='cuda:0',\n",
      "       grad_fn=<_pqBackward>)\n",
      "tensor([[[[ 1.2000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[ 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[-1.8000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         [[ 3.0000]],\n",
      "\n",
      "         [[ 0.6000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3000]],\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[-0.3000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.6000]],\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[-0.3000]]],\n",
      "\n",
      "\n",
      "        [[[-0.0000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         [[-0.3000]]],\n",
      "\n",
      "\n",
      "        [[[-0.3000]],\n",
      "\n",
      "         [[ 2.4000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 0.0000]]]], device='cuda:0', grad_fn=<_pqBackward>)\n",
      "tensor([[[[-0.6000,  0.3000, -0.3000],\n",
      "          [ 0.3000,  2.4000, -0.9000],\n",
      "          [-0.9000,  0.3000, -1.2000]],\n",
      "\n",
      "         [[-0.6000,  1.2000, -0.0000],\n",
      "          [-0.9000,  0.0000, -0.6000],\n",
      "          [ 0.9000,  0.6000,  0.3000]],\n",
      "\n",
      "         [[ 0.3000, -0.9000,  1.2000],\n",
      "          [-0.6000,  0.3000, -0.6000],\n",
      "          [ 1.8000,  1.8000,  0.6000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.9000,  1.2000,  0.3000],\n",
      "          [ 1.2000, -0.3000, -0.3000],\n",
      "          [ 0.3000, -0.9000, -0.3000]],\n",
      "\n",
      "         [[ 1.8000, -0.3000,  0.3000],\n",
      "          [-0.3000, -0.3000, -0.6000],\n",
      "          [-0.6000,  0.9000, -0.3000]],\n",
      "\n",
      "         [[ 1.2000,  0.9000,  0.3000],\n",
      "          [ 1.2000,  0.9000, -1.8000],\n",
      "          [-0.9000, -0.6000, -1.2000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.6000, -0.6000, -0.3000],\n",
      "          [-0.0000, -0.3000,  1.2000],\n",
      "          [-0.3000, -0.3000,  0.9000]],\n",
      "\n",
      "         [[ 1.2000,  0.3000,  0.3000],\n",
      "          [-0.0000, -0.6000, -0.6000],\n",
      "          [ 0.6000, -0.6000, -0.3000]],\n",
      "\n",
      "         [[ 0.0000, -1.2000, -1.2000],\n",
      "          [ 0.3000, -0.3000, -0.6000],\n",
      "          [ 0.9000,  0.9000,  0.9000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3000,  0.3000, -1.2000],\n",
      "          [ 0.9000, -0.6000, -2.4000],\n",
      "          [-0.6000, -0.9000, -1.2000]],\n",
      "\n",
      "         [[-0.3000, -0.0000, -0.3000],\n",
      "          [-0.0000, -0.3000, -1.2000],\n",
      "          [-1.2000, -0.9000,  0.6000]],\n",
      "\n",
      "         [[-0.3000, -0.3000, -1.2000],\n",
      "          [-0.6000, -0.9000, -1.8000],\n",
      "          [-0.9000,  0.3000, -1.8000]]],\n",
      "\n",
      "\n",
      "        [[[-0.0000,  0.0000, -0.9000],\n",
      "          [-0.6000,  0.0000, -1.8000],\n",
      "          [ 0.0000,  0.0000, -0.6000]],\n",
      "\n",
      "         [[ 1.8000,  2.4000, -1.2000],\n",
      "          [ 0.6000,  1.8000,  0.3000],\n",
      "          [-1.8000, -1.8000, -0.6000]],\n",
      "\n",
      "         [[-0.3000,  2.4000,  1.8000],\n",
      "          [-0.6000, -0.9000, -0.0000],\n",
      "          [-1.2000, -0.3000,  0.3000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.6000,  0.6000,  1.8000],\n",
      "          [-0.3000, -1.2000,  0.9000],\n",
      "          [ 1.8000,  0.6000,  3.0000]],\n",
      "\n",
      "         [[-0.6000, -0.9000,  1.2000],\n",
      "          [-0.6000,  0.0000,  0.9000],\n",
      "          [-0.9000,  0.3000,  1.2000]],\n",
      "\n",
      "         [[ 0.3000, -0.3000,  0.9000],\n",
      "          [-1.2000, -1.2000,  1.8000],\n",
      "          [ 1.8000,  1.8000,  1.8000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.3000,  0.6000, -0.6000],\n",
      "          [-0.0000,  1.2000,  0.6000],\n",
      "          [-0.6000,  0.6000,  0.6000]],\n",
      "\n",
      "         [[-1.2000, -0.9000, -1.2000],\n",
      "          [ 0.3000, -0.6000, -1.2000],\n",
      "          [ 1.8000,  3.0000, -0.6000]],\n",
      "\n",
      "         [[-1.2000, -0.9000,  0.6000],\n",
      "          [-1.2000, -0.6000, -0.9000],\n",
      "          [ 0.6000,  1.8000,  1.2000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.2000,  1.2000,  1.2000],\n",
      "          [ 0.3000, -0.0000, -0.3000],\n",
      "          [-0.3000, -1.2000, -0.3000]],\n",
      "\n",
      "         [[-1.2000, -0.6000,  1.2000],\n",
      "          [-0.3000,  1.2000,  0.9000],\n",
      "          [-0.3000,  0.3000,  0.6000]],\n",
      "\n",
      "         [[-0.3000, -0.0000, -0.0000],\n",
      "          [ 0.6000,  0.6000, -0.9000],\n",
      "          [ 0.9000,  0.3000,  0.6000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.6000,  1.8000,  0.3000],\n",
      "          [-0.6000,  0.9000,  0.3000],\n",
      "          [-1.8000, -1.2000, -1.2000]],\n",
      "\n",
      "         [[ 0.3000,  1.8000,  0.3000],\n",
      "          [-1.2000,  0.3000,  1.2000],\n",
      "          [ 0.3000,  0.6000,  1.8000]],\n",
      "\n",
      "         [[-0.6000,  0.6000, -0.0000],\n",
      "          [ 0.9000,  1.8000, -0.3000],\n",
      "          [ 0.3000, -0.3000, -0.9000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.6000, -0.9000, -0.9000],\n",
      "          [ 0.6000, -0.3000,  0.3000],\n",
      "          [ 0.3000,  1.8000,  0.9000]],\n",
      "\n",
      "         [[-0.3000,  0.9000, -0.0000],\n",
      "          [-0.0000,  0.9000, -0.3000],\n",
      "          [-1.2000, -0.9000,  0.3000]],\n",
      "\n",
      "         [[-2.4000, -1.8000, -1.2000],\n",
      "          [ 0.3000,  1.8000, -0.6000],\n",
      "          [ 0.6000,  2.4000, -0.3000]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2000,  0.3000,  1.2000],\n",
      "          [ 1.8000,  0.0000,  1.8000],\n",
      "          [ 0.6000, -0.6000,  0.6000]],\n",
      "\n",
      "         [[ 1.8000,  1.8000,  1.8000],\n",
      "          [-0.3000, -1.8000, -0.3000],\n",
      "          [-0.6000, -0.3000, -1.8000]],\n",
      "\n",
      "         [[-0.6000, -0.3000, -0.9000],\n",
      "          [ 0.6000,  0.6000,  0.3000],\n",
      "          [-0.3000, -0.3000, -0.3000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.8000,  1.2000,  1.8000],\n",
      "          [-0.6000, -0.6000, -0.6000],\n",
      "          [-0.9000, -0.3000, -1.2000]],\n",
      "\n",
      "         [[ 0.9000, -1.2000, -1.8000],\n",
      "          [ 1.2000,  0.0000,  0.0000],\n",
      "          [ 0.9000, -0.9000,  0.3000]],\n",
      "\n",
      "         [[-0.0000, -0.3000,  0.6000],\n",
      "          [-1.2000, -0.0000, -0.9000],\n",
      "          [-0.3000, -0.6000, -0.3000]]]], device='cuda:0',\n",
      "       grad_fn=<_pqBackward>)\n",
      "tensor([[[[ 0.3000]],\n",
      "\n",
      "         [[-1.8000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[-0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.6000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 0.6000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 1.2000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0000]],\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[-0.6000]]],\n",
      "\n",
      "\n",
      "        [[[-0.0000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[-1.8000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[-0.3000]]],\n",
      "\n",
      "\n",
      "        [[[-0.3000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[ 0.3000]]]], device='cuda:0', grad_fn=<_pqBackward>)\n",
      "tensor([[[[-1.2000, -1.2000, -1.2000],\n",
      "          [-0.6000, -0.3000, -0.6000],\n",
      "          [-0.3000,  0.9000, -0.9000]],\n",
      "\n",
      "         [[ 1.8000,  0.3000,  1.8000],\n",
      "          [ 0.6000, -0.3000,  1.8000],\n",
      "          [-0.3000, -1.8000, -1.2000]],\n",
      "\n",
      "         [[-0.0000,  0.9000,  0.9000],\n",
      "          [-0.3000, -0.0000,  1.2000],\n",
      "          [ 0.0000, -1.2000, -0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3000, -1.2000,  0.9000],\n",
      "          [-0.6000, -1.2000,  0.6000],\n",
      "          [ 0.0000,  0.0000,  0.3000]],\n",
      "\n",
      "         [[-0.6000,  1.8000,  1.8000],\n",
      "          [ 0.6000,  1.8000,  0.3000],\n",
      "          [ 0.0000, -1.2000, -0.0000]],\n",
      "\n",
      "         [[-1.2000,  1.8000,  0.9000],\n",
      "          [-0.6000,  1.2000,  0.6000],\n",
      "          [-0.3000, -0.9000, -0.3000]]],\n",
      "\n",
      "\n",
      "        [[[-0.3000, -1.8000,  0.0000],\n",
      "          [ 0.3000, -0.0000,  1.2000],\n",
      "          [ 0.9000,  2.4000,  0.6000]],\n",
      "\n",
      "         [[ 1.2000,  1.8000,  0.3000],\n",
      "          [ 0.0000, -1.8000,  0.6000],\n",
      "          [ 0.9000, -1.8000,  0.6000]],\n",
      "\n",
      "         [[ 0.9000,  1.2000, -0.3000],\n",
      "          [-0.0000, -0.9000,  1.2000],\n",
      "          [ 0.9000, -0.3000,  1.2000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3000, -0.3000,  0.0000],\n",
      "          [ 0.9000,  0.0000,  0.3000],\n",
      "          [-0.6000,  1.2000, -0.3000]],\n",
      "\n",
      "         [[ 0.6000, -0.3000, -0.0000],\n",
      "          [-0.0000, -0.3000,  0.0000],\n",
      "          [ 0.3000,  0.9000,  0.9000]],\n",
      "\n",
      "         [[ 0.6000,  0.3000,  0.9000],\n",
      "          [ 0.9000, -0.3000,  0.3000],\n",
      "          [ 0.3000,  0.6000, -0.9000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.9000,  0.9000,  0.0000],\n",
      "          [ 0.3000,  1.2000, -0.6000],\n",
      "          [-0.3000,  0.6000, -0.3000]],\n",
      "\n",
      "         [[ 0.3000,  2.4000,  0.9000],\n",
      "          [-0.6000, -0.9000, -1.2000],\n",
      "          [ 0.3000,  0.0000,  0.3000]],\n",
      "\n",
      "         [[-0.0000, -0.6000, -0.3000],\n",
      "          [-0.3000, -2.4000,  0.3000],\n",
      "          [-0.3000, -1.2000,  0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.9000,  3.0000, -1.2000],\n",
      "          [-1.2000,  1.2000,  0.3000],\n",
      "          [-1.2000, -0.6000,  1.2000]],\n",
      "\n",
      "         [[-1.2000,  1.8000,  0.0000],\n",
      "          [ 0.0000, -1.8000,  1.2000],\n",
      "          [ 0.6000, -0.6000,  0.9000]],\n",
      "\n",
      "         [[-1.8000,  1.2000, -0.9000],\n",
      "          [ 0.9000,  0.9000, -0.9000],\n",
      "          [ 0.9000,  2.4000,  0.6000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.9000, -0.6000, -1.2000],\n",
      "          [ 0.0000,  0.3000, -1.2000],\n",
      "          [ 0.6000, -0.3000, -1.2000]],\n",
      "\n",
      "         [[-1.2000, -0.6000,  0.0000],\n",
      "          [-2.4000, -1.2000,  1.8000],\n",
      "          [-0.6000, -0.3000,  0.3000]],\n",
      "\n",
      "         [[-0.3000,  0.9000,  1.2000],\n",
      "          [-0.9000,  1.8000,  1.8000],\n",
      "          [-1.2000,  0.3000, -0.3000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3000, -0.9000, -0.9000],\n",
      "          [ 1.2000, -0.3000, -0.3000],\n",
      "          [ 0.6000,  1.8000,  2.4000]],\n",
      "\n",
      "         [[ 1.2000,  0.6000, -1.8000],\n",
      "          [ 0.3000,  1.2000,  0.9000],\n",
      "          [-0.9000,  1.2000,  2.4000]],\n",
      "\n",
      "         [[ 1.8000,  1.8000, -1.2000],\n",
      "          [ 0.9000,  0.3000, -0.3000],\n",
      "          [ 0.6000, -0.3000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2000,  1.2000,  2.4000],\n",
      "          [-0.9000,  0.3000,  0.0000],\n",
      "          [-0.6000, -0.0000, -0.3000]],\n",
      "\n",
      "         [[-0.0000, -0.6000,  0.6000],\n",
      "          [-0.0000, -1.8000,  0.9000],\n",
      "          [ 0.6000,  0.3000,  0.0000]],\n",
      "\n",
      "         [[-0.9000, -0.3000,  0.3000],\n",
      "          [-0.9000, -0.0000,  1.8000],\n",
      "          [-0.9000, -0.6000, -0.9000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.9000,  0.3000, -1.2000],\n",
      "          [ 0.9000,  0.3000, -0.9000],\n",
      "          [-0.0000, -0.3000, -0.3000]],\n",
      "\n",
      "         [[ 0.3000,  0.9000, -0.3000],\n",
      "          [-0.6000,  0.6000, -0.6000],\n",
      "          [-0.6000, -0.3000, -1.2000]],\n",
      "\n",
      "         [[-0.6000, -0.6000, -0.6000],\n",
      "          [-0.9000,  1.2000, -0.3000],\n",
      "          [-0.6000,  0.9000, -1.2000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.6000, -0.0000, -0.3000],\n",
      "          [ 0.0000, -0.0000, -1.8000],\n",
      "          [ 0.9000, -0.0000, -0.6000]],\n",
      "\n",
      "         [[-0.9000,  0.9000, -1.8000],\n",
      "          [ 1.2000,  0.0000, -0.3000],\n",
      "          [ 0.6000,  0.0000, -0.9000]],\n",
      "\n",
      "         [[ 0.0000,  0.3000, -0.9000],\n",
      "          [-0.3000, -0.0000,  0.3000],\n",
      "          [-0.6000, -0.3000, -1.2000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0000, -0.3000, -0.9000],\n",
      "          [ 0.3000, -0.3000,  0.3000],\n",
      "          [-0.6000,  0.3000,  1.2000]],\n",
      "\n",
      "         [[ 0.6000,  0.0000,  1.2000],\n",
      "          [-0.3000,  0.6000,  0.3000],\n",
      "          [-0.6000,  0.9000,  0.6000]],\n",
      "\n",
      "         [[ 0.3000,  0.3000,  0.0000],\n",
      "          [-0.6000, -0.0000, -0.0000],\n",
      "          [ 0.9000, -0.9000, -1.8000]]]], device='cuda:0',\n",
      "       grad_fn=<_pqBackward>)\n",
      "tensor([[[[ 0.6000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[ 0.3000]]],\n",
      "\n",
      "\n",
      "        [[[-0.0000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[-0.3000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[-0.9000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.6000]],\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.8000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 0.6000]]],\n",
      "\n",
      "\n",
      "        [[[-0.6000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[-0.6000]]],\n",
      "\n",
      "\n",
      "        [[[-0.3000]],\n",
      "\n",
      "         [[ 1.8000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[-0.3000]]]], device='cuda:0', grad_fn=<_pqBackward>)\n",
      "tensor([[[[ 0.6000,  0.3000, -0.9000],\n",
      "          [-0.3000,  0.9000,  0.3000],\n",
      "          [-0.0000,  0.9000,  0.6000]],\n",
      "\n",
      "         [[-0.3000,  0.6000,  0.6000],\n",
      "          [-0.6000, -0.3000,  0.0000],\n",
      "          [ 0.3000,  0.6000,  1.2000]],\n",
      "\n",
      "         [[ 1.2000,  1.2000,  1.2000],\n",
      "          [-0.3000,  0.6000,  0.6000],\n",
      "          [-0.9000,  0.3000, -0.3000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3000,  0.9000,  1.2000],\n",
      "          [-0.3000,  0.0000,  1.2000],\n",
      "          [-0.6000, -0.6000, -0.3000]],\n",
      "\n",
      "         [[ 0.9000, -1.8000, -0.9000],\n",
      "          [ 0.6000, -0.6000, -0.6000],\n",
      "          [-0.9000, -0.0000,  0.3000]],\n",
      "\n",
      "         [[ 0.3000, -0.6000, -1.2000],\n",
      "          [ 1.8000,  1.2000,  0.6000],\n",
      "          [ 0.0000,  0.6000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[-1.2000, -2.4000, -0.0000],\n",
      "          [ 0.6000, -0.6000,  0.9000],\n",
      "          [ 0.9000,  1.8000,  0.6000]],\n",
      "\n",
      "         [[-0.6000, -0.6000,  0.6000],\n",
      "          [-0.3000, -0.3000,  0.6000],\n",
      "          [ 0.6000,  1.2000, -0.6000]],\n",
      "\n",
      "         [[ 0.0000, -0.3000,  0.0000],\n",
      "          [-0.3000,  0.0000,  0.3000],\n",
      "          [-0.0000,  0.6000, -0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.6000, -1.8000, -0.3000],\n",
      "          [-0.3000, -0.9000, -0.3000],\n",
      "          [ 0.6000,  0.6000,  0.6000]],\n",
      "\n",
      "         [[ 2.4000,  1.8000, -1.2000],\n",
      "          [ 0.9000, -0.9000, -0.6000],\n",
      "          [ 0.3000,  0.6000,  0.3000]],\n",
      "\n",
      "         [[ 0.0000, -0.0000, -0.3000],\n",
      "          [-0.0000, -0.6000, -0.6000],\n",
      "          [-0.3000,  0.3000,  1.2000]]],\n",
      "\n",
      "\n",
      "        [[[-0.3000, -1.8000, -1.8000],\n",
      "          [ 0.0000, -0.6000, -0.3000],\n",
      "          [ 0.3000, -0.0000, -1.2000]],\n",
      "\n",
      "         [[ 1.2000,  0.3000, -0.9000],\n",
      "          [-0.6000, -0.6000, -1.8000],\n",
      "          [-0.3000, -1.2000, -1.2000]],\n",
      "\n",
      "         [[-1.8000, -1.8000, -0.9000],\n",
      "          [-0.0000, -0.3000,  0.6000],\n",
      "          [ 0.0000,  0.3000,  0.3000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.2000,  1.8000,  0.0000],\n",
      "          [-0.3000,  1.2000, -0.6000],\n",
      "          [-0.9000,  0.0000, -1.2000]],\n",
      "\n",
      "         [[ 0.3000,  0.6000,  0.3000],\n",
      "          [-0.0000,  0.3000,  0.0000],\n",
      "          [-0.6000, -0.3000, -0.3000]],\n",
      "\n",
      "         [[-1.2000, -0.6000, -0.6000],\n",
      "          [-0.3000, -0.6000,  0.9000],\n",
      "          [-0.0000,  0.3000,  0.9000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-1.2000,  0.6000,  0.6000],\n",
      "          [-1.2000, -0.6000,  0.9000],\n",
      "          [ 0.0000, -0.3000,  0.0000]],\n",
      "\n",
      "         [[-0.3000,  0.6000,  1.8000],\n",
      "          [-0.3000, -0.6000,  1.8000],\n",
      "          [-0.3000, -0.9000, -0.6000]],\n",
      "\n",
      "         [[ 0.6000,  1.8000,  0.6000],\n",
      "          [ 0.0000,  0.9000,  0.3000],\n",
      "          [-0.9000, -1.2000, -0.9000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.6000, -0.3000,  1.2000],\n",
      "          [-0.6000, -1.8000,  0.6000],\n",
      "          [ 0.9000,  0.3000,  1.8000]],\n",
      "\n",
      "         [[-1.2000, -0.9000, -1.8000],\n",
      "          [-0.6000,  0.6000,  0.3000],\n",
      "          [ 1.2000,  1.8000, -0.3000]],\n",
      "\n",
      "         [[-0.0000, -0.9000,  0.3000],\n",
      "          [-0.6000, -0.3000, -0.6000],\n",
      "          [ 1.8000,  2.4000,  0.9000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3000, -0.9000,  1.2000],\n",
      "          [ 1.8000, -0.6000, -0.6000],\n",
      "          [ 0.6000, -0.3000, -0.9000]],\n",
      "\n",
      "         [[-1.8000, -0.9000, -0.6000],\n",
      "          [ 0.6000,  0.9000, -0.3000],\n",
      "          [-0.9000,  1.8000,  1.2000]],\n",
      "\n",
      "         [[ 0.3000, -0.9000,  0.0000],\n",
      "          [ 0.6000, -1.8000,  0.6000],\n",
      "          [ 0.0000, -1.2000,  0.9000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3000,  0.3000, -0.9000],\n",
      "          [ 0.0000,  1.2000, -0.6000],\n",
      "          [ 0.3000,  1.2000, -0.9000]],\n",
      "\n",
      "         [[-0.6000, -0.6000, -1.8000],\n",
      "          [-0.0000, -1.2000, -0.6000],\n",
      "          [-0.0000, -0.3000, -0.3000]],\n",
      "\n",
      "         [[-0.3000, -0.6000,  1.8000],\n",
      "          [ 0.9000,  0.0000, -0.3000],\n",
      "          [ 0.9000, -0.6000, -1.8000]]],\n",
      "\n",
      "\n",
      "        [[[ 1.8000,  2.4000,  1.2000],\n",
      "          [-0.3000,  0.3000,  0.3000],\n",
      "          [-0.6000, -1.8000, -0.6000]],\n",
      "\n",
      "         [[-0.6000, -0.6000, -0.3000],\n",
      "          [ 0.3000, -0.3000, -0.0000],\n",
      "          [ 0.6000,  0.0000, -1.2000]],\n",
      "\n",
      "         [[ 1.2000,  2.4000,  1.2000],\n",
      "          [-0.6000, -0.3000, -1.2000],\n",
      "          [-1.8000, -2.4000, -0.9000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.9000, -1.2000, -0.6000],\n",
      "          [ 0.0000, -0.9000, -0.6000],\n",
      "          [ 0.3000,  0.6000,  0.6000]],\n",
      "\n",
      "         [[ 0.3000,  0.0000, -0.3000],\n",
      "          [-0.6000, -0.6000, -0.0000],\n",
      "          [ 0.9000, -0.6000, -0.6000]],\n",
      "\n",
      "         [[-0.0000, -0.3000, -0.6000],\n",
      "          [-0.3000, -0.0000, -0.0000],\n",
      "          [-0.6000,  0.0000,  0.0000]]]], device='cuda:0',\n",
      "       grad_fn=<_pqBackward>)\n",
      "tensor([[[[-1.8000]],\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         [[-1.8000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.8000]],\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         [[-0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.6000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[ 1.8000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[ 0.3000]]],\n",
      "\n",
      "\n",
      "        [[[-0.3000]],\n",
      "\n",
      "         [[ 2.4000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[ 0.6000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.9000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         [[ 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[-0.3000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.8000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[-0.3000]]],\n",
      "\n",
      "\n",
      "        [[[-0.3000]],\n",
      "\n",
      "         [[ 2.4000]],\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         [[ 0.6000]]]], device='cuda:0', grad_fn=<_pqBackward>)\n",
      "tensor([[[[-1.8000, -2.4000, -0.9000],\n",
      "          [-0.6000,  0.6000,  1.2000],\n",
      "          [-0.9000, -0.3000,  0.6000]],\n",
      "\n",
      "         [[-0.6000, -1.2000, -1.2000],\n",
      "          [ 0.0000, -0.0000, -0.6000],\n",
      "          [-0.6000,  0.0000,  2.4000]],\n",
      "\n",
      "         [[ 0.0000,  0.6000, -0.6000],\n",
      "          [-0.3000, -0.3000, -0.0000],\n",
      "          [-1.2000, -1.2000, -0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.8000,  0.0000,  0.6000],\n",
      "          [ 1.8000,  0.0000, -0.6000],\n",
      "          [ 1.8000,  0.9000, -0.3000]],\n",
      "\n",
      "         [[-0.6000, -0.3000, -0.6000],\n",
      "          [ 0.9000,  0.0000, -0.0000],\n",
      "          [ 0.9000,  0.6000,  0.0000]],\n",
      "\n",
      "         [[-0.0000,  1.8000,  0.9000],\n",
      "          [-0.3000, -0.0000,  0.3000],\n",
      "          [-0.3000,  1.2000,  0.9000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3000,  0.6000, -0.6000],\n",
      "          [-0.6000, -0.6000, -0.3000],\n",
      "          [-0.6000, -0.0000,  0.3000]],\n",
      "\n",
      "         [[ 3.0000, -0.6000, -0.6000],\n",
      "          [ 3.0000, -0.0000, -1.8000],\n",
      "          [ 0.9000, -0.3000, -2.4000]],\n",
      "\n",
      "         [[ 0.3000, -1.2000,  0.0000],\n",
      "          [ 0.0000, -1.2000, -0.6000],\n",
      "          [ 0.3000,  0.3000,  0.6000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0000,  0.3000,  0.0000],\n",
      "          [ 0.9000, -0.6000, -0.6000],\n",
      "          [ 1.2000, -0.3000, -0.9000]],\n",
      "\n",
      "         [[-0.0000, -1.8000, -0.3000],\n",
      "          [-0.3000, -1.2000,  0.6000],\n",
      "          [ 1.8000,  1.8000,  1.8000]],\n",
      "\n",
      "         [[ 0.9000,  1.8000,  1.2000],\n",
      "          [ 0.6000,  0.6000, -0.3000],\n",
      "          [-1.8000, -2.4000, -1.8000]]],\n",
      "\n",
      "\n",
      "        [[[-0.6000, -0.9000, -0.3000],\n",
      "          [ 0.3000,  0.6000,  1.8000],\n",
      "          [-0.3000, -0.3000, -1.8000]],\n",
      "\n",
      "         [[ 1.8000,  0.9000,  0.3000],\n",
      "          [-0.0000, -1.2000,  0.3000],\n",
      "          [-0.6000, -1.2000, -1.8000]],\n",
      "\n",
      "         [[ 0.6000,  1.8000,  0.3000],\n",
      "          [-0.9000,  0.3000, -1.2000],\n",
      "          [-1.8000,  0.0000, -2.4000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0000, -0.6000, -0.6000],\n",
      "          [-0.3000, -0.0000,  0.0000],\n",
      "          [ 1.8000,  1.8000,  1.8000]],\n",
      "\n",
      "         [[ 1.8000,  1.8000,  1.8000],\n",
      "          [ 0.3000, -0.3000,  0.6000],\n",
      "          [-1.8000, -1.8000, -1.2000]],\n",
      "\n",
      "         [[-2.4000, -3.0000, -2.4000],\n",
      "          [-0.9000,  0.9000, -0.6000],\n",
      "          [ 0.3000,  1.8000,  0.3000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.3000, -1.2000, -1.8000],\n",
      "          [ 0.6000,  1.2000,  0.9000],\n",
      "          [-0.6000,  0.0000,  0.9000]],\n",
      "\n",
      "         [[-0.3000,  0.9000,  0.9000],\n",
      "          [-1.2000, -0.6000,  0.0000],\n",
      "          [-3.0000,  0.0000, -0.6000]],\n",
      "\n",
      "         [[-0.9000, -0.6000,  0.3000],\n",
      "          [-1.8000, -0.9000,  0.3000],\n",
      "          [-0.6000,  0.0000, -0.3000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0000,  1.8000,  1.8000],\n",
      "          [-0.9000, -0.6000, -0.0000],\n",
      "          [-0.3000, -1.2000, -1.2000]],\n",
      "\n",
      "         [[-0.6000, -0.9000,  0.6000],\n",
      "          [ 0.3000,  1.2000, -0.0000],\n",
      "          [ 1.2000,  0.3000, -0.3000]],\n",
      "\n",
      "         [[-1.2000, -1.8000, -1.2000],\n",
      "          [-0.3000, -0.3000, -0.6000],\n",
      "          [ 0.9000,  1.8000, -0.3000]]],\n",
      "\n",
      "\n",
      "        [[[-0.9000, -0.3000, -0.3000],\n",
      "          [ 0.9000,  0.0000,  0.0000],\n",
      "          [ 2.4000,  2.4000,  2.4000]],\n",
      "\n",
      "         [[-1.2000, -0.3000,  0.9000],\n",
      "          [-0.9000, -0.3000,  2.4000],\n",
      "          [-1.2000,  0.3000,  2.4000]],\n",
      "\n",
      "         [[-0.3000, -1.2000, -0.9000],\n",
      "          [ 0.6000,  0.0000, -0.3000],\n",
      "          [ 0.0000, -0.3000, -0.9000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.6000,  0.9000,  1.2000],\n",
      "          [-0.9000,  0.6000,  0.9000],\n",
      "          [-0.9000, -0.6000, -0.6000]],\n",
      "\n",
      "         [[-0.6000, -1.8000, -2.4000],\n",
      "          [ 0.3000, -0.3000, -0.3000],\n",
      "          [ 0.9000, -0.0000,  1.2000]],\n",
      "\n",
      "         [[-0.0000,  0.3000,  1.2000],\n",
      "          [-1.2000, -0.9000, -0.6000],\n",
      "          [ 0.6000,  0.3000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.6000, -0.3000, -1.2000],\n",
      "          [ 0.3000, -0.6000, -0.6000],\n",
      "          [ 0.3000, -0.3000, -0.6000]],\n",
      "\n",
      "         [[ 0.6000, -0.9000, -1.2000],\n",
      "          [-0.3000, -0.6000, -0.9000],\n",
      "          [ 1.2000,  0.9000, -0.0000]],\n",
      "\n",
      "         [[ 0.3000, -0.0000,  0.0000],\n",
      "          [-0.6000, -0.6000,  0.9000],\n",
      "          [-0.3000,  0.0000,  1.2000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.2000, -0.0000,  0.3000],\n",
      "          [-1.2000, -0.3000,  0.6000],\n",
      "          [ 0.6000,  0.3000, -0.3000]],\n",
      "\n",
      "         [[ 1.2000,  0.3000,  1.2000],\n",
      "          [-0.6000, -0.9000,  1.2000],\n",
      "          [ 0.3000, -0.3000,  0.6000]],\n",
      "\n",
      "         [[ 1.2000, -0.9000, -1.8000],\n",
      "          [ 1.2000, -0.3000, -0.6000],\n",
      "          [ 1.2000, -0.9000, -1.2000]]]], device='cuda:0',\n",
      "       grad_fn=<_pqBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.3000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[-1.2000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000]],\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[ 1.8000]]],\n",
      "\n",
      "\n",
      "        [[[ 2.4000]],\n",
      "\n",
      "         [[ 2.4000]],\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 2.4000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.3000]],\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         [[-1.8000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         [[-1.8000]]],\n",
      "\n",
      "\n",
      "        [[[-0.3000]],\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         [[ 1.8000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[ 0.6000]]],\n",
      "\n",
      "\n",
      "        [[[-0.9000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         [[ 0.9000]]]], device='cuda:0', grad_fn=<_pqBackward>)\n",
      "tensor([[[[-0.3000, -0.9000, -1.2000],\n",
      "          [-0.0000, -0.0000, -1.2000],\n",
      "          [-0.6000, -0.0000, -0.9000]],\n",
      "\n",
      "         [[-0.6000,  0.9000, -0.3000],\n",
      "          [ 0.0000, -0.3000, -0.9000],\n",
      "          [ 0.9000, -0.0000, -1.8000]],\n",
      "\n",
      "         [[ 0.6000,  0.9000,  0.3000],\n",
      "          [ 0.9000,  0.0000, -0.3000],\n",
      "          [ 2.4000,  2.4000,  0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.6000, -1.2000, -0.6000],\n",
      "          [-0.0000, -0.3000, -0.6000],\n",
      "          [-0.9000, -0.3000,  0.6000]],\n",
      "\n",
      "         [[ 1.8000,  0.3000, -0.3000],\n",
      "          [ 1.2000,  0.3000, -0.9000],\n",
      "          [-0.6000,  1.2000, -0.0000]],\n",
      "\n",
      "         [[-0.3000, -0.9000,  0.3000],\n",
      "          [-0.6000, -1.8000, -0.0000],\n",
      "          [ 0.3000, -0.3000, -0.3000]]],\n",
      "\n",
      "\n",
      "        [[[ 1.8000,  1.2000, -0.0000],\n",
      "          [-0.0000, -0.6000, -0.0000],\n",
      "          [ 0.9000, -0.3000, -0.3000]],\n",
      "\n",
      "         [[ 0.3000, -0.9000,  0.3000],\n",
      "          [-1.2000, -1.2000, -0.6000],\n",
      "          [-0.3000,  1.2000,  0.9000]],\n",
      "\n",
      "         [[-0.6000,  0.9000,  0.3000],\n",
      "          [-0.3000,  1.2000,  0.3000],\n",
      "          [ 1.2000, -0.0000, -0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3000, -0.3000,  0.6000],\n",
      "          [-0.6000, -0.9000, -1.2000],\n",
      "          [ 0.9000, -1.2000, -0.3000]],\n",
      "\n",
      "         [[ 0.6000,  0.6000, -0.0000],\n",
      "          [ 0.3000,  0.3000,  1.2000],\n",
      "          [-0.6000,  0.9000,  2.4000]],\n",
      "\n",
      "         [[ 0.9000, -0.3000, -0.3000],\n",
      "          [ 1.8000, -0.0000,  0.0000],\n",
      "          [ 0.9000, -1.2000,  0.3000]]],\n",
      "\n",
      "\n",
      "        [[[-1.8000,  0.0000,  0.3000],\n",
      "          [-1.2000,  0.6000,  0.0000],\n",
      "          [-0.9000,  0.6000,  1.8000]],\n",
      "\n",
      "         [[ 1.2000,  0.9000,  0.3000],\n",
      "          [ 0.0000, -0.3000, -1.2000],\n",
      "          [-1.2000, -1.2000, -1.2000]],\n",
      "\n",
      "         [[-0.9000, -0.6000,  1.8000],\n",
      "          [-0.6000,  0.0000,  1.2000],\n",
      "          [-0.6000, -1.2000, -0.6000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0000,  0.0000, -1.2000],\n",
      "          [ 0.3000,  0.3000, -1.2000],\n",
      "          [-1.2000, -1.2000, -1.2000]],\n",
      "\n",
      "         [[ 0.3000,  0.9000,  1.2000],\n",
      "          [-0.3000,  0.6000,  0.9000],\n",
      "          [-1.2000, -1.2000, -0.9000]],\n",
      "\n",
      "         [[ 1.2000,  0.6000,  1.2000],\n",
      "          [ 0.6000,  0.3000,  0.3000],\n",
      "          [ 0.0000,  0.3000, -0.9000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 2.4000,  1.2000,  0.3000],\n",
      "          [ 0.3000,  0.9000,  0.6000],\n",
      "          [-1.2000,  0.0000, -0.3000]],\n",
      "\n",
      "         [[ 0.0000,  1.2000,  1.2000],\n",
      "          [-0.6000, -0.3000,  0.0000],\n",
      "          [ 0.3000, -2.4000, -1.8000]],\n",
      "\n",
      "         [[ 1.8000, -0.0000, -0.9000],\n",
      "          [ 1.2000, -0.9000, -0.9000],\n",
      "          [ 0.6000, -0.3000,  0.6000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3000,  1.8000, -1.8000],\n",
      "          [-0.0000,  0.3000, -1.2000],\n",
      "          [ 0.3000, -1.2000, -0.6000]],\n",
      "\n",
      "         [[-1.2000,  1.8000,  0.3000],\n",
      "          [-0.9000, -1.2000,  0.6000],\n",
      "          [ 0.0000, -0.6000,  0.3000]],\n",
      "\n",
      "         [[-1.2000, -0.9000,  0.3000],\n",
      "          [-1.2000, -0.3000,  0.3000],\n",
      "          [ 1.2000,  1.2000,  1.2000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3000,  0.6000,  1.2000],\n",
      "          [-0.3000, -0.0000,  0.0000],\n",
      "          [-1.8000, -0.6000,  0.6000]],\n",
      "\n",
      "         [[-0.9000, -0.9000,  0.9000],\n",
      "          [-1.2000, -1.2000,  2.4000],\n",
      "          [-1.8000, -1.2000,  3.0000]],\n",
      "\n",
      "         [[ 1.2000, -0.9000,  0.3000],\n",
      "          [-0.0000, -0.6000,  0.9000],\n",
      "          [ 0.6000,  1.2000,  0.9000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.6000,  1.8000, -1.8000],\n",
      "          [ 0.6000,  0.6000,  0.0000],\n",
      "          [-1.8000, -0.6000,  1.2000]],\n",
      "\n",
      "         [[ 1.2000,  3.0000, -0.9000],\n",
      "          [ 1.8000,  2.4000,  0.0000],\n",
      "          [-0.3000, -0.6000, -0.9000]],\n",
      "\n",
      "         [[-0.6000,  0.0000,  1.2000],\n",
      "          [-1.2000,  0.0000,  1.8000],\n",
      "          [-0.6000,  0.6000,  1.2000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3000, -0.3000, -0.0000],\n",
      "          [ 0.3000,  0.6000, -0.6000],\n",
      "          [ 0.0000,  0.0000, -0.6000]],\n",
      "\n",
      "         [[ 0.3000,  0.6000,  0.6000],\n",
      "          [-0.3000,  0.9000, -0.6000],\n",
      "          [-0.0000,  1.8000, -0.6000]],\n",
      "\n",
      "         [[-1.8000,  0.6000, -0.3000],\n",
      "          [-1.8000,  1.2000,  0.3000],\n",
      "          [-1.2000,  1.2000,  0.9000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.2000, -0.6000,  0.0000],\n",
      "          [ 1.2000, -0.0000, -0.3000],\n",
      "          [ 1.2000, -0.6000,  0.0000]],\n",
      "\n",
      "         [[-0.3000, -1.2000, -0.3000],\n",
      "          [-0.6000, -1.2000, -1.2000],\n",
      "          [ 0.3000,  0.9000, -0.3000]],\n",
      "\n",
      "         [[-0.6000, -0.0000, -0.3000],\n",
      "          [-0.6000,  0.0000, -0.0000],\n",
      "          [-0.3000,  0.6000,  0.0000]]]], device='cuda:0',\n",
      "       grad_fn=<_pqBackward>)\n",
      "tensor([[[[ 2.4000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 1.8000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3000]],\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         [[-0.9000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.6000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         [[-1.8000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.3000]],\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[ 0.6000]]],\n",
      "\n",
      "\n",
      "        [[[ 1.8000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.0000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[-0.3000]]],\n",
      "\n",
      "\n",
      "        [[[-0.6000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         [[-3.0000]]]], device='cuda:0', grad_fn=<_pqBackward>)\n",
      "tensor([[[[ 1.2000, -0.3000, -0.9000],\n",
      "          [ 1.2000, -0.0000, -0.0000],\n",
      "          [ 0.3000,  0.3000, -0.0000]],\n",
      "\n",
      "         [[-1.8000, -1.2000, -0.6000],\n",
      "          [-1.2000, -0.3000,  0.3000],\n",
      "          [-1.2000,  0.3000, -0.0000]],\n",
      "\n",
      "         [[-0.9000, -1.2000,  0.3000],\n",
      "          [ 0.6000,  0.3000,  0.0000],\n",
      "          [-0.3000,  0.6000,  0.3000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3000, -0.3000, -0.9000],\n",
      "          [-0.6000, -0.3000, -0.9000],\n",
      "          [ 0.6000,  0.9000,  0.6000]],\n",
      "\n",
      "         [[ 0.3000,  0.3000,  0.0000],\n",
      "          [ 0.3000,  0.6000, -0.3000],\n",
      "          [-0.3000,  0.3000, -1.2000]],\n",
      "\n",
      "         [[-0.3000, -0.6000,  0.6000],\n",
      "          [ 1.2000,  0.0000,  0.3000],\n",
      "          [ 0.3000,  0.0000, -0.3000]]],\n",
      "\n",
      "\n",
      "        [[[-0.9000, -0.3000, -0.6000],\n",
      "          [ 0.9000,  0.3000, -1.8000],\n",
      "          [ 1.8000, -0.3000, -0.6000]],\n",
      "\n",
      "         [[ 0.9000,  0.9000,  0.6000],\n",
      "          [ 1.2000,  0.3000, -0.9000],\n",
      "          [ 0.3000,  0.0000,  0.6000]],\n",
      "\n",
      "         [[-1.2000,  0.6000, -0.9000],\n",
      "          [-1.8000, -0.6000,  0.6000],\n",
      "          [-1.8000, -0.9000,  0.3000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.9000, -0.3000, -0.9000],\n",
      "          [ 0.6000, -0.3000,  0.6000],\n",
      "          [-1.2000, -0.9000,  1.2000]],\n",
      "\n",
      "         [[-1.2000,  0.9000,  3.0000],\n",
      "          [ 0.6000,  1.8000,  1.8000],\n",
      "          [ 1.2000,  0.6000, -0.3000]],\n",
      "\n",
      "         [[-1.8000, -0.6000,  1.8000],\n",
      "          [-1.2000, -0.6000,  2.4000],\n",
      "          [-1.2000,  1.2000,  2.4000]]],\n",
      "\n",
      "\n",
      "        [[[-1.2000, -0.6000,  0.0000],\n",
      "          [-0.9000,  1.2000,  0.3000],\n",
      "          [-0.6000, -0.9000, -0.9000]],\n",
      "\n",
      "         [[-1.2000, -0.3000,  1.8000],\n",
      "          [-1.2000, -0.9000,  1.8000],\n",
      "          [-1.8000,  0.0000, -0.3000]],\n",
      "\n",
      "         [[-0.6000, -0.9000, -2.4000],\n",
      "          [ 0.0000,  0.6000,  0.3000],\n",
      "          [-1.2000,  1.2000,  1.2000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.6000, -0.6000, -0.9000],\n",
      "          [-0.9000, -0.6000, -0.0000],\n",
      "          [-0.9000, -0.6000, -0.6000]],\n",
      "\n",
      "         [[ 0.3000,  1.8000,  0.9000],\n",
      "          [-0.6000,  0.3000,  0.3000],\n",
      "          [-0.0000,  1.2000, -0.0000]],\n",
      "\n",
      "         [[-0.9000, -0.3000, -0.6000],\n",
      "          [-0.3000,  0.0000, -0.3000],\n",
      "          [ 0.3000,  0.9000,  0.6000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.3000, -0.3000,  1.8000],\n",
      "          [-0.9000,  0.3000,  0.6000],\n",
      "          [ 1.8000,  0.9000, -1.2000]],\n",
      "\n",
      "         [[-1.2000,  0.6000,  0.3000],\n",
      "          [-0.3000,  0.9000,  0.9000],\n",
      "          [ 0.6000, -0.3000, -1.8000]],\n",
      "\n",
      "         [[-1.2000,  0.3000,  1.2000],\n",
      "          [-1.8000, -0.3000,  0.0000],\n",
      "          [ 1.8000,  2.4000, -0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3000, -1.8000, -0.9000],\n",
      "          [ 0.9000,  0.9000,  1.8000],\n",
      "          [-0.9000,  0.9000,  1.8000]],\n",
      "\n",
      "         [[-0.6000, -0.0000, -0.0000],\n",
      "          [ 0.3000,  0.9000, -0.3000],\n",
      "          [ 0.6000,  0.6000, -0.3000]],\n",
      "\n",
      "         [[-1.2000,  0.0000,  1.2000],\n",
      "          [-0.0000,  0.6000, -0.6000],\n",
      "          [ 1.2000,  1.8000,  0.3000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000, -0.3000, -0.6000],\n",
      "          [-0.6000,  0.9000, -0.6000],\n",
      "          [-1.2000,  0.9000, -0.6000]],\n",
      "\n",
      "         [[ 1.8000,  0.3000, -0.3000],\n",
      "          [-0.3000, -0.9000, -0.0000],\n",
      "          [-1.2000, -0.3000,  0.9000]],\n",
      "\n",
      "         [[-1.2000, -1.2000, -1.8000],\n",
      "          [-1.2000,  0.6000, -0.0000],\n",
      "          [-2.4000,  1.2000,  0.9000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3000, -0.6000,  0.3000],\n",
      "          [-0.9000, -1.2000, -0.9000],\n",
      "          [-0.0000, -1.2000, -0.9000]],\n",
      "\n",
      "         [[ 0.3000,  0.3000,  0.3000],\n",
      "          [-0.6000, -0.3000, -0.3000],\n",
      "          [-0.9000, -0.0000, -0.3000]],\n",
      "\n",
      "         [[-1.8000, -0.9000, -0.6000],\n",
      "          [ 0.6000, -0.0000, -0.9000],\n",
      "          [ 0.6000,  0.3000, -1.8000]]],\n",
      "\n",
      "\n",
      "        [[[ 1.8000,  0.3000,  0.9000],\n",
      "          [ 1.2000,  0.6000, -0.3000],\n",
      "          [-0.6000, -1.8000, -0.9000]],\n",
      "\n",
      "         [[ 1.8000,  1.8000,  2.4000],\n",
      "          [-1.8000, -1.2000, -1.8000],\n",
      "          [ 0.6000,  2.4000,  1.8000]],\n",
      "\n",
      "         [[-0.9000, -1.8000, -0.9000],\n",
      "          [ 2.4000,  1.8000,  3.0000],\n",
      "          [-0.9000, -1.8000, -0.3000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3000, -0.3000, -0.3000],\n",
      "          [ 0.3000, -0.3000, -0.3000],\n",
      "          [-0.6000, -1.8000, -0.3000]],\n",
      "\n",
      "         [[ 2.4000,  1.2000,  1.2000],\n",
      "          [-0.3000, -1.8000, -0.9000],\n",
      "          [ 0.3000,  0.9000,  0.3000]],\n",
      "\n",
      "         [[-0.6000, -0.9000,  0.0000],\n",
      "          [ 0.9000, -0.3000, -0.9000],\n",
      "          [-0.6000, -0.3000, -1.2000]]]], device='cuda:0',\n",
      "       grad_fn=<_pqBackward>)\n",
      "tensor([[[[-1.8000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         [[ 0.6000]]],\n",
      "\n",
      "\n",
      "        [[[-1.2000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.8000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[ 0.6000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.6000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[-1.8000]],\n",
      "\n",
      "         [[ 0.3000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-1.2000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         [[-0.6000]]],\n",
      "\n",
      "\n",
      "        [[[-0.3000]],\n",
      "\n",
      "         [[-2.4000]],\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.8000]],\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         [[-1.8000]]],\n",
      "\n",
      "\n",
      "        [[[-0.9000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[-1.8000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[ 0.6000]]]], device='cuda:0', grad_fn=<_pqBackward>)\n",
      "tensor([[[[-1.2000,  0.6000,  0.9000],\n",
      "          [-1.2000, -1.2000, -0.9000],\n",
      "          [-0.3000, -0.9000,  0.3000]],\n",
      "\n",
      "         [[ 1.8000,  1.8000,  1.8000],\n",
      "          [ 1.2000,  0.3000,  0.0000],\n",
      "          [-0.3000,  0.0000, -0.6000]],\n",
      "\n",
      "         [[-0.3000, -0.6000,  0.3000],\n",
      "          [ 0.3000,  0.6000,  0.6000],\n",
      "          [ 0.3000,  0.3000,  0.6000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3000,  0.3000,  1.2000],\n",
      "          [-0.6000, -0.6000, -0.0000],\n",
      "          [-1.8000,  0.3000,  0.6000]],\n",
      "\n",
      "         [[ 2.4000,  0.6000,  0.9000],\n",
      "          [ 0.6000, -0.6000,  0.3000],\n",
      "          [-0.3000, -0.0000, -0.6000]],\n",
      "\n",
      "         [[ 0.9000, -0.9000, -0.0000],\n",
      "          [ 0.9000,  0.3000, -0.6000],\n",
      "          [ 0.9000,  1.2000, -0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2000,  1.2000, -0.3000],\n",
      "          [ 2.4000,  0.3000, -3.0000],\n",
      "          [ 0.9000, -0.0000,  0.6000]],\n",
      "\n",
      "         [[-1.8000, -0.9000,  1.2000],\n",
      "          [ 0.3000, -1.2000,  0.6000],\n",
      "          [-0.0000,  0.9000,  0.3000]],\n",
      "\n",
      "         [[-0.0000,  0.0000, -0.9000],\n",
      "          [-0.6000, -0.0000, -0.3000],\n",
      "          [-0.3000, -0.6000, -0.6000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3000, -0.3000, -2.4000],\n",
      "          [ 0.6000,  0.6000, -1.2000],\n",
      "          [ 0.0000, -0.3000,  0.3000]],\n",
      "\n",
      "         [[ 1.2000,  1.8000,  0.3000],\n",
      "          [ 2.4000, -0.3000, -2.4000],\n",
      "          [ 1.8000, -1.2000, -1.2000]],\n",
      "\n",
      "         [[-0.0000,  2.4000,  2.4000],\n",
      "          [-0.9000, -0.0000,  0.6000],\n",
      "          [-0.3000,  0.0000,  0.9000]]],\n",
      "\n",
      "\n",
      "        [[[-1.2000, -0.9000, -0.6000],\n",
      "          [-0.3000,  0.6000,  0.3000],\n",
      "          [ 0.9000, -0.0000,  0.9000]],\n",
      "\n",
      "         [[ 0.0000,  1.2000,  0.3000],\n",
      "          [-1.8000, -0.0000,  1.8000],\n",
      "          [-0.6000, -0.6000,  0.3000]],\n",
      "\n",
      "         [[-0.6000, -1.2000,  0.3000],\n",
      "          [-0.6000, -0.6000,  0.3000],\n",
      "          [ 0.3000,  0.3000, -0.6000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.0000, -1.8000, -0.6000],\n",
      "          [-3.0000,  0.9000, -0.0000],\n",
      "          [-0.6000,  0.9000, -0.3000]],\n",
      "\n",
      "         [[ 0.9000,  1.2000,  0.9000],\n",
      "          [-0.9000, -1.8000, -1.2000],\n",
      "          [-1.2000, -1.2000, -0.9000]],\n",
      "\n",
      "         [[-0.6000, -0.0000,  0.6000],\n",
      "          [ 0.0000,  0.3000,  1.2000],\n",
      "          [ 0.3000,  0.6000,  0.6000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.3000, -0.3000,  0.0000],\n",
      "          [-0.3000, -0.3000,  1.8000],\n",
      "          [-0.3000,  0.6000,  2.4000]],\n",
      "\n",
      "         [[-0.9000,  0.3000,  0.6000],\n",
      "          [-0.9000,  0.0000,  0.3000],\n",
      "          [-0.3000, -0.6000, -0.3000]],\n",
      "\n",
      "         [[-0.6000, -0.0000,  0.3000],\n",
      "          [ 0.9000,  1.2000,  0.9000],\n",
      "          [ 0.3000,  0.3000,  0.3000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.8000, -0.6000,  1.8000],\n",
      "          [-0.9000, -0.6000,  1.2000],\n",
      "          [-0.3000, -0.0000,  0.6000]],\n",
      "\n",
      "         [[-0.9000,  0.3000,  0.6000],\n",
      "          [-0.9000,  0.6000, -0.0000],\n",
      "          [-0.3000,  0.3000, -0.3000]],\n",
      "\n",
      "         [[-0.3000,  0.9000, -0.3000],\n",
      "          [-0.3000,  0.9000, -0.6000],\n",
      "          [-0.3000,  0.9000, -0.3000]]],\n",
      "\n",
      "\n",
      "        [[[ 3.0000,  1.2000, -1.8000],\n",
      "          [ 3.0000, -0.9000, -1.8000],\n",
      "          [ 3.0000, -0.0000, -0.3000]],\n",
      "\n",
      "         [[ 0.3000,  1.2000,  1.2000],\n",
      "          [ 0.3000, -1.2000, -1.8000],\n",
      "          [ 0.0000, -0.0000, -1.8000]],\n",
      "\n",
      "         [[ 0.0000, -1.2000, -0.3000],\n",
      "          [-0.6000,  0.0000, -0.9000],\n",
      "          [-0.0000, -0.6000, -0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3000,  0.6000, -0.3000],\n",
      "          [-0.0000,  0.9000,  0.3000],\n",
      "          [-0.6000, -0.3000,  0.3000]],\n",
      "\n",
      "         [[-1.8000,  0.9000, -0.9000],\n",
      "          [-1.8000, -0.9000,  0.3000],\n",
      "          [-2.4000, -2.4000,  0.3000]],\n",
      "\n",
      "         [[-0.3000,  0.6000,  0.9000],\n",
      "          [ 0.3000, -0.3000, -0.0000],\n",
      "          [-0.3000, -1.2000, -0.0000]]],\n",
      "\n",
      "\n",
      "        [[[-0.0000,  0.3000,  0.0000],\n",
      "          [ 0.6000,  0.6000,  0.3000],\n",
      "          [ 1.2000,  1.2000,  0.6000]],\n",
      "\n",
      "         [[ 0.6000, -0.6000, -2.4000],\n",
      "          [ 0.9000, -0.3000, -2.4000],\n",
      "          [-0.3000, -0.3000, -0.9000]],\n",
      "\n",
      "         [[ 2.4000, -0.6000, -1.2000],\n",
      "          [ 1.8000,  0.3000,  0.3000],\n",
      "          [ 0.6000, -0.6000,  0.3000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.6000, -0.3000, -1.8000],\n",
      "          [ 0.3000,  0.6000, -0.6000],\n",
      "          [-0.3000,  0.3000, -0.3000]],\n",
      "\n",
      "         [[ 0.9000,  0.3000, -0.0000],\n",
      "          [ 1.8000, -0.3000, -0.6000],\n",
      "          [ 0.0000, -0.3000, -1.2000]],\n",
      "\n",
      "         [[-1.2000,  0.0000,  0.3000],\n",
      "          [-0.6000,  0.0000,  0.0000],\n",
      "          [-0.3000, -0.0000,  0.6000]]]], device='cuda:0',\n",
      "       grad_fn=<_pqBackward>)\n",
      "tensor([[[[ 0.3000]],\n",
      "\n",
      "         [[-2.4000]],\n",
      "\n",
      "         [[-1.8000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         [[-0.6000]]],\n",
      "\n",
      "\n",
      "        [[[-0.3000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[-0.9000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3000]],\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[ 1.2000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.3000]],\n",
      "\n",
      "         [[-2.4000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         [[-0.6000]]],\n",
      "\n",
      "\n",
      "        [[[-0.3000]],\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         [[ 3.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[-1.8000]],\n",
      "\n",
      "         [[ 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 1.8000]],\n",
      "\n",
      "         [[ 1.8000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[-0.3000]]]], device='cuda:0', grad_fn=<_pqBackward>)\n",
      "tensor([[[[-0.0000, -0.0000,  0.3000],\n",
      "          [-0.6000, -0.3000, -0.3000],\n",
      "          [ 0.0000,  0.9000, -0.3000]],\n",
      "\n",
      "         [[ 0.9000,  0.3000,  0.9000],\n",
      "          [-0.9000, -1.8000, -1.2000],\n",
      "          [ 0.0000, -0.3000, -0.0000]],\n",
      "\n",
      "         [[ 0.0000, -0.6000, -0.3000],\n",
      "          [ 0.6000, -0.3000, -0.3000],\n",
      "          [-0.6000, -0.6000, -0.3000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3000, -0.0000,  0.6000],\n",
      "          [-1.2000,  0.3000, -0.3000],\n",
      "          [-0.3000,  0.9000,  0.6000]],\n",
      "\n",
      "         [[-1.8000, -2.4000, -2.4000],\n",
      "          [-1.2000, -0.6000, -0.6000],\n",
      "          [ 0.9000,  1.2000,  1.2000]],\n",
      "\n",
      "         [[-1.2000, -1.2000, -0.9000],\n",
      "          [ 0.3000, -0.0000, -0.6000],\n",
      "          [ 0.9000,  1.2000,  0.3000]]],\n",
      "\n",
      "\n",
      "        [[[-0.3000, -1.2000,  1.8000],\n",
      "          [ 2.4000,  2.4000,  1.2000],\n",
      "          [ 3.0000,  2.4000,  1.2000]],\n",
      "\n",
      "         [[ 1.8000,  0.6000,  0.9000],\n",
      "          [-0.3000, -1.2000, -0.3000],\n",
      "          [ 0.3000, -0.3000,  0.3000]],\n",
      "\n",
      "         [[ 1.2000,  0.6000,  0.6000],\n",
      "          [ 0.6000,  0.0000,  0.6000],\n",
      "          [-0.6000, -0.9000, -0.3000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.6000,  1.8000, -0.0000],\n",
      "          [-0.6000,  0.0000, -0.3000],\n",
      "          [-0.3000, -0.6000,  0.3000]],\n",
      "\n",
      "         [[-0.6000,  0.3000, -1.8000],\n",
      "          [-1.8000, -0.3000, -1.2000],\n",
      "          [-1.2000,  0.3000, -0.9000]],\n",
      "\n",
      "         [[-0.9000, -0.9000, -0.3000],\n",
      "          [ 0.0000,  0.3000,  0.6000],\n",
      "          [-0.6000, -0.3000,  0.9000]]],\n",
      "\n",
      "\n",
      "        [[[-0.6000, -0.6000,  0.3000],\n",
      "          [-0.9000, -0.0000,  0.9000],\n",
      "          [-0.6000,  0.0000,  0.9000]],\n",
      "\n",
      "         [[-0.3000,  1.2000,  1.2000],\n",
      "          [-0.6000,  0.6000,  2.4000],\n",
      "          [-1.2000,  1.2000,  3.0000]],\n",
      "\n",
      "         [[-1.2000,  1.2000,  2.4000],\n",
      "          [-2.4000, -0.3000,  2.4000],\n",
      "          [-0.9000, -1.2000, -0.6000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.8000,  0.9000,  3.0000],\n",
      "          [-0.3000, -0.0000,  1.2000],\n",
      "          [-0.3000,  0.6000,  0.6000]],\n",
      "\n",
      "         [[-1.8000, -1.2000, -0.9000],\n",
      "          [ 1.8000, -0.6000, -1.2000],\n",
      "          [ 2.4000,  0.0000, -0.6000]],\n",
      "\n",
      "         [[-0.0000, -0.3000, -0.3000],\n",
      "          [ 0.3000,  0.3000, -0.3000],\n",
      "          [ 1.2000,  1.2000,  1.2000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 1.2000,  0.3000,  0.3000],\n",
      "          [ 0.6000, -0.3000,  0.0000],\n",
      "          [-0.6000, -1.8000, -1.2000]],\n",
      "\n",
      "         [[ 0.9000,  0.0000,  0.6000],\n",
      "          [-0.0000, -0.6000,  0.3000],\n",
      "          [ 0.6000,  0.3000,  0.9000]],\n",
      "\n",
      "         [[-0.9000, -1.2000, -0.9000],\n",
      "          [ 0.6000,  0.3000,  0.9000],\n",
      "          [-0.3000, -0.6000, -0.3000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.4000,  1.2000,  0.9000],\n",
      "          [ 0.0000, -1.2000, -0.6000],\n",
      "          [-0.3000, -0.6000, -0.9000]],\n",
      "\n",
      "         [[-0.9000, -0.9000,  0.3000],\n",
      "          [-0.9000, -0.3000, -0.0000],\n",
      "          [ 0.6000,  0.0000,  0.6000]],\n",
      "\n",
      "         [[-0.9000,  0.0000, -0.3000],\n",
      "          [-0.9000,  0.3000,  0.3000],\n",
      "          [-1.8000, -1.2000, -0.9000]]],\n",
      "\n",
      "\n",
      "        [[[-0.3000, -0.9000, -0.9000],\n",
      "          [-0.9000, -0.9000, -0.9000],\n",
      "          [-0.6000,  0.6000, -0.9000]],\n",
      "\n",
      "         [[-0.0000,  1.2000,  0.3000],\n",
      "          [-0.9000, -0.3000, -0.6000],\n",
      "          [-0.3000, -1.2000, -1.2000]],\n",
      "\n",
      "         [[-1.2000, -1.2000, -0.0000],\n",
      "          [ 0.3000, -0.3000, -0.6000],\n",
      "          [-0.3000, -0.6000, -0.9000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.8000, -1.8000,  0.6000],\n",
      "          [ 0.9000,  0.0000,  1.2000],\n",
      "          [ 0.3000,  0.6000,  0.3000]],\n",
      "\n",
      "         [[ 0.6000,  1.8000, -0.3000],\n",
      "          [-0.0000,  0.6000, -0.3000],\n",
      "          [-0.3000, -0.3000, -0.3000]],\n",
      "\n",
      "         [[-0.6000, -0.3000, -1.2000],\n",
      "          [-0.9000, -0.9000, -1.2000],\n",
      "          [ 0.3000,  1.2000,  1.8000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.6000,  0.6000,  1.2000],\n",
      "          [ 1.2000, -0.3000,  0.9000],\n",
      "          [ 0.6000,  0.0000,  0.9000]],\n",
      "\n",
      "         [[ 0.3000,  0.6000,  0.3000],\n",
      "          [ 0.3000,  0.0000,  0.3000],\n",
      "          [ 1.2000, -0.3000,  0.3000]],\n",
      "\n",
      "         [[ 1.2000, -0.9000, -1.8000],\n",
      "          [ 1.8000, -0.3000, -1.8000],\n",
      "          [ 0.6000, -0.9000, -0.9000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.4000, -0.6000, -2.4000],\n",
      "          [ 0.3000,  0.3000, -1.8000],\n",
      "          [ 0.3000,  0.6000, -0.3000]],\n",
      "\n",
      "         [[-0.3000, -2.4000, -1.2000],\n",
      "          [-0.6000, -0.9000,  1.2000],\n",
      "          [-0.9000,  0.3000,  1.8000]],\n",
      "\n",
      "         [[ 1.8000,  0.6000,  0.3000],\n",
      "          [ 1.2000, -0.9000, -0.6000],\n",
      "          [-1.2000, -1.2000, -2.4000]]]], device='cuda:0',\n",
      "       grad_fn=<_pqBackward>)\n",
      "tensor([[[[-0.6000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[-0.3000]]],\n",
      "\n",
      "\n",
      "        [[[-0.0000]],\n",
      "\n",
      "         [[ 1.8000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[ 1.2000]]],\n",
      "\n",
      "\n",
      "        [[[-0.9000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         [[-0.9000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.3000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 1.8000]],\n",
      "\n",
      "         [[ 0.6000]]],\n",
      "\n",
      "\n",
      "        [[[-0.3000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[ 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[-0.3000]],\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[ 0.6000]]]], device='cuda:0', grad_fn=<_pqBackward>)\n",
      "tensor([[[[ 0.9000, -2.4000, -0.0000],\n",
      "          [ 1.8000, -0.6000,  0.6000],\n",
      "          [ 1.8000,  0.9000,  0.9000]],\n",
      "\n",
      "         [[-0.9000, -1.8000, -0.9000],\n",
      "          [ 0.9000,  0.0000,  0.3000],\n",
      "          [ 2.4000,  1.8000,  1.2000]],\n",
      "\n",
      "         [[ 0.6000, -0.3000,  1.2000],\n",
      "          [ 0.6000, -0.9000,  0.9000],\n",
      "          [ 1.2000, -0.6000, -1.2000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.9000, -0.6000, -0.3000],\n",
      "          [ 0.3000,  0.3000,  0.0000],\n",
      "          [-1.8000, -0.6000, -0.6000]],\n",
      "\n",
      "         [[ 1.2000,  1.8000,  0.0000],\n",
      "          [ 0.6000,  0.3000, -0.6000],\n",
      "          [-1.2000, -0.9000,  1.2000]],\n",
      "\n",
      "         [[ 3.0000,  1.8000, -2.4000],\n",
      "          [ 0.6000,  0.0000, -1.8000],\n",
      "          [ 0.6000, -0.6000, -0.0000]]],\n",
      "\n",
      "\n",
      "        [[[-0.9000, -0.0000,  0.6000],\n",
      "          [ 0.3000,  1.8000,  1.2000],\n",
      "          [ 1.2000,  1.8000,  0.9000]],\n",
      "\n",
      "         [[-0.6000, -0.9000, -1.2000],\n",
      "          [-0.3000, -0.6000, -0.9000],\n",
      "          [ 0.6000,  0.6000,  1.2000]],\n",
      "\n",
      "         [[ 1.2000, -0.0000, -0.9000],\n",
      "          [ 0.3000, -0.9000,  0.0000],\n",
      "          [-0.0000,  0.3000,  1.8000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3000,  0.3000,  0.3000],\n",
      "          [-0.3000,  0.3000,  0.6000],\n",
      "          [-1.2000, -0.6000,  0.0000]],\n",
      "\n",
      "         [[-0.3000,  0.0000,  0.9000],\n",
      "          [-0.6000,  0.0000,  0.6000],\n",
      "          [-0.3000,  0.0000, -0.6000]],\n",
      "\n",
      "         [[ 0.6000, -0.9000, -0.9000],\n",
      "          [ 0.0000,  0.0000, -0.3000],\n",
      "          [ 1.8000,  0.6000,  0.3000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3000,  0.3000, -0.3000],\n",
      "          [-1.8000, -0.9000, -0.6000],\n",
      "          [-1.2000,  0.0000,  0.6000]],\n",
      "\n",
      "         [[-0.3000, -0.3000, -0.3000],\n",
      "          [-0.0000,  0.3000, -0.9000],\n",
      "          [-1.8000, -0.6000, -1.2000]],\n",
      "\n",
      "         [[-0.9000, -0.9000, -0.3000],\n",
      "          [-0.9000,  0.6000,  0.6000],\n",
      "          [-1.2000,  1.2000,  0.6000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.9000, -0.0000, -0.0000],\n",
      "          [ 0.9000,  0.3000, -0.0000],\n",
      "          [ 0.6000,  0.9000,  0.6000]],\n",
      "\n",
      "         [[-0.6000,  0.6000,  1.2000],\n",
      "          [-0.3000,  0.0000,  0.6000],\n",
      "          [-0.0000, -0.6000, -0.9000]],\n",
      "\n",
      "         [[-0.0000,  2.4000, -0.3000],\n",
      "          [-1.8000,  1.2000,  0.3000],\n",
      "          [-0.0000, -1.8000,  0.3000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.9000,  0.9000, -1.2000],\n",
      "          [ 0.9000,  0.9000, -1.2000],\n",
      "          [-1.2000, -0.3000, -0.6000]],\n",
      "\n",
      "         [[ 0.6000,  0.9000,  0.6000],\n",
      "          [-0.3000, -0.6000,  0.3000],\n",
      "          [-0.9000,  0.3000, -1.2000]],\n",
      "\n",
      "         [[ 2.4000,  3.0000,  1.8000],\n",
      "          [-0.3000,  0.6000,  0.6000],\n",
      "          [-2.4000, -1.2000, -0.9000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3000,  0.3000, -0.9000],\n",
      "          [-0.3000,  0.6000,  0.6000],\n",
      "          [ 0.3000,  0.6000,  0.3000]],\n",
      "\n",
      "         [[-0.3000, -1.8000, -1.2000],\n",
      "          [ 0.3000,  0.0000,  0.6000],\n",
      "          [ 0.9000,  1.8000,  2.4000]],\n",
      "\n",
      "         [[-0.6000, -0.0000, -1.8000],\n",
      "          [-1.2000, -0.3000,  0.9000],\n",
      "          [ 0.0000,  0.6000,  1.8000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.6000,  0.3000,  1.2000],\n",
      "          [ 1.2000,  0.6000,  0.9000],\n",
      "          [ 1.8000,  1.8000,  0.3000]],\n",
      "\n",
      "         [[-0.3000,  3.0000,  1.2000],\n",
      "          [-0.0000,  0.6000, -0.9000],\n",
      "          [-0.6000, -1.2000, -1.2000]],\n",
      "\n",
      "         [[ 0.3000,  0.3000, -0.9000],\n",
      "          [-0.0000,  0.6000,  1.2000],\n",
      "          [-1.2000, -0.3000,  1.2000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3000, -0.6000, -0.6000],\n",
      "          [ 0.6000,  0.3000, -0.9000],\n",
      "          [ 1.8000,  0.9000, -0.6000]],\n",
      "\n",
      "         [[-0.3000,  0.9000,  3.0000],\n",
      "          [-0.9000,  0.0000,  0.3000],\n",
      "          [-1.2000,  0.3000, -0.6000]],\n",
      "\n",
      "         [[ 0.9000, -0.0000, -1.2000],\n",
      "          [ 0.6000, -0.6000, -2.4000],\n",
      "          [ 1.8000,  1.8000, -0.3000]]],\n",
      "\n",
      "\n",
      "        [[[-0.3000,  0.3000,  0.9000],\n",
      "          [-0.9000,  0.0000, -0.0000],\n",
      "          [-1.2000, -0.6000, -0.6000]],\n",
      "\n",
      "         [[-1.2000, -0.6000, -0.6000],\n",
      "          [-0.9000, -0.6000, -0.0000],\n",
      "          [ 0.3000,  0.3000,  0.0000]],\n",
      "\n",
      "         [[-0.6000, -0.3000, -1.2000],\n",
      "          [ 0.9000,  1.2000, -0.6000],\n",
      "          [ 2.4000,  2.4000,  0.3000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.2000,  0.6000,  0.6000],\n",
      "          [ 1.2000,  0.3000, -0.3000],\n",
      "          [ 0.9000, -0.3000, -0.9000]],\n",
      "\n",
      "         [[ 0.6000,  0.9000, -0.6000],\n",
      "          [-1.8000,  1.2000,  0.6000],\n",
      "          [-1.2000,  1.8000,  1.2000]],\n",
      "\n",
      "         [[-1.2000,  0.6000, -0.6000],\n",
      "          [-0.3000,  0.0000, -1.2000],\n",
      "          [-0.9000, -0.3000, -1.2000]]]], device='cuda:0',\n",
      "       grad_fn=<_pqBackward>)\n",
      "tensor([[[[-1.8000]],\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[ 0.3000]]],\n",
      "\n",
      "\n",
      "        [[[-1.2000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.8000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 1.2000]]],\n",
      "\n",
      "\n",
      "        [[[-2.4000]],\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[-0.3000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.3000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[ 0.3000]]],\n",
      "\n",
      "\n",
      "        [[[-1.8000]],\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         [[ 1.8000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[ 1.2000]]],\n",
      "\n",
      "\n",
      "        [[[ 3.0000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         [[ 0.6000]]]], device='cuda:0', grad_fn=<_pqBackward>)\n",
      "tensor([[[[ 1.8000,  0.6000,  0.0000],\n",
      "          [-0.6000, -0.9000, -1.2000],\n",
      "          [-0.6000, -0.9000, -1.2000]],\n",
      "\n",
      "         [[ 0.3000, -0.3000,  0.6000],\n",
      "          [-0.6000, -0.3000,  0.0000],\n",
      "          [ 0.6000,  0.3000,  1.2000]],\n",
      "\n",
      "         [[ 0.3000, -0.9000, -0.3000],\n",
      "          [ 1.8000,  0.3000,  0.0000],\n",
      "          [ 1.8000,  1.8000,  0.9000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.9000, -1.2000, -0.9000],\n",
      "          [ 2.4000, -1.2000, -0.3000],\n",
      "          [ 1.8000,  1.2000, -0.0000]],\n",
      "\n",
      "         [[-0.9000, -1.2000, -0.3000],\n",
      "          [-0.0000, -1.2000, -0.3000],\n",
      "          [ 1.8000,  2.4000,  2.4000]],\n",
      "\n",
      "         [[-0.0000,  0.9000,  0.3000],\n",
      "          [-1.8000, -0.6000, -0.6000],\n",
      "          [-1.2000, -1.2000, -0.6000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3000, -0.0000, -0.3000],\n",
      "          [ 0.0000,  0.0000,  1.2000],\n",
      "          [ 0.6000, -0.3000,  1.8000]],\n",
      "\n",
      "         [[ 1.2000,  1.8000,  0.9000],\n",
      "          [ 0.9000,  0.3000,  0.3000],\n",
      "          [ 0.6000,  0.9000, -0.9000]],\n",
      "\n",
      "         [[-0.6000,  0.0000,  0.3000],\n",
      "          [-0.3000,  2.4000,  3.0000],\n",
      "          [-0.6000,  1.8000,  1.2000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.2000, -2.4000, -0.9000],\n",
      "          [-1.8000, -0.9000,  0.3000],\n",
      "          [-0.9000,  2.4000,  2.4000]],\n",
      "\n",
      "         [[-0.3000,  1.8000,  2.4000],\n",
      "          [ 0.9000,  0.6000,  1.8000],\n",
      "          [ 0.3000, -1.2000, -0.0000]],\n",
      "\n",
      "         [[-0.9000,  0.9000,  0.3000],\n",
      "          [-0.9000,  1.2000,  1.8000],\n",
      "          [-1.8000,  0.9000,  1.8000]]],\n",
      "\n",
      "\n",
      "        [[[ 2.4000,  1.8000,  1.8000],\n",
      "          [ 0.9000,  0.6000, -0.0000],\n",
      "          [-0.3000, -1.8000,  0.6000]],\n",
      "\n",
      "         [[-0.6000, -0.0000, -1.2000],\n",
      "          [-0.6000, -0.6000, -1.8000],\n",
      "          [-1.8000, -1.2000, -2.4000]],\n",
      "\n",
      "         [[-0.3000, -0.6000,  0.3000],\n",
      "          [-0.6000, -0.0000,  0.0000],\n",
      "          [-0.3000, -0.6000, -0.9000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.2000, -0.6000, -0.0000],\n",
      "          [-0.9000, -1.2000,  0.0000],\n",
      "          [ 0.6000,  1.2000,  1.8000]],\n",
      "\n",
      "         [[-0.0000, -0.3000,  0.3000],\n",
      "          [-1.2000, -0.3000, -0.3000],\n",
      "          [-0.9000, -0.9000, -0.0000]],\n",
      "\n",
      "         [[-0.3000, -0.9000, -0.6000],\n",
      "          [ 1.8000,  0.3000,  1.2000],\n",
      "          [ 3.0000,  2.4000,  2.4000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.6000, -0.6000, -0.9000],\n",
      "          [-0.0000,  0.0000, -0.3000],\n",
      "          [-0.6000, -0.3000,  0.0000]],\n",
      "\n",
      "         [[-0.6000, -0.9000, -0.6000],\n",
      "          [-0.6000, -1.2000, -0.6000],\n",
      "          [-0.0000, -0.3000, -0.3000]],\n",
      "\n",
      "         [[ 0.3000,  0.6000, -0.3000],\n",
      "          [ 0.6000,  0.0000,  0.6000],\n",
      "          [ 0.9000,  0.0000,  0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.9000, -0.3000, -0.3000],\n",
      "          [-1.2000, -0.3000, -0.3000],\n",
      "          [-0.6000, -0.3000, -0.6000]],\n",
      "\n",
      "         [[-1.2000, -0.3000, -1.2000],\n",
      "          [ 0.3000, -0.0000, -0.6000],\n",
      "          [ 1.2000,  0.3000, -1.2000]],\n",
      "\n",
      "         [[-0.9000, -0.3000, -0.3000],\n",
      "          [-0.6000, -0.3000, -1.2000],\n",
      "          [-0.3000, -0.9000, -1.2000]]],\n",
      "\n",
      "\n",
      "        [[[-1.2000, -1.2000, -0.6000],\n",
      "          [-0.3000, -0.0000, -0.3000],\n",
      "          [ 0.9000,  0.9000,  1.8000]],\n",
      "\n",
      "         [[-1.2000, -0.3000, -0.3000],\n",
      "          [-0.0000, -0.9000,  0.6000],\n",
      "          [ 1.2000,  1.2000,  1.2000]],\n",
      "\n",
      "         [[ 0.3000,  0.6000,  1.8000],\n",
      "          [ 0.6000, -0.3000,  0.6000],\n",
      "          [ 0.9000, -0.6000,  0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.0000,  2.4000,  0.6000],\n",
      "          [-0.3000, -0.6000, -0.9000],\n",
      "          [ 0.6000, -0.6000,  0.0000]],\n",
      "\n",
      "         [[ 1.8000,  1.8000,  2.4000],\n",
      "          [-0.0000, -1.8000, -0.9000],\n",
      "          [ 0.3000, -1.2000, -0.0000]],\n",
      "\n",
      "         [[-1.8000, -1.2000, -1.8000],\n",
      "          [-1.2000, -0.3000, -0.9000],\n",
      "          [-0.6000, -0.0000, -0.3000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.9000,  1.2000,  0.9000],\n",
      "          [ 0.0000, -0.3000, -0.0000],\n",
      "          [ 0.6000,  0.6000,  0.6000]],\n",
      "\n",
      "         [[-0.6000, -1.8000, -0.9000],\n",
      "          [ 1.8000, -0.3000, -0.6000],\n",
      "          [ 1.2000,  1.2000,  1.2000]],\n",
      "\n",
      "         [[-1.8000, -1.2000, -1.8000],\n",
      "          [-0.3000, -0.0000,  0.6000],\n",
      "          [ 1.2000,  1.2000,  0.9000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3000, -0.3000, -0.3000],\n",
      "          [ 0.6000,  0.0000,  0.3000],\n",
      "          [ 0.3000,  0.6000,  1.2000]],\n",
      "\n",
      "         [[-0.0000,  0.3000, -0.0000],\n",
      "          [ 0.6000,  0.0000,  1.8000],\n",
      "          [ 1.2000,  0.3000,  1.2000]],\n",
      "\n",
      "         [[ 1.8000,  1.8000,  0.6000],\n",
      "          [ 0.9000,  1.8000,  0.6000],\n",
      "          [-0.0000, -0.9000, -1.2000]]]], device='cuda:0',\n",
      "       grad_fn=<_pqBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.6000]],\n",
      "\n",
      "         [[-1.8000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 3.0000]],\n",
      "\n",
      "         [[-0.3000]]],\n",
      "\n",
      "\n",
      "        [[[-0.0000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         [[-2.4000]],\n",
      "\n",
      "         [[-0.3000]]],\n",
      "\n",
      "\n",
      "        [[[-0.0000]],\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[ 2.4000]],\n",
      "\n",
      "         [[ 0.6000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-1.8000]],\n",
      "\n",
      "         [[ 1.8000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[ 3.0000]],\n",
      "\n",
      "         [[-0.9000]]],\n",
      "\n",
      "\n",
      "        [[[-1.8000]],\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 1.8000]],\n",
      "\n",
      "         [[-1.2000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         [[ 0.9000]]]], device='cuda:0', grad_fn=<_pqBackward>)\n",
      "tensor([[[[ 1.2000, -0.3000, -3.0000],\n",
      "          [ 2.4000,  1.8000, -0.9000],\n",
      "          [-0.0000,  0.6000, -0.0000]],\n",
      "\n",
      "         [[-1.2000, -0.6000, -0.6000],\n",
      "          [-0.3000, -0.3000, -0.0000],\n",
      "          [-0.0000,  0.3000,  0.3000]],\n",
      "\n",
      "         [[-0.9000, -0.6000,  0.6000],\n",
      "          [-1.2000, -0.9000, -0.9000],\n",
      "          [-0.0000, -0.9000,  0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.8000, -0.3000,  1.8000],\n",
      "          [ 0.6000,  0.6000,  1.2000],\n",
      "          [ 1.8000,  0.6000, -0.3000]],\n",
      "\n",
      "         [[ 1.2000,  0.3000, -0.0000],\n",
      "          [ 1.8000,  1.2000,  0.9000],\n",
      "          [ 1.2000,  0.3000,  0.6000]],\n",
      "\n",
      "         [[-0.6000, -1.2000, -0.3000],\n",
      "          [ 0.6000, -0.6000,  0.6000],\n",
      "          [ 1.2000, -0.6000, -0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.6000,  0.9000, -0.3000],\n",
      "          [-1.2000, -0.9000, -0.3000],\n",
      "          [-0.6000, -0.3000, -0.3000]],\n",
      "\n",
      "         [[ 1.2000,  1.8000,  1.2000],\n",
      "          [ 2.4000,  3.0000,  2.4000],\n",
      "          [-0.0000, -0.3000, -0.9000]],\n",
      "\n",
      "         [[ 0.6000,  2.4000,  1.2000],\n",
      "          [-0.3000,  1.2000, -0.3000],\n",
      "          [-0.6000,  0.3000,  0.6000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.2000,  0.0000,  0.3000],\n",
      "          [-0.0000,  0.3000,  1.2000],\n",
      "          [-0.3000, -0.9000, -0.6000]],\n",
      "\n",
      "         [[ 0.9000,  0.9000,  0.3000],\n",
      "          [ 0.3000,  0.0000,  0.3000],\n",
      "          [-0.9000, -0.6000,  0.6000]],\n",
      "\n",
      "         [[-1.2000, -0.3000, -0.3000],\n",
      "          [ 1.2000,  0.3000,  0.0000],\n",
      "          [ 0.6000,  0.3000,  0.6000]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2000,  2.4000,  0.6000],\n",
      "          [ 0.0000, -0.6000, -0.3000],\n",
      "          [ 0.0000, -1.8000,  0.0000]],\n",
      "\n",
      "         [[ 0.6000,  0.6000,  0.6000],\n",
      "          [ 0.6000, -0.0000,  0.3000],\n",
      "          [ 0.6000,  1.2000,  0.9000]],\n",
      "\n",
      "         [[ 2.4000,  3.0000,  2.4000],\n",
      "          [ 0.3000, -0.6000,  0.6000],\n",
      "          [ 0.3000, -1.8000,  0.3000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0000,  1.2000,  1.8000],\n",
      "          [-1.8000, -0.3000,  1.8000],\n",
      "          [-1.2000, -0.6000,  0.9000]],\n",
      "\n",
      "         [[ 0.9000,  0.9000, -0.3000],\n",
      "          [ 0.3000, -0.3000, -1.2000],\n",
      "          [-0.6000, -1.8000, -1.2000]],\n",
      "\n",
      "         [[ 2.4000,  0.3000, -2.4000],\n",
      "          [ 1.8000, -0.0000, -0.6000],\n",
      "          [ 0.9000,  0.3000,  1.2000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0000, -1.8000,  0.3000],\n",
      "          [-0.0000, -0.3000,  0.6000],\n",
      "          [-0.6000, -0.9000, -1.2000]],\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.3000],\n",
      "          [-0.0000, -0.6000,  0.0000],\n",
      "          [-0.3000, -0.9000, -0.6000]],\n",
      "\n",
      "         [[ 0.6000, -2.4000, -0.3000],\n",
      "          [ 1.8000, -0.0000,  2.4000],\n",
      "          [-0.3000, -0.3000,  0.6000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.6000, -1.8000, -1.2000],\n",
      "          [-0.6000, -0.0000, -0.3000],\n",
      "          [-1.2000,  1.2000,  2.4000]],\n",
      "\n",
      "         [[-1.2000, -1.8000, -0.6000],\n",
      "          [-0.0000, -0.0000,  0.6000],\n",
      "          [ 2.4000,  2.4000,  0.9000]],\n",
      "\n",
      "         [[ 0.6000,  1.8000,  0.6000],\n",
      "          [-0.0000,  0.9000, -0.3000],\n",
      "          [ 0.9000, -0.0000, -0.9000]]],\n",
      "\n",
      "\n",
      "        [[[ 2.4000,  1.8000,  0.0000],\n",
      "          [-0.3000, -0.0000, -0.9000],\n",
      "          [-0.3000, -0.0000, -0.9000]],\n",
      "\n",
      "         [[ 0.6000,  0.0000, -0.6000],\n",
      "          [ 0.6000,  0.3000,  0.6000],\n",
      "          [-0.3000, -0.9000, -0.9000]],\n",
      "\n",
      "         [[ 0.9000,  1.8000,  1.8000],\n",
      "          [-0.6000, -0.3000,  0.9000],\n",
      "          [-1.2000, -1.2000, -0.9000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.9000, -0.0000,  1.8000],\n",
      "          [-0.9000, -0.9000,  0.0000],\n",
      "          [-1.2000, -3.0000, -0.9000]],\n",
      "\n",
      "         [[-0.0000, -1.2000, -1.2000],\n",
      "          [-0.6000, -0.6000, -0.3000],\n",
      "          [-1.2000, -1.8000, -0.3000]],\n",
      "\n",
      "         [[-0.9000, -1.2000,  0.0000],\n",
      "          [ 0.3000, -0.3000,  0.9000],\n",
      "          [ 1.2000, -0.0000, -0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  1.8000,  0.9000],\n",
      "          [ 1.2000,  0.3000,  0.9000],\n",
      "          [-1.2000, -1.2000, -0.9000]],\n",
      "\n",
      "         [[-0.6000, -0.3000, -0.0000],\n",
      "          [-0.9000,  0.9000,  0.9000],\n",
      "          [-0.9000,  0.3000,  1.8000]],\n",
      "\n",
      "         [[-1.2000, -0.6000,  0.9000],\n",
      "          [-1.2000, -0.6000, -0.3000],\n",
      "          [-1.2000, -0.3000, -0.3000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.9000,  1.2000,  1.8000],\n",
      "          [-0.6000, -0.6000, -0.0000],\n",
      "          [-0.3000, -0.9000, -1.8000]],\n",
      "\n",
      "         [[ 0.6000,  0.9000,  0.3000],\n",
      "          [ 0.6000, -0.0000, -1.2000],\n",
      "          [-0.3000, -0.3000, -1.8000]],\n",
      "\n",
      "         [[ 0.6000,  0.3000,  0.6000],\n",
      "          [ 1.2000,  0.9000,  0.6000],\n",
      "          [-0.0000,  0.0000,  0.3000]]]], device='cuda:0',\n",
      "       grad_fn=<_pqBackward>)\n",
      "tensor([[[[ 0.3000]],\n",
      "\n",
      "         [[-1.8000]],\n",
      "\n",
      "         [[-1.8000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[ 1.8000]],\n",
      "\n",
      "         [[-0.3000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.6000]],\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[ 2.4000]]],\n",
      "\n",
      "\n",
      "        [[[-1.8000]],\n",
      "\n",
      "         [[-1.8000]],\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.4000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 1.8000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-1.2000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[ 1.8000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[-0.6000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 2.4000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.8000]],\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         [[-1.2000]]],\n",
      "\n",
      "\n",
      "        [[[-0.6000]],\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[ 3.0000]],\n",
      "\n",
      "         [[ 2.4000]]]], device='cuda:0', grad_fn=<_pqBackward>)\n",
      "tensor([[[[-1.8000, -1.2000, -0.9000],\n",
      "          [-0.3000, -1.2000, -0.3000],\n",
      "          [ 0.6000,  0.6000,  0.6000]],\n",
      "\n",
      "         [[-0.0000, -1.8000,  0.9000],\n",
      "          [-0.3000,  0.3000,  0.6000],\n",
      "          [ 1.8000,  2.4000,  0.0000]],\n",
      "\n",
      "         [[-0.3000, -0.9000,  0.0000],\n",
      "          [-0.3000, -0.3000,  1.2000],\n",
      "          [ 1.2000,  0.3000,  0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.6000,  0.3000,  0.3000],\n",
      "          [-0.3000,  0.3000,  0.9000],\n",
      "          [ 1.8000,  0.9000,  0.9000]],\n",
      "\n",
      "         [[ 0.0000, -0.9000, -0.6000],\n",
      "          [ 0.6000,  0.0000, -0.0000],\n",
      "          [ 0.3000,  0.3000,  0.3000]],\n",
      "\n",
      "         [[ 0.9000,  0.3000,  1.2000],\n",
      "          [ 0.6000,  0.9000,  0.0000],\n",
      "          [ 1.2000,  0.0000,  0.6000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.9000,  0.0000],\n",
      "          [ 0.6000,  1.2000, -0.6000],\n",
      "          [ 0.3000,  0.3000, -0.9000]],\n",
      "\n",
      "         [[-0.6000,  0.6000,  1.2000],\n",
      "          [-0.9000, -0.3000,  1.2000],\n",
      "          [-0.9000, -1.2000,  0.6000]],\n",
      "\n",
      "         [[ 0.6000,  0.3000, -0.3000],\n",
      "          [ 0.3000,  0.0000, -0.9000],\n",
      "          [-1.2000, -1.2000, -0.9000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.2000, -0.3000,  1.8000],\n",
      "          [-0.3000,  0.0000,  0.9000],\n",
      "          [-0.3000,  0.3000, -0.6000]],\n",
      "\n",
      "         [[ 0.6000,  0.6000, -0.3000],\n",
      "          [ 0.3000,  0.3000,  0.3000],\n",
      "          [ 1.2000,  0.0000, -0.3000]],\n",
      "\n",
      "         [[-0.3000, -0.3000,  0.6000],\n",
      "          [ 0.6000,  0.6000,  0.6000],\n",
      "          [ 0.9000,  0.9000,  1.2000]]],\n",
      "\n",
      "\n",
      "        [[[-1.2000, -1.2000, -1.8000],\n",
      "          [-0.3000, -0.6000, -0.9000],\n",
      "          [ 1.8000,  1.8000,  1.8000]],\n",
      "\n",
      "         [[ 0.0000, -0.3000,  0.0000],\n",
      "          [-1.2000, -0.0000, -0.6000],\n",
      "          [-0.9000, -0.6000, -0.9000]],\n",
      "\n",
      "         [[-1.2000, -1.2000, -1.2000],\n",
      "          [ 0.3000,  0.3000,  0.3000],\n",
      "          [ 1.2000,  0.6000,  0.6000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.2000, -1.2000, -1.8000],\n",
      "          [-0.9000, -0.3000, -0.9000],\n",
      "          [-0.3000,  0.3000, -0.3000]],\n",
      "\n",
      "         [[-0.9000, -0.6000, -0.9000],\n",
      "          [-0.3000, -0.3000, -0.0000],\n",
      "          [ 0.0000,  0.3000, -0.0000]],\n",
      "\n",
      "         [[-1.8000, -1.2000, -1.2000],\n",
      "          [ 0.9000,  1.2000,  1.8000],\n",
      "          [ 0.6000,  1.2000,  1.8000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.9000, -0.3000, -0.6000],\n",
      "          [ 0.3000,  1.8000,  0.9000],\n",
      "          [ 1.2000,  1.2000,  1.8000]],\n",
      "\n",
      "         [[-0.3000, -1.2000,  1.2000],\n",
      "          [ 0.3000, -0.6000, -0.9000],\n",
      "          [ 0.6000,  0.6000, -0.0000]],\n",
      "\n",
      "         [[ 0.6000,  1.8000,  1.2000],\n",
      "          [ 1.8000,  1.2000,  0.6000],\n",
      "          [ 0.3000, -2.4000, -2.4000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.9000, -0.3000,  1.2000],\n",
      "          [ 0.6000, -0.3000,  1.2000],\n",
      "          [ 1.2000, -0.6000,  0.6000]],\n",
      "\n",
      "         [[ 0.3000, -0.0000, -0.6000],\n",
      "          [-0.6000, -0.3000, -0.9000],\n",
      "          [ 0.9000,  2.4000,  1.2000]],\n",
      "\n",
      "         [[ 0.6000, -0.6000,  0.9000],\n",
      "          [ 0.3000, -0.0000,  0.9000],\n",
      "          [-0.6000, -0.6000, -1.2000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.6000,  0.3000,  0.3000],\n",
      "          [ 0.3000, -0.0000,  0.3000],\n",
      "          [ 0.6000,  0.0000,  0.9000]],\n",
      "\n",
      "         [[-1.2000, -1.2000, -0.6000],\n",
      "          [-0.9000, -0.6000, -0.0000],\n",
      "          [-0.6000, -0.3000, -0.3000]],\n",
      "\n",
      "         [[ 0.6000, -0.6000, -0.3000],\n",
      "          [ 1.2000,  1.2000,  1.2000],\n",
      "          [ 0.0000,  0.6000,  0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.2000, -1.2000, -0.9000],\n",
      "          [-0.9000, -0.6000, -0.0000],\n",
      "          [ 0.9000,  1.8000,  0.6000]],\n",
      "\n",
      "         [[-0.6000, -0.9000,  0.3000],\n",
      "          [-0.3000, -0.3000,  0.9000],\n",
      "          [ 0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[ 0.3000,  0.0000, -0.0000],\n",
      "          [ 1.2000,  0.6000,  1.8000],\n",
      "          [ 0.9000,  0.9000,  0.9000]]],\n",
      "\n",
      "\n",
      "        [[[-0.3000, -0.3000, -1.2000],\n",
      "          [ 0.3000,  0.6000, -0.0000],\n",
      "          [-1.2000, -0.6000,  0.0000]],\n",
      "\n",
      "         [[-1.2000,  0.6000,  0.6000],\n",
      "          [-0.9000,  0.3000, -1.2000],\n",
      "          [ 0.0000,  1.2000, -0.9000]],\n",
      "\n",
      "         [[-1.8000,  0.3000, -0.3000],\n",
      "          [-1.2000,  0.3000,  1.2000],\n",
      "          [-1.2000,  0.3000,  0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.4000, -0.6000, -0.6000],\n",
      "          [ 1.8000, -0.6000, -0.6000],\n",
      "          [-0.0000,  0.0000, -0.6000]],\n",
      "\n",
      "         [[ 1.2000,  1.2000,  1.8000],\n",
      "          [-0.0000,  1.2000,  1.2000],\n",
      "          [-0.6000,  0.3000,  1.2000]],\n",
      "\n",
      "         [[ 0.0000, -0.9000, -0.6000],\n",
      "          [ 0.6000, -0.3000, -0.6000],\n",
      "          [ 0.6000,  0.6000, -0.6000]]]], device='cuda:0',\n",
      "       grad_fn=<_pqBackward>)\n",
      "tensor([[[[-1.8000]],\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 1.8000]]],\n",
      "\n",
      "\n",
      "        [[[-0.3000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         [[-2.4000]],\n",
      "\n",
      "         [[-0.3000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.6000]],\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[-0.3000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.3000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.4000]],\n",
      "\n",
      "         [[ 1.8000]],\n",
      "\n",
      "         [[-0.9000]]],\n",
      "\n",
      "\n",
      "        [[[-0.9000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[-1.2000]]],\n",
      "\n",
      "\n",
      "        [[[-1.2000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[-2.4000]],\n",
      "\n",
      "         [[ 0.6000]]]], device='cuda:0', grad_fn=<_pqBackward>)\n",
      "tensor([[[[-0.6000, -0.6000, -0.9000],\n",
      "          [ 0.9000,  0.9000,  0.0000],\n",
      "          [ 0.3000, -0.0000,  0.3000]],\n",
      "\n",
      "         [[-1.2000, -1.8000, -1.2000],\n",
      "          [-0.3000, -0.9000, -0.0000],\n",
      "          [ 0.9000,  0.6000,  0.0000]],\n",
      "\n",
      "         [[ 0.6000, -1.8000,  2.4000],\n",
      "          [ 0.9000, -0.6000,  1.2000],\n",
      "          [-0.3000, -1.8000, -1.8000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.6000, -0.9000, -0.3000],\n",
      "          [ 0.3000,  0.9000,  0.9000],\n",
      "          [-0.9000,  0.3000, -0.3000]],\n",
      "\n",
      "         [[-0.0000, -1.2000,  0.6000],\n",
      "          [ 0.9000, -0.6000,  0.6000],\n",
      "          [ 1.8000,  0.6000,  0.3000]],\n",
      "\n",
      "         [[ 0.6000,  0.3000, -0.6000],\n",
      "          [-0.9000, -1.2000, -1.2000],\n",
      "          [ 0.3000,  1.8000,  1.2000]]],\n",
      "\n",
      "\n",
      "        [[[-0.0000, -0.3000, -0.3000],\n",
      "          [ 1.2000,  1.2000, -0.6000],\n",
      "          [ 1.8000,  1.8000,  0.0000]],\n",
      "\n",
      "         [[-0.0000, -0.3000,  0.0000],\n",
      "          [-1.2000, -0.6000, -1.2000],\n",
      "          [-0.9000, -0.6000, -1.2000]],\n",
      "\n",
      "         [[ 0.9000,  1.2000, -0.0000],\n",
      "          [ 1.2000, -0.0000,  0.6000],\n",
      "          [-0.9000, -1.2000, -0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.6000,  0.3000, -0.0000],\n",
      "          [-0.9000, -0.3000, -0.3000],\n",
      "          [-0.9000, -1.8000, -0.3000]],\n",
      "\n",
      "         [[ 1.8000,  1.2000,  1.8000],\n",
      "          [ 2.4000,  0.3000,  0.9000],\n",
      "          [-0.3000,  0.3000, -0.3000]],\n",
      "\n",
      "         [[ 0.3000, -0.0000,  0.6000],\n",
      "          [-0.9000, -0.6000, -0.3000],\n",
      "          [-1.8000, -0.9000, -1.8000]]],\n",
      "\n",
      "\n",
      "        [[[-0.0000, -1.2000, -0.3000],\n",
      "          [-0.6000,  0.0000, -1.2000],\n",
      "          [ 1.2000, -0.0000, -1.2000]],\n",
      "\n",
      "         [[ 0.0000,  0.0000, -0.3000],\n",
      "          [ 0.6000,  1.2000, -0.3000],\n",
      "          [ 0.0000, -0.6000, -0.6000]],\n",
      "\n",
      "         [[ 0.3000,  0.6000,  1.2000],\n",
      "          [-0.9000, -0.3000,  0.6000],\n",
      "          [-0.9000,  0.0000, -0.3000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.8000, -0.3000,  1.2000],\n",
      "          [-1.8000,  0.6000,  3.0000],\n",
      "          [-2.4000,  0.3000,  1.2000]],\n",
      "\n",
      "         [[ 0.3000,  1.2000,  0.9000],\n",
      "          [-0.6000,  1.2000,  1.2000],\n",
      "          [ 0.3000,  0.6000,  0.9000]],\n",
      "\n",
      "         [[-0.9000,  0.6000, -0.0000],\n",
      "          [ 1.2000,  0.3000, -1.2000],\n",
      "          [ 0.9000, -0.6000, -0.3000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-1.2000, -0.6000, -0.6000],\n",
      "          [-0.6000, -0.3000, -0.0000],\n",
      "          [-0.9000, -0.6000, -0.3000]],\n",
      "\n",
      "         [[-2.4000, -0.6000, -0.6000],\n",
      "          [-0.3000,  1.2000,  0.0000],\n",
      "          [ 0.6000,  1.2000, -0.6000]],\n",
      "\n",
      "         [[-0.3000,  0.0000,  0.3000],\n",
      "          [ 0.0000, -0.0000,  0.0000],\n",
      "          [ 0.3000,  0.6000,  1.2000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.6000, -1.2000, -0.9000],\n",
      "          [-0.6000, -1.2000, -0.3000],\n",
      "          [-0.6000, -0.3000, -0.0000]],\n",
      "\n",
      "         [[-0.9000, -1.2000, -0.9000],\n",
      "          [-0.9000, -0.6000, -0.6000],\n",
      "          [-0.6000, -0.9000, -0.6000]],\n",
      "\n",
      "         [[ 1.2000,  1.8000,  1.2000],\n",
      "          [ 0.3000,  1.2000,  0.6000],\n",
      "          [ 1.2000,  0.9000,  0.9000]]],\n",
      "\n",
      "\n",
      "        [[[ 3.0000,  3.0000,  2.4000],\n",
      "          [-1.2000, -0.9000, -1.2000],\n",
      "          [-0.3000, -0.3000, -1.2000]],\n",
      "\n",
      "         [[ 0.9000,  1.2000,  1.8000],\n",
      "          [-0.6000,  0.3000,  0.6000],\n",
      "          [ 0.3000, -0.3000, -0.6000]],\n",
      "\n",
      "         [[-0.9000,  0.3000, -0.3000],\n",
      "          [ 0.0000,  0.0000, -0.3000],\n",
      "          [ 1.8000,  1.2000,  0.3000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.6000, -0.6000, -0.6000],\n",
      "          [ 1.8000,  1.8000,  1.8000],\n",
      "          [ 1.2000,  1.2000,  1.2000]],\n",
      "\n",
      "         [[-0.6000,  0.3000, -0.6000],\n",
      "          [-1.2000, -1.2000,  0.6000],\n",
      "          [-0.6000,  0.3000, -0.3000]],\n",
      "\n",
      "         [[ 1.2000,  0.9000,  0.9000],\n",
      "          [-0.6000, -0.9000, -1.8000],\n",
      "          [ 0.9000,  0.3000, -0.3000]]],\n",
      "\n",
      "\n",
      "        [[[-0.9000, -0.6000, -0.0000],\n",
      "          [ 0.0000, -1.2000, -0.6000],\n",
      "          [ 0.6000, -0.9000, -1.2000]],\n",
      "\n",
      "         [[-0.3000, -0.3000, -1.2000],\n",
      "          [ 0.0000,  0.9000, -0.9000],\n",
      "          [ 0.0000, -0.6000, -1.8000]],\n",
      "\n",
      "         [[-0.3000, -0.9000,  1.2000],\n",
      "          [-1.8000, -1.2000, -0.9000],\n",
      "          [-2.4000, -1.2000, -1.8000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.8000,  1.2000,  0.3000],\n",
      "          [ 0.3000,  0.6000,  0.3000],\n",
      "          [ 0.9000,  1.8000,  0.9000]],\n",
      "\n",
      "         [[-1.2000, -0.3000, -1.2000],\n",
      "          [-1.8000, -1.2000, -0.9000],\n",
      "          [-0.3000, -0.0000, -0.3000]],\n",
      "\n",
      "         [[-1.8000, -0.9000, -1.8000],\n",
      "          [-0.3000, -1.2000, -0.6000],\n",
      "          [ 0.9000, -1.2000,  1.2000]]]], device='cuda:0',\n",
      "       grad_fn=<_pqBackward>)\n",
      "tensor([[[[-0.9000]],\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[ 1.8000]]],\n",
      "\n",
      "\n",
      "        [[[ 1.8000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[-1.8000]],\n",
      "\n",
      "         [[-0.3000]]],\n",
      "\n",
      "\n",
      "        [[[-0.3000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[-0.6000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.9000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 0.6000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.6000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[ 1.8000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[-1.8000]],\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.0000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[-0.6000]]]], device='cuda:0', grad_fn=<_pqBackward>)\n",
      "tensor([[[[ 0.9000,  0.6000,  0.9000],\n",
      "          [ 0.6000,  0.6000,  0.3000],\n",
      "          [-0.6000, -0.3000, -0.6000]],\n",
      "\n",
      "         [[-0.3000, -1.2000, -1.2000],\n",
      "          [-0.9000, -1.2000, -0.9000],\n",
      "          [-0.6000, -0.9000, -0.9000]],\n",
      "\n",
      "         [[-0.0000,  0.9000, -0.0000],\n",
      "          [-0.3000,  0.9000,  0.6000],\n",
      "          [ 0.3000, -0.0000, -0.3000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.4000, -1.2000, -0.9000],\n",
      "          [-1.2000, -0.9000, -1.2000],\n",
      "          [-0.6000, -0.0000,  0.6000]],\n",
      "\n",
      "         [[-1.2000, -1.2000, -0.6000],\n",
      "          [-0.6000, -0.9000, -0.3000],\n",
      "          [-0.3000,  0.6000,  1.2000]],\n",
      "\n",
      "         [[ 0.9000,  0.9000,  0.9000],\n",
      "          [ 0.6000, -0.3000, -0.3000],\n",
      "          [-1.8000, -1.2000, -1.2000]]],\n",
      "\n",
      "\n",
      "        [[[-0.0000,  0.3000,  0.0000],\n",
      "          [ 0.3000,  0.3000,  0.6000],\n",
      "          [ 0.9000,  0.6000,  1.2000]],\n",
      "\n",
      "         [[ 0.6000,  0.0000, -0.9000],\n",
      "          [-0.6000, -0.9000, -0.9000],\n",
      "          [-1.2000, -0.9000, -0.6000]],\n",
      "\n",
      "         [[-0.3000, -0.6000, -1.2000],\n",
      "          [-0.3000,  0.0000, -0.6000],\n",
      "          [-0.3000,  0.3000, -0.3000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.6000, -0.3000,  0.3000],\n",
      "          [-0.0000, -0.3000,  0.3000],\n",
      "          [-0.9000, -0.9000, -0.0000]],\n",
      "\n",
      "         [[-0.3000,  0.6000,  0.3000],\n",
      "          [-0.6000,  0.0000, -0.6000],\n",
      "          [-1.2000, -0.3000, -0.6000]],\n",
      "\n",
      "         [[-0.3000, -0.6000, -1.8000],\n",
      "          [ 0.3000,  0.6000,  0.3000],\n",
      "          [ 0.9000,  0.9000,  0.6000]]],\n",
      "\n",
      "\n",
      "        [[[-0.6000, -0.3000, -0.3000],\n",
      "          [ 0.3000, -0.0000, -0.3000],\n",
      "          [ 1.8000,  0.0000,  0.6000]],\n",
      "\n",
      "         [[ 0.9000,  1.8000,  2.4000],\n",
      "          [ 0.6000,  0.9000,  0.9000],\n",
      "          [ 0.6000,  0.3000,  0.6000]],\n",
      "\n",
      "         [[-0.0000, -0.6000, -0.0000],\n",
      "          [ 0.9000,  0.9000,  0.9000],\n",
      "          [ 1.8000,  1.2000,  1.2000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3000, -0.0000,  0.3000],\n",
      "          [ 0.9000,  1.8000,  1.8000],\n",
      "          [ 1.2000,  2.4000,  1.8000]],\n",
      "\n",
      "         [[ 0.3000,  0.9000,  0.0000],\n",
      "          [ 0.3000,  0.6000,  0.0000],\n",
      "          [-0.3000, -0.3000, -0.3000]],\n",
      "\n",
      "         [[-0.9000, -0.6000, -1.2000],\n",
      "          [-0.3000, -0.3000,  0.3000],\n",
      "          [ 0.0000,  0.3000,  0.3000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.9000,  0.3000,  1.8000],\n",
      "          [-3.0000, -1.2000,  2.4000],\n",
      "          [-1.8000, -0.6000,  1.8000]],\n",
      "\n",
      "         [[-0.9000,  0.3000, -0.0000],\n",
      "          [-0.0000,  0.0000, -0.9000],\n",
      "          [-0.3000,  0.0000, -0.9000]],\n",
      "\n",
      "         [[ 0.0000, -0.9000, -0.3000],\n",
      "          [ 0.6000, -1.2000, -1.2000],\n",
      "          [ 0.6000, -0.9000, -1.8000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0000,  0.0000, -0.3000],\n",
      "          [-1.2000, -0.0000,  0.6000],\n",
      "          [-0.6000, -0.9000, -0.9000]],\n",
      "\n",
      "         [[-1.8000,  0.0000,  2.4000],\n",
      "          [-0.9000, -0.0000,  3.0000],\n",
      "          [ 0.3000, -0.9000, -0.3000]],\n",
      "\n",
      "         [[-1.8000,  0.0000,  1.8000],\n",
      "          [-2.4000, -0.6000,  0.6000],\n",
      "          [-0.3000,  1.2000,  0.6000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.9000, -1.2000, -0.6000],\n",
      "          [ 0.0000, -0.3000,  0.6000],\n",
      "          [ 0.3000,  0.9000,  0.9000]],\n",
      "\n",
      "         [[-1.2000, -0.6000,  1.2000],\n",
      "          [-0.3000,  0.3000,  1.2000],\n",
      "          [ 0.3000,  0.6000,  1.2000]],\n",
      "\n",
      "         [[ 0.0000, -0.6000, -0.3000],\n",
      "          [ 0.6000,  0.6000, -0.3000],\n",
      "          [ 2.4000,  1.2000,  1.2000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.6000,  0.3000,  0.6000],\n",
      "          [ 0.3000, -0.6000,  0.3000],\n",
      "          [-1.2000, -0.0000,  1.2000]],\n",
      "\n",
      "         [[ 0.9000, -0.0000, -0.6000],\n",
      "          [ 0.6000,  0.3000, -0.3000],\n",
      "          [ 0.9000,  0.3000, -0.3000]],\n",
      "\n",
      "         [[-0.6000, -0.6000,  2.4000],\n",
      "          [-1.2000,  0.3000,  3.0000],\n",
      "          [-0.6000,  0.6000,  2.4000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.6000,  0.3000,  0.3000],\n",
      "          [ 0.6000,  1.2000,  0.3000],\n",
      "          [-0.3000, -0.0000, -0.0000]],\n",
      "\n",
      "         [[ 0.9000,  0.6000,  0.9000],\n",
      "          [-0.3000, -0.3000,  0.0000],\n",
      "          [-0.0000,  0.0000, -0.3000]],\n",
      "\n",
      "         [[ 1.8000,  0.6000,  0.3000],\n",
      "          [ 0.3000,  0.0000,  0.3000],\n",
      "          [-0.6000, -1.2000, -1.2000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.9000, -0.9000, -0.6000],\n",
      "          [-0.6000, -0.3000, -0.6000],\n",
      "          [ 1.2000,  1.2000,  0.9000]],\n",
      "\n",
      "         [[ 1.2000,  2.4000,  0.6000],\n",
      "          [ 0.0000,  0.9000,  0.0000],\n",
      "          [-1.8000, -1.2000, -1.8000]],\n",
      "\n",
      "         [[ 0.3000, -0.0000,  1.2000],\n",
      "          [-0.3000, -0.9000,  0.0000],\n",
      "          [-0.6000, -0.3000,  0.3000]]]], device='cuda:0',\n",
      "       grad_fn=<_pqBackward>)\n",
      "tensor([[[[ 0.9000]],\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[-0.6000]]],\n",
      "\n",
      "\n",
      "        [[[-0.6000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[-1.8000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[ 0.9000]]],\n",
      "\n",
      "\n",
      "        [[[-0.3000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[-1.2000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.9000]],\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[ 0.3000]]],\n",
      "\n",
      "\n",
      "        [[[-0.9000]],\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         [[-2.4000]]],\n",
      "\n",
      "\n",
      "        [[[-1.2000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         [[ 1.8000]],\n",
      "\n",
      "         [[-0.3000]]]], device='cuda:0', grad_fn=<_pqBackward>)\n",
      "tensor([[[[ 0.3000,  0.6000,  0.3000],\n",
      "          [ 0.3000,  0.0000,  0.0000],\n",
      "          [ 1.8000, -0.0000,  0.9000]],\n",
      "\n",
      "         [[ 0.0000,  0.6000,  0.9000],\n",
      "          [ 1.2000,  1.8000,  0.9000],\n",
      "          [-0.3000, -0.0000, -0.6000]],\n",
      "\n",
      "         [[-0.3000, -0.3000, -0.9000],\n",
      "          [-0.6000,  0.3000, -0.3000],\n",
      "          [ 0.3000,  0.6000,  0.9000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.9000, -0.0000, -1.2000],\n",
      "          [ 1.2000,  0.3000, -0.6000],\n",
      "          [ 1.8000,  0.0000,  1.2000]],\n",
      "\n",
      "         [[ 0.6000, -0.3000, -0.6000],\n",
      "          [ 0.0000, -0.0000,  0.3000],\n",
      "          [ 1.2000,  1.2000, -0.0000]],\n",
      "\n",
      "         [[ 1.8000,  0.9000,  1.8000],\n",
      "          [ 0.3000,  1.2000,  0.6000],\n",
      "          [ 0.9000,  0.9000,  1.2000]]],\n",
      "\n",
      "\n",
      "        [[[-0.9000, -1.8000, -0.3000],\n",
      "          [-0.6000, -0.3000, -0.3000],\n",
      "          [-0.0000,  0.3000,  0.3000]],\n",
      "\n",
      "         [[-1.2000, -0.9000, -0.6000],\n",
      "          [-1.8000, -1.8000, -1.8000],\n",
      "          [ 0.0000, -0.6000, -1.2000]],\n",
      "\n",
      "         [[ 1.8000,  1.8000,  1.2000],\n",
      "          [ 0.6000,  1.8000,  0.6000],\n",
      "          [-0.3000,  0.9000,  0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.2000, -1.2000, -0.9000],\n",
      "          [ 0.0000,  0.0000,  0.6000],\n",
      "          [-0.6000,  0.3000,  0.3000]],\n",
      "\n",
      "         [[-0.3000, -0.6000, -0.9000],\n",
      "          [-0.6000, -1.8000, -1.8000],\n",
      "          [-0.6000, -0.6000, -0.6000]],\n",
      "\n",
      "         [[-1.8000, -1.2000, -0.9000],\n",
      "          [-0.9000, -1.8000, -0.6000],\n",
      "          [ 0.6000,  0.3000,  0.3000]]],\n",
      "\n",
      "\n",
      "        [[[-1.2000, -0.9000, -0.6000],\n",
      "          [-0.6000,  0.3000,  0.6000],\n",
      "          [ 1.2000,  0.6000,  1.8000]],\n",
      "\n",
      "         [[ 0.0000,  0.3000,  1.2000],\n",
      "          [-1.2000, -1.2000, -0.3000],\n",
      "          [-0.9000, -1.2000, -0.3000]],\n",
      "\n",
      "         [[-0.3000,  0.3000, -0.3000],\n",
      "          [-0.6000, -0.3000, -0.9000],\n",
      "          [-1.2000, -0.3000, -1.2000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.0000,  2.4000,  1.8000],\n",
      "          [-0.0000, -0.9000, -0.9000],\n",
      "          [-1.2000, -1.8000, -1.2000]],\n",
      "\n",
      "         [[-0.9000, -0.6000,  0.6000],\n",
      "          [-1.2000, -0.9000, -0.3000],\n",
      "          [-1.2000, -0.6000, -1.2000]],\n",
      "\n",
      "         [[ 1.8000,  1.8000,  2.4000],\n",
      "          [-0.0000, -0.6000, -0.6000],\n",
      "          [ 1.2000,  1.2000,  0.6000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.3000, -0.3000, -0.0000],\n",
      "          [ 1.2000,  0.0000,  0.6000],\n",
      "          [ 0.9000,  0.9000,  0.6000]],\n",
      "\n",
      "         [[-0.9000, -1.2000, -0.6000],\n",
      "          [-0.9000, -1.2000, -0.6000],\n",
      "          [-1.2000, -1.2000, -0.6000]],\n",
      "\n",
      "         [[ 0.0000, -0.6000, -0.3000],\n",
      "          [ 0.3000, -0.0000,  0.3000],\n",
      "          [ 0.9000,  0.9000,  0.6000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.6000, -0.3000, -0.3000],\n",
      "          [-0.6000, -0.9000, -0.3000],\n",
      "          [-0.3000, -0.6000, -0.9000]],\n",
      "\n",
      "         [[-1.2000, -1.2000, -0.9000],\n",
      "          [-0.6000, -0.6000, -0.3000],\n",
      "          [ 1.8000,  0.9000,  0.9000]],\n",
      "\n",
      "         [[-0.0000, -0.6000,  0.9000],\n",
      "          [ 0.0000,  0.6000,  0.3000],\n",
      "          [ 0.6000,  0.9000,  0.9000]]],\n",
      "\n",
      "\n",
      "        [[[ 1.8000,  1.2000,  1.8000],\n",
      "          [-0.3000, -0.6000,  0.0000],\n",
      "          [-0.3000, -0.3000,  0.6000]],\n",
      "\n",
      "         [[ 1.2000,  2.4000,  1.2000],\n",
      "          [ 1.2000,  0.9000,  0.6000],\n",
      "          [-0.3000, -0.3000, -0.6000]],\n",
      "\n",
      "         [[-1.2000, -0.9000, -0.9000],\n",
      "          [-1.8000, -1.8000, -1.2000],\n",
      "          [-1.8000, -1.8000, -1.8000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.6000, -0.3000, -0.9000],\n",
      "          [-0.6000, -2.4000, -1.2000],\n",
      "          [-0.0000,  0.6000,  1.8000]],\n",
      "\n",
      "         [[ 0.6000,  0.3000, -0.3000],\n",
      "          [-0.9000, -1.8000, -1.2000],\n",
      "          [-0.6000, -0.6000, -0.9000]],\n",
      "\n",
      "         [[-0.0000, -0.3000, -0.3000],\n",
      "          [-0.3000, -1.8000, -1.2000],\n",
      "          [ 0.9000,  0.6000,  0.9000]]],\n",
      "\n",
      "\n",
      "        [[[-0.6000, -0.6000,  0.3000],\n",
      "          [-0.3000, -0.3000,  0.6000],\n",
      "          [ 0.9000,  0.3000,  0.9000]],\n",
      "\n",
      "         [[ 0.0000,  1.2000,  0.6000],\n",
      "          [ 0.9000,  1.8000,  0.6000],\n",
      "          [ 1.2000,  1.2000,  0.9000]],\n",
      "\n",
      "         [[-0.6000, -0.0000, -0.6000],\n",
      "          [-0.6000, -0.6000, -0.6000],\n",
      "          [-0.6000, -0.3000, -0.3000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0000, -0.6000, -0.9000],\n",
      "          [ 0.9000,  0.3000,  0.3000],\n",
      "          [ 0.3000,  0.3000,  0.9000]],\n",
      "\n",
      "         [[ 0.6000, -0.0000, -0.3000],\n",
      "          [-0.0000, -0.3000, -0.0000],\n",
      "          [-0.9000, -0.6000, -0.6000]],\n",
      "\n",
      "         [[ 0.6000,  0.9000,  0.6000],\n",
      "          [ 0.9000,  0.9000, -0.3000],\n",
      "          [ 0.9000,  0.9000,  0.3000]]]], device='cuda:0',\n",
      "       grad_fn=<_pqBackward>)\n",
      "tensor([[[[-2.4000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[-0.9000]]],\n",
      "\n",
      "\n",
      "        [[[-1.2000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 1.2000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000]],\n",
      "\n",
      "         [[-1.8000]],\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[ 1.2000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0000]],\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[-1.8000]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 1.2000]]],\n",
      "\n",
      "\n",
      "        [[[-0.0000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[ 3.0000]]]], device='cuda:0', grad_fn=<_pqBackward>)\n",
      "tensor([[[[ 0.6000,  0.6000, -0.3000],\n",
      "          [-0.0000, -0.6000,  0.3000],\n",
      "          [ 0.3000, -0.3000, -0.3000]],\n",
      "\n",
      "         [[-1.2000, -1.2000, -1.2000],\n",
      "          [-0.6000, -0.3000,  0.0000],\n",
      "          [ 0.6000,  0.6000,  0.6000]],\n",
      "\n",
      "         [[-0.0000,  0.6000,  0.9000],\n",
      "          [-0.0000,  0.0000, -1.2000],\n",
      "          [-1.2000, -1.8000, -1.2000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.2000, -0.9000, -0.6000],\n",
      "          [ 0.9000,  0.0000,  0.3000],\n",
      "          [ 1.2000,  0.6000, -0.6000]],\n",
      "\n",
      "         [[ 0.9000,  0.3000, -0.3000],\n",
      "          [-0.3000, -0.3000, -0.6000],\n",
      "          [-0.6000, -0.3000, -0.6000]],\n",
      "\n",
      "         [[-0.6000, -0.6000, -0.3000],\n",
      "          [ 0.6000,  1.2000,  0.3000],\n",
      "          [-1.8000, -1.2000, -0.3000]]],\n",
      "\n",
      "\n",
      "        [[[-0.3000, -0.9000, -0.6000],\n",
      "          [ 0.6000, -0.0000,  0.3000],\n",
      "          [-0.3000,  0.0000,  0.3000]],\n",
      "\n",
      "         [[-1.8000, -1.2000, -0.9000],\n",
      "          [-1.2000, -0.6000, -0.6000],\n",
      "          [ 0.9000,  1.2000,  1.8000]],\n",
      "\n",
      "         [[ 2.4000,  2.4000,  0.9000],\n",
      "          [ 0.9000,  0.3000,  0.0000],\n",
      "          [-1.2000, -2.4000, -1.8000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.8000,  2.4000,  3.0000],\n",
      "          [ 1.8000,  0.9000,  1.8000],\n",
      "          [-1.8000, -1.8000, -0.9000]],\n",
      "\n",
      "         [[ 0.3000,  0.6000, -0.0000],\n",
      "          [ 0.9000,  0.6000,  0.0000],\n",
      "          [ 0.3000,  0.6000,  1.2000]],\n",
      "\n",
      "         [[-0.6000,  0.3000, -0.6000],\n",
      "          [ 0.3000, -0.0000, -0.9000],\n",
      "          [ 1.8000,  1.8000,  1.2000]]],\n",
      "\n",
      "\n",
      "        [[[-0.9000,  0.9000,  1.8000],\n",
      "          [-1.8000, -0.3000,  2.4000],\n",
      "          [-0.6000,  0.6000,  1.8000]],\n",
      "\n",
      "         [[ 0.3000,  0.3000,  0.3000],\n",
      "          [ 0.6000,  0.9000,  0.3000],\n",
      "          [-0.0000,  0.0000, -0.6000]],\n",
      "\n",
      "         [[-0.6000, -0.6000, -0.3000],\n",
      "          [ 0.0000,  0.3000, -0.3000],\n",
      "          [ 1.8000,  2.4000,  0.3000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.2000,  1.2000,  0.6000],\n",
      "          [ 0.9000,  0.3000,  0.3000],\n",
      "          [ 0.3000, -0.0000, -0.3000]],\n",
      "\n",
      "         [[-1.8000, -0.3000, -0.3000],\n",
      "          [-1.2000, -1.2000, -0.6000],\n",
      "          [-0.6000, -0.3000,  1.2000]],\n",
      "\n",
      "         [[ 0.3000,  0.6000, -0.9000],\n",
      "          [-0.0000,  0.6000, -0.6000],\n",
      "          [-0.3000,  0.6000,  0.3000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.6000, -1.2000, -1.2000],\n",
      "          [-1.2000, -2.4000, -1.2000],\n",
      "          [-0.6000, -0.9000, -0.3000]],\n",
      "\n",
      "         [[ 0.6000,  1.2000,  0.3000],\n",
      "          [-0.0000, -0.3000, -0.3000],\n",
      "          [-0.3000, -1.2000, -1.8000]],\n",
      "\n",
      "         [[-0.9000, -1.8000, -0.9000],\n",
      "          [ 0.6000, -0.3000, -1.2000],\n",
      "          [ 0.3000, -0.9000, -0.6000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0000,  0.3000,  0.9000],\n",
      "          [ 1.2000,  0.6000,  1.2000],\n",
      "          [ 1.2000, -0.6000, -0.6000]],\n",
      "\n",
      "         [[-1.8000, -1.8000, -1.2000],\n",
      "          [ 0.0000, -0.3000, -0.3000],\n",
      "          [ 0.0000, -0.3000, -1.2000]],\n",
      "\n",
      "         [[-0.9000, -0.6000, -0.6000],\n",
      "          [-1.2000, -1.2000, -0.9000],\n",
      "          [-1.8000, -1.2000, -1.8000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000, -0.6000, -0.9000],\n",
      "          [ 0.3000, -0.0000, -0.9000],\n",
      "          [ 0.3000,  1.2000,  0.9000]],\n",
      "\n",
      "         [[ 1.8000,  1.8000,  1.8000],\n",
      "          [ 0.9000,  0.0000,  0.3000],\n",
      "          [-0.0000,  0.0000,  0.9000]],\n",
      "\n",
      "         [[ 1.2000,  1.8000,  1.8000],\n",
      "          [ 1.2000, -0.3000,  0.3000],\n",
      "          [-0.6000, -0.9000, -0.6000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.6000,  0.6000,  0.6000],\n",
      "          [ 0.9000,  0.3000,  0.6000],\n",
      "          [ 0.9000,  0.6000,  0.0000]],\n",
      "\n",
      "         [[-0.6000,  0.0000, -0.3000],\n",
      "          [ 0.3000,  0.9000, -0.3000],\n",
      "          [-0.6000,  0.3000, -0.6000]],\n",
      "\n",
      "         [[ 1.8000,  2.4000,  1.8000],\n",
      "          [ 1.8000,  0.9000,  0.9000],\n",
      "          [ 1.8000,  1.2000,  1.8000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.9000,  0.0000,  1.2000],\n",
      "          [-0.6000, -0.9000,  0.6000],\n",
      "          [-0.9000, -0.9000,  0.3000]],\n",
      "\n",
      "         [[-0.9000, -0.6000, -0.3000],\n",
      "          [-0.3000, -0.6000,  0.3000],\n",
      "          [ 1.8000,  0.0000,  0.3000]],\n",
      "\n",
      "         [[-0.9000, -0.0000,  0.6000],\n",
      "          [-1.2000, -0.9000, -0.9000],\n",
      "          [ 0.3000, -0.6000,  0.3000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.8000, -1.8000, -1.8000],\n",
      "          [-0.6000, -1.2000,  0.6000],\n",
      "          [ 1.2000,  1.8000,  2.4000]],\n",
      "\n",
      "         [[-0.6000, -0.9000, -0.3000],\n",
      "          [-0.3000, -0.9000, -1.2000],\n",
      "          [ 1.2000,  0.3000,  0.6000]],\n",
      "\n",
      "         [[-0.3000,  0.0000, -0.0000],\n",
      "          [ 0.3000,  0.6000,  0.6000],\n",
      "          [ 2.4000,  0.6000,  1.8000]]]], device='cuda:0',\n",
      "       grad_fn=<_pqBackward>)\n",
      "tensor([[[[-1.2000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[ 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3000]],\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 1.8000]]],\n",
      "\n",
      "\n",
      "        [[[-0.9000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[-1.2000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.3000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[ 1.8000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.8000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[ 1.8000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3000]],\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         [[ 1.8000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         [[-3.0000]],\n",
      "\n",
      "         [[ 0.9000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.6000]],\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         [[ 1.2000]]]], device='cuda:0', grad_fn=<_pqBackward>)\n",
      "tensor([[[[-0.6000,  0.3000, -0.3000],\n",
      "          [-0.3000,  0.0000, -0.0000],\n",
      "          [ 0.6000,  0.6000,  0.9000]],\n",
      "\n",
      "         [[-1.8000, -0.6000, -0.6000],\n",
      "          [-1.2000, -0.6000,  0.3000],\n",
      "          [ 0.0000, -0.0000,  0.9000]],\n",
      "\n",
      "         [[-1.2000, -0.3000, -0.6000],\n",
      "          [ 0.3000,  0.0000, -0.0000],\n",
      "          [ 0.3000,  0.0000,  0.6000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.2000, -0.3000, -0.9000],\n",
      "          [-1.2000, -1.2000, -1.8000],\n",
      "          [-0.9000, -0.3000, -0.6000]],\n",
      "\n",
      "         [[-0.0000,  0.0000, -0.6000],\n",
      "          [-0.6000, -0.3000,  0.0000],\n",
      "          [-0.6000,  0.3000,  0.0000]],\n",
      "\n",
      "         [[ 0.3000,  0.3000,  0.0000],\n",
      "          [ 1.2000,  0.6000,  0.9000],\n",
      "          [ 0.0000,  0.0000, -0.3000]]],\n",
      "\n",
      "\n",
      "        [[[-0.6000, -0.6000,  0.3000],\n",
      "          [ 0.3000, -0.3000,  0.3000],\n",
      "          [ 1.2000,  1.2000,  1.2000]],\n",
      "\n",
      "         [[-0.9000, -0.3000, -0.6000],\n",
      "          [ 0.3000,  0.3000, -0.3000],\n",
      "          [ 0.3000, -0.3000,  0.0000]],\n",
      "\n",
      "         [[ 0.3000,  0.6000, -0.0000],\n",
      "          [-0.0000,  0.6000,  0.0000],\n",
      "          [ 0.3000,  0.0000, -0.6000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0000,  0.6000, -0.9000],\n",
      "          [-0.6000, -0.0000, -0.6000],\n",
      "          [-0.6000, -0.3000, -0.0000]],\n",
      "\n",
      "         [[-0.3000,  0.3000,  0.3000],\n",
      "          [-1.8000, -0.9000, -0.6000],\n",
      "          [-1.8000, -1.2000, -1.2000]],\n",
      "\n",
      "         [[ 0.6000,  0.9000,  0.9000],\n",
      "          [-0.6000, -1.2000, -1.2000],\n",
      "          [ 0.9000,  0.3000,  0.6000]]],\n",
      "\n",
      "\n",
      "        [[[-0.6000,  0.6000,  0.3000],\n",
      "          [ 0.6000,  0.3000,  0.6000],\n",
      "          [ 1.8000,  1.2000,  1.2000]],\n",
      "\n",
      "         [[ 1.8000,  1.2000,  0.3000],\n",
      "          [ 1.8000,  1.8000,  1.8000],\n",
      "          [-0.9000, -0.9000, -0.3000]],\n",
      "\n",
      "         [[-1.2000, -0.3000, -1.2000],\n",
      "          [-1.8000, -0.6000, -2.4000],\n",
      "          [-0.3000,  0.0000, -0.9000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.8000,  1.2000,  0.3000],\n",
      "          [ 2.4000,  1.2000,  3.0000],\n",
      "          [ 0.3000,  1.8000,  1.8000]],\n",
      "\n",
      "         [[ 0.9000,  0.0000,  0.3000],\n",
      "          [-0.9000, -0.9000, -0.6000],\n",
      "          [ 1.8000,  3.0000,  1.8000]],\n",
      "\n",
      "         [[-1.8000, -0.9000, -1.8000],\n",
      "          [-0.9000, -0.6000, -1.8000],\n",
      "          [-0.9000, -0.3000, -0.6000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 1.8000,  1.8000,  1.8000],\n",
      "          [-0.0000, -0.3000,  0.3000],\n",
      "          [-0.3000, -0.9000, -0.6000]],\n",
      "\n",
      "         [[-0.9000,  0.3000, -0.6000],\n",
      "          [-1.2000, -0.6000, -0.9000],\n",
      "          [ 0.3000, -0.3000, -0.6000]],\n",
      "\n",
      "         [[ 1.8000,  1.2000,  1.8000],\n",
      "          [ 1.2000,  0.0000,  0.9000],\n",
      "          [-0.9000, -1.2000, -0.6000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.2000, -1.8000, -1.2000],\n",
      "          [-1.2000, -1.2000, -0.6000],\n",
      "          [ 0.3000,  0.6000,  0.9000]],\n",
      "\n",
      "         [[-0.3000, -0.0000, -0.0000],\n",
      "          [ 0.0000,  0.6000,  0.0000],\n",
      "          [ 0.3000,  0.9000,  0.6000]],\n",
      "\n",
      "         [[ 0.0000, -0.3000, -0.6000],\n",
      "          [-0.9000, -0.3000,  0.3000],\n",
      "          [-1.8000, -1.2000, -1.2000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.9000,  0.3000],\n",
      "          [-0.9000, -0.9000, -0.6000],\n",
      "          [-0.6000, -0.9000, -0.3000]],\n",
      "\n",
      "         [[-0.0000,  0.9000,  0.0000],\n",
      "          [ 0.9000,  0.9000, -0.0000],\n",
      "          [ 1.8000,  2.4000,  1.2000]],\n",
      "\n",
      "         [[-0.0000,  1.2000, -0.6000],\n",
      "          [-1.2000, -0.3000, -1.2000],\n",
      "          [-1.8000, -0.9000,  0.3000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.2000,  0.3000, -1.2000],\n",
      "          [ 1.2000,  1.2000, -0.3000],\n",
      "          [ 1.2000,  1.2000,  0.3000]],\n",
      "\n",
      "         [[-0.6000, -0.9000, -0.6000],\n",
      "          [-0.3000,  0.0000, -0.6000],\n",
      "          [ 0.3000,  0.9000,  0.3000]],\n",
      "\n",
      "         [[ 1.8000,  1.8000,  0.9000],\n",
      "          [ 0.6000,  0.9000,  0.9000],\n",
      "          [-1.8000, -0.9000, -0.3000]]],\n",
      "\n",
      "\n",
      "        [[[ 2.4000,  1.8000,  2.4000],\n",
      "          [-0.3000, -0.3000, -0.3000],\n",
      "          [-0.0000,  0.3000, -0.3000]],\n",
      "\n",
      "         [[ 0.9000,  1.8000,  1.8000],\n",
      "          [-0.3000, -0.0000, -0.3000],\n",
      "          [ 0.3000, -0.0000, -0.0000]],\n",
      "\n",
      "         [[-0.9000,  0.3000,  0.0000],\n",
      "          [-1.2000, -1.2000, -0.9000],\n",
      "          [ 0.3000, -0.0000,  0.3000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.9000, -0.3000, -0.9000],\n",
      "          [-0.0000, -0.0000,  0.0000],\n",
      "          [ 1.8000,  0.9000,  1.8000]],\n",
      "\n",
      "         [[ 0.9000,  1.2000,  1.2000],\n",
      "          [ 1.2000,  2.4000,  1.8000],\n",
      "          [-0.3000,  0.3000, -0.0000]],\n",
      "\n",
      "         [[-0.9000, -0.9000, -0.0000],\n",
      "          [ 1.2000,  0.9000,  1.2000],\n",
      "          [ 0.9000,  0.6000,  0.9000]]]], device='cuda:0',\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       grad_fn=<_pqBackward>)\n",
      "tensor([[[[ 0.6000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[ 2.4000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[ 3.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[ 0.9000]]],\n",
      "\n",
      "\n",
      "        [[[-0.9000]],\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.9000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-1.8000]],\n",
      "\n",
      "         [[ 1.8000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[ 0.9000]]],\n",
      "\n",
      "\n",
      "        [[[-0.9000]],\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         [[ 2.4000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         [[ 2.4000]]],\n",
      "\n",
      "\n",
      "        [[[-1.8000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[ 1.8000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[ 0.3000]]]], device='cuda:0', grad_fn=<_pqBackward>)\n",
      "tensor([[[[ 0.6000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[ 1.8000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[-0.3000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.6000]],\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[ 1.2000]]],\n",
      "\n",
      "\n",
      "        [[[-0.9000]],\n",
      "\n",
      "         [[ 2.4000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 0.9000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.6000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 0.3000]]],\n",
      "\n",
      "\n",
      "        [[[-0.9000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 3.0000]]],\n",
      "\n",
      "\n",
      "        [[[-0.6000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[-0.0000]]]], device='cuda:0', grad_fn=<_pqBackward>)\n",
      "tensor([[[[ 0.6000, -0.3000,  0.3000],\n",
      "          [ 0.6000, -0.0000,  0.6000],\n",
      "          [-1.2000, -0.9000, -0.6000]],\n",
      "\n",
      "         [[ 1.8000,  1.2000,  2.4000],\n",
      "          [ 0.9000,  0.6000,  1.2000],\n",
      "          [ 0.6000, -0.0000,  0.0000]],\n",
      "\n",
      "         [[ 0.3000, -0.3000,  0.3000],\n",
      "          [ 0.6000, -0.9000,  0.3000],\n",
      "          [ 1.8000, -0.6000,  0.9000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.6000,  0.0000, -0.3000],\n",
      "          [-0.0000,  0.3000, -0.0000],\n",
      "          [ 0.0000, -0.3000, -0.3000]],\n",
      "\n",
      "         [[ 0.3000, -0.9000, -0.3000],\n",
      "          [ 0.6000,  1.2000,  1.2000],\n",
      "          [-0.9000, -0.3000, -0.9000]],\n",
      "\n",
      "         [[ 0.0000,  0.3000,  0.3000],\n",
      "          [-0.9000,  0.3000, -0.9000],\n",
      "          [ 0.6000,  0.3000, -0.6000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000, -0.6000, -0.3000],\n",
      "          [-0.6000, -0.6000, -0.6000],\n",
      "          [-0.3000, -0.6000, -0.0000]],\n",
      "\n",
      "         [[-0.0000, -0.9000,  0.3000],\n",
      "          [-0.6000, -0.0000,  0.3000],\n",
      "          [-0.6000, -0.9000, -0.6000]],\n",
      "\n",
      "         [[-0.3000, -0.0000,  0.0000],\n",
      "          [-0.6000, -0.3000, -0.3000],\n",
      "          [-0.3000, -0.0000, -0.6000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3000,  0.9000,  0.3000],\n",
      "          [ 0.3000,  0.6000,  0.0000],\n",
      "          [ 0.0000, -0.0000,  0.0000]],\n",
      "\n",
      "         [[ 1.2000,  0.9000,  1.2000],\n",
      "          [ 0.3000, -0.6000,  0.3000],\n",
      "          [ 1.2000, -1.2000,  0.0000]],\n",
      "\n",
      "         [[ 0.3000,  1.8000,  0.3000],\n",
      "          [-0.6000,  0.6000, -0.9000],\n",
      "          [-0.0000, -0.3000, -0.9000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.9000,  1.2000,  1.8000],\n",
      "          [-1.2000,  0.6000,  0.0000],\n",
      "          [-1.8000, -2.4000, -1.8000]],\n",
      "\n",
      "         [[ 0.9000,  0.0000,  1.8000],\n",
      "          [-1.2000, -0.6000, -0.6000],\n",
      "          [-0.3000, -1.2000, -0.3000]],\n",
      "\n",
      "         [[-0.6000, -1.2000, -0.3000],\n",
      "          [ 0.6000, -1.8000,  0.9000],\n",
      "          [ 2.4000,  0.3000,  2.4000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.6000, -0.0000, -0.6000],\n",
      "          [-0.6000, -0.0000, -0.6000],\n",
      "          [-0.3000,  0.9000, -0.0000]],\n",
      "\n",
      "         [[ 0.3000,  0.3000,  1.8000],\n",
      "          [-0.6000,  0.6000,  0.9000],\n",
      "          [ 0.6000,  1.2000,  0.0000]],\n",
      "\n",
      "         [[-0.9000, -0.3000, -0.9000],\n",
      "          [-1.2000,  0.3000, -1.8000],\n",
      "          [-1.8000, -0.3000, -2.4000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 2.4000,  2.4000,  3.0000],\n",
      "          [ 0.9000,  0.0000,  0.3000],\n",
      "          [-0.3000, -1.8000, -0.3000]],\n",
      "\n",
      "         [[ 1.8000,  0.3000,  1.8000],\n",
      "          [ 1.2000, -0.3000,  1.2000],\n",
      "          [-0.3000, -1.2000, -0.6000]],\n",
      "\n",
      "         [[ 2.4000,  1.8000,  1.8000],\n",
      "          [-0.0000, -1.2000,  0.3000],\n",
      "          [ 0.9000, -0.0000,  0.3000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.9000, -0.3000, -0.9000],\n",
      "          [-1.2000, -0.3000, -0.9000],\n",
      "          [-0.6000, -0.6000, -0.3000]],\n",
      "\n",
      "         [[-0.6000,  0.3000,  0.3000],\n",
      "          [-0.0000,  0.6000,  0.9000],\n",
      "          [-1.2000, -1.2000, -0.6000]],\n",
      "\n",
      "         [[ 0.3000, -0.3000,  0.0000],\n",
      "          [-0.9000, -1.2000, -0.9000],\n",
      "          [ 0.0000, -0.3000, -0.3000]]],\n",
      "\n",
      "\n",
      "        [[[-1.2000, -1.8000, -1.2000],\n",
      "          [-0.6000,  0.3000, -0.6000],\n",
      "          [ 1.2000,  1.2000,  0.0000]],\n",
      "\n",
      "         [[ 0.9000,  1.8000,  1.2000],\n",
      "          [-1.2000, -0.9000, -1.2000],\n",
      "          [-1.2000, -1.2000, -1.2000]],\n",
      "\n",
      "         [[-0.9000, -0.6000, -1.8000],\n",
      "          [-0.6000,  0.6000,  0.0000],\n",
      "          [-1.2000, -0.3000, -0.9000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3000, -0.6000,  0.3000],\n",
      "          [ 0.3000, -0.3000,  1.2000],\n",
      "          [ 0.3000,  0.3000,  0.0000]],\n",
      "\n",
      "         [[-0.3000,  1.8000,  0.3000],\n",
      "          [-1.2000, -0.0000, -0.9000],\n",
      "          [-0.9000, -1.8000, -1.2000]],\n",
      "\n",
      "         [[ 0.9000, -0.6000, -0.6000],\n",
      "          [ 0.0000, -1.2000, -0.3000],\n",
      "          [ 0.9000,  0.6000,  0.9000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.9000, -0.3000,  0.3000],\n",
      "          [-0.3000, -0.3000, -0.6000],\n",
      "          [-0.6000,  0.6000, -0.3000]],\n",
      "\n",
      "         [[ 0.9000,  1.8000, -0.3000],\n",
      "          [ 0.3000,  0.6000, -0.3000],\n",
      "          [-0.9000, -0.0000, -0.6000]],\n",
      "\n",
      "         [[-0.0000,  0.6000, -0.9000],\n",
      "          [ 0.3000, -0.3000, -0.0000],\n",
      "          [ 2.4000,  0.3000,  1.8000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0000, -0.0000, -0.0000],\n",
      "          [ 0.0000,  0.0000, -0.0000],\n",
      "          [ 1.2000, -0.0000,  0.3000]],\n",
      "\n",
      "         [[-0.6000,  0.6000, -0.6000],\n",
      "          [-0.9000,  1.8000, -0.9000],\n",
      "          [-1.8000, -1.2000, -1.8000]],\n",
      "\n",
      "         [[-0.9000, -1.2000, -0.6000],\n",
      "          [-1.8000, -0.3000, -0.9000],\n",
      "          [-0.9000, -0.9000, -1.2000]]]], device='cuda:0',\n",
      "       grad_fn=<_pqBackward>)\n",
      "tensor([[[[ 0.3000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         [[-0.6000]]],\n",
      "\n",
      "\n",
      "        [[[-0.3000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[ 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[-0.9000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[ 0.0000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.6000]],\n",
      "\n",
      "         [[-1.8000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.8000]],\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         [[ 0.3000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3000]],\n",
      "\n",
      "         [[-2.4000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[-0.0000]]],\n",
      "\n",
      "\n",
      "        [[[-0.3000]],\n",
      "\n",
      "         [[-2.4000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[-0.0000]]]], device='cuda:0', grad_fn=<_pqBackward>)\n",
      "tensor([[[[ 1.2000, -0.6000,  1.2000],\n",
      "          [-0.3000,  0.6000, -0.6000],\n",
      "          [ 0.0000,  0.3000,  0.0000]],\n",
      "\n",
      "         [[ 1.8000,  0.0000,  1.8000],\n",
      "          [ 1.2000, -0.3000,  0.9000],\n",
      "          [ 0.3000,  0.6000, -0.3000]],\n",
      "\n",
      "         [[ 0.0000, -0.3000,  0.3000],\n",
      "          [-0.9000,  0.3000, -0.6000],\n",
      "          [-1.2000, -0.0000, -1.2000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.6000,  0.6000, -0.9000],\n",
      "          [ 0.6000, -0.6000,  1.2000],\n",
      "          [-0.0000, -0.6000,  0.6000]],\n",
      "\n",
      "         [[-0.3000, -1.2000, -1.2000],\n",
      "          [ 1.2000, -1.8000,  1.2000],\n",
      "          [ 3.0000,  0.0000,  3.0000]],\n",
      "\n",
      "         [[ 3.0000,  0.6000,  2.4000],\n",
      "          [-0.0000, -1.8000, -0.9000],\n",
      "          [ 1.8000, -0.3000, -0.3000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3000, -1.8000,  0.6000],\n",
      "          [-0.6000, -1.8000, -0.6000],\n",
      "          [ 0.6000,  1.2000,  0.3000]],\n",
      "\n",
      "         [[-1.8000, -1.2000, -0.9000],\n",
      "          [-0.9000,  0.3000, -0.3000],\n",
      "          [ 0.9000,  1.2000,  0.9000]],\n",
      "\n",
      "         [[-0.0000, -0.0000, -0.3000],\n",
      "          [-1.2000, -1.8000, -1.8000],\n",
      "          [ 0.0000, -0.0000, -0.6000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.2000, -0.0000, -2.4000],\n",
      "          [-0.0000, -0.3000,  0.0000],\n",
      "          [ 0.3000, -0.3000, -0.3000]],\n",
      "\n",
      "         [[-0.9000,  1.2000, -0.3000],\n",
      "          [-0.6000,  0.9000,  0.9000],\n",
      "          [-0.9000,  0.3000, -0.3000]],\n",
      "\n",
      "         [[-0.9000, -1.8000, -0.6000],\n",
      "          [-0.6000, -0.3000, -0.3000],\n",
      "          [ 0.3000,  0.9000, -0.0000]]],\n",
      "\n",
      "\n",
      "        [[[-0.9000, -0.3000, -0.3000],\n",
      "          [-0.0000,  0.6000, -0.0000],\n",
      "          [-0.6000, -0.6000, -0.3000]],\n",
      "\n",
      "         [[-0.9000, -0.6000, -0.6000],\n",
      "          [-0.9000,  0.6000,  0.6000],\n",
      "          [ 0.3000,  0.9000,  0.6000]],\n",
      "\n",
      "         [[-0.6000, -0.3000, -0.3000],\n",
      "          [-0.6000,  0.0000, -0.6000],\n",
      "          [-0.6000, -0.9000, -0.6000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.8000,  0.3000,  1.8000],\n",
      "          [ 0.9000,  0.3000,  0.6000],\n",
      "          [ 0.9000,  1.2000,  1.2000]],\n",
      "\n",
      "         [[ 3.0000,  2.4000,  3.0000],\n",
      "          [ 0.9000, -0.6000,  0.6000],\n",
      "          [ 0.9000, -0.0000,  0.9000]],\n",
      "\n",
      "         [[-0.6000,  0.3000, -0.3000],\n",
      "          [-1.2000, -0.0000, -0.6000],\n",
      "          [ 2.4000,  1.2000,  2.4000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.6000,  0.9000],\n",
      "          [-0.0000,  0.6000,  0.3000],\n",
      "          [-0.0000, -0.0000, -0.9000]],\n",
      "\n",
      "         [[ 1.8000, -0.3000,  1.8000],\n",
      "          [ 0.3000, -1.8000,  1.2000],\n",
      "          [-1.2000, -1.2000, -0.9000]],\n",
      "\n",
      "         [[ 0.6000,  0.9000,  0.6000],\n",
      "          [-0.0000, -0.9000, -0.0000],\n",
      "          [-0.3000, -1.8000, -1.8000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.2000, -1.2000,  0.3000],\n",
      "          [ 0.0000,  0.3000,  0.9000],\n",
      "          [ 0.3000,  1.2000,  0.6000]],\n",
      "\n",
      "         [[-0.9000, -0.3000, -0.0000],\n",
      "          [ 0.9000,  0.0000,  0.6000],\n",
      "          [ 0.6000, -0.9000, -0.0000]],\n",
      "\n",
      "         [[ 0.6000,  0.6000,  0.6000],\n",
      "          [ 0.3000, -0.6000,  0.9000],\n",
      "          [-0.9000, -1.8000, -0.9000]]],\n",
      "\n",
      "\n",
      "        [[[-0.6000, -0.9000,  0.0000],\n",
      "          [ 0.6000, -0.0000, -0.3000],\n",
      "          [ 0.3000,  1.2000,  0.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.3000,  0.0000],\n",
      "          [-0.6000,  0.3000, -0.6000],\n",
      "          [-1.2000, -0.3000, -1.2000]],\n",
      "\n",
      "         [[-1.8000, -1.2000, -0.6000],\n",
      "          [-0.3000, -0.6000, -0.3000],\n",
      "          [ 0.0000,  0.0000,  0.3000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.8000,  2.4000,  0.9000],\n",
      "          [-0.0000,  0.9000, -0.3000],\n",
      "          [-0.3000, -0.3000, -0.3000]],\n",
      "\n",
      "         [[-0.3000, -0.3000,  0.6000],\n",
      "          [ 0.0000, -0.0000, -0.9000],\n",
      "          [ 0.6000,  0.0000,  0.9000]],\n",
      "\n",
      "         [[-2.4000, -2.4000, -1.2000],\n",
      "          [-0.3000,  0.6000,  0.3000],\n",
      "          [ 1.2000,  1.8000,  0.6000]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2000,  1.2000,  0.9000],\n",
      "          [ 0.6000,  0.6000,  0.6000],\n",
      "          [ 0.0000,  0.3000,  0.0000]],\n",
      "\n",
      "         [[ 1.8000,  1.8000,  1.8000],\n",
      "          [ 1.2000,  1.8000,  1.2000],\n",
      "          [ 1.2000,  2.4000,  1.2000]],\n",
      "\n",
      "         [[-0.3000,  0.0000, -0.3000],\n",
      "          [-0.3000,  0.3000, -0.0000],\n",
      "          [ 0.6000,  0.6000,  0.6000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3000, -0.3000, -0.3000],\n",
      "          [-0.3000, -0.0000, -0.0000],\n",
      "          [-0.3000, -0.3000, -0.6000]],\n",
      "\n",
      "         [[-1.2000, -1.2000, -0.9000],\n",
      "          [-0.3000, -0.3000, -0.6000],\n",
      "          [-0.9000, -2.4000, -1.8000]],\n",
      "\n",
      "         [[ 0.6000,  0.3000, -0.3000],\n",
      "          [-0.0000,  0.9000,  0.3000],\n",
      "          [ 0.3000,  1.2000,  0.3000]]]], device='cuda:0',\n",
      "       grad_fn=<_pqBackward>)\n",
      "tensor([[[[ 0.6000]],\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[-0.0000]]],\n",
      "\n",
      "\n",
      "        [[[-1.2000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[ 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[-1.8000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         [[-0.3000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.9000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.8000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[-0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2000]],\n",
      "\n",
      "         [[ 2.4000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.8000]],\n",
      "\n",
      "         [[-1.8000]],\n",
      "\n",
      "         [[ 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 2.4000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         [[ 0.3000]]]], device='cuda:0', grad_fn=<_pqBackward>)\n",
      "tensor([[[[-1.8000, -1.2000, -2.4000],\n",
      "          [-1.8000, -0.3000, -0.9000],\n",
      "          [ 1.8000,  1.8000,  1.8000]],\n",
      "\n",
      "         [[ 1.8000,  1.8000,  1.2000],\n",
      "          [-0.6000, -0.3000, -0.9000],\n",
      "          [-1.2000, -0.9000, -1.2000]],\n",
      "\n",
      "         [[ 0.6000,  0.6000,  0.0000],\n",
      "          [-0.0000, -0.6000, -0.0000],\n",
      "          [ 1.2000,  1.8000,  1.8000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.2000,  1.8000,  1.2000],\n",
      "          [ 0.3000,  0.6000,  0.6000],\n",
      "          [-0.6000, -0.3000, -0.3000]],\n",
      "\n",
      "         [[ 1.2000,  1.8000,  0.6000],\n",
      "          [ 0.6000, -0.0000, -0.0000],\n",
      "          [-0.9000, -0.9000, -0.6000]],\n",
      "\n",
      "         [[ 0.3000,  0.3000,  0.3000],\n",
      "          [-0.0000,  0.0000,  0.0000],\n",
      "          [-0.6000, -0.6000, -0.6000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3000,  1.8000,  0.6000],\n",
      "          [-0.6000,  1.2000, -0.3000],\n",
      "          [-1.8000,  0.9000, -1.2000]],\n",
      "\n",
      "         [[ 0.3000,  0.0000,  1.2000],\n",
      "          [ 1.8000, -0.9000,  0.3000],\n",
      "          [-0.6000, -0.3000,  0.3000]],\n",
      "\n",
      "         [[ 1.2000,  1.2000,  2.4000],\n",
      "          [ 0.0000, -0.3000, -0.6000],\n",
      "          [ 0.3000,  0.6000,  0.9000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.9000, -0.9000, -2.4000],\n",
      "          [ 1.2000,  0.6000,  0.6000],\n",
      "          [-0.3000,  0.3000,  0.0000]],\n",
      "\n",
      "         [[-0.9000,  3.0000, -1.2000],\n",
      "          [-1.2000,  0.3000, -0.9000],\n",
      "          [ 1.2000,  0.6000,  0.6000]],\n",
      "\n",
      "         [[-0.6000, -0.9000, -1.2000],\n",
      "          [-1.8000,  1.8000, -3.0000],\n",
      "          [-0.9000, -0.6000, -1.2000]]],\n",
      "\n",
      "\n",
      "        [[[-1.2000, -0.0000, -0.6000],\n",
      "          [-0.9000,  0.3000, -0.9000],\n",
      "          [ 1.2000,  0.9000,  1.8000]],\n",
      "\n",
      "         [[ 0.9000, -1.2000,  0.3000],\n",
      "          [-0.6000, -0.6000, -0.6000],\n",
      "          [-0.6000, -0.3000, -0.3000]],\n",
      "\n",
      "         [[ 0.3000, -1.8000, -1.2000],\n",
      "          [-0.3000,  0.0000,  0.3000],\n",
      "          [ 0.9000, -0.6000,  1.8000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3000, -0.3000, -0.6000],\n",
      "          [-0.6000,  0.0000, -0.3000],\n",
      "          [-1.8000, -2.4000, -1.8000]],\n",
      "\n",
      "         [[-0.6000,  1.2000, -0.9000],\n",
      "          [-0.3000, -0.3000,  0.3000],\n",
      "          [-0.3000, -0.3000, -0.0000]],\n",
      "\n",
      "         [[-0.0000,  0.3000, -0.6000],\n",
      "          [-0.6000, -0.6000, -1.2000],\n",
      "          [ 0.0000, -0.3000, -0.3000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.6000, -0.3000, -0.9000],\n",
      "          [-0.6000,  0.3000, -0.9000],\n",
      "          [-0.0000, -0.3000, -1.2000]],\n",
      "\n",
      "         [[-0.3000, -0.0000, -0.3000],\n",
      "          [-0.6000, -0.6000, -0.9000],\n",
      "          [ 0.6000,  1.2000, -0.3000]],\n",
      "\n",
      "         [[ 0.6000,  1.8000,  0.9000],\n",
      "          [-0.3000,  0.9000, -0.0000],\n",
      "          [-0.9000,  1.8000, -0.3000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0000,  0.3000, -0.3000],\n",
      "          [ 0.3000,  0.3000, -0.6000],\n",
      "          [ 0.3000,  0.9000, -0.6000]],\n",
      "\n",
      "         [[ 0.9000, -2.4000,  0.9000],\n",
      "          [ 1.8000, -0.9000,  1.8000],\n",
      "          [ 1.2000, -0.3000,  0.9000]],\n",
      "\n",
      "         [[-0.3000, -0.3000, -0.6000],\n",
      "          [-0.9000, -0.3000, -0.9000],\n",
      "          [-0.6000, -0.6000, -0.3000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3000,  0.3000,  0.0000],\n",
      "          [-0.3000,  0.6000, -0.6000],\n",
      "          [ 0.6000,  1.2000, -0.9000]],\n",
      "\n",
      "         [[ 0.6000,  0.6000,  0.3000],\n",
      "          [-0.0000, -0.0000, -0.0000],\n",
      "          [ 0.0000,  0.6000, -0.3000]],\n",
      "\n",
      "         [[-0.3000,  0.6000, -0.3000],\n",
      "          [ 0.3000,  0.6000, -0.3000],\n",
      "          [ 0.6000,  0.9000, -0.9000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0000,  0.6000, -0.6000],\n",
      "          [-0.3000,  0.0000, -0.3000],\n",
      "          [-0.3000, -0.6000, -0.6000]],\n",
      "\n",
      "         [[ 0.3000,  0.0000,  0.3000],\n",
      "          [ 0.0000, -0.3000,  0.6000],\n",
      "          [ 0.0000, -0.3000,  1.2000]],\n",
      "\n",
      "         [[ 0.3000, -0.0000,  0.3000],\n",
      "          [-0.3000,  0.3000, -0.6000],\n",
      "          [-0.0000, -0.3000, -0.3000]]],\n",
      "\n",
      "\n",
      "        [[[-1.2000, -0.3000, -0.6000],\n",
      "          [ 0.0000, -0.6000, -0.3000],\n",
      "          [-0.9000, -0.6000, -0.9000]],\n",
      "\n",
      "         [[ 0.3000,  1.2000,  1.2000],\n",
      "          [-0.6000,  0.3000, -0.0000],\n",
      "          [-1.2000, -0.6000,  0.0000]],\n",
      "\n",
      "         [[ 1.8000,  2.4000,  3.0000],\n",
      "          [-0.3000,  0.6000,  0.6000],\n",
      "          [-2.4000, -2.4000, -1.8000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3000, -0.3000, -0.9000],\n",
      "          [ 0.6000,  0.9000,  0.3000],\n",
      "          [ 1.2000,  0.6000,  0.9000]],\n",
      "\n",
      "         [[ 0.3000, -0.3000, -0.6000],\n",
      "          [ 0.6000, -0.3000,  0.0000],\n",
      "          [ 0.6000,  0.3000,  0.6000]],\n",
      "\n",
      "         [[-0.3000,  0.3000,  0.3000],\n",
      "          [ 0.9000,  0.9000,  2.4000],\n",
      "          [ 0.9000,  0.9000,  0.3000]]]], device='cuda:0',\n",
      "       grad_fn=<_pqBackward>)\n",
      "tensor([[[[-2.4000]],\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[ 0.6000]]],\n",
      "\n",
      "\n",
      "        [[[-0.3000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[-1.2000]]],\n",
      "\n",
      "\n",
      "        [[[-0.3000]],\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[ 2.4000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 1.2000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 1.8000]]],\n",
      "\n",
      "\n",
      "        [[[-0.3000]],\n",
      "\n",
      "         [[-2.4000]],\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.4000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[-1.8000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3000]],\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[-1.2000]]]], device='cuda:0', grad_fn=<_pqBackward>)\n",
      "tensor([[[[ 0.3000, -1.2000, -0.3000],\n",
      "          [-0.3000, -0.6000, -0.6000],\n",
      "          [ 0.6000,  0.6000, -0.3000]],\n",
      "\n",
      "         [[-0.3000, -0.3000, -0.3000],\n",
      "          [-0.3000, -0.6000,  0.3000],\n",
      "          [-0.3000, -0.0000,  0.0000]],\n",
      "\n",
      "         [[-0.6000,  0.3000, -0.6000],\n",
      "          [-1.2000, -0.0000,  0.0000],\n",
      "          [ 1.8000, -0.3000,  1.8000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.2000,  0.9000, -1.2000],\n",
      "          [-1.8000,  0.0000, -1.8000],\n",
      "          [-0.6000,  1.8000, -1.2000]],\n",
      "\n",
      "         [[ 0.3000,  0.6000, -0.3000],\n",
      "          [ 1.8000,  1.2000,  1.2000],\n",
      "          [ 0.3000, -0.6000, -0.9000]],\n",
      "\n",
      "         [[-0.3000, -0.9000, -0.0000],\n",
      "          [-0.9000, -0.3000, -0.9000],\n",
      "          [ 0.0000, -0.0000, -0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 1.8000,  1.8000,  2.4000],\n",
      "          [-0.6000, -1.8000, -0.0000],\n",
      "          [-1.2000, -2.4000, -1.8000]],\n",
      "\n",
      "         [[-1.2000, -0.9000, -0.9000],\n",
      "          [-0.3000, -0.9000, -0.6000],\n",
      "          [ 0.0000,  0.3000, -0.3000]],\n",
      "\n",
      "         [[ 0.0000, -1.8000,  0.0000],\n",
      "          [ 0.3000, -0.3000,  1.2000],\n",
      "          [ 0.6000, -0.9000,  0.9000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.2000, -2.4000, -1.2000],\n",
      "          [-0.3000,  0.3000,  0.3000],\n",
      "          [ 0.6000,  1.8000,  0.3000]],\n",
      "\n",
      "         [[ 2.4000, -0.3000, -0.6000],\n",
      "          [ 0.9000, -0.0000,  0.6000],\n",
      "          [ 0.9000, -0.0000,  0.9000]],\n",
      "\n",
      "         [[ 0.9000,  1.8000,  0.6000],\n",
      "          [-0.9000, -0.3000, -0.6000],\n",
      "          [ 0.6000,  0.9000,  0.3000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.9000,  0.3000,  0.9000],\n",
      "          [-0.6000,  0.3000,  0.3000],\n",
      "          [-0.3000,  0.3000, -0.6000]],\n",
      "\n",
      "         [[-0.0000, -0.6000, -0.3000],\n",
      "          [ 0.6000, -0.0000,  0.0000],\n",
      "          [ 1.2000,  0.6000,  1.2000]],\n",
      "\n",
      "         [[ 0.3000,  0.0000,  0.3000],\n",
      "          [ 0.9000, -0.6000,  0.3000],\n",
      "          [-0.3000,  0.3000, -0.9000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.9000, -0.6000, -0.3000],\n",
      "          [ 0.6000,  0.9000,  0.6000],\n",
      "          [ 0.9000,  1.8000,  0.6000]],\n",
      "\n",
      "         [[ 0.9000,  1.2000,  0.9000],\n",
      "          [ 0.0000, -0.6000,  0.6000],\n",
      "          [-1.2000, -2.4000, -1.2000]],\n",
      "\n",
      "         [[ 0.6000, -0.6000,  0.0000],\n",
      "          [-0.3000, -0.3000,  0.3000],\n",
      "          [ 0.3000,  0.3000,  0.3000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.3000, -0.0000,  0.0000],\n",
      "          [-0.6000, -1.2000, -0.6000],\n",
      "          [-0.6000, -0.9000, -1.2000]],\n",
      "\n",
      "         [[ 0.0000, -0.3000, -0.0000],\n",
      "          [-0.3000, -0.9000, -0.9000],\n",
      "          [-0.9000, -0.9000, -1.2000]],\n",
      "\n",
      "         [[ 0.9000,  0.6000,  0.9000],\n",
      "          [ 1.2000,  1.8000,  1.8000],\n",
      "          [-0.3000,  0.6000,  0.3000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.6000,  0.6000,  0.9000],\n",
      "          [ 1.2000,  1.2000,  1.2000],\n",
      "          [ 0.9000,  1.2000,  0.3000]],\n",
      "\n",
      "         [[ 0.3000, -0.3000, -0.0000],\n",
      "          [ 0.0000,  0.3000,  0.3000],\n",
      "          [ 0.3000,  0.9000,  0.0000]],\n",
      "\n",
      "         [[-1.2000,  0.0000, -0.6000],\n",
      "          [-0.6000, -0.9000, -0.3000],\n",
      "          [ 0.6000, -0.0000,  0.3000]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2000,  0.0000,  0.6000],\n",
      "          [-0.3000, -0.3000, -0.0000],\n",
      "          [-0.3000,  0.9000, -0.3000]],\n",
      "\n",
      "         [[-0.0000, -0.6000, -0.6000],\n",
      "          [-0.6000, -0.6000, -0.3000],\n",
      "          [ 1.8000,  1.2000,  1.8000]],\n",
      "\n",
      "         [[-2.4000, -1.2000, -1.8000],\n",
      "          [-1.2000, -1.2000, -0.6000],\n",
      "          [ 0.3000,  0.3000,  0.9000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.2000,  1.2000, -1.8000],\n",
      "          [-0.9000,  1.8000, -1.2000],\n",
      "          [ 0.6000,  1.2000,  0.6000]],\n",
      "\n",
      "         [[ 1.8000,  3.0000,  1.8000],\n",
      "          [ 1.2000,  0.3000,  1.8000],\n",
      "          [-1.8000, -2.4000, -1.2000]],\n",
      "\n",
      "         [[-0.3000, -1.8000, -0.3000],\n",
      "          [-1.8000, -1.2000, -1.2000],\n",
      "          [ 0.9000,  2.4000,  0.6000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3000,  0.0000,  0.6000],\n",
      "          [-0.3000, -0.3000,  0.3000],\n",
      "          [ 0.0000,  0.3000,  0.3000]],\n",
      "\n",
      "         [[ 0.3000,  0.6000, -0.0000],\n",
      "          [-0.0000,  0.6000,  0.0000],\n",
      "          [-0.6000, -0.6000, -0.9000]],\n",
      "\n",
      "         [[-0.6000, -0.6000, -0.6000],\n",
      "          [ 1.2000,  0.6000,  0.9000],\n",
      "          [ 2.4000,  3.0000,  3.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0000, -0.3000, -0.3000],\n",
      "          [ 0.3000, -0.6000, -0.0000],\n",
      "          [ 0.0000, -0.3000,  0.0000]],\n",
      "\n",
      "         [[-0.3000, -0.9000, -0.3000],\n",
      "          [ 0.3000, -0.9000, -0.0000],\n",
      "          [-0.9000, -0.9000, -0.6000]],\n",
      "\n",
      "         [[-1.2000, -0.6000, -0.9000],\n",
      "          [-1.2000, -0.6000, -0.6000],\n",
      "          [ 0.3000,  0.6000,  0.3000]]]], device='cuda:0',\n",
      "       grad_fn=<_pqBackward>)\n",
      "tensor([[[[-0.0000]],\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[-1.2000]]],\n",
      "\n",
      "\n",
      "        [[[-0.6000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[-0.3000]]],\n",
      "\n",
      "\n",
      "        [[[-0.6000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         [[-1.8000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.6000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[-0.9000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.9000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 1.2000]]],\n",
      "\n",
      "\n",
      "        [[[-2.4000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[ 3.0000]],\n",
      "\n",
      "         [[ 1.8000]]]], device='cuda:0', grad_fn=<_pqBackward>)\n",
      "tensor([[[[ 0.3000,  0.0000,  0.3000],\n",
      "          [ 1.2000,  0.3000, -0.0000],\n",
      "          [-0.0000,  0.3000, -0.3000]],\n",
      "\n",
      "         [[-1.2000, -1.8000, -1.2000],\n",
      "          [-1.2000, -1.2000, -1.2000],\n",
      "          [ 0.3000, -0.6000, -0.3000]],\n",
      "\n",
      "         [[-0.3000, -0.6000,  0.0000],\n",
      "          [ 0.3000, -0.0000,  0.3000],\n",
      "          [ 1.2000,  0.9000,  0.3000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.9000,  0.0000,  1.2000],\n",
      "          [-0.6000, -0.6000,  0.3000],\n",
      "          [ 0.0000, -0.0000,  0.3000]],\n",
      "\n",
      "         [[-0.3000, -0.6000, -0.3000],\n",
      "          [-0.0000, -0.3000, -0.0000],\n",
      "          [-0.0000, -0.0000, -0.3000]],\n",
      "\n",
      "         [[-1.2000, -0.9000, -0.3000],\n",
      "          [-1.2000, -0.9000, -0.3000],\n",
      "          [-1.8000, -1.2000, -0.9000]]],\n",
      "\n",
      "\n",
      "        [[[-0.3000, -1.2000, -0.3000],\n",
      "          [-1.2000, -0.6000, -0.9000],\n",
      "          [-1.2000, -1.8000, -0.6000]],\n",
      "\n",
      "         [[ 0.0000,  0.3000, -0.3000],\n",
      "          [-0.0000, -1.2000, -0.3000],\n",
      "          [ 0.9000, -0.0000,  0.3000]],\n",
      "\n",
      "         [[ 1.8000, -0.3000,  1.2000],\n",
      "          [ 0.6000, -2.4000, -0.3000],\n",
      "          [-0.9000, -3.0000, -1.2000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.6000, -0.3000, -0.3000],\n",
      "          [-1.2000, -0.0000, -0.6000],\n",
      "          [-1.8000, -1.2000, -0.6000]],\n",
      "\n",
      "         [[-0.9000,  0.0000, -0.9000],\n",
      "          [-0.6000, -0.0000, -0.3000],\n",
      "          [-0.6000, -0.6000, -0.9000]],\n",
      "\n",
      "         [[ 0.6000,  0.9000,  0.0000],\n",
      "          [ 0.6000,  0.3000,  0.9000],\n",
      "          [-0.3000, -1.8000, -0.0000]]],\n",
      "\n",
      "\n",
      "        [[[-0.6000, -0.3000, -0.3000],\n",
      "          [ 0.3000, -0.3000,  0.0000],\n",
      "          [ 0.3000,  0.0000,  0.3000]],\n",
      "\n",
      "         [[-0.9000, -0.3000, -0.6000],\n",
      "          [-0.3000, -0.9000, -0.9000],\n",
      "          [ 0.0000, -0.3000,  0.0000]],\n",
      "\n",
      "         [[ 0.0000, -0.3000, -0.0000],\n",
      "          [-0.9000, -2.4000, -1.8000],\n",
      "          [-0.9000, -1.8000, -1.2000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.2000,  1.2000,  1.2000],\n",
      "          [ 0.6000, -0.3000,  0.6000],\n",
      "          [-0.9000, -1.2000, -1.2000]],\n",
      "\n",
      "         [[-0.3000, -0.3000, -0.3000],\n",
      "          [ 0.0000, -0.3000, -0.3000],\n",
      "          [-0.6000, -0.3000, -0.9000]],\n",
      "\n",
      "         [[-0.6000, -0.3000, -0.6000],\n",
      "          [-0.9000, -0.3000, -0.6000],\n",
      "          [-1.8000, -1.2000, -1.8000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-1.8000, -1.8000, -1.8000],\n",
      "          [-0.6000,  0.0000, -0.9000],\n",
      "          [ 2.4000,  3.0000,  2.4000]],\n",
      "\n",
      "         [[-0.3000, -0.6000, -0.6000],\n",
      "          [-1.8000, -2.4000, -2.4000],\n",
      "          [-1.8000, -1.2000, -1.8000]],\n",
      "\n",
      "         [[-0.0000, -1.2000,  0.3000],\n",
      "          [-0.9000, -2.4000, -0.9000],\n",
      "          [ 0.3000, -0.3000,  0.3000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.6000,  0.6000,  0.6000],\n",
      "          [ 0.6000,  0.6000,  0.9000],\n",
      "          [ 1.2000,  1.2000,  1.8000]],\n",
      "\n",
      "         [[ 0.3000,  0.0000, -0.0000],\n",
      "          [-0.0000, -0.0000, -1.2000],\n",
      "          [-0.3000, -0.9000, -0.9000]],\n",
      "\n",
      "         [[-1.8000, -2.4000, -1.2000],\n",
      "          [-0.9000, -0.3000, -0.6000],\n",
      "          [-1.8000, -1.2000, -0.9000]]],\n",
      "\n",
      "\n",
      "        [[[-1.2000, -0.3000, -0.6000],\n",
      "          [-0.0000, -0.3000,  0.0000],\n",
      "          [ 0.3000, -0.0000, -0.6000]],\n",
      "\n",
      "         [[ 0.6000, -0.9000, -0.3000],\n",
      "          [-0.6000, -0.6000,  0.3000],\n",
      "          [ 0.3000,  0.6000,  0.3000]],\n",
      "\n",
      "         [[ 0.0000, -0.9000, -0.6000],\n",
      "          [-0.0000, -0.9000, -0.6000],\n",
      "          [ 0.3000,  0.3000, -0.3000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0000,  0.6000,  1.2000],\n",
      "          [ 0.9000,  0.0000,  0.6000],\n",
      "          [ 0.9000,  0.3000,  0.6000]],\n",
      "\n",
      "         [[-0.3000, -0.0000, -0.3000],\n",
      "          [-0.3000, -0.3000, -0.3000],\n",
      "          [-0.3000, -0.3000, -0.3000]],\n",
      "\n",
      "         [[ 0.6000,  1.2000,  1.2000],\n",
      "          [ 0.9000,  0.9000,  1.8000],\n",
      "          [-0.3000, -0.3000, -0.6000]]],\n",
      "\n",
      "\n",
      "        [[[-1.8000, -0.9000, -1.2000],\n",
      "          [-1.8000, -1.2000, -1.2000],\n",
      "          [-1.8000, -1.8000, -1.2000]],\n",
      "\n",
      "         [[-0.6000, -0.9000, -1.2000],\n",
      "          [-0.6000, -0.9000, -0.6000],\n",
      "          [-0.0000, -0.0000,  0.0000]],\n",
      "\n",
      "         [[ 0.9000,  2.4000,  1.8000],\n",
      "          [-1.8000, -0.9000, -1.2000],\n",
      "          [-1.2000, -0.3000, -0.6000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.4000,  2.4000,  2.4000],\n",
      "          [-0.0000,  0.3000,  0.0000],\n",
      "          [-2.4000, -3.0000, -2.4000]],\n",
      "\n",
      "         [[ 0.0000,  0.3000,  0.0000],\n",
      "          [-0.3000,  0.0000, -0.0000],\n",
      "          [-0.3000, -0.3000, -0.0000]],\n",
      "\n",
      "         [[-0.6000, -0.6000, -0.9000],\n",
      "          [ 0.3000, -0.0000, -0.0000],\n",
      "          [ 0.0000, -0.3000,  0.3000]]]], device='cuda:0',\n",
      "       grad_fn=<_pqBackward>)\n",
      "tensor([[[[ 0.0000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[-0.0000]]],\n",
      "\n",
      "\n",
      "        [[[-0.9000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[-0.3000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[-1.8000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[ 0.0000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.3000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[-1.8000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[ 0.3000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000]],\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         [[-2.4000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[ 0.6000]]],\n",
      "\n",
      "\n",
      "        [[[-0.6000]],\n",
      "\n",
      "         [[-2.4000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[-1.2000]]]], device='cuda:0', grad_fn=<_pqBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.9000,  0.0000,  0.9000],\n",
      "          [ 0.3000,  1.8000,  1.2000],\n",
      "          [-1.2000, -1.2000, -0.9000]],\n",
      "\n",
      "         [[ 0.3000,  0.6000, -0.3000],\n",
      "          [ 0.6000,  0.0000, -0.6000],\n",
      "          [ 1.2000,  1.2000, -0.6000]],\n",
      "\n",
      "         [[-1.2000, -1.2000, -0.9000],\n",
      "          [-1.2000, -0.3000, -0.9000],\n",
      "          [ 2.4000,  3.0000,  2.4000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3000,  0.9000,  0.9000],\n",
      "          [-0.9000, -0.6000,  1.2000],\n",
      "          [-0.6000, -0.6000,  1.2000]],\n",
      "\n",
      "         [[-0.6000, -1.2000, -0.9000],\n",
      "          [-0.3000, -0.6000, -0.3000],\n",
      "          [-0.9000, -0.6000, -0.3000]],\n",
      "\n",
      "         [[-0.6000, -0.6000, -0.6000],\n",
      "          [-0.0000,  0.9000,  0.3000],\n",
      "          [ 0.9000,  1.2000, -0.3000]]],\n",
      "\n",
      "\n",
      "        [[[ 2.4000,  1.8000,  2.4000],\n",
      "          [ 0.6000,  0.9000,  1.2000],\n",
      "          [ 0.0000, -0.6000, -0.6000]],\n",
      "\n",
      "         [[-1.8000, -1.2000, -1.8000],\n",
      "          [-0.0000,  0.6000,  0.0000],\n",
      "          [ 0.3000,  0.3000,  0.3000]],\n",
      "\n",
      "         [[-0.0000,  1.2000, -0.0000],\n",
      "          [-0.6000,  0.0000, -0.0000],\n",
      "          [-0.9000, -0.3000, -0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3000, -0.9000, -0.3000],\n",
      "          [-0.0000, -0.3000, -0.9000],\n",
      "          [-0.9000, -0.3000, -0.3000]],\n",
      "\n",
      "         [[ 3.0000,  2.4000,  3.0000],\n",
      "          [ 1.8000,  1.2000,  3.0000],\n",
      "          [ 0.3000,  0.0000,  0.6000]],\n",
      "\n",
      "         [[-0.9000, -0.9000, -1.2000],\n",
      "          [ 0.6000,  0.3000, -0.0000],\n",
      "          [ 0.6000,  1.2000,  0.6000]]],\n",
      "\n",
      "\n",
      "        [[[-0.0000,  2.4000, -0.0000],\n",
      "          [-1.2000,  0.3000, -1.2000],\n",
      "          [-0.3000,  0.0000, -0.3000]],\n",
      "\n",
      "         [[ 0.6000, -0.6000,  1.2000],\n",
      "          [ 0.9000,  0.6000,  0.6000],\n",
      "          [-0.9000, -1.2000, -0.9000]],\n",
      "\n",
      "         [[ 1.2000, -0.3000,  1.2000],\n",
      "          [ 0.9000,  0.3000, -0.3000],\n",
      "          [-0.6000, -0.9000, -0.6000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.2000,  0.6000, -1.2000],\n",
      "          [ 0.0000,  0.3000, -0.0000],\n",
      "          [ 0.6000, -0.6000,  0.9000]],\n",
      "\n",
      "         [[-0.0000,  2.4000, -0.6000],\n",
      "          [-1.2000, -0.3000, -1.8000],\n",
      "          [-0.9000, -0.6000, -0.3000]],\n",
      "\n",
      "         [[-0.3000,  0.6000,  0.0000],\n",
      "          [ 0.6000,  0.6000,  0.9000],\n",
      "          [-0.9000, -1.2000, -0.3000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.6000,  0.3000,  0.3000],\n",
      "          [-2.4000, -0.0000, -0.3000],\n",
      "          [-0.9000, -1.2000, -1.2000]],\n",
      "\n",
      "         [[-1.8000, -0.9000, -0.6000],\n",
      "          [-1.2000, -0.3000, -0.6000],\n",
      "          [-0.9000,  0.0000, -0.6000]],\n",
      "\n",
      "         [[-0.9000, -0.9000, -0.6000],\n",
      "          [-0.3000,  0.6000,  0.9000],\n",
      "          [ 0.3000,  1.8000,  1.8000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0000,  0.6000, -0.0000],\n",
      "          [-0.3000, -1.2000, -0.9000],\n",
      "          [-1.8000, -3.0000, -1.8000]],\n",
      "\n",
      "         [[ 0.3000, -0.3000, -0.3000],\n",
      "          [-0.9000, -0.6000, -0.6000],\n",
      "          [-0.9000, -0.0000, -0.9000]],\n",
      "\n",
      "         [[-0.9000, -0.3000, -0.9000],\n",
      "          [ 0.9000,  0.9000,  0.6000],\n",
      "          [ 2.4000,  2.4000,  2.4000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3000, -0.3000, -0.0000],\n",
      "          [-0.9000, -0.9000, -1.8000],\n",
      "          [-0.9000, -0.3000, -0.6000]],\n",
      "\n",
      "         [[ 0.3000,  1.2000,  0.6000],\n",
      "          [ 0.6000,  1.2000,  0.9000],\n",
      "          [ 0.3000,  1.2000,  0.9000]],\n",
      "\n",
      "         [[-0.9000, -0.3000, -0.6000],\n",
      "          [-0.9000, -0.9000, -0.0000],\n",
      "          [ 0.6000,  0.0000,  0.3000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.9000,  0.0000,  0.6000],\n",
      "          [ 0.3000, -0.3000, -0.6000],\n",
      "          [-0.6000, -0.6000, -0.9000]],\n",
      "\n",
      "         [[ 0.6000,  0.3000,  0.9000],\n",
      "          [ 0.6000,  0.3000,  0.9000],\n",
      "          [-0.0000, -0.3000, -0.3000]],\n",
      "\n",
      "         [[-0.6000, -0.9000, -0.6000],\n",
      "          [ 0.3000, -0.0000,  0.9000],\n",
      "          [ 0.6000,  0.3000,  0.3000]]],\n",
      "\n",
      "\n",
      "        [[[-0.0000, -0.6000, -0.3000],\n",
      "          [-1.8000, -1.8000, -1.8000],\n",
      "          [-0.9000, -0.6000, -0.9000]],\n",
      "\n",
      "         [[ 0.9000,  1.2000,  0.9000],\n",
      "          [-0.3000,  0.3000, -0.0000],\n",
      "          [-0.9000, -0.9000, -0.6000]],\n",
      "\n",
      "         [[-1.2000, -1.2000, -0.9000],\n",
      "          [-0.6000, -0.6000, -0.3000],\n",
      "          [ 0.0000, -0.3000,  0.6000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.9000,  0.3000,  0.6000],\n",
      "          [ 0.6000,  0.9000,  0.6000],\n",
      "          [-1.2000, -0.9000, -0.6000]],\n",
      "\n",
      "         [[ 0.9000,  0.9000,  1.2000],\n",
      "          [-0.0000,  0.0000,  0.3000],\n",
      "          [-0.0000, -0.3000, -0.0000]],\n",
      "\n",
      "         [[-0.9000, -1.2000, -1.2000],\n",
      "          [ 0.3000,  0.9000,  0.6000],\n",
      "          [-0.0000,  0.3000,  0.0000]]]], device='cuda:0',\n",
      "       grad_fn=<_pqBackward>)\n",
      "tensor([[[[ 0.6000]],\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         [[ 0.3000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.8000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[-0.0000]]],\n",
      "\n",
      "\n",
      "        [[[-0.9000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.4000]],\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         [[ 0.9000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.3000]],\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         [[ 2.4000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         [[-0.6000]]],\n",
      "\n",
      "\n",
      "        [[[-0.0000]],\n",
      "\n",
      "         [[-2.4000]],\n",
      "\n",
      "         [[-1.8000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[-0.9000]]],\n",
      "\n",
      "\n",
      "        [[[-0.6000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.8000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[ 0.9000]]]], device='cuda:0', grad_fn=<_pqBackward>)\n",
      "tensor([[[[-1.2000, -1.2000, -1.2000],\n",
      "          [ 0.3000,  0.0000, -0.0000],\n",
      "          [ 1.2000,  0.3000,  0.6000]],\n",
      "\n",
      "         [[-0.9000,  0.0000, -0.6000],\n",
      "          [-1.2000, -0.9000, -0.9000],\n",
      "          [ 0.3000,  0.9000,  0.3000]],\n",
      "\n",
      "         [[-1.2000, -0.6000, -1.2000],\n",
      "          [-0.6000, -0.3000, -0.6000],\n",
      "          [-0.3000,  0.0000, -0.3000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.2000, -0.9000, -1.2000],\n",
      "          [-0.6000, -0.3000, -1.2000],\n",
      "          [-0.3000, -0.0000, -0.9000]],\n",
      "\n",
      "         [[-0.3000,  0.0000,  0.0000],\n",
      "          [-0.3000, -0.0000,  0.6000],\n",
      "          [ 0.3000,  0.3000,  0.6000]],\n",
      "\n",
      "         [[ 1.2000,  0.6000,  0.3000],\n",
      "          [-0.0000, -0.6000, -0.9000],\n",
      "          [-0.9000, -1.2000, -0.9000]]],\n",
      "\n",
      "\n",
      "        [[[-0.3000, -0.0000, -0.0000],\n",
      "          [ 0.6000,  0.9000,  0.9000],\n",
      "          [ 0.3000,  0.6000, -0.3000]],\n",
      "\n",
      "         [[ 0.9000,  1.8000,  0.9000],\n",
      "          [ 0.3000,  0.6000,  0.0000],\n",
      "          [-1.8000, -1.2000, -0.9000]],\n",
      "\n",
      "         [[-1.8000, -1.2000, -1.8000],\n",
      "          [-0.3000, -0.6000, -0.9000],\n",
      "          [ 0.6000,  0.6000,  0.6000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3000, -0.3000, -0.9000],\n",
      "          [ 1.8000,  1.8000,  1.8000],\n",
      "          [ 0.6000,  1.8000,  0.9000]],\n",
      "\n",
      "         [[-0.6000, -0.6000, -0.3000],\n",
      "          [ 0.0000, -0.6000, -0.3000],\n",
      "          [ 1.2000,  1.2000,  1.2000]],\n",
      "\n",
      "         [[ 0.6000,  0.9000,  0.3000],\n",
      "          [ 0.0000,  0.3000,  0.6000],\n",
      "          [-0.9000, -0.9000, -0.3000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.9000,  0.6000,  0.6000],\n",
      "          [ 1.2000,  1.2000,  1.2000],\n",
      "          [ 0.3000,  0.6000, -0.9000]],\n",
      "\n",
      "         [[ 1.8000,  2.4000,  1.8000],\n",
      "          [-0.3000,  0.0000, -1.2000],\n",
      "          [-1.8000, -0.9000, -1.2000]],\n",
      "\n",
      "         [[-1.8000, -0.6000, -0.9000],\n",
      "          [ 1.2000,  1.8000,  0.9000],\n",
      "          [ 1.8000,  1.8000,  2.4000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0000,  0.6000, -0.3000],\n",
      "          [ 0.3000,  1.2000,  0.9000],\n",
      "          [ 0.6000,  1.2000, -0.0000]],\n",
      "\n",
      "         [[-1.2000, -0.3000, -0.3000],\n",
      "          [-0.3000, -1.2000, -0.3000],\n",
      "          [ 1.8000,  1.2000,  1.8000]],\n",
      "\n",
      "         [[ 1.8000,  1.8000,  1.2000],\n",
      "          [ 0.3000,  0.6000,  0.3000],\n",
      "          [-0.3000, -0.3000,  0.0000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-1.8000, -0.6000, -1.2000],\n",
      "          [-1.2000, -1.2000, -1.2000],\n",
      "          [-1.8000, -2.4000, -2.4000]],\n",
      "\n",
      "         [[ 0.6000,  0.3000, -0.3000],\n",
      "          [ 0.9000,  1.8000,  1.8000],\n",
      "          [ 0.6000,  0.3000, -0.6000]],\n",
      "\n",
      "         [[-1.2000, -0.6000, -1.2000],\n",
      "          [-0.9000, -0.6000, -0.9000],\n",
      "          [-1.8000, -0.9000, -1.2000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.8000, -0.9000, -1.8000],\n",
      "          [ 0.6000,  2.4000,  0.3000],\n",
      "          [-0.6000,  1.2000, -0.6000]],\n",
      "\n",
      "         [[ 1.2000, -0.3000,  0.9000],\n",
      "          [ 0.0000,  0.0000,  0.6000],\n",
      "          [ 1.2000,  1.8000,  2.4000]],\n",
      "\n",
      "         [[-2.4000, -1.8000, -1.8000],\n",
      "          [ 0.9000,  0.9000,  0.6000],\n",
      "          [-1.8000, -2.4000, -3.0000]]],\n",
      "\n",
      "\n",
      "        [[[-0.0000,  0.3000,  0.0000],\n",
      "          [ 0.3000,  0.3000,  0.3000],\n",
      "          [ 0.3000,  0.3000,  0.9000]],\n",
      "\n",
      "         [[-0.9000, -0.6000, -1.2000],\n",
      "          [ 0.0000,  0.6000,  0.6000],\n",
      "          [-0.0000,  0.3000,  0.6000]],\n",
      "\n",
      "         [[ 0.0000, -0.3000, -0.3000],\n",
      "          [-0.6000, -0.9000, -0.9000],\n",
      "          [ 0.3000, -0.3000, -0.3000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0000,  0.6000,  0.0000],\n",
      "          [-0.6000, -0.3000, -1.2000],\n",
      "          [-0.6000,  0.0000, -0.0000]],\n",
      "\n",
      "         [[ 0.9000, -0.3000,  0.3000],\n",
      "          [ 0.3000, -0.3000,  0.0000],\n",
      "          [ 0.0000,  0.0000, -0.0000]],\n",
      "\n",
      "         [[-0.6000, -0.3000, -0.6000],\n",
      "          [-0.9000, -0.6000, -0.6000],\n",
      "          [-0.3000, -0.9000, -1.2000]]],\n",
      "\n",
      "\n",
      "        [[[-0.9000, -0.9000, -0.6000],\n",
      "          [ 0.3000,  0.3000,  0.3000],\n",
      "          [ 0.6000,  0.3000,  0.3000]],\n",
      "\n",
      "         [[ 0.6000,  0.3000,  0.9000],\n",
      "          [ 1.8000,  1.8000,  1.2000],\n",
      "          [ 1.2000,  1.2000,  1.2000]],\n",
      "\n",
      "         [[ 0.6000,  0.9000,  0.3000],\n",
      "          [ 1.8000,  2.4000,  1.8000],\n",
      "          [ 1.2000,  1.8000,  1.2000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.2000, -1.8000, -1.8000],\n",
      "          [-1.2000, -0.9000, -1.2000],\n",
      "          [-1.2000, -0.3000, -0.6000]],\n",
      "\n",
      "         [[ 1.8000,  1.8000,  1.2000],\n",
      "          [ 1.8000,  1.2000,  2.4000],\n",
      "          [ 0.9000,  0.6000,  0.3000]],\n",
      "\n",
      "         [[-1.2000, -0.9000, -1.2000],\n",
      "          [-0.6000, -0.6000, -1.2000],\n",
      "          [ 1.8000,  2.4000,  1.2000]]]], device='cuda:0',\n",
      "       grad_fn=<_pqBackward>)\n",
      "tensor([[[[ 0.9000]],\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[-1.2000]]],\n",
      "\n",
      "\n",
      "        [[[-0.3000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[-0.3000]]],\n",
      "\n",
      "\n",
      "        [[[-0.0000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[ 0.9000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.3000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         [[ 1.8000]]],\n",
      "\n",
      "\n",
      "        [[[-0.0000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 0.6000]]],\n",
      "\n",
      "\n",
      "        [[[-0.3000]],\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         [[ 1.2000]]]], device='cuda:0', grad_fn=<_pqBackward>)\n",
      "tensor([[[[-1.2000, -1.2000, -0.9000],\n",
      "          [-1.2000, -1.2000, -0.9000],\n",
      "          [-1.2000, -1.2000, -0.6000]],\n",
      "\n",
      "         [[-0.6000, -0.3000, -0.9000],\n",
      "          [-0.9000, -0.9000, -0.9000],\n",
      "          [ 0.3000,  0.0000, -0.3000]],\n",
      "\n",
      "         [[-1.2000, -1.2000, -1.2000],\n",
      "          [ 0.9000,  0.9000,  0.6000],\n",
      "          [ 0.3000,  0.0000,  0.6000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3000, -0.0000,  0.6000],\n",
      "          [ 0.0000, -0.3000,  0.3000],\n",
      "          [-0.0000,  0.0000,  0.3000]],\n",
      "\n",
      "         [[ 0.6000,  1.2000,  1.2000],\n",
      "          [ 1.2000,  1.8000,  0.9000],\n",
      "          [-0.3000, -0.3000, -1.2000]],\n",
      "\n",
      "         [[-0.6000, -0.0000,  0.3000],\n",
      "          [-0.6000, -0.6000, -0.6000],\n",
      "          [ 0.3000,  0.3000,  0.6000]]],\n",
      "\n",
      "\n",
      "        [[[-0.3000,  2.4000, -0.9000],\n",
      "          [-0.9000,  3.0000, -0.3000],\n",
      "          [-0.9000,  3.0000, -0.6000]],\n",
      "\n",
      "         [[-0.3000, -0.3000,  0.3000],\n",
      "          [ 0.0000, -1.2000,  0.3000],\n",
      "          [-0.6000, -2.4000, -1.2000]],\n",
      "\n",
      "         [[-3.0000, -0.9000, -3.0000],\n",
      "          [-0.9000,  2.4000, -0.9000],\n",
      "          [-0.9000,  0.0000, -1.2000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.9000,  0.3000,  0.9000],\n",
      "          [ 0.6000,  0.3000,  0.3000],\n",
      "          [ 0.3000,  0.6000, -0.3000]],\n",
      "\n",
      "         [[-0.6000,  0.3000, -0.3000],\n",
      "          [-1.2000, -1.8000, -0.6000],\n",
      "          [-0.9000,  0.3000, -0.6000]],\n",
      "\n",
      "         [[ 0.6000, -0.6000, -0.3000],\n",
      "          [-0.9000,  0.6000, -0.3000],\n",
      "          [-0.9000, -0.6000, -1.2000]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2000,  1.2000,  1.2000],\n",
      "          [ 1.2000,  1.8000,  1.8000],\n",
      "          [ 0.6000,  0.3000,  0.3000]],\n",
      "\n",
      "         [[-0.0000,  0.0000,  0.3000],\n",
      "          [-0.0000, -0.0000,  0.0000],\n",
      "          [-0.6000, -0.3000, -0.6000]],\n",
      "\n",
      "         [[-0.0000,  0.0000,  0.6000],\n",
      "          [-0.3000, -0.0000, -0.3000],\n",
      "          [-0.0000, -0.3000, -0.3000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3000,  0.3000,  0.6000],\n",
      "          [-0.6000, -0.6000, -0.0000],\n",
      "          [-0.3000,  0.3000, -0.0000]],\n",
      "\n",
      "         [[-0.6000, -0.6000, -0.6000],\n",
      "          [-0.3000, -0.9000,  0.6000],\n",
      "          [ 0.3000, -0.0000,  0.0000]],\n",
      "\n",
      "         [[-0.3000, -0.3000, -0.6000],\n",
      "          [-1.2000, -0.6000, -1.2000],\n",
      "          [-0.3000,  0.6000,  0.0000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-1.2000, -1.8000, -1.2000],\n",
      "          [ 0.6000,  0.3000,  0.0000],\n",
      "          [ 0.0000, -0.3000,  0.3000]],\n",
      "\n",
      "         [[-1.2000, -0.6000, -1.2000],\n",
      "          [-1.2000, -0.9000, -1.2000],\n",
      "          [-0.6000, -0.6000, -0.9000]],\n",
      "\n",
      "         [[-0.9000, -0.9000, -1.2000],\n",
      "          [ 0.9000,  1.8000,  0.9000],\n",
      "          [-0.0000,  0.3000,  0.3000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.2000, -0.0000, -0.9000],\n",
      "          [-0.9000, -0.3000, -1.2000],\n",
      "          [ 0.9000,  1.2000,  0.6000]],\n",
      "\n",
      "         [[-0.6000,  0.3000,  0.3000],\n",
      "          [-1.8000, -1.2000, -1.8000],\n",
      "          [-0.9000, -1.8000, -1.8000]],\n",
      "\n",
      "         [[ 0.6000,  0.3000,  0.3000],\n",
      "          [ 1.8000,  1.8000,  1.8000],\n",
      "          [ 3.0000,  3.0000,  3.0000]]],\n",
      "\n",
      "\n",
      "        [[[-1.8000, -2.4000, -1.8000],\n",
      "          [-0.9000, -0.3000, -1.8000],\n",
      "          [-0.6000,  0.9000, -1.2000]],\n",
      "\n",
      "         [[ 0.6000,  0.9000,  0.3000],\n",
      "          [-1.2000,  0.0000, -0.6000],\n",
      "          [ 0.0000,  0.9000, -0.9000]],\n",
      "\n",
      "         [[ 0.9000,  0.0000, -0.0000],\n",
      "          [ 0.0000,  0.6000, -0.0000],\n",
      "          [-0.6000, -0.3000, -0.9000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.9000, -1.2000, -0.0000],\n",
      "          [-1.2000, -0.6000, -0.6000],\n",
      "          [-0.3000,  0.0000, -0.3000]],\n",
      "\n",
      "         [[-0.6000,  0.3000, -2.4000],\n",
      "          [ 0.9000, -0.6000, -0.3000],\n",
      "          [-1.8000, -1.8000, -1.2000]],\n",
      "\n",
      "         [[ 0.3000, -0.9000,  0.0000],\n",
      "          [-0.3000,  0.3000, -0.3000],\n",
      "          [-0.9000, -0.9000, -0.9000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3000,  0.0000,  0.9000],\n",
      "          [ 0.6000, -0.3000,  1.2000],\n",
      "          [ 0.9000,  0.9000,  1.2000]],\n",
      "\n",
      "         [[ 2.4000,  0.9000,  2.4000],\n",
      "          [ 1.2000,  0.3000,  1.2000],\n",
      "          [-0.6000, -1.2000, -0.6000]],\n",
      "\n",
      "         [[-0.0000, -0.0000, -0.3000],\n",
      "          [ 0.0000,  0.3000, -0.3000],\n",
      "          [ 0.6000, -0.0000, -0.9000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3000,  0.3000, -0.3000],\n",
      "          [-0.0000,  0.3000, -0.9000],\n",
      "          [ 0.0000,  0.3000, -0.3000]],\n",
      "\n",
      "         [[ 0.0000, -0.6000, -1.2000],\n",
      "          [-0.3000, -0.9000, -1.8000],\n",
      "          [-0.6000, -0.9000, -1.8000]],\n",
      "\n",
      "         [[ 0.3000,  0.6000, -0.0000],\n",
      "          [-0.0000, -0.3000, -1.2000],\n",
      "          [ 0.3000, -0.6000, -1.8000]]]], device='cuda:0',\n",
      "       grad_fn=<_pqBackward>)\n",
      "tensor([[[[ 0.0000]],\n",
      "\n",
      "         [[ 1.8000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[-0.0000]]],\n",
      "\n",
      "\n",
      "        [[[-0.0000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[ 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000]],\n",
      "\n",
      "         [[-1.8000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.8000]],\n",
      "\n",
      "         [[ 2.4000]],\n",
      "\n",
      "         [[ 0.6000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[-0.3000]]],\n",
      "\n",
      "\n",
      "        [[[-0.6000]],\n",
      "\n",
      "         [[ 1.8000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[ 0.6000]]],\n",
      "\n",
      "\n",
      "        [[[-0.6000]],\n",
      "\n",
      "         [[ 1.8000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[ 0.0000]]]], device='cuda:0', grad_fn=<_pqBackward>)\n",
      "tensor([[[[ 1.2000,  0.6000,  0.3000],\n",
      "          [-0.0000, -0.6000, -0.9000],\n",
      "          [-0.3000, -0.9000, -0.6000]],\n",
      "\n",
      "         [[ 0.3000, -0.3000,  0.3000],\n",
      "          [-0.6000, -0.9000, -0.6000],\n",
      "          [-0.6000,  0.0000,  0.3000]],\n",
      "\n",
      "         [[-0.6000, -0.9000, -0.9000],\n",
      "          [-0.3000,  0.3000, -0.6000],\n",
      "          [-0.6000,  0.6000,  0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3000, -0.3000, -0.0000],\n",
      "          [ 0.3000,  0.6000,  0.3000],\n",
      "          [-0.0000,  0.3000,  0.0000]],\n",
      "\n",
      "         [[-0.6000, -1.2000, -1.2000],\n",
      "          [-0.9000, -0.6000, -0.9000],\n",
      "          [-0.0000,  0.6000,  0.6000]],\n",
      "\n",
      "         [[ 0.3000, -0.6000,  0.3000],\n",
      "          [-0.9000, -0.6000, -0.6000],\n",
      "          [-1.2000, -0.9000, -0.9000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3000,  0.6000,  0.9000],\n",
      "          [ 0.6000,  0.9000,  0.6000],\n",
      "          [-0.0000,  0.3000, -0.0000]],\n",
      "\n",
      "         [[-0.6000, -0.6000, -0.6000],\n",
      "          [-0.3000, -0.6000, -0.3000],\n",
      "          [-0.0000,  0.0000, -0.3000]],\n",
      "\n",
      "         [[-0.6000, -1.2000, -0.6000],\n",
      "          [-0.0000, -0.3000, -0.6000],\n",
      "          [-0.6000, -0.3000,  0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.6000, -0.9000, -1.2000],\n",
      "          [-0.3000, -0.3000, -0.3000],\n",
      "          [-0.3000,  0.3000, -0.0000]],\n",
      "\n",
      "         [[-0.6000, -0.6000, -0.9000],\n",
      "          [-0.6000, -0.6000, -0.6000],\n",
      "          [-0.3000, -0.0000, -0.3000]],\n",
      "\n",
      "         [[-0.6000,  0.3000,  0.6000],\n",
      "          [ 0.0000,  0.3000,  0.3000],\n",
      "          [-0.9000, -0.3000,  0.3000]]],\n",
      "\n",
      "\n",
      "        [[[ 3.0000,  3.0000,  3.0000],\n",
      "          [ 1.2000,  0.6000,  0.9000],\n",
      "          [-0.3000, -0.6000, -0.3000]],\n",
      "\n",
      "         [[-0.9000, -0.9000, -0.9000],\n",
      "          [-0.3000, -0.0000, -0.3000],\n",
      "          [-0.3000, -0.3000, -0.3000]],\n",
      "\n",
      "         [[-0.6000, -1.8000, -1.2000],\n",
      "          [-0.3000, -0.3000, -0.3000],\n",
      "          [-0.3000,  0.0000, -0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.9000,  0.6000,  0.3000],\n",
      "          [ 0.9000,  1.2000,  0.9000],\n",
      "          [-0.3000,  0.3000, -0.0000]],\n",
      "\n",
      "         [[-0.3000, -0.0000, -0.3000],\n",
      "          [-0.0000,  0.3000, -0.3000],\n",
      "          [ 0.0000,  0.3000, -0.0000]],\n",
      "\n",
      "         [[ 3.0000,  3.0000,  3.0000],\n",
      "          [ 3.0000,  0.6000,  1.8000],\n",
      "          [-0.0000,  0.0000, -0.0000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0000, -0.0000, -0.3000],\n",
      "          [-0.6000, -0.3000, -0.9000],\n",
      "          [-0.6000, -0.9000, -1.2000]],\n",
      "\n",
      "         [[ 1.2000,  1.2000,  2.4000],\n",
      "          [-0.3000, -0.3000,  0.6000],\n",
      "          [-1.2000, -0.9000, -0.6000]],\n",
      "\n",
      "         [[-0.6000,  0.0000, -0.3000],\n",
      "          [-1.2000, -1.8000, -1.8000],\n",
      "          [-0.6000, -0.9000, -1.2000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.8000,  1.2000,  1.8000],\n",
      "          [ 1.8000,  1.8000,  2.4000],\n",
      "          [-0.0000,  0.0000, -0.0000]],\n",
      "\n",
      "         [[ 1.8000,  1.8000,  2.4000],\n",
      "          [ 2.4000,  1.8000,  2.4000],\n",
      "          [ 0.6000,  0.6000,  0.9000]],\n",
      "\n",
      "         [[-0.0000, -0.0000, -0.3000],\n",
      "          [-1.8000, -1.8000, -1.8000],\n",
      "          [-1.2000, -1.2000, -1.2000]]],\n",
      "\n",
      "\n",
      "        [[[-2.4000, -2.4000, -1.8000],\n",
      "          [-0.9000, -0.6000, -0.6000],\n",
      "          [-0.6000, -0.3000, -0.3000]],\n",
      "\n",
      "         [[-1.2000, -0.9000, -1.2000],\n",
      "          [-0.9000, -0.3000, -0.3000],\n",
      "          [-0.9000,  0.3000, -0.3000]],\n",
      "\n",
      "         [[ 0.3000,  1.2000,  0.6000],\n",
      "          [-0.6000, -0.3000, -0.6000],\n",
      "          [-1.2000, -0.6000, -0.3000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.3000],\n",
      "          [ 0.0000,  0.3000,  0.0000],\n",
      "          [-0.0000,  0.3000,  0.3000]],\n",
      "\n",
      "         [[-0.9000, -0.6000,  0.3000],\n",
      "          [ 1.2000,  1.8000,  1.8000],\n",
      "          [ 1.2000,  1.2000,  1.2000]],\n",
      "\n",
      "         [[ 0.9000,  1.8000,  1.8000],\n",
      "          [ 0.3000, -0.6000, -0.6000],\n",
      "          [ 0.6000,  0.0000,  0.9000]]],\n",
      "\n",
      "\n",
      "        [[[-0.3000,  0.6000, -0.3000],\n",
      "          [-1.2000, -1.2000, -0.6000],\n",
      "          [-0.6000, -0.9000, -0.9000]],\n",
      "\n",
      "         [[ 1.2000,  0.6000,  1.2000],\n",
      "          [ 1.2000,  1.2000,  1.2000],\n",
      "          [-0.0000,  0.3000, -0.3000]],\n",
      "\n",
      "         [[-1.2000, -0.9000, -0.6000],\n",
      "          [-0.6000, -0.3000,  0.0000],\n",
      "          [-0.3000, -0.3000, -0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.6000, -1.2000, -0.6000],\n",
      "          [ 0.9000,  0.6000,  1.2000],\n",
      "          [ 0.6000,  0.6000,  0.0000]],\n",
      "\n",
      "         [[ 2.4000,  1.8000,  3.0000],\n",
      "          [ 0.9000,  1.2000,  2.4000],\n",
      "          [-1.8000, -1.2000, -1.2000]],\n",
      "\n",
      "         [[-1.8000, -0.9000, -1.8000],\n",
      "          [-0.9000, -0.6000, -1.2000],\n",
      "          [-0.9000, -0.9000, -0.9000]]]], device='cuda:0',\n",
      "       grad_fn=<_pqBackward>)\n",
      "tensor([[[[ 0.9000]],\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 0.3000]]],\n",
      "\n",
      "\n",
      "        [[[-1.2000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[-0.6000]]],\n",
      "\n",
      "\n",
      "        [[[-0.3000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[-0.3000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.3000]],\n",
      "\n",
      "         [[ 1.8000]],\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 0.9000]]],\n",
      "\n",
      "\n",
      "        [[[-0.3000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.9000]]],\n",
      "\n",
      "\n",
      "        [[[-0.6000]],\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[-0.6000]]]], device='cuda:0', grad_fn=<_pqBackward>)\n",
      "tensor([[[[ 0.9000,  1.8000,  1.8000],\n",
      "          [ 0.3000,  0.6000,  0.3000],\n",
      "          [-0.3000, -0.6000, -0.6000]],\n",
      "\n",
      "         [[-0.3000, -0.6000, -0.3000],\n",
      "          [-0.0000,  1.8000,  0.6000],\n",
      "          [ 0.6000,  2.4000,  1.2000]],\n",
      "\n",
      "         [[ 0.3000,  0.3000, -0.0000],\n",
      "          [-0.0000, -0.6000, -0.6000],\n",
      "          [-1.8000, -1.8000, -0.9000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3000, -0.3000, -0.6000],\n",
      "          [-1.2000, -0.3000, -1.2000],\n",
      "          [-1.8000, -0.9000, -1.2000]],\n",
      "\n",
      "         [[ 0.0000,  0.6000,  0.0000],\n",
      "          [-0.6000, -0.3000, -0.6000],\n",
      "          [-0.6000,  0.6000, -0.3000]],\n",
      "\n",
      "         [[-0.6000,  0.3000, -0.0000],\n",
      "          [ 0.0000,  0.3000, -0.0000],\n",
      "          [-0.9000, -0.0000, -0.9000]]],\n",
      "\n",
      "\n",
      "        [[[-0.0000, -0.6000, -0.3000],\n",
      "          [ 1.2000,  0.9000,  1.2000],\n",
      "          [ 3.0000,  3.0000,  3.0000]],\n",
      "\n",
      "         [[ 1.2000,  1.8000,  0.9000],\n",
      "          [ 1.2000,  1.2000,  0.9000],\n",
      "          [ 0.9000,  0.6000,  0.9000]],\n",
      "\n",
      "         [[-0.6000, -1.2000, -0.6000],\n",
      "          [-0.3000, -0.9000, -0.9000],\n",
      "          [ 0.6000, -0.0000, -0.3000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.2000, -0.6000, -0.9000],\n",
      "          [-2.4000, -1.8000, -1.8000],\n",
      "          [-0.3000, -0.0000, -0.6000]],\n",
      "\n",
      "         [[-1.2000, -0.9000, -1.2000],\n",
      "          [-0.9000, -0.6000, -0.9000],\n",
      "          [ 0.3000,  0.3000,  0.3000]],\n",
      "\n",
      "         [[-1.2000, -0.6000, -0.6000],\n",
      "          [ 0.3000,  0.6000, -0.0000],\n",
      "          [ 0.3000,  0.3000,  0.3000]]],\n",
      "\n",
      "\n",
      "        [[[-0.9000, -0.9000, -0.3000],\n",
      "          [-0.3000, -0.9000, -0.6000],\n",
      "          [ 0.3000,  0.3000,  0.3000]],\n",
      "\n",
      "         [[ 0.9000,  0.6000,  0.6000],\n",
      "          [ 0.3000, -0.3000,  0.0000],\n",
      "          [ 1.2000,  1.2000,  1.2000]],\n",
      "\n",
      "         [[ 0.9000,  1.8000,  1.2000],\n",
      "          [ 1.2000,  2.4000,  1.8000],\n",
      "          [ 0.9000,  2.4000,  1.2000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3000, -0.6000, -0.3000],\n",
      "          [-0.3000, -0.6000, -0.6000],\n",
      "          [-0.0000, -0.3000, -0.3000]],\n",
      "\n",
      "         [[-0.0000, -0.0000, -0.3000],\n",
      "          [-0.0000,  0.0000, -0.0000],\n",
      "          [ 0.0000,  0.3000,  0.0000]],\n",
      "\n",
      "         [[ 0.6000,  0.9000,  0.6000],\n",
      "          [ 1.2000,  1.2000,  1.2000],\n",
      "          [ 0.6000,  0.9000,  1.2000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.3000,  0.9000,  0.6000],\n",
      "          [-0.3000, -0.9000, -0.9000],\n",
      "          [ 0.6000, -0.0000,  0.6000]],\n",
      "\n",
      "         [[-0.6000, -0.9000, -0.9000],\n",
      "          [-1.8000, -1.8000, -0.9000],\n",
      "          [-0.9000, -0.9000, -0.6000]],\n",
      "\n",
      "         [[ 0.9000,  0.3000,  0.3000],\n",
      "          [ 0.0000,  0.0000,  0.3000],\n",
      "          [ 0.3000,  0.3000, -0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0000, -0.3000,  0.0000],\n",
      "          [-0.6000, -0.9000, -0.9000],\n",
      "          [-1.2000, -0.9000, -0.6000]],\n",
      "\n",
      "         [[ 0.6000,  1.2000,  0.6000],\n",
      "          [ 1.2000,  1.8000,  1.8000],\n",
      "          [ 1.2000,  2.4000,  1.2000]],\n",
      "\n",
      "         [[ 0.6000,  0.6000,  0.6000],\n",
      "          [ 0.6000,  0.9000,  0.9000],\n",
      "          [ 0.9000,  1.2000,  0.9000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3000,  0.3000,  0.6000],\n",
      "          [-0.9000, -1.2000, -0.9000],\n",
      "          [-1.8000, -1.8000, -1.2000]],\n",
      "\n",
      "         [[ 1.2000,  1.2000,  1.2000],\n",
      "          [ 2.4000,  2.4000,  2.4000],\n",
      "          [ 0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[ 1.2000,  1.8000,  1.2000],\n",
      "          [ 1.8000,  3.0000,  1.8000],\n",
      "          [ 0.3000,  1.2000,  0.3000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3000, -0.0000, -0.0000],\n",
      "          [ 0.0000, -0.3000, -0.3000],\n",
      "          [-0.9000, -0.9000, -0.9000]],\n",
      "\n",
      "         [[ 0.3000,  0.6000,  0.6000],\n",
      "          [ 0.6000,  0.9000,  0.9000],\n",
      "          [ 0.6000,  0.9000,  0.3000]],\n",
      "\n",
      "         [[ 0.6000,  0.9000,  0.6000],\n",
      "          [ 0.6000,  0.6000,  0.6000],\n",
      "          [ 0.3000,  0.3000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[-0.3000, -0.6000, -0.6000],\n",
      "          [-0.3000, -0.9000, -1.8000],\n",
      "          [ 0.9000,  0.3000, -0.3000]],\n",
      "\n",
      "         [[ 0.6000,  0.6000, -0.3000],\n",
      "          [ 0.9000,  0.3000, -0.6000],\n",
      "          [ 1.2000,  0.9000,  0.9000]],\n",
      "\n",
      "         [[ 0.3000,  0.0000, -0.3000],\n",
      "          [-0.3000,  0.0000,  0.3000],\n",
      "          [-0.3000,  0.3000,  0.6000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.9000, -0.9000, -0.3000],\n",
      "          [-1.2000, -0.9000, -0.3000],\n",
      "          [-1.2000, -0.9000, -0.6000]],\n",
      "\n",
      "         [[-0.9000, -0.6000, -0.6000],\n",
      "          [-0.3000, -0.0000, -0.6000],\n",
      "          [-0.3000, -0.0000, -0.3000]],\n",
      "\n",
      "         [[-0.0000, -0.0000, -0.3000],\n",
      "          [ 0.6000,  0.6000, -0.3000],\n",
      "          [ 0.9000,  0.9000,  0.6000]]]], device='cuda:0',\n",
      "       grad_fn=<_pqBackward>)\n",
      "tensor([[[[-0.3000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[ 0.6000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         [[-2.4000]],\n",
      "\n",
      "         [[-1.8000]]],\n",
      "\n",
      "\n",
      "        [[[-0.3000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[-1.2000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.3000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[-1.8000]],\n",
      "\n",
      "         [[ 0.3000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         [[ 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[-0.3000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 1.8000]]]], device='cuda:0', grad_fn=<_pqBackward>)\n",
      "tensor([[[[-0.0000, -0.0000,  0.3000],\n",
      "          [-0.6000, -0.3000,  0.0000],\n",
      "          [-0.3000, -0.9000, -0.0000]],\n",
      "\n",
      "         [[-0.3000, -0.6000, -0.3000],\n",
      "          [-0.0000, -0.6000, -0.0000],\n",
      "          [-0.3000, -0.6000, -0.9000]],\n",
      "\n",
      "         [[-0.6000, -0.3000, -0.3000],\n",
      "          [-0.6000, -0.6000, -0.6000],\n",
      "          [-0.9000, -0.9000, -0.6000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.9000, -0.9000, -0.9000],\n",
      "          [-1.2000, -0.9000, -0.6000],\n",
      "          [-0.6000, -0.6000, -0.3000]],\n",
      "\n",
      "         [[ 0.0000, -0.0000, -0.3000],\n",
      "          [ 0.0000, -0.6000, -0.6000],\n",
      "          [-1.2000, -1.8000, -1.2000]],\n",
      "\n",
      "         [[-0.0000, -0.3000, -0.6000],\n",
      "          [-0.3000, -0.3000, -0.9000],\n",
      "          [-0.3000, -0.6000, -0.9000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.9000, -0.9000,  0.3000],\n",
      "          [ 0.0000, -0.3000,  0.3000],\n",
      "          [-0.3000, -0.9000, -0.3000]],\n",
      "\n",
      "         [[-0.6000, -0.6000, -0.3000],\n",
      "          [-1.2000, -0.9000, -0.9000],\n",
      "          [-0.6000, -1.2000, -1.2000]],\n",
      "\n",
      "         [[ 0.3000, -0.0000,  0.6000],\n",
      "          [-1.2000, -1.2000, -0.0000],\n",
      "          [-1.2000, -1.8000, -0.9000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.9000, -0.0000, -0.9000],\n",
      "          [-1.8000, -1.2000, -1.2000],\n",
      "          [-1.2000, -1.2000, -1.2000]],\n",
      "\n",
      "         [[ 1.8000,  2.4000,  2.4000],\n",
      "          [ 0.9000,  1.2000,  0.9000],\n",
      "          [-1.8000, -1.2000, -1.8000]],\n",
      "\n",
      "         [[-0.6000, -0.3000, -0.3000],\n",
      "          [-0.0000, -0.0000, -0.9000],\n",
      "          [-0.9000, -0.6000, -0.6000]]],\n",
      "\n",
      "\n",
      "        [[[-0.9000, -0.6000, -1.2000],\n",
      "          [-0.0000,  0.6000,  0.6000],\n",
      "          [ 2.4000,  1.8000,  2.4000]],\n",
      "\n",
      "         [[-0.3000,  0.3000,  0.6000],\n",
      "          [-0.9000, -1.2000, -0.9000],\n",
      "          [-0.9000, -1.2000, -1.2000]],\n",
      "\n",
      "         [[-1.2000, -1.8000, -1.2000],\n",
      "          [-0.6000, -0.3000, -0.6000],\n",
      "          [ 1.2000,  1.2000,  1.2000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.2000,  1.8000,  0.9000],\n",
      "          [ 1.2000,  1.2000,  0.3000],\n",
      "          [-0.6000, -0.9000, -1.8000]],\n",
      "\n",
      "         [[ 0.6000,  0.9000,  0.9000],\n",
      "          [ 0.3000,  0.9000,  0.3000],\n",
      "          [-0.6000, -0.6000, -0.9000]],\n",
      "\n",
      "         [[ 0.6000,  0.6000,  0.0000],\n",
      "          [ 1.2000,  1.8000,  1.2000],\n",
      "          [ 1.2000,  1.8000,  0.9000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.3000, -0.3000, -0.3000],\n",
      "          [-1.8000, -0.6000, -0.9000],\n",
      "          [-1.2000, -0.6000, -0.9000]],\n",
      "\n",
      "         [[ 3.0000,  3.0000,  3.0000],\n",
      "          [ 1.8000,  1.8000,  0.6000],\n",
      "          [-0.3000, -0.6000, -1.8000]],\n",
      "\n",
      "         [[ 0.3000,  0.9000, -0.3000],\n",
      "          [ 1.8000,  2.4000,  1.2000],\n",
      "          [ 0.3000,  1.2000,  0.6000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0000, -0.3000, -0.0000],\n",
      "          [ 1.2000,  0.6000,  0.6000],\n",
      "          [ 0.9000,  1.2000,  0.9000]],\n",
      "\n",
      "         [[ 1.2000,  2.4000,  0.0000],\n",
      "          [-0.6000,  0.9000, -0.6000],\n",
      "          [-0.9000, -0.3000, -0.9000]],\n",
      "\n",
      "         [[-0.3000,  0.0000, -0.9000],\n",
      "          [-0.0000,  0.0000, -0.9000],\n",
      "          [-0.3000, -0.3000, -0.3000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.6000,  0.6000,  0.0000],\n",
      "          [ 0.6000,  0.3000,  0.3000],\n",
      "          [-0.6000, -0.6000, -0.6000]],\n",
      "\n",
      "         [[-0.0000,  0.0000, -0.3000],\n",
      "          [ 1.2000,  0.6000,  0.3000],\n",
      "          [ 0.6000,  0.6000,  0.6000]],\n",
      "\n",
      "         [[ 0.3000, -0.3000,  0.0000],\n",
      "          [ 0.6000, -0.0000,  0.0000],\n",
      "          [ 0.3000, -0.0000,  0.3000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3000, -0.9000, -1.2000],\n",
      "          [-0.3000, -0.9000, -0.9000],\n",
      "          [-0.3000, -0.6000, -0.6000]],\n",
      "\n",
      "         [[ 0.9000,  0.9000,  0.9000],\n",
      "          [ 1.2000,  1.2000,  0.6000],\n",
      "          [ 1.2000,  0.6000,  0.9000]],\n",
      "\n",
      "         [[-0.0000,  0.0000, -0.0000],\n",
      "          [-0.9000, -0.9000, -0.3000],\n",
      "          [-0.9000, -1.2000, -1.2000]]],\n",
      "\n",
      "\n",
      "        [[[-0.0000, -1.8000, -0.9000],\n",
      "          [ 0.3000, -1.8000, -0.6000],\n",
      "          [ 0.3000, -1.2000,  0.3000]],\n",
      "\n",
      "         [[ 0.0000,  0.3000,  1.2000],\n",
      "          [ 0.6000,  0.6000,  1.2000],\n",
      "          [ 0.9000,  1.2000,  0.9000]],\n",
      "\n",
      "         [[-0.3000, -0.3000, -0.6000],\n",
      "          [-1.8000, -0.9000, -0.9000],\n",
      "          [-1.8000, -1.2000, -1.2000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.8000, -0.6000, -0.6000],\n",
      "          [-1.8000, -1.8000, -0.9000],\n",
      "          [-0.0000,  0.0000, -0.3000]],\n",
      "\n",
      "         [[ 0.3000,  1.2000,  0.3000],\n",
      "          [-1.2000, -0.0000, -1.2000],\n",
      "          [-0.3000,  0.3000, -0.6000]],\n",
      "\n",
      "         [[-1.2000, -0.6000, -1.2000],\n",
      "          [-1.2000, -1.2000, -1.2000],\n",
      "          [-0.6000, -0.6000, -0.6000]]]], device='cuda:0',\n",
      "       grad_fn=<_pqBackward>)\n",
      "tensor([[[[-0.0000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.8000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[ 0.6000]]],\n",
      "\n",
      "\n",
      "        [[[-0.9000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[-2.4000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[ 0.9000]]],\n",
      "\n",
      "\n",
      "        [[[-0.3000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.4000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[-0.9000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.9000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[-1.8000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.6000]]],\n",
      "\n",
      "\n",
      "        [[[-0.0000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[-0.6000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.8000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 1.8000]]]], device='cuda:0', grad_fn=<_pqBackward>)\n",
      "tensor([[[[ 0.6000,  1.2000,  0.9000],\n",
      "          [ 0.6000,  1.2000,  0.3000],\n",
      "          [-0.6000, -0.3000, -0.6000]],\n",
      "\n",
      "         [[-0.6000, -0.6000, -0.6000],\n",
      "          [-1.2000, -0.9000, -1.2000],\n",
      "          [-1.2000, -1.2000, -1.8000]],\n",
      "\n",
      "         [[ 1.8000,  0.9000,  1.2000],\n",
      "          [ 1.8000,  1.2000,  1.2000],\n",
      "          [-1.8000, -1.8000, -1.8000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.9000, -1.2000, -0.6000],\n",
      "          [-0.9000, -1.2000, -0.9000],\n",
      "          [-0.3000, -0.0000, -0.0000]],\n",
      "\n",
      "         [[-1.8000, -1.8000, -1.8000],\n",
      "          [ 0.3000,  0.0000,  0.3000],\n",
      "          [ 0.3000,  0.3000,  0.3000]],\n",
      "\n",
      "         [[ 0.6000,  0.6000,  0.6000],\n",
      "          [ 0.6000,  0.9000,  0.3000],\n",
      "          [ 0.6000,  1.2000,  0.9000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.6000,  0.6000,  0.0000],\n",
      "          [-0.6000, -0.3000, -0.3000],\n",
      "          [-0.9000, -0.9000, -0.9000]],\n",
      "\n",
      "         [[-0.9000, -0.9000, -0.9000],\n",
      "          [-1.8000, -1.8000, -1.8000],\n",
      "          [-2.4000, -2.4000, -2.4000]],\n",
      "\n",
      "         [[-1.2000, -1.2000, -1.2000],\n",
      "          [-1.2000, -1.2000, -1.2000],\n",
      "          [-1.2000, -1.2000, -1.2000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3000, -0.6000, -0.3000],\n",
      "          [-0.6000, -0.6000, -0.3000],\n",
      "          [-0.6000, -0.3000, -0.0000]],\n",
      "\n",
      "         [[ 0.3000,  0.6000,  0.3000],\n",
      "          [ 0.9000,  0.3000,  0.6000],\n",
      "          [ 0.6000,  0.9000,  0.3000]],\n",
      "\n",
      "         [[ 0.9000,  0.9000,  0.6000],\n",
      "          [ 0.6000,  1.2000,  0.6000],\n",
      "          [-0.0000, -0.0000, -0.3000]]],\n",
      "\n",
      "\n",
      "        [[[-0.0000,  0.3000,  0.3000],\n",
      "          [-0.3000, -0.0000, -0.0000],\n",
      "          [-0.3000, -0.3000, -0.0000]],\n",
      "\n",
      "         [[-0.6000, -0.3000, -0.6000],\n",
      "          [-0.3000, -0.3000, -0.3000],\n",
      "          [-0.9000, -0.6000, -0.3000]],\n",
      "\n",
      "         [[-0.0000, -0.0000, -0.6000],\n",
      "          [-0.6000, -0.6000, -0.6000],\n",
      "          [-0.9000, -0.9000, -0.6000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3000,  0.9000,  0.0000],\n",
      "          [ 0.6000,  0.3000, -0.0000],\n",
      "          [ 0.6000,  0.3000,  0.3000]],\n",
      "\n",
      "         [[ 0.0000,  0.0000, -0.3000],\n",
      "          [ 0.0000,  0.0000,  0.3000],\n",
      "          [ 0.0000,  0.0000,  0.3000]],\n",
      "\n",
      "         [[-0.3000,  0.3000,  0.0000],\n",
      "          [-0.0000,  0.0000, -0.3000],\n",
      "          [-0.3000, -0.3000, -0.6000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.3000,  1.2000,  0.6000],\n",
      "          [-0.3000,  0.3000, -0.0000],\n",
      "          [-0.9000, -0.6000, -0.3000]],\n",
      "\n",
      "         [[-1.2000, -1.2000, -0.9000],\n",
      "          [-1.2000, -1.8000, -1.2000],\n",
      "          [-1.8000, -1.8000, -1.8000]],\n",
      "\n",
      "         [[-0.9000, -0.6000, -0.3000],\n",
      "          [-1.8000, -1.8000, -1.8000],\n",
      "          [-1.2000, -1.8000, -1.8000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.9000,  0.9000,  0.6000],\n",
      "          [ 0.6000,  0.9000,  0.3000],\n",
      "          [ 1.2000,  1.8000,  1.2000]],\n",
      "\n",
      "         [[ 0.3000,  0.3000,  0.3000],\n",
      "          [ 0.3000,  0.0000,  0.0000],\n",
      "          [-0.3000, -0.3000, -0.0000]],\n",
      "\n",
      "         [[-0.3000, -0.3000, -0.3000],\n",
      "          [ 0.6000,  1.2000,  0.6000],\n",
      "          [ 0.3000,  1.2000,  0.6000]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2000,  1.2000,  0.6000],\n",
      "          [ 0.3000,  0.6000, -0.3000],\n",
      "          [-0.3000, -0.6000, -0.3000]],\n",
      "\n",
      "         [[-1.2000, -0.6000, -1.2000],\n",
      "          [-1.8000, -1.2000, -1.8000],\n",
      "          [-2.4000, -2.4000, -3.0000]],\n",
      "\n",
      "         [[ 0.0000, -0.3000, -0.6000],\n",
      "          [ 0.6000,  0.6000,  0.3000],\n",
      "          [-0.3000, -0.3000, -0.6000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.9000, -1.2000, -0.9000],\n",
      "          [-0.9000, -1.2000, -0.9000],\n",
      "          [-0.9000, -0.6000, -0.6000]],\n",
      "\n",
      "         [[ 2.4000,  1.8000,  1.8000],\n",
      "          [ 2.4000,  2.4000,  2.4000],\n",
      "          [ 1.8000,  2.4000,  0.9000]],\n",
      "\n",
      "         [[ 1.2000,  1.8000,  1.8000],\n",
      "          [ 0.9000,  1.2000,  0.6000],\n",
      "          [ 0.0000,  0.3000,  0.3000]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2000,  1.2000,  0.9000],\n",
      "          [ 0.9000,  1.2000,  0.9000],\n",
      "          [-1.2000, -0.3000, -0.6000]],\n",
      "\n",
      "         [[-1.2000, -1.2000, -0.9000],\n",
      "          [-1.2000, -0.6000, -0.9000],\n",
      "          [-2.4000, -2.4000, -2.4000]],\n",
      "\n",
      "         [[ 2.4000,  1.8000,  2.4000],\n",
      "          [ 1.8000,  1.2000,  1.2000],\n",
      "          [-1.2000, -1.2000, -1.2000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0000, -0.3000,  0.0000],\n",
      "          [ 0.0000, -0.3000,  0.3000],\n",
      "          [-0.0000, -0.0000, -0.3000]],\n",
      "\n",
      "         [[-1.8000, -1.2000, -1.8000],\n",
      "          [-0.0000,  0.0000, -0.3000],\n",
      "          [ 0.9000,  0.3000,  1.2000]],\n",
      "\n",
      "         [[ 0.3000, -0.3000, -0.3000],\n",
      "          [-0.0000,  0.0000, -0.0000],\n",
      "          [ 0.0000,  0.6000,  0.3000]]]], device='cuda:0',\n",
      "       grad_fn=<_pqBackward>)\n"
     ]
    }
   ],
   "source": [
    "bit = 4\n",
    "for m in model_quant.modules():\n",
    "    if isinstance(m, QuantConv2d):\n",
    "        m.weight_quant = weight_quantize_fn(w_bit=bit)\n",
    "        print(m.weight_quant(m.weight))\n",
    "        m.act_grid = build_power_value(bit)\n",
    "        m.act_alq = act_quantization(bit, m.act_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NocOKuK7geBE"
   },
   "source": [
    "On peut voir que les poids sont bien quantizés sur 4 bits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n5v7x3s9zdiv",
    "outputId": "22d3f633-a3c5-47e1-f170-eb7060287629",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 2459.104750\n",
      "\n",
      "test accuracy of plane:  0% ( 1/1000)\n",
      "test accuracy of car: 100% (1000/1000)\n",
      "test accuracy of bird:  0% ( 0/1000)\n",
      "test accuracy of cat:  0% ( 0/1000)\n",
      "test accuracy of deer:  0% ( 0/1000)\n",
      "test accuracy of dog:  0% ( 0/1000)\n",
      "test accuracy of frog:  0% ( 0/1000)\n",
      "test accuracy of horse:  0% ( 0/1000)\n",
      "test accuracy of ship:  0% ( 0/1000)\n",
      "test accuracy of truck:  0% ( 0/1000)\n",
      "\n",
      "test accuracy (overall): 10.01% (1001/10000)\n"
     ]
    }
   ],
   "source": [
    "evaluation(model_quant, testloader, criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il est difficile d'implémenter le calcul du score pour notre modèle quantizé donc nous utilisons un modèle non quantizé mais avec la variable Quantization True pour prendre en compte la quantization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score flops: 0.06795413525587332 Score Params: 0.007912502297752578\n",
      "Final score: 0.0758666375536259\n"
     ]
    }
   ],
   "source": [
    "model = densenet_cifar()\n",
    "model.to(device=device)\n",
    "flops , params = score(model,quantization = True)\n",
    "print(\"Score flops: {} Score Params: {}\".format(flops,params))\n",
    "print(\"Final score: {}\".format(flops + params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On remarque que le score Micronet est plus faible que le score original donc il peut être intéressant de combiner le pruning et la quantization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T579-i8HgeBF"
   },
   "source": [
    "# Combinaison Apot Quantization et Pruning\n",
    "Le principal challenge de notre projet était de combiner Quantization et Pruning. En modifiant la classe QuantConv2D, nous avons réussi et cela nous a permis d'obtenir un score au Micronet Challenge de 0.071"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mZx7BWdvproQ",
    "outputId": "b4fba681-8d9f-4d3d-fe87-2fd7165eb2c0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseNet_Quant(\n",
       "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (dense1): Sequential(\n",
       "    (0): Bottleneck_Quant(\n",
       "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantConv2d(\n",
       "        16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantConv2d(\n",
       "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck_Quant(\n",
       "      (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantConv2d(\n",
       "        24, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantConv2d(\n",
       "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "    )\n",
       "    (2): Bottleneck_Quant(\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantConv2d(\n",
       "        32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantConv2d(\n",
       "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "    )\n",
       "    (3): Bottleneck_Quant(\n",
       "      (bn1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantConv2d(\n",
       "        40, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantConv2d(\n",
       "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "    )\n",
       "    (4): Bottleneck_Quant(\n",
       "      (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantConv2d(\n",
       "        48, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantConv2d(\n",
       "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "    )\n",
       "    (5): Bottleneck_Quant(\n",
       "      (bn1): BatchNorm2d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantConv2d(\n",
       "        56, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantConv2d(\n",
       "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (trans1): Transition_Quant(\n",
       "    (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv): QuantConv2d(\n",
       "      64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "      (weight_quant): weight_quantize_fn()\n",
       "    )\n",
       "  )\n",
       "  (dense2): Sequential(\n",
       "    (0): Bottleneck_Quant(\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantConv2d(\n",
       "        32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantConv2d(\n",
       "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck_Quant(\n",
       "      (bn1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantConv2d(\n",
       "        40, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantConv2d(\n",
       "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "    )\n",
       "    (2): Bottleneck_Quant(\n",
       "      (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantConv2d(\n",
       "        48, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantConv2d(\n",
       "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "    )\n",
       "    (3): Bottleneck_Quant(\n",
       "      (bn1): BatchNorm2d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantConv2d(\n",
       "        56, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantConv2d(\n",
       "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "    )\n",
       "    (4): Bottleneck_Quant(\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantConv2d(\n",
       "        64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantConv2d(\n",
       "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "    )\n",
       "    (5): Bottleneck_Quant(\n",
       "      (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantConv2d(\n",
       "        72, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantConv2d(\n",
       "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "    )\n",
       "    (6): Bottleneck_Quant(\n",
       "      (bn1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantConv2d(\n",
       "        80, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantConv2d(\n",
       "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "    )\n",
       "    (7): Bottleneck_Quant(\n",
       "      (bn1): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantConv2d(\n",
       "        88, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantConv2d(\n",
       "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "    )\n",
       "    (8): Bottleneck_Quant(\n",
       "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantConv2d(\n",
       "        96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantConv2d(\n",
       "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "    )\n",
       "    (9): Bottleneck_Quant(\n",
       "      (bn1): BatchNorm2d(104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantConv2d(\n",
       "        104, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantConv2d(\n",
       "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (trans2): Transition_Quant(\n",
       "    (bn): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv): QuantConv2d(\n",
       "      112, 56, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "      (weight_quant): weight_quantize_fn()\n",
       "    )\n",
       "  )\n",
       "  (dense3): Sequential(\n",
       "    (0): Bottleneck_Quant(\n",
       "      (bn1): BatchNorm2d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantConv2d(\n",
       "        56, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantConv2d(\n",
       "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck_Quant(\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantConv2d(\n",
       "        64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantConv2d(\n",
       "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "    )\n",
       "    (2): Bottleneck_Quant(\n",
       "      (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantConv2d(\n",
       "        72, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantConv2d(\n",
       "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "    )\n",
       "    (3): Bottleneck_Quant(\n",
       "      (bn1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantConv2d(\n",
       "        80, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantConv2d(\n",
       "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "    )\n",
       "    (4): Bottleneck_Quant(\n",
       "      (bn1): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantConv2d(\n",
       "        88, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantConv2d(\n",
       "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "    )\n",
       "    (5): Bottleneck_Quant(\n",
       "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantConv2d(\n",
       "        96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantConv2d(\n",
       "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "    )\n",
       "    (6): Bottleneck_Quant(\n",
       "      (bn1): BatchNorm2d(104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantConv2d(\n",
       "        104, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantConv2d(\n",
       "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "    )\n",
       "    (7): Bottleneck_Quant(\n",
       "      (bn1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantConv2d(\n",
       "        112, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantConv2d(\n",
       "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "    )\n",
       "    (8): Bottleneck_Quant(\n",
       "      (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantConv2d(\n",
       "        120, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantConv2d(\n",
       "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "    )\n",
       "    (9): Bottleneck_Quant(\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantConv2d(\n",
       "        128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantConv2d(\n",
       "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "    )\n",
       "    (10): Bottleneck_Quant(\n",
       "      (bn1): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantConv2d(\n",
       "        136, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantConv2d(\n",
       "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "    )\n",
       "    (11): Bottleneck_Quant(\n",
       "      (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantConv2d(\n",
       "        144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantConv2d(\n",
       "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "    )\n",
       "    (12): Bottleneck_Quant(\n",
       "      (bn1): BatchNorm2d(152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantConv2d(\n",
       "        152, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantConv2d(\n",
       "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "    )\n",
       "    (13): Bottleneck_Quant(\n",
       "      (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantConv2d(\n",
       "        160, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantConv2d(\n",
       "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "    )\n",
       "    (14): Bottleneck_Quant(\n",
       "      (bn1): BatchNorm2d(168, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantConv2d(\n",
       "        168, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantConv2d(\n",
       "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "    )\n",
       "    (15): Bottleneck_Quant(\n",
       "      (bn1): BatchNorm2d(176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantConv2d(\n",
       "        176, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantConv2d(\n",
       "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "    )\n",
       "    (16): Bottleneck_Quant(\n",
       "      (bn1): BatchNorm2d(184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantConv2d(\n",
       "        184, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantConv2d(\n",
       "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "    )\n",
       "    (17): Bottleneck_Quant(\n",
       "      (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantConv2d(\n",
       "        192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantConv2d(\n",
       "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "    )\n",
       "    (18): Bottleneck_Quant(\n",
       "      (bn1): BatchNorm2d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantConv2d(\n",
       "        200, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantConv2d(\n",
       "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "    )\n",
       "    (19): Bottleneck_Quant(\n",
       "      (bn1): BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantConv2d(\n",
       "        208, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantConv2d(\n",
       "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (trans3): Transition_Quant(\n",
       "    (bn): BatchNorm2d(216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv): QuantConv2d(\n",
       "      216, 108, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "      (weight_quant): weight_quantize_fn()\n",
       "    )\n",
       "  )\n",
       "  (dense4): Sequential(\n",
       "    (0): Bottleneck_Quant(\n",
       "      (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantConv2d(\n",
       "        108, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantConv2d(\n",
       "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck_Quant(\n",
       "      (bn1): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantConv2d(\n",
       "        116, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantConv2d(\n",
       "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "    )\n",
       "    (2): Bottleneck_Quant(\n",
       "      (bn1): BatchNorm2d(124, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantConv2d(\n",
       "        124, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantConv2d(\n",
       "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "    )\n",
       "    (3): Bottleneck_Quant(\n",
       "      (bn1): BatchNorm2d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantConv2d(\n",
       "        132, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantConv2d(\n",
       "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "    )\n",
       "    (4): Bottleneck_Quant(\n",
       "      (bn1): BatchNorm2d(140, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantConv2d(\n",
       "        140, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantConv2d(\n",
       "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "    )\n",
       "    (5): Bottleneck_Quant(\n",
       "      (bn1): BatchNorm2d(148, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantConv2d(\n",
       "        148, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantConv2d(\n",
       "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "    )\n",
       "    (6): Bottleneck_Quant(\n",
       "      (bn1): BatchNorm2d(156, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantConv2d(\n",
       "        156, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantConv2d(\n",
       "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "    )\n",
       "    (7): Bottleneck_Quant(\n",
       "      (bn1): BatchNorm2d(164, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantConv2d(\n",
       "        164, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantConv2d(\n",
       "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "    )\n",
       "    (8): Bottleneck_Quant(\n",
       "      (bn1): BatchNorm2d(172, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantConv2d(\n",
       "        172, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantConv2d(\n",
       "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "    )\n",
       "    (9): Bottleneck_Quant(\n",
       "      (bn1): BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantConv2d(\n",
       "        180, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantConv2d(\n",
       "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "    )\n",
       "    (10): Bottleneck_Quant(\n",
       "      (bn1): BatchNorm2d(188, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantConv2d(\n",
       "        188, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantConv2d(\n",
       "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "    )\n",
       "    (11): Bottleneck_Quant(\n",
       "      (bn1): BatchNorm2d(196, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantConv2d(\n",
       "        196, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantConv2d(\n",
       "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (bn): BatchNorm2d(204, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (linear): Linear(in_features=204, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_quant_pruned = densenet_cifar_quant()\n",
    "model_quant_pruned.to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "6hlsDFgipt7r"
   },
   "outputs": [],
   "source": [
    "parameters_to_prune=[]\n",
    "for name, module in model_quant_pruned.named_modules():\n",
    "    if isinstance(module, torch.nn.Conv2d) or isinstance(module, torch.nn.Linear) or isinstance(module, QuantConv2d):\n",
    "        parameters_to_prune.append((module,'weight'))\n",
    "prune.global_unstructured(parameters_to_prune, pruning_method=prune.L1Unstructured, amount=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CinjaCcap0wl",
    "outputId": "4eba55ac-5410-49b7-e58e-832d8e034c7c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    loaded_cpt=torch.load('models\\\\Densenet_cifar_pruned.pt')\n",
    "else:\n",
    "    loaded_cpt=torch.load('models\\\\Densenet_cifar_pruned.pt', map_location=torch.device('cpu'))\n",
    "\n",
    "loaded_cpt_clone = loaded_cpt.copy()\n",
    "for key in loaded_cpt.keys():\n",
    "  if key.startswith(\"conv1\") == False:\n",
    "      if \"conv\" in key and \"orig\" in key:\n",
    "        loaded_cpt_clone[key.replace(\"weight_orig\",\"act_alpha\")] = torch.nn.Parameter(torch.tensor(8.0))\n",
    "        loaded_cpt_clone[key.replace(\"weight_orig\",\"weight_quant.wgt_alpha\")] = Parameter(torch.tensor(3.0))\n",
    "\n",
    "model_quant_pruned.load_state_dict(loaded_cpt_clone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dS-bLysLp5u7",
    "outputId": "baa33d61-8dba-42de-d52d-2048ac8d0cee",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 569.035003\n",
      "\n",
      "test accuracy of plane: 72% (726/1000)\n",
      "test accuracy of car: 20% (201/1000)\n",
      "test accuracy of bird:  0% ( 2/1000)\n",
      "test accuracy of cat:  1% (10/1000)\n",
      "test accuracy of deer:  0% ( 0/1000)\n",
      "test accuracy of dog:  0% ( 0/1000)\n",
      "test accuracy of frog:  0% ( 0/1000)\n",
      "test accuracy of horse:  0% ( 0/1000)\n",
      "test accuracy of ship:  0% ( 0/1000)\n",
      "test accuracy of truck:  0% ( 0/1000)\n",
      "\n",
      "test accuracy (overall): 9.39% (939/10000)\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.SGD(model_quant_pruned.parameters(),lr=0.1, momentum=0.9,weight_decay=1e-4) \n",
    "scheduler = MultiStepLR(optimizer, milestones=[80, 110,130], gamma=0.1)\n",
    "\n",
    "evaluation(model_quant_pruned, testloader, criterion)\n",
    "\n",
    "bit = 4\n",
    "for m in model_quant_pruned.modules():\n",
    "  if isinstance(m, QuantConv2d):\n",
    "    m.weight_quant = weight_quantize_fn(w_bit=bit)\n",
    "    #print(m.weight_quant(m.weight))\n",
    "    m.act_grid = build_power_value(bit)\n",
    "    m.act_alq = act_quantization(bit, m.act_grid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "id": "lPOCXeRop7xc",
    "outputId": "06b97f03-dcd8-4e6e-fc83-4dc7ae3df877"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 \ttraining Loss: 0.639468 \tvalidation Loss: 0.667596\n",
      "validation loss decreased (inf --> 0.667596).  Saving model ...\n",
      "lr : 0.01 for epochs : 0\n",
      "epoch: 2 \ttraining Loss: 0.651299 \tvalidation Loss: 0.667246\n",
      "validation loss decreased (0.667596 --> 0.667246).  Saving model ...\n",
      "lr : 0.01 for epochs : 1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-8f2b3ffa754f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_quant_prun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"bite\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/content/util.py\u001b[0m in \u001b[0;36mtraining\u001b[0;34m(train_loader, valid_loader, model, criterion, optimizer, n_epochs, scheduler, filename)\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# clear the gradients of all optimized variables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# forward pass: compute predicted outputs by passing inputs to the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# calculate the loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# backward pass: compute gradient of the loss with respect to model parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/content/Densenet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrans1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrans2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrans3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavg_pool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/content/Densenet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/content/util.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    527\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'weight_mask'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m             \u001b[0mweight_q\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight_quant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 529\u001b[0;31m         \u001b[0;32melse\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    530\u001b[0m             \u001b[0mweight_q\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight_quant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact_alq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact_alpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/content/util.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, weight, mask)\u001b[0m\n\u001b[1;32m    466\u001b[0m             \u001b[0;31m#std = weight.data.std()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m             \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 468\u001b[0;31m                 \u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmask\u001b[0m      \u001b[0;31m# weights normalization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    469\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m                 \u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_losses, valid_losses, train_acc, valid_acc = training(trainloader, validloader, model_quant_pruned, criterion, optimizer,150,scheduler,\"Densenet_pruned_quantized\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V2iQfTSageBJ"
   },
   "source": [
    "Il est également possible de loader notre modèle final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    loaded_cpt=torch.load('models\\\\Densenet_cifar_pruned_quantized.pt')\n",
    "else:\n",
    "    loaded_cpt=torch.load('models\\\\Densenet_cifar_pruned_quantized.pt', map_location=torch.device('cpu'))\n",
    "\n",
    "loaded_cpt_clone = loaded_cpt.copy()\n",
    "for key in loaded_cpt.keys():\n",
    "  if key.startswith(\"conv1\") == False:\n",
    "      if \"conv\" in key and \"orig\" in key:\n",
    "        loaded_cpt_clone[key.replace(\"weight_orig\",\"act_alpha\")] = torch.nn.Parameter(torch.tensor(8.0))\n",
    "        loaded_cpt_clone[key.replace(\"weight_orig\",\"weight_quant.wgt_alpha\")] = Parameter(torch.tensor(3.0))\n",
    "\n",
    "model_quant_pruned.load_state_dict(loaded_cpt_clone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseNet_Quant(\n",
       "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (dense1): Sequential(\n",
       "    (0): Bottleneck_Quant(\n",
       "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantConv2d(\n",
       "        16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantConv2d(\n",
       "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck_Quant(\n",
       "      (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantConv2d(\n",
       "        24, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantConv2d(\n",
       "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "    )\n",
       "    (2): Bottleneck_Quant(\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantConv2d(\n",
       "        32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantConv2d(\n",
       "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "    )\n",
       "    (3): Bottleneck_Quant(\n",
       "      (bn1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantConv2d(\n",
       "        40, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantConv2d(\n",
       "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "    )\n",
       "    (4): Bottleneck_Quant(\n",
       "      (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantConv2d(\n",
       "        48, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantConv2d(\n",
       "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "    )\n",
       "    (5): Bottleneck_Quant(\n",
       "      (bn1): BatchNorm2d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantConv2d(\n",
       "        56, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantConv2d(\n",
       "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (trans1): Transition_Quant(\n",
       "    (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv): QuantConv2d(\n",
       "      64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "      (weight_quant): weight_quantize_fn()\n",
       "    )\n",
       "  )\n",
       "  (dense2): Sequential(\n",
       "    (0): Bottleneck_Quant(\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantConv2d(\n",
       "        32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantConv2d(\n",
       "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck_Quant(\n",
       "      (bn1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantConv2d(\n",
       "        40, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantConv2d(\n",
       "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "    )\n",
       "    (2): Bottleneck_Quant(\n",
       "      (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantConv2d(\n",
       "        48, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantConv2d(\n",
       "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "    )\n",
       "    (3): Bottleneck_Quant(\n",
       "      (bn1): BatchNorm2d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantConv2d(\n",
       "        56, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantConv2d(\n",
       "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "    )\n",
       "    (4): Bottleneck_Quant(\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantConv2d(\n",
       "        64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantConv2d(\n",
       "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "    )\n",
       "    (5): Bottleneck_Quant(\n",
       "      (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantConv2d(\n",
       "        72, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantConv2d(\n",
       "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "    )\n",
       "    (6): Bottleneck_Quant(\n",
       "      (bn1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantConv2d(\n",
       "        80, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantConv2d(\n",
       "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "    )\n",
       "    (7): Bottleneck_Quant(\n",
       "      (bn1): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantConv2d(\n",
       "        88, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantConv2d(\n",
       "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "    )\n",
       "    (8): Bottleneck_Quant(\n",
       "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantConv2d(\n",
       "        96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantConv2d(\n",
       "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "    )\n",
       "    (9): Bottleneck_Quant(\n",
       "      (bn1): BatchNorm2d(104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantConv2d(\n",
       "        104, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantConv2d(\n",
       "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (trans2): Transition_Quant(\n",
       "    (bn): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv): QuantConv2d(\n",
       "      112, 56, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "      (weight_quant): weight_quantize_fn()\n",
       "    )\n",
       "  )\n",
       "  (dense3): Sequential(\n",
       "    (0): Bottleneck_Quant(\n",
       "      (bn1): BatchNorm2d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantConv2d(\n",
       "        56, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantConv2d(\n",
       "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck_Quant(\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantConv2d(\n",
       "        64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantConv2d(\n",
       "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "    )\n",
       "    (2): Bottleneck_Quant(\n",
       "      (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantConv2d(\n",
       "        72, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantConv2d(\n",
       "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "    )\n",
       "    (3): Bottleneck_Quant(\n",
       "      (bn1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantConv2d(\n",
       "        80, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantConv2d(\n",
       "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "    )\n",
       "    (4): Bottleneck_Quant(\n",
       "      (bn1): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantConv2d(\n",
       "        88, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantConv2d(\n",
       "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "    )\n",
       "    (5): Bottleneck_Quant(\n",
       "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantConv2d(\n",
       "        96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantConv2d(\n",
       "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "    )\n",
       "    (6): Bottleneck_Quant(\n",
       "      (bn1): BatchNorm2d(104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantConv2d(\n",
       "        104, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantConv2d(\n",
       "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "    )\n",
       "    (7): Bottleneck_Quant(\n",
       "      (bn1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantConv2d(\n",
       "        112, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantConv2d(\n",
       "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "    )\n",
       "    (8): Bottleneck_Quant(\n",
       "      (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantConv2d(\n",
       "        120, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantConv2d(\n",
       "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "    )\n",
       "    (9): Bottleneck_Quant(\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantConv2d(\n",
       "        128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantConv2d(\n",
       "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "    )\n",
       "    (10): Bottleneck_Quant(\n",
       "      (bn1): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantConv2d(\n",
       "        136, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantConv2d(\n",
       "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "    )\n",
       "    (11): Bottleneck_Quant(\n",
       "      (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantConv2d(\n",
       "        144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantConv2d(\n",
       "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "    )\n",
       "    (12): Bottleneck_Quant(\n",
       "      (bn1): BatchNorm2d(152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantConv2d(\n",
       "        152, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantConv2d(\n",
       "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "    )\n",
       "    (13): Bottleneck_Quant(\n",
       "      (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantConv2d(\n",
       "        160, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantConv2d(\n",
       "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "    )\n",
       "    (14): Bottleneck_Quant(\n",
       "      (bn1): BatchNorm2d(168, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantConv2d(\n",
       "        168, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantConv2d(\n",
       "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "    )\n",
       "    (15): Bottleneck_Quant(\n",
       "      (bn1): BatchNorm2d(176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantConv2d(\n",
       "        176, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantConv2d(\n",
       "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "    )\n",
       "    (16): Bottleneck_Quant(\n",
       "      (bn1): BatchNorm2d(184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantConv2d(\n",
       "        184, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantConv2d(\n",
       "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "    )\n",
       "    (17): Bottleneck_Quant(\n",
       "      (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantConv2d(\n",
       "        192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantConv2d(\n",
       "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "    )\n",
       "    (18): Bottleneck_Quant(\n",
       "      (bn1): BatchNorm2d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantConv2d(\n",
       "        200, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantConv2d(\n",
       "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "    )\n",
       "    (19): Bottleneck_Quant(\n",
       "      (bn1): BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantConv2d(\n",
       "        208, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantConv2d(\n",
       "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (trans3): Transition_Quant(\n",
       "    (bn): BatchNorm2d(216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv): QuantConv2d(\n",
       "      216, 108, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "      (weight_quant): weight_quantize_fn()\n",
       "    )\n",
       "  )\n",
       "  (dense4): Sequential(\n",
       "    (0): Bottleneck_Quant(\n",
       "      (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantConv2d(\n",
       "        108, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantConv2d(\n",
       "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck_Quant(\n",
       "      (bn1): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantConv2d(\n",
       "        116, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantConv2d(\n",
       "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "    )\n",
       "    (2): Bottleneck_Quant(\n",
       "      (bn1): BatchNorm2d(124, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantConv2d(\n",
       "        124, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantConv2d(\n",
       "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "    )\n",
       "    (3): Bottleneck_Quant(\n",
       "      (bn1): BatchNorm2d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantConv2d(\n",
       "        132, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantConv2d(\n",
       "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "    )\n",
       "    (4): Bottleneck_Quant(\n",
       "      (bn1): BatchNorm2d(140, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantConv2d(\n",
       "        140, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantConv2d(\n",
       "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "    )\n",
       "    (5): Bottleneck_Quant(\n",
       "      (bn1): BatchNorm2d(148, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantConv2d(\n",
       "        148, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantConv2d(\n",
       "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "    )\n",
       "    (6): Bottleneck_Quant(\n",
       "      (bn1): BatchNorm2d(156, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantConv2d(\n",
       "        156, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantConv2d(\n",
       "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "    )\n",
       "    (7): Bottleneck_Quant(\n",
       "      (bn1): BatchNorm2d(164, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantConv2d(\n",
       "        164, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantConv2d(\n",
       "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "    )\n",
       "    (8): Bottleneck_Quant(\n",
       "      (bn1): BatchNorm2d(172, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantConv2d(\n",
       "        172, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantConv2d(\n",
       "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "    )\n",
       "    (9): Bottleneck_Quant(\n",
       "      (bn1): BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantConv2d(\n",
       "        180, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantConv2d(\n",
       "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "    )\n",
       "    (10): Bottleneck_Quant(\n",
       "      (bn1): BatchNorm2d(188, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantConv2d(\n",
       "        188, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantConv2d(\n",
       "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "    )\n",
       "    (11): Bottleneck_Quant(\n",
       "      (bn1): BatchNorm2d(196, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantConv2d(\n",
       "        196, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantConv2d(\n",
       "        32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (weight_quant): weight_quantize_fn()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (bn): BatchNorm2d(204, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (linear): Linear(in_features=204, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_quant_pruned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Puf2NPb_lD_-",
    "outputId": "bb8478b1-2a38-4c3e-d68d-323f455a9282"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[-1.8000]],\n",
      "\n",
      "         [[ 2.4000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[-0.9000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 1.8000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[-0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[-1.8000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[-3.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[-0.9000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[-1.8000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[-1.8000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[-0.6000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[ 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[-0.3000]],\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 1.8000]],\n",
      "\n",
      "         [[-0.3000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[-2.4000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.9000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[-0.9000]]],\n",
      "\n",
      "\n",
      "        [[[-0.3000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         [[ 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[-0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[-1.2000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[-0.6000]]],\n",
      "\n",
      "\n",
      "        [[[-0.9000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         [[ 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.6000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 1.8000]],\n",
      "\n",
      "         [[-0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.9000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 1.8000]],\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.3000]],\n",
      "\n",
      "         [[ 1.2000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.6000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[ 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[-1.8000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[-0.9000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         [[ 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 1.2000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[-0.6000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[-1.2000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[ 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.9000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[ 0.0000]],\n",
      "\n",
      "         [[-0.6000]],\n",
      "\n",
      "         [[ 0.6000]],\n",
      "\n",
      "         [[ 0.0000]]]], device='cuda:0', grad_fn=<_pqBackward>)\n"
     ]
    }
   ],
   "source": [
    "m = model_quant_pruned.dense1[0].conv1\n",
    "print(m.weight_quant(m.weight,m.weight_mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AxeOX7hYgeBJ",
    "outputId": "4bd7dece-6dce-425c-be1b-4f7535f2a10b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.399867\n",
      "\n",
      "test accuracy of plane: 90% (908/1000)\n",
      "test accuracy of car: 96% (960/1000)\n",
      "test accuracy of bird: 85% (855/1000)\n",
      "test accuracy of cat: 76% (767/1000)\n",
      "test accuracy of deer: 92% (922/1000)\n",
      "test accuracy of dog: 87% (877/1000)\n",
      "test accuracy of frog: 92% (925/1000)\n",
      "test accuracy of horse: 91% (914/1000)\n",
      "test accuracy of ship: 94% (944/1000)\n",
      "test accuracy of truck: 93% (937/1000)\n",
      "\n",
      "test accuracy (overall): 90.09% (9009/10000)\n"
     ]
    }
   ],
   "source": [
    "evaluation(model_quant_pruned, testloader, criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On voit que les poids sont bien prunés et quantizés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.304136\n",
      "\n",
      "test accuracy of plane: 93% (939/1000)\n",
      "test accuracy of car: 97% (974/1000)\n",
      "test accuracy of bird: 90% (903/1000)\n",
      "test accuracy of cat: 84% (843/1000)\n",
      "test accuracy of deer: 95% (950/1000)\n",
      "test accuracy of dog: 88% (881/1000)\n",
      "test accuracy of frog: 94% (944/1000)\n",
      "test accuracy of horse: 93% (935/1000)\n",
      "test accuracy of ship: 94% (949/1000)\n",
      "test accuracy of truck: 94% (947/1000)\n",
      "\n",
      "test accuracy (overall): 92.65% (9265/10000)\n",
      "Score flops: 0.06795413525587332 Score Params: 0.0028913423904609664\n",
      "Final score: 0.07084547764633428\n"
     ]
    }
   ],
   "source": [
    "model_pruned = densenet_cifar()\n",
    "model_pruned.to(device=device)\n",
    "\n",
    "parameters_to_prune=[]\n",
    "for name, module in model_pruned.named_modules():\n",
    "    if isinstance(module, torch.nn.Conv2d) or isinstance(module, torch.nn.Linear) or isinstance(module, QuantConv2d):\n",
    "        parameters_to_prune.append((module,'weight'))\n",
    "prune.global_unstructured(parameters_to_prune, pruning_method=prune.L1Unstructured, amount=0.2)\n",
    "        \n",
    "if torch.cuda.is_available():\n",
    "    loaded_cpt=torch.load('models\\\\Densenet_cifar_pruned.pt')\n",
    "else:\n",
    "    loaded_cpt=torch.load('models\\\\Densenet_cifar_pruned.pt', map_location=torch.device('cpu'))\n",
    "model_pruned.load_state_dict(loaded_cpt)\n",
    "evaluation(model_pruned, testloader, criterion)\n",
    "\n",
    "\n",
    "# En exécutant cette cellule, nous perdons le mask associé au pruning, mais cela nous permet de pouvoir calculer le score micronet\n",
    "for name, module in model_pruned.named_modules():\n",
    "# prune X % of connections in all 2D-conv layers\n",
    "    if isinstance(module, torch.nn.Conv2d):\n",
    "        prune.remove(module, 'weight')\n",
    "    elif isinstance(module, QuantConv2d):\n",
    "        prune.remove(module, 'weight')\n",
    "    elif isinstance(module, torch.nn.Linear):\n",
    "        prune.remove(module, 'weight')\n",
    "\n",
    "flops , params = score(model_pruned,quantization = True)\n",
    "print(\"Score flops: {} Score Params: {}\".format(flops,params))\n",
    "print(\"Final score: {}\".format(flops + params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On obtient finalement en combinant ces deux techniques un score Micronet de 0.071   \n",
    "On aurait pu améliorer notre score en quantizant sur 2 bits ou en effectuant du Structured Pruning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Project_Model_Cifar10.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
