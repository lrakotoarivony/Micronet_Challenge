{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Project_Model_Cifar10.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4fe8b81b13364d60a97c6e65ff37708a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1dc532a0c1a84750aed4aacf7c1cb100",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_93ee760e703c4d3e899111bf3ca51aee",
              "IPY_MODEL_202ec2e42fe6409582f303c4aa7c2d39"
            ]
          }
        },
        "1dc532a0c1a84750aed4aacf7c1cb100": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "93ee760e703c4d3e899111bf3ca51aee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c3a909ba37894fe4931f310803c8cc53",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 170498071,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 170498071,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ee69bca39a334888868ac74935c21121"
          }
        },
        "202ec2e42fe6409582f303c4aa7c2d39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b291261c9c8448e9a34848ce43d13e54",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170499072/? [00:35&lt;00:00, 4769265.05it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7d6a54b353e64cd7b948d66964ac530b"
          }
        },
        "c3a909ba37894fe4931f310803c8cc53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ee69bca39a334888868ac74935c21121": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b291261c9c8448e9a34848ce43d13e54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7d6a54b353e64cd7b948d66964ac530b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lrakotoarivony/Micronet_Challenge/blob/main/Project_Model_Cifar10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WMHg7fp3QQP0"
      },
      "source": [
        "# Data & Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYrygCr3QQP7"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122,
          "referenced_widgets": [
            "4fe8b81b13364d60a97c6e65ff37708a",
            "1dc532a0c1a84750aed4aacf7c1cb100",
            "93ee760e703c4d3e899111bf3ca51aee",
            "202ec2e42fe6409582f303c4aa7c2d39",
            "c3a909ba37894fe4931f310803c8cc53",
            "ee69bca39a334888868ac74935c21121",
            "b291261c9c8448e9a34848ce43d13e54",
            "7d6a54b353e64cd7b948d66964ac530b"
          ]
        },
        "id": "OBhdlahUQQP9",
        "outputId": "49f55486-e43e-4647-9171-5b4f4a7c38d0"
      },
      "source": [
        "n_classes_cifar10 = 10\n",
        "train_size = 0.8\n",
        "R = 5\n",
        "\n",
        "\n",
        "# Download the entire CIFAR10 dataset\n",
        "\n",
        "from torchvision.datasets import CIFAR10\n",
        "import numpy as np \n",
        "from torch.utils.data import Subset\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "\n",
        "\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "## Normalization is different when training from scratch and when training using an imagenet pretrained backbone\n",
        "\n",
        "normalize_scratch = transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
        "\n",
        "\n",
        "# Data augmentation is needed in order to train from scratch\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    normalize_scratch,\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    normalize_scratch,\n",
        "])\n",
        "\n",
        "\n",
        "\n",
        "### The data from CIFAR10 will be downloaded in the following dataset\n",
        "rootdir = './data/cifar10'\n",
        "\n",
        "c10train = CIFAR10(rootdir,train=True,download=True,transform=transform_train)\n",
        "c10test = CIFAR10(rootdir,train=False,download=True,transform=transform_test)\n",
        "\n",
        "\n",
        "\n",
        "# CIFAR10 is sufficiently large so that training a model up to the state of the art performance will take approximately 3 hours on the 1060 GPU available on your machine. \n",
        "\n",
        "\n",
        "def train_validation_split(train_size, num_train_examples):\n",
        "    # obtain training indices that will be used for validation\n",
        "    indices = list(range(num_train_examples))\n",
        "    np.random.shuffle(indices)\n",
        "    idx_split = int(np.floor(train_size * num_train_examples))\n",
        "    train_index, valid_index = indices[:idx_split], indices[idx_split:]\n",
        "\n",
        "    # define samplers for obtaining training and validation batches\n",
        "    train_sampler = SubsetRandomSampler(train_index)\n",
        "    valid_sampler = SubsetRandomSampler(valid_index)\n",
        "\n",
        "    return train_sampler,valid_sampler\n",
        "\n",
        "def generate_subset(dataset,n_classes,reducefactor,n_ex_class_init):\n",
        "\n",
        "    nb_examples_per_class = int(np.floor(n_ex_class_init / reducefactor))\n",
        "    # Generate the indices. They are the same for each class, could easily be modified to have different ones. But be careful to keep the random seed! \n",
        "\n",
        "    indices_split = np.random.RandomState(seed=42).choice(n_ex_class_init,nb_examples_per_class,replace=False)\n",
        "\n",
        "    all_indices = []\n",
        "    for curclas in range(n_classes):\n",
        "        curtargets = np.where(np.array(dataset.targets) == curclas)\n",
        "        indices_curclas = curtargets[0]\n",
        "        indices_subset = indices_curclas[indices_split]\n",
        "        #print(len(indices_subset))\n",
        "        all_indices.append(indices_subset)\n",
        "    all_indices = np.hstack(all_indices)\n",
        "    \n",
        "    return Subset(dataset,indices=all_indices)\n",
        "    \n",
        "\n",
        "\n",
        "### These dataloader are ready to be used to train for scratch \n",
        "cifar10_train= generate_subset(dataset=c10train,n_classes=n_classes_cifar10,reducefactor=R,n_ex_class_init=5000)\n",
        "num_train_examples=len(cifar10_train)\n",
        "train_sampler,valid_sampler=train_validation_split(train_size, num_train_examples)\n",
        "\n",
        "cifar10_test = generate_subset(dataset=c10test,n_classes=n_classes_cifar10,reducefactor=1,n_ex_class_init=1000) \n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar10/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4fe8b81b13364d60a97c6e65ff37708a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=170498071.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting ./data/cifar10/cifar-10-python.tar.gz to ./data/cifar10\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jquWwc-QQP-"
      },
      "source": [
        "#from minicifar import minicifar_train,minicifar_test,train_sampler,valid_sampler\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "\n",
        "trainloader = DataLoader(c10train,batch_size=64,sampler=train_sampler)\n",
        "validloader = DataLoader(c10train,batch_size=64,sampler=valid_sampler)\n",
        "testloader = DataLoader(c10test,batch_size=64) "
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kse9bIgDQQQA"
      },
      "source": [
        "# Device"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2bJJAjcDQQQA",
        "outputId": "43e37e94-3582-483b-fc15-96a84dca3715"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using device '+str(device))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using device cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GeKizMXJQQQB"
      },
      "source": [
        "# Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Koj9RB4sQQQC"
      },
      "source": [
        "def training(train_loader, valid_loader, model, criterion, optimizer,n_epochs=10):\n",
        "    \n",
        "    train_losses, valid_losses, train_acc, valid_acc  = [], [], [], []\n",
        "    # initialize tracker for minimum validation loss\n",
        "    valid_loss_min = np.Inf  # set initial \"min\" to infinity\n",
        "    \n",
        "    for epoch in range(n_epochs):\n",
        "        train_loss, valid_loss = 0, 0 # monitor losses\n",
        "        class_correct_train ,class_total_train = 0, 0 \n",
        "        class_correct_valid ,class_total_valid = 0, 0 \n",
        "        \n",
        "\n",
        "        # train the model\n",
        "        model.train() # prep model for training\n",
        "        for data, label in train_loader:\n",
        "            data = data.to(device=device, dtype=torch.float32)\n",
        "            label = label.to(device=device, dtype=torch.long)\n",
        "            optimizer.zero_grad() # clear the gradients of all optimized variables\n",
        "            output = model(data) # forward pass: compute predicted outputs by passing inputs to the model\n",
        "            loss = criterion(output, label) # calculate the loss\n",
        "            loss.backward() # backward pass: compute gradient of the loss with respect to model parameters\n",
        "            optimizer.step() # perform a single optimization step (parameter update)\n",
        "            train_loss += loss.item() * data.size(0) # update running training loss\n",
        "\n",
        "            _, pred = torch.max(output, 1)\n",
        "            correct = np.squeeze(pred.eq(label.data.view_as(pred)))\n",
        "            for i in range(len(label)):\n",
        "                digit = label.data[i]\n",
        "                class_correct_train += correct[i].item()\n",
        "                class_total_train += 1\n",
        "            \n",
        "\n",
        "        # validate the model\n",
        "        model.eval()\n",
        "        for data, label in valid_loader:\n",
        "            data = data.to(device=device, dtype=torch.float32)\n",
        "            label = label.to(device=device, dtype=torch.long)\n",
        "            with torch.no_grad():\n",
        "                output = model(data)\n",
        "            loss = criterion(output,label)\n",
        "            valid_loss += loss.item() * data.size(0)\n",
        "\n",
        "            _, pred = torch.max(output, 1)\n",
        "            correct = np.squeeze(pred.eq(label.data.view_as(pred)))\n",
        "            for i in range(len(label)):\n",
        "                digit = label.data[i]\n",
        "                class_correct_valid += correct[i].item()\n",
        "                class_total_valid += 1\n",
        "        \n",
        "\n",
        "\n",
        "\n",
        "        # calculate average loss over an epoch\n",
        "        train_loss /= len(train_loader.sampler)\n",
        "        valid_loss /= len(valid_loader.sampler)\n",
        "\n",
        "        train_losses.append(train_loss)\n",
        "        valid_losses.append(valid_loss)\n",
        "\n",
        "\n",
        "        train_acc.append(class_correct_train/class_total_train)\n",
        "        valid_acc.append(class_correct_valid/class_total_valid)\n",
        "\n",
        "\n",
        "        print('epoch: {} \\ttraining Loss: {:.6f} \\tvalidation Loss: {:.6f}'.format(epoch+1, train_loss, valid_loss))\n",
        "\n",
        "        # save model if validation loss has decreased\n",
        "        if valid_loss <= valid_loss_min:\n",
        "            print('validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
        "            valid_loss_min,\n",
        "            valid_loss))\n",
        "            torch.save(model.state_dict(), 'model_densenet121_0.1.pt')\n",
        "            valid_loss_min = valid_loss\n",
        "            \n",
        "        #scheduler.step()\n",
        "        print('lr : {} for epochs : {}'.format(optimizer.param_groups[0]['lr'],epoch))\n",
        "\n",
        "    return train_losses, valid_losses,  train_acc, valid_acc"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MFyO3HmdQQQC"
      },
      "source": [
        "class_names = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZIYgnaFmQQQC"
      },
      "source": [
        "def evaluation(model, test_loader, criterion): \n",
        "\n",
        "    test_loss = 0.0\n",
        "    class_correct = list(0. for i in range(10))\n",
        "    class_total = list(0. for i in range(10))\n",
        "\n",
        "    model.eval()\n",
        "    for data, label in test_loader:\n",
        "        data = data.to(device=device, dtype=torch.float32)\n",
        "        label = label.to(device=device, dtype=torch.long)\n",
        "        with torch.no_grad():\n",
        "            output = model(data)\n",
        "        loss = criterion(output, label)\n",
        "        test_loss += loss.item()*data.size(0)\n",
        "        _, pred = torch.max(output, 1)\n",
        "        correct = np.squeeze(pred.eq(label.data.view_as(pred)))\n",
        "        for i in range(len(label)):\n",
        "            digit = label.data[i]\n",
        "            class_correct[digit] += correct[i].item()\n",
        "            class_total[digit] += 1\n",
        "\n",
        "    test_loss = test_loss/len(test_loader.sampler)\n",
        "    print('test Loss: {:.6f}\\n'.format(test_loss))\n",
        "    for i in range(10):\n",
        "\n",
        "        if(np.sum(class_total[i])==0):\n",
        "            print(class_names[i])\n",
        "        else:\n",
        "            print('test accuracy of %s: %2d%% (%2d/%2d)' % (class_names[i], 100 * class_correct[i] / class_total[i], np.sum(class_correct[i]), np.sum(class_total[i])))\n",
        "    print('\\ntest accuracy (overall): %2.2f%% (%2d/%2d)' % (100. * np.sum(class_correct) / np.sum(class_total), np.sum(class_correct), np.sum(class_total)))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IUoUD0qZQQQD"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 409
        },
        "id": "hpnERK62QQQD",
        "outputId": "28f26531-cf60-4857-d585-f4630459b501"
      },
      "source": [
        "#import wget\n",
        "!wget.download('https://raw.githubusercontent.com/kuangliu/pytorch-cifar/master/models/densenet.py')\n",
        "from densenet import *"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/bin/bash: -c: line 0: syntax error near unexpected token `'https://raw.githubusercontent.com/kuangliu/pytorch-cifar/master/models/densenet.py''\n",
            "/bin/bash: -c: line 0: `wget.download('https://raw.githubusercontent.com/kuangliu/pytorch-cifar/master/models/densenet.py')'\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-2de7b98bbabb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#import wget\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"wget.download('https://raw.githubusercontent.com/kuangliu/pytorch-cifar/master/models/densenet.py')\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdensenet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'densenet'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0farfaMNRXDH",
        "outputId": "347eb800-cf49-43f6-c457-2f94a22b4528"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/kuangliu/pytorch-cifar/master/models/densenet.py\r\n",
        "from densenet import *"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-03-07 14:49:29--  https://raw.githubusercontent.com/kuangliu/pytorch-cifar/master/models/densenet.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3542 (3.5K) [text/plain]\n",
            "Saving to: â€˜densenet.pyâ€™\n",
            "\n",
            "densenet.py         100%[===================>]   3.46K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-03-07 14:49:29 (58.5 MB/s) - â€˜densenet.pyâ€™ saved [3542/3542]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yyzqOe6jTQhL"
      },
      "source": [
        "'''DenseNet in PyTorch.'''\r\n",
        "import math\r\n",
        "\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "\r\n",
        "\r\n",
        "class Bottleneck(nn.Module):\r\n",
        "    def __init__(self, in_planes, growth_rate):\r\n",
        "        super(Bottleneck, self).__init__()\r\n",
        "        self.bn1 = nn.BatchNorm2d(in_planes)\r\n",
        "        self.conv1 = nn.Conv2d(in_planes, 4*growth_rate, kernel_size=1, bias=False)\r\n",
        "        self.bn2 = nn.BatchNorm2d(4*growth_rate)\r\n",
        "        self.conv2 = nn.Conv2d(4*growth_rate, growth_rate, kernel_size=3, padding=1, bias=False)\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        out = self.conv1(F.relu(self.bn1(x)))\r\n",
        "        out = self.conv2(F.relu(self.bn2(out)))\r\n",
        "        out = torch.cat([out,x], 1)\r\n",
        "        return out\r\n",
        "\r\n",
        "class Bottleneck_Quant(nn.Module):\r\n",
        "    def __init__(self, in_planes, growth_rate):\r\n",
        "        super(Bottleneck_Quant, self).__init__()\r\n",
        "        self.bn1 = nn.BatchNorm2d(in_planes)\r\n",
        "        self.conv1 = QuantConv2d(in_planes, 4*growth_rate, kernel_size=1, bias=False)\r\n",
        "        self.bn2 = nn.BatchNorm2d(4*growth_rate)\r\n",
        "        self.conv2 = QuantConv2d(4*growth_rate, growth_rate, kernel_size=3, padding=1, bias=False)\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        out = self.conv1(F.relu(self.bn1(x)))\r\n",
        "        out = self.conv2(F.relu(self.bn2(out)))\r\n",
        "        out = torch.cat([out,x], 1)\r\n",
        "        return out\r\n",
        "\r\n",
        "\r\n",
        "class Transition(nn.Module):\r\n",
        "    def __init__(self, in_planes, out_planes):\r\n",
        "        super(Transition, self).__init__()\r\n",
        "        self.bn = nn.BatchNorm2d(in_planes)\r\n",
        "        self.conv = nn.Conv2d(in_planes, out_planes, kernel_size=1, bias=False)\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        out = self.conv(F.relu(self.bn(x)))\r\n",
        "        out = F.avg_pool2d(out, 2)\r\n",
        "        return out\r\n",
        "\r\n",
        "class Transition_Quant(nn.Module):\r\n",
        "    def __init__(self, in_planes, out_planes):\r\n",
        "        super(Transition_Quant, self).__init__()\r\n",
        "        self.bn = nn.BatchNorm2d(in_planes)\r\n",
        "        self.conv = QuantConv2d(in_planes, out_planes, kernel_size=1, bias=False)\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        out = self.conv(F.relu(self.bn(x)))\r\n",
        "        out = F.avg_pool2d(out, 2)\r\n",
        "        return out\r\n",
        "\r\n",
        "\r\n",
        "class DenseNet(nn.Module):\r\n",
        "    def __init__(self, block, nblocks, growth_rate=12, reduction=0.5, num_classes=10):\r\n",
        "        super(DenseNet, self).__init__()\r\n",
        "        self.growth_rate = growth_rate\r\n",
        "\r\n",
        "        num_planes = 2*growth_rate\r\n",
        "        self.conv1 = nn.Conv2d(3, num_planes, kernel_size=3, padding=1, bias=False)\r\n",
        "\r\n",
        "        self.dense1 = self._make_dense_layers(block, num_planes, nblocks[0])\r\n",
        "        num_planes += nblocks[0]*growth_rate\r\n",
        "        out_planes = int(math.floor(num_planes*reduction))\r\n",
        "        self.trans1 = Transition(num_planes, out_planes)\r\n",
        "        num_planes = out_planes\r\n",
        "\r\n",
        "        self.dense2 = self._make_dense_layers(block, num_planes, nblocks[1])\r\n",
        "        num_planes += nblocks[1]*growth_rate\r\n",
        "        out_planes = int(math.floor(num_planes*reduction))\r\n",
        "        self.trans2 = Transition(num_planes, out_planes)\r\n",
        "        num_planes = out_planes\r\n",
        "\r\n",
        "        self.dense3 = self._make_dense_layers(block, num_planes, nblocks[2])\r\n",
        "        num_planes += nblocks[2]*growth_rate\r\n",
        "        out_planes = int(math.floor(num_planes*reduction))\r\n",
        "        self.trans3 = Transition(num_planes, out_planes)\r\n",
        "        num_planes = out_planes\r\n",
        "\r\n",
        "        self.dense4 = self._make_dense_layers(block, num_planes, nblocks[3])\r\n",
        "        num_planes += nblocks[3]*growth_rate\r\n",
        "\r\n",
        "        self.bn = nn.BatchNorm2d(num_planes)\r\n",
        "        self.linear = nn.Linear(num_planes, num_classes)\r\n",
        "\r\n",
        "    def _make_dense_layers(self, block, in_planes, nblock):\r\n",
        "        layers = []\r\n",
        "        for i in range(nblock):\r\n",
        "            layers.append(block(in_planes, self.growth_rate))\r\n",
        "            in_planes += self.growth_rate\r\n",
        "        return nn.Sequential(*layers)\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        out = self.conv1(x)\r\n",
        "        out = self.trans1(self.dense1(out))\r\n",
        "        out = self.trans2(self.dense2(out))\r\n",
        "        out = self.trans3(self.dense3(out))\r\n",
        "        out = self.dense4(out)\r\n",
        "        out = F.avg_pool2d(F.relu(self.bn(out)), 4)\r\n",
        "        out = out.view(out.size(0), -1)\r\n",
        "        out = self.linear(out)\r\n",
        "        return out\r\n",
        "\r\n",
        "    def show_params(self):\r\n",
        "        for m in self.modules():\r\n",
        "            if isinstance(m, QuantConv2d):\r\n",
        "                m.show_params()\r\n",
        "\r\n",
        "class DenseNet_Quant(nn.Module):\r\n",
        "    def __init__(self, block, nblocks, growth_rate=12, reduction=0.5, num_classes=10):\r\n",
        "        super(DenseNet_Quant, self).__init__()\r\n",
        "        self.growth_rate = growth_rate\r\n",
        "\r\n",
        "        num_planes = 2*growth_rate\r\n",
        "        self.conv1 = QuantConv2d(3, num_planes, kernel_size=3, padding=1, bias=False)\r\n",
        "\r\n",
        "        self.dense1 = self._make_dense_layers(block, num_planes, nblocks[0])\r\n",
        "        num_planes += nblocks[0]*growth_rate\r\n",
        "        out_planes = int(math.floor(num_planes*reduction))\r\n",
        "        self.trans1 = Transition_Quant(num_planes, out_planes)\r\n",
        "        num_planes = out_planes\r\n",
        "\r\n",
        "        self.dense2 = self._make_dense_layers(block, num_planes, nblocks[1])\r\n",
        "        num_planes += nblocks[1]*growth_rate\r\n",
        "        out_planes = int(math.floor(num_planes*reduction))\r\n",
        "        self.trans2 = Transition_Quant(num_planes, out_planes)\r\n",
        "        num_planes = out_planes\r\n",
        "\r\n",
        "        self.dense3 = self._make_dense_layers(block, num_planes, nblocks[2])\r\n",
        "        num_planes += nblocks[2]*growth_rate\r\n",
        "        out_planes = int(math.floor(num_planes*reduction))\r\n",
        "        self.trans3 = Transition_Quant(num_planes, out_planes)\r\n",
        "        num_planes = out_planes\r\n",
        "\r\n",
        "        self.dense4 = self._make_dense_layers(block, num_planes, nblocks[3])\r\n",
        "        num_planes += nblocks[3]*growth_rate\r\n",
        "\r\n",
        "        self.bn = nn.BatchNorm2d(num_planes)\r\n",
        "        self.linear = nn.Linear(num_planes, num_classes)\r\n",
        "\r\n",
        "    def _make_dense_layers(self, block, in_planes, nblock):\r\n",
        "        layers = []\r\n",
        "        for i in range(nblock):\r\n",
        "            layers.append(block(in_planes, self.growth_rate))\r\n",
        "            in_planes += self.growth_rate\r\n",
        "        return nn.Sequential(*layers)\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        out = self.conv1(x)\r\n",
        "        out = self.trans1(self.dense1(out))\r\n",
        "        out = self.trans2(self.dense2(out))\r\n",
        "        out = self.trans3(self.dense3(out))\r\n",
        "        out = self.dense4(out)\r\n",
        "        out = F.avg_pool2d(F.relu(self.bn(out)), 4)\r\n",
        "        out = out.view(out.size(0), -1)\r\n",
        "        out = self.linear(out)\r\n",
        "        return out\r\n",
        "\r\n",
        "    def show_params(self):\r\n",
        "        for m in self.modules():\r\n",
        "            if isinstance(m, QuantConv2d):\r\n",
        "                m.show_params()\r\n",
        "\r\n",
        "\r\n",
        "def DenseNet121():\r\n",
        "    return DenseNet(Bottleneck, [6,12,24,16], growth_rate=32)\r\n",
        "\r\n",
        "def DenseNet169():\r\n",
        "    return DenseNet(Bottleneck, [6,12,32,32], growth_rate=32)\r\n",
        "\r\n",
        "def DenseNet201():\r\n",
        "    return DenseNet(Bottleneck, [6,12,48,32], growth_rate=32)\r\n",
        "\r\n",
        "def DenseNet161():\r\n",
        "    return DenseNet(Bottleneck, [6,12,36,24], growth_rate=48)\r\n",
        "\r\n",
        "def densenet_cifar():\r\n",
        "    return DenseNet(Bottleneck, [6,12,24,16], growth_rate=12)\r\n",
        "\r\n",
        "def densenet_cifar_quant():\r\n",
        "    return DenseNet_Quant(Bottleneck_Quant, [6,12,24,16], growth_rate=12)\r\n",
        "\r\n",
        "def test():\r\n",
        "    net = densenet_cifar()\r\n",
        "    x = torch.randn(1,3,32,32)\r\n",
        "    y = net(x)\r\n",
        "    print(y)\r\n",
        "\r\n",
        "# test()\r\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ahqmM3nQQQD",
        "outputId": "fd41c15c-1c07-4794-9d30-c42a18e5278e"
      },
      "source": [
        "#model = DenseNet121()\n",
        "model = densenet_cifar()\n",
        "model.to(device=device)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DenseNet_Quant(\n",
              "  (conv1): QuantConv2d(\n",
              "    3, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
              "    (weight_quant): weight_quantize_fn()\n",
              "  )\n",
              "  (dense1): Sequential(\n",
              "    (0): Bottleneck_Quant(\n",
              "      (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): QuantConv2d(\n",
              "        24, 48, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (weight_quant): weight_quantize_fn()\n",
              "      )\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): QuantConv2d(\n",
              "        48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
              "        (weight_quant): weight_quantize_fn()\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck_Quant(\n",
              "      (bn1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): QuantConv2d(\n",
              "        36, 48, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (weight_quant): weight_quantize_fn()\n",
              "      )\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): QuantConv2d(\n",
              "        48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
              "        (weight_quant): weight_quantize_fn()\n",
              "      )\n",
              "    )\n",
              "    (2): Bottleneck_Quant(\n",
              "      (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): QuantConv2d(\n",
              "        48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (weight_quant): weight_quantize_fn()\n",
              "      )\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): QuantConv2d(\n",
              "        48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
              "        (weight_quant): weight_quantize_fn()\n",
              "      )\n",
              "    )\n",
              "    (3): Bottleneck_Quant(\n",
              "      (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): QuantConv2d(\n",
              "        60, 48, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (weight_quant): weight_quantize_fn()\n",
              "      )\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): QuantConv2d(\n",
              "        48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
              "        (weight_quant): weight_quantize_fn()\n",
              "      )\n",
              "    )\n",
              "    (4): Bottleneck_Quant(\n",
              "      (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): QuantConv2d(\n",
              "        72, 48, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (weight_quant): weight_quantize_fn()\n",
              "      )\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): QuantConv2d(\n",
              "        48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
              "        (weight_quant): weight_quantize_fn()\n",
              "      )\n",
              "    )\n",
              "    (5): Bottleneck_Quant(\n",
              "      (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): QuantConv2d(\n",
              "        84, 48, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (weight_quant): weight_quantize_fn()\n",
              "      )\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): QuantConv2d(\n",
              "        48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
              "        (weight_quant): weight_quantize_fn()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (trans1): Transition_Quant(\n",
              "    (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (conv): QuantConv2d(\n",
              "      96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "      (weight_quant): weight_quantize_fn()\n",
              "    )\n",
              "  )\n",
              "  (dense2): Sequential(\n",
              "    (0): Bottleneck_Quant(\n",
              "      (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): QuantConv2d(\n",
              "        48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (weight_quant): weight_quantize_fn()\n",
              "      )\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): QuantConv2d(\n",
              "        48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
              "        (weight_quant): weight_quantize_fn()\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck_Quant(\n",
              "      (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): QuantConv2d(\n",
              "        60, 48, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (weight_quant): weight_quantize_fn()\n",
              "      )\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): QuantConv2d(\n",
              "        48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
              "        (weight_quant): weight_quantize_fn()\n",
              "      )\n",
              "    )\n",
              "    (2): Bottleneck_Quant(\n",
              "      (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): QuantConv2d(\n",
              "        72, 48, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (weight_quant): weight_quantize_fn()\n",
              "      )\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): QuantConv2d(\n",
              "        48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
              "        (weight_quant): weight_quantize_fn()\n",
              "      )\n",
              "    )\n",
              "    (3): Bottleneck_Quant(\n",
              "      (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): QuantConv2d(\n",
              "        84, 48, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (weight_quant): weight_quantize_fn()\n",
              "      )\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): QuantConv2d(\n",
              "        48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
              "        (weight_quant): weight_quantize_fn()\n",
              "      )\n",
              "    )\n",
              "    (4): Bottleneck_Quant(\n",
              "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): QuantConv2d(\n",
              "        96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (weight_quant): weight_quantize_fn()\n",
              "      )\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): QuantConv2d(\n",
              "        48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
              "        (weight_quant): weight_quantize_fn()\n",
              "      )\n",
              "    )\n",
              "    (5): Bottleneck_Quant(\n",
              "      (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): QuantConv2d(\n",
              "        108, 48, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (weight_quant): weight_quantize_fn()\n",
              "      )\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): QuantConv2d(\n",
              "        48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
              "        (weight_quant): weight_quantize_fn()\n",
              "      )\n",
              "    )\n",
              "    (6): Bottleneck_Quant(\n",
              "      (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): QuantConv2d(\n",
              "        120, 48, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (weight_quant): weight_quantize_fn()\n",
              "      )\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): QuantConv2d(\n",
              "        48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
              "        (weight_quant): weight_quantize_fn()\n",
              "      )\n",
              "    )\n",
              "    (7): Bottleneck_Quant(\n",
              "      (bn1): BatchNorm2d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): QuantConv2d(\n",
              "        132, 48, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (weight_quant): weight_quantize_fn()\n",
              "      )\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): QuantConv2d(\n",
              "        48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
              "        (weight_quant): weight_quantize_fn()\n",
              "      )\n",
              "    )\n",
              "    (8): Bottleneck_Quant(\n",
              "      (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): QuantConv2d(\n",
              "        144, 48, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (weight_quant): weight_quantize_fn()\n",
              "      )\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): QuantConv2d(\n",
              "        48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
              "        (weight_quant): weight_quantize_fn()\n",
              "      )\n",
              "    )\n",
              "    (9): Bottleneck_Quant(\n",
              "      (bn1): BatchNorm2d(156, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): QuantConv2d(\n",
              "        156, 48, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (weight_quant): weight_quantize_fn()\n",
              "      )\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): QuantConv2d(\n",
              "        48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
              "        (weight_quant): weight_quantize_fn()\n",
              "      )\n",
              "    )\n",
              "    (10): Bottleneck_Quant(\n",
              "      (bn1): BatchNorm2d(168, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): QuantConv2d(\n",
              "        168, 48, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (weight_quant): weight_quantize_fn()\n",
              "      )\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): QuantConv2d(\n",
              "        48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
              "        (weight_quant): weight_quantize_fn()\n",
              "      )\n",
              "    )\n",
              "    (11): Bottleneck_Quant(\n",
              "      (bn1): BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): QuantConv2d(\n",
              "        180, 48, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (weight_quant): weight_quantize_fn()\n",
              "      )\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): QuantConv2d(\n",
              "        48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
              "        (weight_quant): weight_quantize_fn()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (trans2): Transition_Quant(\n",
              "    (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (conv): QuantConv2d(\n",
              "      192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "      (weight_quant): weight_quantize_fn()\n",
              "    )\n",
              "  )\n",
              "  (dense3): Sequential(\n",
              "    (0): Bottleneck_Quant(\n",
              "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): QuantConv2d(\n",
              "        96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (weight_quant): weight_quantize_fn()\n",
              "      )\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): QuantConv2d(\n",
              "        48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
              "        (weight_quant): weight_quantize_fn()\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck_Quant(\n",
              "      (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): QuantConv2d(\n",
              "        108, 48, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (weight_quant): weight_quantize_fn()\n",
              "      )\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): QuantConv2d(\n",
              "        48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
              "        (weight_quant): weight_quantize_fn()\n",
              "      )\n",
              "    )\n",
              "    (2): Bottleneck_Quant(\n",
              "      (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): QuantConv2d(\n",
              "        120, 48, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (weight_quant): weight_quantize_fn()\n",
              "      )\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): QuantConv2d(\n",
              "        48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
              "        (weight_quant): weight_quantize_fn()\n",
              "      )\n",
              "    )\n",
              "    (3): Bottleneck_Quant(\n",
              "      (bn1): BatchNorm2d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): QuantConv2d(\n",
              "        132, 48, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (weight_quant): weight_quantize_fn()\n",
              "      )\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): QuantConv2d(\n",
              "        48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
              "        (weight_quant): weight_quantize_fn()\n",
              "      )\n",
              "    )\n",
              "    (4): Bottleneck_Quant(\n",
              "      (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): QuantConv2d(\n",
              "        144, 48, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (weight_quant): weight_quantize_fn()\n",
              "      )\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): QuantConv2d(\n",
              "        48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
              "        (weight_quant): weight_quantize_fn()\n",
              "      )\n",
              "    )\n",
              "    (5): Bottleneck_Quant(\n",
              "      (bn1): BatchNorm2d(156, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): QuantConv2d(\n",
              "        156, 48, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (weight_quant): weight_quantize_fn()\n",
              "      )\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): QuantConv2d(\n",
              "        48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
              "        (weight_quant): weight_quantize_fn()\n",
              "      )\n",
              "    )\n",
              "    (6): Bottleneck_Quant(\n",
              "      (bn1): BatchNorm2d(168, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): QuantConv2d(\n",
              "        168, 48, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (weight_quant): weight_quantize_fn()\n",
              "      )\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): QuantConv2d(\n",
              "        48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
              "        (weight_quant): weight_quantize_fn()\n",
              "      )\n",
              "    )\n",
              "    (7): Bottleneck_Quant(\n",
              "      (bn1): BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): QuantConv2d(\n",
              "        180, 48, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (weight_quant): weight_quantize_fn()\n",
              "      )\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): QuantConv2d(\n",
              "        48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
              "        (weight_quant): weight_quantize_fn()\n",
              "      )\n",
              "    )\n",
              "    (8): Bottleneck_Quant(\n",
              "      (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): QuantConv2d(\n",
              "        192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (weight_quant): weight_quantize_fn()\n",
              "      )\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): QuantConv2d(\n",
              "        48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
              "        (weight_quant): weight_quantize_fn()\n",
              "      )\n",
              "    )\n",
              "    (9): Bottleneck_Quant(\n",
              "      (bn1): BatchNorm2d(204, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): QuantConv2d(\n",
              "        204, 48, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (weight_quant): weight_quantize_fn()\n",
              "      )\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): QuantConv2d(\n",
              "        48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
              "        (weight_quant): weight_quantize_fn()\n",
              "      )\n",
              "    )\n",
              "    (10): Bottleneck_Quant(\n",
              "      (bn1): BatchNorm2d(216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): QuantConv2d(\n",
              "        216, 48, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (weight_quant): weight_quantize_fn()\n",
              "      )\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): QuantConv2d(\n",
              "        48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
              "        (weight_quant): weight_quantize_fn()\n",
              "      )\n",
              "    )\n",
              "    (11): Bottleneck_Quant(\n",
              "      (bn1): BatchNorm2d(228, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): QuantConv2d(\n",
              "        228, 48, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (weight_quant): weight_quantize_fn()\n",
              "      )\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): QuantConv2d(\n",
              "        48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
              "        (weight_quant): weight_quantize_fn()\n",
              "      )\n",
              "    )\n",
              "    (12): Bottleneck_Quant(\n",
              "      (bn1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): QuantConv2d(\n",
              "        240, 48, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (weight_quant): weight_quantize_fn()\n",
              "      )\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): QuantConv2d(\n",
              "        48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
              "        (weight_quant): weight_quantize_fn()\n",
              "      )\n",
              "    )\n",
              "    (13): Bottleneck_Quant(\n",
              "      (bn1): BatchNorm2d(252, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): QuantConv2d(\n",
              "        252, 48, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (weight_quant): weight_quantize_fn()\n",
              "      )\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): QuantConv2d(\n",
              "        48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
              "        (weight_quant): weight_quantize_fn()\n",
              "      )\n",
              "    )\n",
              "    (14): Bottleneck_Quant(\n",
              "      (bn1): BatchNorm2d(264, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): QuantConv2d(\n",
              "        264, 48, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (weight_quant): weight_quantize_fn()\n",
              "      )\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): QuantConv2d(\n",
              "        48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
              "        (weight_quant): weight_quantize_fn()\n",
              "      )\n",
              "    )\n",
              "    (15): Bottleneck_Quant(\n",
              "      (bn1): BatchNorm2d(276, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): QuantConv2d(\n",
              "        276, 48, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (weight_quant): weight_quantize_fn()\n",
              "      )\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): QuantConv2d(\n",
              "        48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
              "        (weight_quant): weight_quantize_fn()\n",
              "      )\n",
              "    )\n",
              "    (16): Bottleneck_Quant(\n",
              "      (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): QuantConv2d(\n",
              "        288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (weight_quant): weight_quantize_fn()\n",
              "      )\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): QuantConv2d(\n",
              "        48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
              "        (weight_quant): weight_quantize_fn()\n",
              "      )\n",
              "    )\n",
              "    (17): Bottleneck_Quant(\n",
              "      (bn1): BatchNorm2d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): QuantConv2d(\n",
              "        300, 48, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (weight_quant): weight_quantize_fn()\n",
              "      )\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): QuantConv2d(\n",
              "        48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
              "        (weight_quant): weight_quantize_fn()\n",
              "      )\n",
              "    )\n",
              "    (18): Bottleneck_Quant(\n",
              "      (bn1): BatchNorm2d(312, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): QuantConv2d(\n",
              "        312, 48, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (weight_quant): weight_quantize_fn()\n",
              "      )\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): QuantConv2d(\n",
              "        48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
              "        (weight_quant): weight_quantize_fn()\n",
              "      )\n",
              "    )\n",
              "    (19): Bottleneck_Quant(\n",
              "      (bn1): BatchNorm2d(324, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): QuantConv2d(\n",
              "        324, 48, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (weight_quant): weight_quantize_fn()\n",
              "      )\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): QuantConv2d(\n",
              "        48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
              "        (weight_quant): weight_quantize_fn()\n",
              "      )\n",
              "    )\n",
              "    (20): Bottleneck_Quant(\n",
              "      (bn1): BatchNorm2d(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): QuantConv2d(\n",
              "        336, 48, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (weight_quant): weight_quantize_fn()\n",
              "      )\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): QuantConv2d(\n",
              "        48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
              "        (weight_quant): weight_quantize_fn()\n",
              "      )\n",
              "    )\n",
              "    (21): Bottleneck_Quant(\n",
              "      (bn1): BatchNorm2d(348, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): QuantConv2d(\n",
              "        348, 48, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (weight_quant): weight_quantize_fn()\n",
              "      )\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): QuantConv2d(\n",
              "        48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
              "        (weight_quant): weight_quantize_fn()\n",
              "      )\n",
              "    )\n",
              "    (22): Bottleneck_Quant(\n",
              "      (bn1): BatchNorm2d(360, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): QuantConv2d(\n",
              "        360, 48, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (weight_quant): weight_quantize_fn()\n",
              "      )\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): QuantConv2d(\n",
              "        48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
              "        (weight_quant): weight_quantize_fn()\n",
              "      )\n",
              "    )\n",
              "    (23): Bottleneck_Quant(\n",
              "      (bn1): BatchNorm2d(372, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): QuantConv2d(\n",
              "        372, 48, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (weight_quant): weight_quantize_fn()\n",
              "      )\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): QuantConv2d(\n",
              "        48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
              "        (weight_quant): weight_quantize_fn()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (trans3): Transition_Quant(\n",
              "    (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (conv): QuantConv2d(\n",
              "      384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "      (weight_quant): weight_quantize_fn()\n",
              "    )\n",
              "  )\n",
              "  (dense4): Sequential(\n",
              "    (0): Bottleneck_Quant(\n",
              "      (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): QuantConv2d(\n",
              "        192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (weight_quant): weight_quantize_fn()\n",
              "      )\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): QuantConv2d(\n",
              "        48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
              "        (weight_quant): weight_quantize_fn()\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck_Quant(\n",
              "      (bn1): BatchNorm2d(204, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): QuantConv2d(\n",
              "        204, 48, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (weight_quant): weight_quantize_fn()\n",
              "      )\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): QuantConv2d(\n",
              "        48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
              "        (weight_quant): weight_quantize_fn()\n",
              "      )\n",
              "    )\n",
              "    (2): Bottleneck_Quant(\n",
              "      (bn1): BatchNorm2d(216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): QuantConv2d(\n",
              "        216, 48, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (weight_quant): weight_quantize_fn()\n",
              "      )\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): QuantConv2d(\n",
              "        48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
              "        (weight_quant): weight_quantize_fn()\n",
              "      )\n",
              "    )\n",
              "    (3): Bottleneck_Quant(\n",
              "      (bn1): BatchNorm2d(228, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): QuantConv2d(\n",
              "        228, 48, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (weight_quant): weight_quantize_fn()\n",
              "      )\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): QuantConv2d(\n",
              "        48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
              "        (weight_quant): weight_quantize_fn()\n",
              "      )\n",
              "    )\n",
              "    (4): Bottleneck_Quant(\n",
              "      (bn1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): QuantConv2d(\n",
              "        240, 48, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (weight_quant): weight_quantize_fn()\n",
              "      )\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): QuantConv2d(\n",
              "        48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
              "        (weight_quant): weight_quantize_fn()\n",
              "      )\n",
              "    )\n",
              "    (5): Bottleneck_Quant(\n",
              "      (bn1): BatchNorm2d(252, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): QuantConv2d(\n",
              "        252, 48, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (weight_quant): weight_quantize_fn()\n",
              "      )\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): QuantConv2d(\n",
              "        48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
              "        (weight_quant): weight_quantize_fn()\n",
              "      )\n",
              "    )\n",
              "    (6): Bottleneck_Quant(\n",
              "      (bn1): BatchNorm2d(264, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): QuantConv2d(\n",
              "        264, 48, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (weight_quant): weight_quantize_fn()\n",
              "      )\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): QuantConv2d(\n",
              "        48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
              "        (weight_quant): weight_quantize_fn()\n",
              "      )\n",
              "    )\n",
              "    (7): Bottleneck_Quant(\n",
              "      (bn1): BatchNorm2d(276, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): QuantConv2d(\n",
              "        276, 48, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (weight_quant): weight_quantize_fn()\n",
              "      )\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): QuantConv2d(\n",
              "        48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
              "        (weight_quant): weight_quantize_fn()\n",
              "      )\n",
              "    )\n",
              "    (8): Bottleneck_Quant(\n",
              "      (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): QuantConv2d(\n",
              "        288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (weight_quant): weight_quantize_fn()\n",
              "      )\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): QuantConv2d(\n",
              "        48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
              "        (weight_quant): weight_quantize_fn()\n",
              "      )\n",
              "    )\n",
              "    (9): Bottleneck_Quant(\n",
              "      (bn1): BatchNorm2d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): QuantConv2d(\n",
              "        300, 48, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (weight_quant): weight_quantize_fn()\n",
              "      )\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): QuantConv2d(\n",
              "        48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
              "        (weight_quant): weight_quantize_fn()\n",
              "      )\n",
              "    )\n",
              "    (10): Bottleneck_Quant(\n",
              "      (bn1): BatchNorm2d(312, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): QuantConv2d(\n",
              "        312, 48, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (weight_quant): weight_quantize_fn()\n",
              "      )\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): QuantConv2d(\n",
              "        48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
              "        (weight_quant): weight_quantize_fn()\n",
              "      )\n",
              "    )\n",
              "    (11): Bottleneck_Quant(\n",
              "      (bn1): BatchNorm2d(324, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): QuantConv2d(\n",
              "        324, 48, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (weight_quant): weight_quantize_fn()\n",
              "      )\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): QuantConv2d(\n",
              "        48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
              "        (weight_quant): weight_quantize_fn()\n",
              "      )\n",
              "    )\n",
              "    (12): Bottleneck_Quant(\n",
              "      (bn1): BatchNorm2d(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): QuantConv2d(\n",
              "        336, 48, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (weight_quant): weight_quantize_fn()\n",
              "      )\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): QuantConv2d(\n",
              "        48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
              "        (weight_quant): weight_quantize_fn()\n",
              "      )\n",
              "    )\n",
              "    (13): Bottleneck_Quant(\n",
              "      (bn1): BatchNorm2d(348, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): QuantConv2d(\n",
              "        348, 48, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (weight_quant): weight_quantize_fn()\n",
              "      )\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): QuantConv2d(\n",
              "        48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
              "        (weight_quant): weight_quantize_fn()\n",
              "      )\n",
              "    )\n",
              "    (14): Bottleneck_Quant(\n",
              "      (bn1): BatchNorm2d(360, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): QuantConv2d(\n",
              "        360, 48, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (weight_quant): weight_quantize_fn()\n",
              "      )\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): QuantConv2d(\n",
              "        48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
              "        (weight_quant): weight_quantize_fn()\n",
              "      )\n",
              "    )\n",
              "    (15): Bottleneck_Quant(\n",
              "      (bn1): BatchNorm2d(372, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): QuantConv2d(\n",
              "        372, 48, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (weight_quant): weight_quantize_fn()\n",
              "      )\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): QuantConv2d(\n",
              "        48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
              "        (weight_quant): weight_quantize_fn()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (linear): Linear(in_features=384, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bew5LaNhaFqr",
        "outputId": "df3dcb22-9b41-4ec4-ffab-7d5d59e39067"
      },
      "source": [
        "loaded_cpt=torch.load('model_densenet121_moinsepochs.pt')\r\n",
        "model.load_state_dict(loaded_cpt)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aHWyF4tTg7yT",
        "outputId": "beb5a7e5-3a6a-49ff-8208-a9af36568a6a"
      },
      "source": [
        "pytorch_total_params = sum(p.numel() for p in model_quant.parameters())\r\n",
        "pytorch_total_params_training = sum(p.numel() for p in model.parameters() if p.requires_grad)\r\n",
        "print(pytorch_total_params)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000850\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qup2GPnvsbjz"
      },
      "source": [
        "optimizer = torch.optim.SGD(model.parameters(),lr = 0.01)\r\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jaGghNTTQQQE"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(),lr=0.1, momentum=0.9,weight_decay=5e-4) #weight_decay=1e-4\n",
        "\n",
        "from torch.optim.lr_scheduler import MultiStepLR\n",
        "\n",
        "scheduler = MultiStepLR(optimizer, milestones=[150, 250], gamma=0.1)\n",
        "# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2AlbZJntsobK"
      },
      "source": [
        "train_losses, valid_losses, train_acc, valid_acc = training(trainloader, validloader, model, criterion, optimizer,n_epochs=350)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YwWTkVCWfBLM",
        "outputId": "4c4c6a7d-3ce5-4026-aa22-d6de235f4f09"
      },
      "source": [
        "evaluation(model, testloader, criterion)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test Loss: 0.218348\n",
            "\n",
            "test accuracy of plane: 95% (952/1000)\n",
            "test accuracy of car: 97% (976/1000)\n",
            "test accuracy of bird: 91% (917/1000)\n",
            "test accuracy of cat: 83% (837/1000)\n",
            "test accuracy of deer: 95% (957/1000)\n",
            "test accuracy of dog: 90% (902/1000)\n",
            "test accuracy of frog: 94% (947/1000)\n",
            "test accuracy of horse: 95% (950/1000)\n",
            "test accuracy of ship: 94% (947/1000)\n",
            "test accuracy of truck: 93% (933/1000)\n",
            "\n",
            "test accuracy (overall): 93.18% (9318/10000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gTaTBkSMQQQF"
      },
      "source": [
        "torch.save(model.state_dict(), 'model_densenet121_v1.pt')\n",
        "# 22"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OqhRwBtvQQQF"
      },
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "\n",
        "plt.subplot(3,1,1)\n",
        "plt.plot(range(n_epochs), train_losses)\n",
        "plt.plot(range(n_epochs), valid_losses)\n",
        "\n",
        "plt.legend(['train', 'validation'], prop={'size': 10})\n",
        "plt.title('loss function', size=10)\n",
        "plt.xlabel('epoch', size=10)\n",
        "plt.ylabel('loss value', size=10)\n",
        "\n",
        "plt.subplot(3,1,3)\n",
        "plt.plot(range(n_epochs), train_acc)\n",
        "plt.plot(range(n_epochs), valid_acc)\n",
        "\n",
        "plt.legend(['train', 'validation'], prop={'size': 10})\n",
        "plt.title('accuracy', size=10)\n",
        "plt.xlabel('epoch', size=10)\n",
        "plt.ylabel('acc value', size=10)\n",
        "plt.savefig(\"Densenet161_training_scratch.png\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w38B9iUbq0eQ"
      },
      "source": [
        "# Quantization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ak09y00ELPfC"
      },
      "source": [
        "import torch.nn as nn\r\n",
        "import torch\r\n",
        "import torch.nn.functional as F\r\n",
        "from torch.nn.parameter import Parameter\r\n",
        "\r\n",
        "\r\n",
        "# this function construct an additive pot quantization levels set, with clipping threshold = 1,\r\n",
        "def build_power_value(B=2, additive=True):\r\n",
        "    base_a = [0.]\r\n",
        "    base_b = [0.]\r\n",
        "    base_c = [0.]\r\n",
        "    if additive:\r\n",
        "        if B == 2:\r\n",
        "            for i in range(3):\r\n",
        "                base_a.append(2 ** (-i - 1))\r\n",
        "        elif B == 4:\r\n",
        "            for i in range(3):\r\n",
        "                base_a.append(2 ** (-2 * i - 1))\r\n",
        "                base_b.append(2 ** (-2 * i - 2))\r\n",
        "        elif B == 6:\r\n",
        "            for i in range(3):\r\n",
        "                base_a.append(2 ** (-3 * i - 1))\r\n",
        "                base_b.append(2 ** (-3 * i - 2))\r\n",
        "                base_c.append(2 ** (-3 * i - 3))\r\n",
        "        elif B == 3:\r\n",
        "            for i in range(3):\r\n",
        "                if i < 2:\r\n",
        "                    base_a.append(2 ** (-i - 1))\r\n",
        "                else:\r\n",
        "                    base_b.append(2 ** (-i - 1))\r\n",
        "                    base_a.append(2 ** (-i - 2))\r\n",
        "        elif B == 5:\r\n",
        "            for i in range(3):\r\n",
        "                if i < 2:\r\n",
        "                    base_a.append(2 ** (-2 * i - 1))\r\n",
        "                    base_b.append(2 ** (-2 * i - 2))\r\n",
        "                else:\r\n",
        "                    base_c.append(2 ** (-2 * i - 1))\r\n",
        "                    base_a.append(2 ** (-2 * i - 2))\r\n",
        "                    base_b.append(2 ** (-2 * i - 3))\r\n",
        "        else:\r\n",
        "            pass\r\n",
        "    else:\r\n",
        "        for i in range(2 ** B - 1):\r\n",
        "            base_a.append(2 ** (-i - 1))\r\n",
        "    values = []\r\n",
        "    for a in base_a:\r\n",
        "        for b in base_b:\r\n",
        "            for c in base_c:\r\n",
        "                values.append((a + b + c))\r\n",
        "    values = torch.Tensor(list(set(values)))\r\n",
        "    values = values.mul(1.0 / torch.max(values))\r\n",
        "    return values\r\n",
        "\r\n",
        "\r\n",
        "def weight_quantization(b, grids, power=True):\r\n",
        "\r\n",
        "    def uniform_quant(x, b):\r\n",
        "        xdiv = x.mul((2 ** b - 1))\r\n",
        "        xhard = xdiv.round().div(2 ** b - 1)\r\n",
        "        return xhard\r\n",
        "\r\n",
        "    def power_quant(x, value_s):\r\n",
        "        shape = x.shape\r\n",
        "        xhard = x.view(-1)\r\n",
        "        value_s = value_s.type_as(x)\r\n",
        "        idxs = (xhard.unsqueeze(0) - value_s.unsqueeze(1)).abs().min(dim=0)[1]  # project to nearest quantization level\r\n",
        "        xhard = value_s[idxs].view(shape)\r\n",
        "        # xout = (xhard - x).detach() + x\r\n",
        "        return xhard\r\n",
        "\r\n",
        "    class _pq(torch.autograd.Function):\r\n",
        "        @staticmethod\r\n",
        "        def forward(ctx, input, alpha):\r\n",
        "            input.div_(alpha)                          # weights are first divided by alpha\r\n",
        "            input_c = input.clamp(min=-1, max=1)       # then clipped to [-1,1]\r\n",
        "            sign = input_c.sign()\r\n",
        "            input_abs = input_c.abs()\r\n",
        "            if power:\r\n",
        "                input_q = power_quant(input_abs, grids).mul(sign)  # project to Q^a(alpha, B)\r\n",
        "            else:\r\n",
        "                input_q = uniform_quant(input_abs, b).mul(sign)\r\n",
        "            ctx.save_for_backward(input, input_q)\r\n",
        "            input_q = input_q.mul(alpha)               # rescale to the original range\r\n",
        "            return input_q\r\n",
        "\r\n",
        "        @staticmethod\r\n",
        "        def backward(ctx, grad_output):\r\n",
        "            grad_input = grad_output.clone()             # grad for weights will not be clipped\r\n",
        "            input, input_q = ctx.saved_tensors\r\n",
        "            i = (input.abs()>1.).float()\r\n",
        "            sign = input.sign()\r\n",
        "            grad_alpha = (grad_output*(sign*i + (input_q-input)*(1-i))).sum()\r\n",
        "            return grad_input, grad_alpha\r\n",
        "\r\n",
        "    return _pq().apply\r\n",
        "\r\n",
        "\r\n",
        "class weight_quantize_fn(nn.Module):\r\n",
        "    def __init__(self, w_bit, power=True):\r\n",
        "        super(weight_quantize_fn, self).__init__()\r\n",
        "        assert (w_bit <=5 and w_bit > 0) or w_bit == 32\r\n",
        "        self.w_bit = w_bit-1\r\n",
        "        self.power = power if w_bit>2 else False\r\n",
        "        self.grids = build_power_value(self.w_bit, additive=True)\r\n",
        "        self.weight_q = weight_quantization(b=self.w_bit, grids=self.grids, power=self.power)\r\n",
        "        self.register_parameter('wgt_alpha', Parameter(torch.tensor(3.0)))\r\n",
        "\r\n",
        "    def forward(self, weight):\r\n",
        "        if self.w_bit == 32:\r\n",
        "            weight_q = weight\r\n",
        "        else:\r\n",
        "            mean = weight.data.mean()\r\n",
        "            std = weight.data.std()\r\n",
        "            weight = weight.add(-mean).div(std)      # weights normalization\r\n",
        "            weight_q = self.weight_q(weight, self.wgt_alpha)\r\n",
        "        return weight_q\r\n",
        "\r\n",
        "\r\n",
        "def act_quantization(b, grid, power=True):\r\n",
        "\r\n",
        "    def uniform_quant(x, b=3):\r\n",
        "        xdiv = x.mul(2 ** b - 1)\r\n",
        "        xhard = xdiv.round().div(2 ** b - 1)\r\n",
        "        return xhard\r\n",
        "\r\n",
        "    def power_quant(x, grid):\r\n",
        "        shape = x.shape\r\n",
        "        xhard = x.view(-1)\r\n",
        "        value_s = grid.type_as(x)\r\n",
        "        idxs = (xhard.unsqueeze(0) - value_s.unsqueeze(1)).abs().min(dim=0)[1]\r\n",
        "        xhard = value_s[idxs].view(shape)\r\n",
        "        return xhard\r\n",
        "\r\n",
        "    class _uq(torch.autograd.Function):\r\n",
        "        @staticmethod\r\n",
        "        def forward(ctx, input, alpha):\r\n",
        "            input=input.div(alpha)\r\n",
        "            input_c = input.clamp(max=1)\r\n",
        "            if power:\r\n",
        "                input_q = power_quant(input_c, grid)\r\n",
        "            else:\r\n",
        "                input_q = uniform_quant(input_c, b)\r\n",
        "            ctx.save_for_backward(input, input_q)\r\n",
        "            input_q = input_q.mul(alpha)\r\n",
        "            return input_q\r\n",
        "\r\n",
        "        @staticmethod\r\n",
        "        def backward(ctx, grad_output):\r\n",
        "            grad_input = grad_output.clone()\r\n",
        "            input, input_q = ctx.saved_tensors\r\n",
        "            i = (input > 1.).float()\r\n",
        "            grad_alpha = (grad_output * (i + (input_q - input) * (1 - i))).sum()\r\n",
        "            grad_input = grad_input*(1-i)\r\n",
        "            return grad_input, grad_alpha\r\n",
        "\r\n",
        "    return _uq().apply\r\n",
        "\r\n",
        "\r\n",
        "class QuantConv2d(nn.Conv2d):\r\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=False):\r\n",
        "        super(QuantConv2d, self).__init__(in_channels, out_channels, kernel_size, stride, padding, dilation, groups,\r\n",
        "                                          bias)\r\n",
        "        self.layer_type = 'QuantConv2d'\r\n",
        "        self.bit = 4\r\n",
        "        self.weight_quant = weight_quantize_fn(w_bit=self.bit, power=True)\r\n",
        "        self.act_grid = build_power_value(self.bit, additive=True)\r\n",
        "        self.act_alq = act_quantization(self.bit, self.act_grid, power=True)\r\n",
        "        self.act_alpha = torch.nn.Parameter(torch.tensor(8.0))\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        weight_q = self.weight_quant(self.weight)\r\n",
        "        x = self.act_alq(x, self.act_alpha)\r\n",
        "        return F.conv2d(x, weight_q, self.bias, self.stride,\r\n",
        "                        self.padding, self.dilation, self.groups)\r\n",
        "\r\n",
        "    def show_params(self):\r\n",
        "        wgt_alpha = round(self.weight_quant.wgt_alpha.data.item(), 3)\r\n",
        "        act_alpha = round(self.act_alpha.data.item(), 3)\r\n",
        "        print('clipping threshold weight alpha: {:2f}, activation alpha: {:2f}'.format(wgt_alpha, act_alpha))\r\n",
        "\r\n",
        "\r\n",
        "# 8-bit quantization for the first and the last layer\r\n",
        "class first_conv(nn.Conv2d):\r\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=False):\r\n",
        "        super(first_conv, self).__init__(in_channels, out_channels, kernel_size, stride, padding, dilation, groups, bias)\r\n",
        "        self.layer_type = 'FConv2d'\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        max = self.weight.data.max()\r\n",
        "        weight_q = self.weight.div(max).mul(127).round().div(127).mul(max)\r\n",
        "        weight_q = (weight_q-self.weight).detach()+self.weight\r\n",
        "        return F.conv2d(x, weight_q, self.bias, self.stride,\r\n",
        "                        self.padding, self.dilation, self.groups)\r\n",
        "\r\n",
        "class last_fc(nn.Linear):\r\n",
        "    def __init__(self, in_features, out_features, bias=True):\r\n",
        "        super(last_fc, self).__init__(in_features, out_features, bias)\r\n",
        "        self.layer_type = 'LFC'\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        max = self.weight.data.max()\r\n",
        "        weight_q = self.weight.div(max).mul(127).round().div(127).mul(max)\r\n",
        "        weight_q = (weight_q-self.weight).detach()+self.weight\r\n",
        "        return F.linear(x, weight_q, self.bias)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrPN9yGJrU8x"
      },
      "source": [
        "model_quant = densenet_cifar_quant()\r\n",
        "model_quant.to(device=device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7SnDPgFZHfG_"
      },
      "source": [
        "loaded_cpt_clone = loaded_cpt.copy()\r\n",
        "for key in loaded_cpt.keys():\r\n",
        "  if \"conv\" in key:\r\n",
        "    #print(key)\r\n",
        "    loaded_cpt_clone[key.replace(\"weight\",\"act_alpha\")] = torch.nn.Parameter(torch.tensor(8.0))\r\n",
        "    loaded_cpt_clone[key.replace(\"weight\",\"weight_quant.wgt_alpha\")] = Parameter(torch.tensor(3.0))"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WOYXEGREKP6I",
        "outputId": "ac16cfe7-2bdf-4f1c-a23f-13602c2fe680"
      },
      "source": [
        "model_quant.load_state_dict(loaded_cpt_clone)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ocZacUcqaYWy",
        "outputId": "76ad88fb-0a94-4cb3-99b7-428ee8f62aa2"
      },
      "source": [
        "module1 = model.dense1[0].conv1\r\n",
        "print(module1)\r\n",
        "#.weight_quant.wgt_alpha.data.item()\r\n",
        "print(module1.weight_quant(module1.weight))\r\n",
        "print(module1.weight)\r\n",
        "#print(module1.weight)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "QuantConv2d(\n",
            "  24, 48, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "  (weight_quant): weight_quantize_fn()\n",
            ")\n",
            "tensor([[[[-1.8000]],\n",
            "\n",
            "         [[-0.3000]],\n",
            "\n",
            "         [[-0.9000]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.3000]],\n",
            "\n",
            "         [[ 1.2000]],\n",
            "\n",
            "         [[ 0.9000]]],\n",
            "\n",
            "\n",
            "        [[[ 0.9000]],\n",
            "\n",
            "         [[ 1.8000]],\n",
            "\n",
            "         [[ 0.3000]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.9000]],\n",
            "\n",
            "         [[ 0.0000]],\n",
            "\n",
            "         [[ 0.0000]]],\n",
            "\n",
            "\n",
            "        [[[-0.0000]],\n",
            "\n",
            "         [[ 1.2000]],\n",
            "\n",
            "         [[ 0.9000]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.6000]],\n",
            "\n",
            "         [[-0.9000]],\n",
            "\n",
            "         [[ 0.3000]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.3000]],\n",
            "\n",
            "         [[ 0.6000]],\n",
            "\n",
            "         [[-1.2000]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.2000]],\n",
            "\n",
            "         [[-0.0000]],\n",
            "\n",
            "         [[ 0.0000]]],\n",
            "\n",
            "\n",
            "        [[[-0.9000]],\n",
            "\n",
            "         [[-0.3000]],\n",
            "\n",
            "         [[-0.0000]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.2000]],\n",
            "\n",
            "         [[-0.0000]],\n",
            "\n",
            "         [[ 1.2000]]],\n",
            "\n",
            "\n",
            "        [[[-1.8000]],\n",
            "\n",
            "         [[ 0.6000]],\n",
            "\n",
            "         [[ 0.3000]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.6000]],\n",
            "\n",
            "         [[-1.2000]],\n",
            "\n",
            "         [[-1.2000]]]], device='cuda:0', grad_fn=<_pqBackward>)\n",
            "Parameter containing:\n",
            "tensor([[[[-0.1809]],\n",
            "\n",
            "         [[-0.0373]],\n",
            "\n",
            "         [[-0.1243]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0263]],\n",
            "\n",
            "         [[ 0.1331]],\n",
            "\n",
            "         [[ 0.0943]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0908]],\n",
            "\n",
            "         [[ 0.1839]],\n",
            "\n",
            "         [[ 0.0301]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.1015]],\n",
            "\n",
            "         [[ 0.0062]],\n",
            "\n",
            "         [[ 0.0070]]],\n",
            "\n",
            "\n",
            "        [[[-0.0046]],\n",
            "\n",
            "         [[ 0.1500]],\n",
            "\n",
            "         [[ 0.1170]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0690]],\n",
            "\n",
            "         [[-0.0997]],\n",
            "\n",
            "         [[ 0.0303]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.0449]],\n",
            "\n",
            "         [[ 0.0848]],\n",
            "\n",
            "         [[-0.1525]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.1505]],\n",
            "\n",
            "         [[-0.0150]],\n",
            "\n",
            "         [[ 0.0075]]],\n",
            "\n",
            "\n",
            "        [[[-0.0963]],\n",
            "\n",
            "         [[-0.0461]],\n",
            "\n",
            "         [[-0.0062]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.1481]],\n",
            "\n",
            "         [[-0.0097]],\n",
            "\n",
            "         [[ 0.1320]]],\n",
            "\n",
            "\n",
            "        [[[-0.1831]],\n",
            "\n",
            "         [[ 0.0641]],\n",
            "\n",
            "         [[ 0.0311]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0617]],\n",
            "\n",
            "         [[-0.1354]],\n",
            "\n",
            "         [[-0.1486]]]], device='cuda:0', requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Htr1Monhaoq7",
        "outputId": "062f39db-03e8-404a-c0f5-7493aa735d34"
      },
      "source": [
        "bit = 5\r\n",
        "for m in model.modules():\r\n",
        "  if isinstance(m, QuantConv2d):\r\n",
        "    m.weight_quant = weight_quantize_fn(w_bit=bit)\r\n",
        "    print(m.weight_quant(m.weight))\r\n",
        "    m.act_grid = build_power_value(bit)\r\n",
        "    m.act_alq = act_quantization(bit, m.act_grid)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mLe flux de sortie a Ã©tÃ© tronquÃ© et ne contient que les 5000Â derniÃ¨res lignes.\u001b[0m\n",
            "          [ 0.3750, -0.0625, -0.7500],\n",
            "          [ 1.1250,  0.7500,  0.2500]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.3750, -1.1250,  0.2500],\n",
            "          [ 0.1250,  1.5000,  1.5000],\n",
            "          [ 1.1250,  1.0000,  0.7500]],\n",
            "\n",
            "         [[-0.1875, -0.7500,  0.3750],\n",
            "          [ 0.5625, -1.1250,  0.0000],\n",
            "          [-1.0000,  0.7500, -1.5000]],\n",
            "\n",
            "         [[-1.1250,  0.1250,  0.3750],\n",
            "          [-1.5000,  1.1250,  1.5000],\n",
            "          [ 1.5000,  0.2500,  0.3750]]],\n",
            "\n",
            "\n",
            "        [[[-1.0000,  0.7500,  1.5000],\n",
            "          [-0.1250, -1.5000,  0.1875],\n",
            "          [-1.0000,  1.0000, -1.5000]],\n",
            "\n",
            "         [[ 0.3750,  1.1250,  0.5000],\n",
            "          [-0.7500, -1.0000, -0.3750],\n",
            "          [-0.2500, -1.5000,  0.7500]],\n",
            "\n",
            "         [[ 0.7500, -1.0000,  1.1250],\n",
            "          [ 1.1250, -1.5000,  1.5000],\n",
            "          [-0.5000, -0.5000,  1.5000]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.7500, -0.3750,  0.5000],\n",
            "          [-1.5000,  0.1875, -0.1250],\n",
            "          [ 1.5000,  0.7500,  0.2500]],\n",
            "\n",
            "         [[ 1.1250,  0.7500,  0.1250],\n",
            "          [ 1.1250,  1.5000,  1.5000],\n",
            "          [-1.5000,  1.0000, -1.5000]],\n",
            "\n",
            "         [[ 1.0000,  0.0625, -0.7500],\n",
            "          [-0.5000,  0.7500, -0.7500],\n",
            "          [-0.7500, -1.5000,  0.5625]]],\n",
            "\n",
            "\n",
            "        [[[-1.5000, -1.5000, -0.3750],\n",
            "          [ 1.5000,  1.1250, -0.2500],\n",
            "          [ 1.0000, -0.1875, -1.0000]],\n",
            "\n",
            "         [[-1.5000, -1.1250,  1.5000],\n",
            "          [ 1.0000, -0.1250, -1.5000],\n",
            "          [-1.0000,  0.5625, -0.3750]],\n",
            "\n",
            "         [[ 0.5000,  1.5000,  0.3750],\n",
            "          [ 0.2500,  0.1250,  0.5625],\n",
            "          [ 1.0000, -1.0000,  1.5000]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.5000, -0.3750, -1.5000],\n",
            "          [-0.5625, -1.5000, -0.7500],\n",
            "          [ 1.1250, -1.5000, -1.5000]],\n",
            "\n",
            "         [[-0.2500,  1.5000,  0.0625],\n",
            "          [-0.3750,  0.2500,  0.5000],\n",
            "          [-1.0000,  1.0000,  1.5000]],\n",
            "\n",
            "         [[-0.5000, -0.3750,  1.0000],\n",
            "          [-0.7500,  0.7500,  0.2500],\n",
            "          [-0.1250, -0.1250, -1.5000]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 1.5000, -0.3750, -1.5000],\n",
            "          [-0.0625, -1.0000, -1.5000],\n",
            "          [ 0.0625, -1.0000, -1.1250]],\n",
            "\n",
            "         [[ 1.5000, -0.5625, -0.2500],\n",
            "          [-1.0000, -1.1250,  1.5000],\n",
            "          [-0.7500, -1.5000, -0.7500]],\n",
            "\n",
            "         [[ 0.5625,  1.0000, -1.1250],\n",
            "          [ 0.0625, -1.0000, -1.1250],\n",
            "          [ 1.5000,  0.5000, -1.1250]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.0000, -0.7500, -0.7500],\n",
            "          [ 0.5625,  1.5000, -0.1875],\n",
            "          [-1.0000, -0.3750,  0.0625]],\n",
            "\n",
            "         [[ 1.0000,  1.1250,  1.1250],\n",
            "          [-1.5000, -0.3750, -0.2500],\n",
            "          [-0.3750,  1.5000, -0.7500]],\n",
            "\n",
            "         [[ 0.7500, -0.7500, -0.0625],\n",
            "          [-0.1875, -0.7500,  0.5000],\n",
            "          [-1.0000, -0.7500,  1.0000]]],\n",
            "\n",
            "\n",
            "        [[[ 1.1250,  1.0000, -0.7500],\n",
            "          [ 1.5000, -1.0000, -0.2500],\n",
            "          [ 1.5000, -0.3750, -0.7500]],\n",
            "\n",
            "         [[ 0.7500,  1.5000, -0.0625],\n",
            "          [ 1.5000, -0.5000,  0.3750],\n",
            "          [ 0.2500, -1.5000, -0.2500]],\n",
            "\n",
            "         [[ 1.5000, -0.7500,  0.2500],\n",
            "          [ 0.2500, -1.5000, -0.7500],\n",
            "          [-1.1250, -1.1250,  0.2500]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.3750,  1.5000,  1.1250],\n",
            "          [-0.5625,  0.2500, -0.3750],\n",
            "          [-1.1250, -0.5625,  1.1250]],\n",
            "\n",
            "         [[-0.3750,  1.5000,  1.1250],\n",
            "          [-1.5000, -1.1250, -1.5000],\n",
            "          [-0.5625, -0.2500, -1.0000]],\n",
            "\n",
            "         [[ 0.1250, -1.1250,  0.2500],\n",
            "          [-1.5000,  0.7500,  1.0000],\n",
            "          [ 1.5000, -0.5000,  0.0000]]],\n",
            "\n",
            "\n",
            "        [[[-0.0625, -0.3750,  1.0000],\n",
            "          [-0.1250,  1.5000, -1.5000],\n",
            "          [ 0.7500,  0.5625, -1.5000]],\n",
            "\n",
            "         [[-0.7500, -1.5000, -1.0000],\n",
            "          [-0.5625,  1.1250, -1.5000],\n",
            "          [-1.1250,  0.1875, -0.5625]],\n",
            "\n",
            "         [[ 0.3750,  1.1250,  0.0625],\n",
            "          [ 0.7500, -1.5000,  0.7500],\n",
            "          [-0.0625, -0.3750, -1.1250]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.7500, -1.5000,  1.0000],\n",
            "          [-1.1250,  0.1875, -0.5000],\n",
            "          [-0.0000,  1.0000,  1.1250]],\n",
            "\n",
            "         [[-0.5625, -1.1250, -0.7500],\n",
            "          [ 1.1250, -1.5000,  1.1250],\n",
            "          [ 0.7500, -0.7500,  0.3750]],\n",
            "\n",
            "         [[-0.0000,  1.5000, -1.1250],\n",
            "          [-0.5625,  1.5000, -1.1250],\n",
            "          [-1.0000, -1.0000,  0.5000]]]], device='cuda:0',\n",
            "       grad_fn=<_pqBackward>)\n",
            "tensor([[[[ 0.5000]],\n",
            "\n",
            "         [[-0.2500]],\n",
            "\n",
            "         [[-0.5000]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.5000]],\n",
            "\n",
            "         [[ 0.5000]],\n",
            "\n",
            "         [[-1.5000]]],\n",
            "\n",
            "\n",
            "        [[[ 1.5000]],\n",
            "\n",
            "         [[ 1.5000]],\n",
            "\n",
            "         [[ 0.3750]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.5000]],\n",
            "\n",
            "         [[ 0.7500]],\n",
            "\n",
            "         [[ 1.5000]]],\n",
            "\n",
            "\n",
            "        [[[ 1.5000]],\n",
            "\n",
            "         [[-0.7500]],\n",
            "\n",
            "         [[ 0.0000]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.1250]],\n",
            "\n",
            "         [[ 0.1875]],\n",
            "\n",
            "         [[ 1.1250]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-1.1250]],\n",
            "\n",
            "         [[ 0.5000]],\n",
            "\n",
            "         [[ 0.7500]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.7500]],\n",
            "\n",
            "         [[ 0.7500]],\n",
            "\n",
            "         [[ 0.5000]]],\n",
            "\n",
            "\n",
            "        [[[ 1.0000]],\n",
            "\n",
            "         [[-0.7500]],\n",
            "\n",
            "         [[-1.1250]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.7500]],\n",
            "\n",
            "         [[ 0.7500]],\n",
            "\n",
            "         [[ 0.5625]]],\n",
            "\n",
            "\n",
            "        [[[ 1.0000]],\n",
            "\n",
            "         [[-0.7500]],\n",
            "\n",
            "         [[ 0.5000]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.5000]],\n",
            "\n",
            "         [[ 1.1250]],\n",
            "\n",
            "         [[-0.7500]]]], device='cuda:0', grad_fn=<_pqBackward>)\n",
            "tensor([[[[ 1.0000, -1.0000, -0.2500],\n",
            "          [ 0.2500, -1.0000,  1.1250],\n",
            "          [ 1.1250, -1.1250,  0.1875]],\n",
            "\n",
            "         [[-0.7500, -0.0625, -0.5625],\n",
            "          [-1.5000, -0.0000,  1.1250],\n",
            "          [-1.0000, -0.3750, -1.1250]],\n",
            "\n",
            "         [[ 0.5625,  0.3750, -1.5000],\n",
            "          [ 1.0000, -0.5000, -0.1250],\n",
            "          [-0.2500, -0.7500, -0.7500]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.5000,  1.5000,  1.1250],\n",
            "          [-0.1875, -0.7500, -1.5000],\n",
            "          [ 0.0625, -0.7500, -0.3750]],\n",
            "\n",
            "         [[ 1.1250, -1.1250, -1.1250],\n",
            "          [-1.5000, -0.7500,  1.1250],\n",
            "          [-0.2500,  1.5000,  0.5625]],\n",
            "\n",
            "         [[ 0.1250, -0.5000, -1.5000],\n",
            "          [ 0.7500,  0.7500, -0.1250],\n",
            "          [ 0.0625,  1.5000,  1.1250]]],\n",
            "\n",
            "\n",
            "        [[[ 1.5000, -0.0625,  0.7500],\n",
            "          [ 1.1250,  1.5000,  0.3750],\n",
            "          [-1.1250, -1.5000, -1.5000]],\n",
            "\n",
            "         [[ 0.7500,  0.1875, -0.5625],\n",
            "          [ 0.0000,  0.7500, -0.3750],\n",
            "          [-1.5000,  1.0000,  0.7500]],\n",
            "\n",
            "         [[-0.1250, -0.7500,  0.0000],\n",
            "          [ 0.7500,  1.5000,  0.3750],\n",
            "          [-1.1250, -1.1250, -0.1250]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.5000,  1.0000, -0.3750],\n",
            "          [-0.7500,  1.1250, -1.1250],\n",
            "          [-0.5000,  1.5000,  0.5625]],\n",
            "\n",
            "         [[-0.1250, -0.5625, -0.7500],\n",
            "          [ 1.5000, -1.1250,  1.0000],\n",
            "          [ 1.1250,  1.5000,  0.1875]],\n",
            "\n",
            "         [[-1.5000,  1.1250, -0.5000],\n",
            "          [ 1.5000,  0.5625, -0.5625],\n",
            "          [ 1.5000,  1.5000,  0.5000]]],\n",
            "\n",
            "\n",
            "        [[[ 0.5625, -1.0000, -1.1250],\n",
            "          [-1.5000, -0.7500, -0.0625],\n",
            "          [-1.0000,  0.3750,  0.3750]],\n",
            "\n",
            "         [[ 0.1875,  0.5625, -1.5000],\n",
            "          [ 1.1250,  0.5625,  1.1250],\n",
            "          [-0.5625, -0.7500,  0.5625]],\n",
            "\n",
            "         [[-1.1250,  1.0000,  0.1250],\n",
            "          [-0.5625,  1.1250,  0.0625],\n",
            "          [ 1.5000,  0.1250, -1.1250]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.5000,  0.0625, -0.7500],\n",
            "          [ 1.0000, -1.5000,  1.0000],\n",
            "          [ 1.1250,  1.0000,  0.5000]],\n",
            "\n",
            "         [[ 0.7500,  0.0000, -0.5625],\n",
            "          [ 1.1250, -1.5000,  0.5625],\n",
            "          [ 1.0000,  1.1250, -1.0000]],\n",
            "\n",
            "         [[ 0.3750, -1.5000,  0.3750],\n",
            "          [-0.5625,  0.3750, -0.3750],\n",
            "          [-1.5000, -1.1250,  1.5000]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-1.5000, -0.7500, -0.3750],\n",
            "          [-0.3750,  0.3750,  1.0000],\n",
            "          [-0.7500,  1.0000,  1.1250]],\n",
            "\n",
            "         [[-0.2500, -1.1250,  0.5625],\n",
            "          [ 0.7500, -0.5000,  1.1250],\n",
            "          [-0.7500,  1.5000, -1.0000]],\n",
            "\n",
            "         [[ 0.7500, -1.1250, -0.1250],\n",
            "          [ 0.7500,  0.2500,  0.7500],\n",
            "          [-1.5000,  1.0000, -1.5000]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.0000,  1.1250, -1.5000],\n",
            "          [-1.0000,  0.5000, -0.3750],\n",
            "          [-1.5000,  1.0000, -0.5625]],\n",
            "\n",
            "         [[ 1.5000,  1.5000,  0.5625],\n",
            "          [-1.0000,  0.5625, -1.5000],\n",
            "          [ 1.5000, -1.5000,  0.5000]],\n",
            "\n",
            "         [[ 1.5000, -0.3750, -1.5000],\n",
            "          [-1.0000,  0.5625,  0.7500],\n",
            "          [ 0.5000,  0.7500, -0.0625]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0625,  0.0000,  0.0000],\n",
            "          [-1.5000, -1.5000, -1.5000],\n",
            "          [ 0.1875, -0.0000,  1.0000]],\n",
            "\n",
            "         [[-1.1250,  0.5000, -1.0000],\n",
            "          [-0.1250,  1.1250, -0.7500],\n",
            "          [ 0.2500,  0.7500,  1.5000]],\n",
            "\n",
            "         [[-1.0000,  1.0000, -1.5000],\n",
            "          [ 1.0000,  1.1250, -1.1250],\n",
            "          [ 0.2500, -1.1250,  0.7500]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0625,  1.5000,  1.1250],\n",
            "          [ 0.1875, -0.3750,  0.7500],\n",
            "          [-1.1250, -0.0625, -0.0000]],\n",
            "\n",
            "         [[ 1.5000,  1.5000, -0.1250],\n",
            "          [-1.5000, -1.1250, -1.1250],\n",
            "          [-1.1250, -1.1250, -1.5000]],\n",
            "\n",
            "         [[ 1.5000, -0.2500,  1.1250],\n",
            "          [-1.5000,  1.1250,  0.1875],\n",
            "          [-0.2500,  1.5000,  1.5000]]],\n",
            "\n",
            "\n",
            "        [[[ 0.3750,  1.5000,  0.3750],\n",
            "          [-1.5000, -1.5000, -0.7500],\n",
            "          [-1.1250, -1.5000,  1.1250]],\n",
            "\n",
            "         [[-0.7500,  1.5000,  0.3750],\n",
            "          [ 0.7500,  0.3750, -0.7500],\n",
            "          [-1.1250,  0.1250, -1.1250]],\n",
            "\n",
            "         [[ 1.5000, -1.5000,  1.5000],\n",
            "          [ 0.1875,  0.0625, -0.7500],\n",
            "          [-1.0000, -0.3750, -1.5000]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.1250,  0.7500,  1.5000],\n",
            "          [-1.1250,  0.1875,  1.0000],\n",
            "          [-0.3750, -0.2500,  0.3750]],\n",
            "\n",
            "         [[-1.5000, -0.7500, -1.1250],\n",
            "          [ 1.5000,  0.7500,  1.1250],\n",
            "          [ 1.5000, -1.5000,  0.5625]],\n",
            "\n",
            "         [[ 1.5000, -0.5625, -0.3750],\n",
            "          [-0.3750, -0.7500, -0.7500],\n",
            "          [ 1.0000,  0.0625, -1.0000]]]], device='cuda:0',\n",
            "       grad_fn=<_pqBackward>)\n",
            "tensor([[[[-0.3750]],\n",
            "\n",
            "         [[ 0.7500]],\n",
            "\n",
            "         [[-1.1250]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.1250]],\n",
            "\n",
            "         [[-1.1250]],\n",
            "\n",
            "         [[ 0.7500]]],\n",
            "\n",
            "\n",
            "        [[[ 0.7500]],\n",
            "\n",
            "         [[-1.5000]],\n",
            "\n",
            "         [[ 1.1250]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.1250]],\n",
            "\n",
            "         [[-1.5000]],\n",
            "\n",
            "         [[ 0.3750]]],\n",
            "\n",
            "\n",
            "        [[[ 0.5000]],\n",
            "\n",
            "         [[-1.0000]],\n",
            "\n",
            "         [[-1.1250]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0625]],\n",
            "\n",
            "         [[-1.5000]],\n",
            "\n",
            "         [[-0.2500]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.3750]],\n",
            "\n",
            "         [[ 0.5000]],\n",
            "\n",
            "         [[ 0.7500]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.5000]],\n",
            "\n",
            "         [[-0.3750]],\n",
            "\n",
            "         [[ 1.5000]]],\n",
            "\n",
            "\n",
            "        [[[ 1.5000]],\n",
            "\n",
            "         [[ 0.3750]],\n",
            "\n",
            "         [[-0.1250]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.5000]],\n",
            "\n",
            "         [[ 0.1250]],\n",
            "\n",
            "         [[ 0.5000]]],\n",
            "\n",
            "\n",
            "        [[[ 0.5000]],\n",
            "\n",
            "         [[-1.0000]],\n",
            "\n",
            "         [[ 1.1250]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.5000]],\n",
            "\n",
            "         [[-0.5000]],\n",
            "\n",
            "         [[ 1.1250]]]], device='cuda:0', grad_fn=<_pqBackward>)\n",
            "tensor([[[[ 0.1875,  0.3750,  1.5000],\n",
            "          [-0.7500,  1.5000, -1.5000],\n",
            "          [ 0.7500, -0.5625, -0.2500]],\n",
            "\n",
            "         [[ 1.5000, -1.1250, -1.1250],\n",
            "          [ 1.1250,  0.2500,  1.0000],\n",
            "          [-0.5625,  1.1250, -0.1250]],\n",
            "\n",
            "         [[-0.5625, -0.3750, -0.3750],\n",
            "          [-0.5000,  1.5000, -1.5000],\n",
            "          [-1.0000,  0.1875,  0.1875]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.0000,  0.7500,  1.1250],\n",
            "          [-1.5000,  0.5625, -1.1250],\n",
            "          [ 1.0000, -1.1250,  1.1250]],\n",
            "\n",
            "         [[ 0.5000, -1.5000,  1.5000],\n",
            "          [-1.5000, -1.5000,  1.5000],\n",
            "          [ 0.7500, -0.2500,  0.3750]],\n",
            "\n",
            "         [[ 0.0625,  0.7500,  1.0000],\n",
            "          [ 0.5000, -1.0000,  0.1875],\n",
            "          [ 1.0000,  0.7500, -0.7500]]],\n",
            "\n",
            "\n",
            "        [[[ 0.3750,  1.5000, -1.5000],\n",
            "          [ 1.5000,  0.0625,  1.0000],\n",
            "          [ 0.1875,  0.0625,  1.0000]],\n",
            "\n",
            "         [[-1.5000, -0.5000,  0.5000],\n",
            "          [-1.0000, -1.5000, -1.5000],\n",
            "          [-1.5000,  1.5000, -1.5000]],\n",
            "\n",
            "         [[ 1.0000, -0.0000,  1.0000],\n",
            "          [ 1.1250,  1.5000,  1.0000],\n",
            "          [ 0.5625,  1.1250, -1.1250]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.0000,  1.5000,  1.5000],\n",
            "          [-0.2500,  0.7500,  1.0000],\n",
            "          [ 1.5000, -0.2500, -1.0000]],\n",
            "\n",
            "         [[-1.5000, -1.1250,  0.7500],\n",
            "          [ 0.7500, -0.5625,  1.5000],\n",
            "          [ 0.7500, -1.1250,  1.5000]],\n",
            "\n",
            "         [[ 0.2500, -0.2500, -1.1250],\n",
            "          [ 0.7500, -1.0000,  1.5000],\n",
            "          [ 1.0000, -0.1875,  1.1250]]],\n",
            "\n",
            "\n",
            "        [[[-0.5625,  0.7500, -0.2500],\n",
            "          [-0.1250, -0.2500,  0.7500],\n",
            "          [ 1.5000,  0.3750, -1.1250]],\n",
            "\n",
            "         [[-1.5000, -1.1250,  0.5625],\n",
            "          [ 0.5625,  1.5000,  0.7500],\n",
            "          [-0.0000,  0.1875,  0.5000]],\n",
            "\n",
            "         [[-1.1250,  0.0625,  1.1250],\n",
            "          [-0.1250, -0.7500, -0.2500],\n",
            "          [-1.1250,  0.0000, -1.1250]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.1250, -0.2500, -1.0000],\n",
            "          [ 0.7500, -1.5000, -0.7500],\n",
            "          [-0.0625,  1.5000, -1.0000]],\n",
            "\n",
            "         [[ 1.5000,  0.7500,  0.3750],\n",
            "          [ 1.0000, -0.1250, -1.0000],\n",
            "          [-1.5000,  0.1875,  1.5000]],\n",
            "\n",
            "         [[ 0.5000, -0.1250,  0.7500],\n",
            "          [-1.5000,  1.0000, -0.5000],\n",
            "          [ 0.3750,  0.5000, -1.5000]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.7500, -0.0000,  0.7500],\n",
            "          [ 1.5000,  1.1250,  0.5000],\n",
            "          [ 0.1250, -0.5000, -0.0625]],\n",
            "\n",
            "         [[-1.0000,  1.1250,  0.7500],\n",
            "          [ 0.7500,  0.5000,  0.1875],\n",
            "          [-1.1250,  1.1250,  1.1250]],\n",
            "\n",
            "         [[-1.1250, -1.1250,  0.5000],\n",
            "          [ 1.5000,  1.5000,  0.0000],\n",
            "          [ 0.7500, -0.5625, -0.7500]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.3750, -0.3750, -0.1875],\n",
            "          [-0.1250, -0.7500, -1.1250],\n",
            "          [-0.1875,  1.5000,  1.0000]],\n",
            "\n",
            "         [[-0.5625,  0.0625, -0.1875],\n",
            "          [-1.5000,  1.5000, -1.1250],\n",
            "          [ 0.3750, -1.0000, -1.1250]],\n",
            "\n",
            "         [[ 0.7500,  1.5000, -1.5000],\n",
            "          [-0.5000,  0.7500,  1.5000],\n",
            "          [-0.5625, -0.7500,  1.1250]]],\n",
            "\n",
            "\n",
            "        [[[-0.3750, -1.5000,  0.5625],\n",
            "          [ 1.0000, -0.5000, -1.5000],\n",
            "          [-1.5000, -1.0000, -1.1250]],\n",
            "\n",
            "         [[-1.1250, -1.5000,  1.5000],\n",
            "          [ 0.3750,  0.3750, -0.1875],\n",
            "          [-0.5000,  0.5625, -0.7500]],\n",
            "\n",
            "         [[ 1.5000, -0.7500,  0.7500],\n",
            "          [ 0.3750, -0.3750,  0.5625],\n",
            "          [-0.2500, -0.1250, -1.0000]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.1875, -1.5000,  1.5000],\n",
            "          [-0.3750, -0.5000,  0.5625],\n",
            "          [ 1.5000,  0.7500, -0.1875]],\n",
            "\n",
            "         [[-1.5000,  0.5000, -1.0000],\n",
            "          [ 0.2500, -0.5625, -1.5000],\n",
            "          [-0.1250, -1.5000, -0.3750]],\n",
            "\n",
            "         [[ 1.5000, -1.5000, -0.7500],\n",
            "          [ 1.5000, -0.5000,  0.5000],\n",
            "          [-0.2500, -0.5625, -1.5000]]],\n",
            "\n",
            "\n",
            "        [[[ 1.5000,  1.5000,  1.0000],\n",
            "          [ 1.1250, -0.7500,  0.1250],\n",
            "          [ 0.1250, -1.0000, -0.5625]],\n",
            "\n",
            "         [[-0.5625,  1.5000, -1.1250],\n",
            "          [ 1.5000,  0.5000,  1.5000],\n",
            "          [ 1.5000, -1.5000,  0.3750]],\n",
            "\n",
            "         [[-0.5625, -1.5000, -1.1250],\n",
            "          [ 1.1250,  0.5625, -1.5000],\n",
            "          [-1.1250, -1.1250,  0.0000]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.3750,  0.0625,  1.0000],\n",
            "          [-1.1250,  1.5000,  0.7500],\n",
            "          [ 1.1250,  0.7500,  1.1250]],\n",
            "\n",
            "         [[ 1.5000, -1.0000,  1.1250],\n",
            "          [-1.5000, -0.5000,  0.3750],\n",
            "          [-0.7500, -0.5625, -0.0625]],\n",
            "\n",
            "         [[-0.1875,  1.1250, -1.5000],\n",
            "          [ 0.1250, -1.1250, -0.7500],\n",
            "          [-1.1250,  0.0625, -0.7500]]]], device='cuda:0',\n",
            "       grad_fn=<_pqBackward>)\n",
            "tensor([[[[ 1.5000]],\n",
            "\n",
            "         [[-1.5000]],\n",
            "\n",
            "         [[ 1.5000]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.5000]],\n",
            "\n",
            "         [[ 1.5000]],\n",
            "\n",
            "         [[ 1.1250]]],\n",
            "\n",
            "\n",
            "        [[[-0.5625]],\n",
            "\n",
            "         [[ 1.0000]],\n",
            "\n",
            "         [[-0.1250]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.7500]],\n",
            "\n",
            "         [[ 0.7500]],\n",
            "\n",
            "         [[ 1.5000]]],\n",
            "\n",
            "\n",
            "        [[[-0.1250]],\n",
            "\n",
            "         [[ 1.1250]],\n",
            "\n",
            "         [[-1.1250]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.7500]],\n",
            "\n",
            "         [[-1.1250]],\n",
            "\n",
            "         [[ 0.1875]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.2500]],\n",
            "\n",
            "         [[ 1.1250]],\n",
            "\n",
            "         [[-0.5000]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.3750]],\n",
            "\n",
            "         [[-0.5625]],\n",
            "\n",
            "         [[-0.7500]]],\n",
            "\n",
            "\n",
            "        [[[-1.0000]],\n",
            "\n",
            "         [[-0.3750]],\n",
            "\n",
            "         [[ 1.1250]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.5625]],\n",
            "\n",
            "         [[-1.0000]],\n",
            "\n",
            "         [[ 0.7500]]],\n",
            "\n",
            "\n",
            "        [[[-0.3750]],\n",
            "\n",
            "         [[ 0.2500]],\n",
            "\n",
            "         [[-1.5000]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.0000]],\n",
            "\n",
            "         [[ 1.5000]],\n",
            "\n",
            "         [[ 0.2500]]]], device='cuda:0', grad_fn=<_pqBackward>)\n",
            "tensor([[[[-1.5000, -0.1250,  1.5000],\n",
            "          [ 0.5625,  0.0625,  0.7500],\n",
            "          [ 1.5000, -0.5625,  0.7500]],\n",
            "\n",
            "         [[-1.5000,  1.5000, -1.5000],\n",
            "          [ 1.1250, -0.7500, -1.1250],\n",
            "          [-1.0000,  0.1875, -0.5625]],\n",
            "\n",
            "         [[-0.0625, -0.5000, -1.0000],\n",
            "          [-0.1875, -1.1250,  0.0625],\n",
            "          [-1.5000, -0.1250, -0.5625]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.1250, -1.5000, -0.5000],\n",
            "          [ 1.5000,  1.5000,  1.1250],\n",
            "          [ 0.0625, -1.1250,  1.0000]],\n",
            "\n",
            "         [[-0.7500,  1.1250,  1.5000],\n",
            "          [-1.5000, -1.0000, -1.1250],\n",
            "          [-1.1250, -1.5000,  0.7500]],\n",
            "\n",
            "         [[-0.2500,  0.1250,  1.5000],\n",
            "          [-0.7500, -0.1250,  0.0625],\n",
            "          [ 0.7500,  1.5000, -0.3750]]],\n",
            "\n",
            "\n",
            "        [[[-0.7500,  1.0000, -0.7500],\n",
            "          [ 1.0000, -1.5000, -0.7500],\n",
            "          [ 0.7500, -1.5000,  1.5000]],\n",
            "\n",
            "         [[ 0.5625, -1.1250, -1.5000],\n",
            "          [ 1.5000, -1.1250,  0.5000],\n",
            "          [ 0.3750, -1.0000, -0.3750]],\n",
            "\n",
            "         [[-1.0000, -1.5000, -0.1875],\n",
            "          [-1.5000, -1.0000, -1.0000],\n",
            "          [ 0.5625,  0.7500, -1.5000]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.1250, -1.1250,  1.5000],\n",
            "          [ 0.5625,  0.7500, -0.0625],\n",
            "          [ 1.1250, -0.0625, -1.1250]],\n",
            "\n",
            "         [[ 0.3750,  0.7500,  1.5000],\n",
            "          [-0.7500,  0.5625, -0.3750],\n",
            "          [-1.0000,  1.1250,  1.5000]],\n",
            "\n",
            "         [[-1.5000, -0.5625,  1.5000],\n",
            "          [ 0.1250,  0.5000,  0.3750],\n",
            "          [-0.5625,  1.0000, -0.5625]]],\n",
            "\n",
            "\n",
            "        [[[ 0.5000, -1.1250,  1.5000],\n",
            "          [-1.0000, -1.5000,  1.1250],\n",
            "          [ 0.5625, -0.1875,  1.1250]],\n",
            "\n",
            "         [[-0.3750, -0.5000,  1.5000],\n",
            "          [ 1.1250,  1.1250, -1.5000],\n",
            "          [ 0.7500,  1.1250,  0.7500]],\n",
            "\n",
            "         [[ 0.5625, -0.0000,  1.5000],\n",
            "          [ 0.0625, -0.1875,  1.5000],\n",
            "          [ 1.1250, -1.1250,  1.0000]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.1250, -0.7500, -0.3750],\n",
            "          [-0.3750,  0.7500, -0.7500],\n",
            "          [ 0.0000,  0.5000, -0.5625]],\n",
            "\n",
            "         [[-0.2500, -0.1250, -1.0000],\n",
            "          [-0.5000, -1.5000, -1.1250],\n",
            "          [-0.2500, -1.1250, -1.5000]],\n",
            "\n",
            "         [[ 1.5000, -1.5000,  0.5000],\n",
            "          [ 0.3750,  1.5000, -0.5000],\n",
            "          [-1.5000,  1.1250, -0.7500]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 1.0000,  1.5000,  0.1875],\n",
            "          [-0.3750, -0.1250,  1.5000],\n",
            "          [ 0.1250,  0.7500, -0.7500]],\n",
            "\n",
            "         [[-0.1250,  1.5000, -1.0000],\n",
            "          [ 0.3750, -0.7500, -1.0000],\n",
            "          [-1.5000,  0.5000,  1.5000]],\n",
            "\n",
            "         [[ 1.5000, -0.7500, -0.7500],\n",
            "          [-1.1250,  0.7500, -0.5625],\n",
            "          [ 0.2500, -0.5000, -1.1250]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.5000, -0.0000, -1.0000],\n",
            "          [-0.7500, -0.2500,  0.0000],\n",
            "          [-1.0000, -0.7500,  0.5625]],\n",
            "\n",
            "         [[ 1.5000,  1.5000,  0.2500],\n",
            "          [-1.5000, -0.1250, -0.5625],\n",
            "          [-0.2500,  0.5000, -0.3750]],\n",
            "\n",
            "         [[ 1.1250, -0.5000,  0.0000],\n",
            "          [ 1.5000, -1.5000, -1.1250],\n",
            "          [-1.5000,  1.1250, -0.5000]]],\n",
            "\n",
            "\n",
            "        [[[ 0.5000, -0.7500,  0.7500],\n",
            "          [ 0.5625, -0.7500,  1.5000],\n",
            "          [ 1.5000,  0.5000, -1.1250]],\n",
            "\n",
            "         [[-0.2500,  1.5000,  0.2500],\n",
            "          [-0.1250, -1.5000, -0.7500],\n",
            "          [ 0.2500,  0.1875,  0.5625]],\n",
            "\n",
            "         [[ 1.0000, -0.2500,  1.0000],\n",
            "          [ 0.2500,  0.5000, -0.0625],\n",
            "          [ 0.3750,  0.5000, -1.1250]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.1250,  0.7500, -1.5000],\n",
            "          [ 0.1250,  1.5000,  0.3750],\n",
            "          [ 0.3750,  0.1250, -1.0000]],\n",
            "\n",
            "         [[ 1.0000,  1.1250, -1.0000],\n",
            "          [-0.5000,  1.1250,  1.1250],\n",
            "          [ 0.1250, -1.5000, -0.3750]],\n",
            "\n",
            "         [[-0.3750,  0.7500, -0.1875],\n",
            "          [-1.1250,  1.1250, -1.5000],\n",
            "          [-1.1250, -1.0000,  1.0000]]],\n",
            "\n",
            "\n",
            "        [[[-0.3750,  1.0000,  0.5000],\n",
            "          [ 1.5000,  0.7500, -1.0000],\n",
            "          [-1.5000,  1.5000, -0.5625]],\n",
            "\n",
            "         [[ 0.2500, -1.5000, -1.5000],\n",
            "          [ 0.7500, -1.1250, -0.5625],\n",
            "          [-1.5000,  1.5000, -0.3750]],\n",
            "\n",
            "         [[ 0.2500, -1.0000,  1.0000],\n",
            "          [ 1.0000, -1.0000,  1.0000],\n",
            "          [ 1.5000, -1.0000,  1.1250]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.2500, -1.5000, -0.1250],\n",
            "          [-0.3750,  1.5000,  0.1250],\n",
            "          [-0.5625, -0.7500, -0.7500]],\n",
            "\n",
            "         [[ 1.0000, -0.7500,  0.2500],\n",
            "          [-1.5000, -1.1250, -1.1250],\n",
            "          [ 0.5625, -1.1250, -0.7500]],\n",
            "\n",
            "         [[-0.2500, -0.0000, -0.3750],\n",
            "          [ 1.0000,  1.5000,  1.5000],\n",
            "          [-1.1250,  1.1250, -0.5000]]]], device='cuda:0',\n",
            "       grad_fn=<_pqBackward>)\n",
            "tensor([[[[-1.1250]],\n",
            "\n",
            "         [[-0.5625]],\n",
            "\n",
            "         [[-0.1875]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.7500]],\n",
            "\n",
            "         [[ 1.0000]],\n",
            "\n",
            "         [[ 1.1250]]],\n",
            "\n",
            "\n",
            "        [[[-0.1875]],\n",
            "\n",
            "         [[-1.1250]],\n",
            "\n",
            "         [[-1.5000]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.7500]],\n",
            "\n",
            "         [[-1.5000]],\n",
            "\n",
            "         [[-0.7500]]],\n",
            "\n",
            "\n",
            "        [[[-0.7500]],\n",
            "\n",
            "         [[ 0.1875]],\n",
            "\n",
            "         [[ 0.5625]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.5625]],\n",
            "\n",
            "         [[-0.7500]],\n",
            "\n",
            "         [[ 0.3750]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.5625]],\n",
            "\n",
            "         [[-1.1250]],\n",
            "\n",
            "         [[-0.3750]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.5000]],\n",
            "\n",
            "         [[ 0.5625]],\n",
            "\n",
            "         [[-1.5000]]],\n",
            "\n",
            "\n",
            "        [[[ 1.5000]],\n",
            "\n",
            "         [[-1.5000]],\n",
            "\n",
            "         [[-0.7500]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.5000]],\n",
            "\n",
            "         [[-1.1250]],\n",
            "\n",
            "         [[ 1.5000]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1250]],\n",
            "\n",
            "         [[-1.5000]],\n",
            "\n",
            "         [[ 0.7500]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.7500]],\n",
            "\n",
            "         [[ 0.7500]],\n",
            "\n",
            "         [[-0.7500]]]], device='cuda:0', grad_fn=<_pqBackward>)\n",
            "tensor([[[[ 1.0000, -0.7500, -0.5625],\n",
            "          [ 0.3750,  0.0000, -1.0000],\n",
            "          [-1.1250,  0.7500,  0.3750]],\n",
            "\n",
            "         [[ 1.0000, -0.0625, -1.5000],\n",
            "          [-0.0625,  0.7500,  1.5000],\n",
            "          [ 1.5000, -1.1250,  1.5000]],\n",
            "\n",
            "         [[-0.5625, -0.1250, -0.5000],\n",
            "          [ 0.7500, -0.2500, -1.5000],\n",
            "          [-1.0000, -0.7500,  0.5625]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.7500, -0.1875, -0.7500],\n",
            "          [ 1.5000,  1.5000,  1.5000],\n",
            "          [ 0.5625, -1.5000,  1.5000]],\n",
            "\n",
            "         [[ 1.1250, -1.1250,  1.5000],\n",
            "          [-1.1250,  0.5000, -1.5000],\n",
            "          [-1.5000,  0.3750,  1.5000]],\n",
            "\n",
            "         [[-0.5625,  0.7500, -0.5625],\n",
            "          [-0.1875,  0.1875,  0.7500],\n",
            "          [ 1.5000,  1.1250,  0.1250]]],\n",
            "\n",
            "\n",
            "        [[[ 1.5000, -1.5000,  1.1250],\n",
            "          [ 0.5000,  0.3750,  0.0625],\n",
            "          [-1.5000,  1.1250, -1.1250]],\n",
            "\n",
            "         [[ 0.0625, -0.0000, -0.3750],\n",
            "          [-1.5000,  1.1250,  0.2500],\n",
            "          [-0.1250, -1.1250, -1.1250]],\n",
            "\n",
            "         [[-1.1250,  0.3750,  1.0000],\n",
            "          [-1.1250,  0.5625,  0.5000],\n",
            "          [ 0.2500, -1.5000,  0.7500]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.7500, -1.5000, -0.7500],\n",
            "          [-1.5000,  0.7500, -0.3750],\n",
            "          [ 1.1250, -0.0625,  1.5000]],\n",
            "\n",
            "         [[ 0.7500,  1.1250,  0.3750],\n",
            "          [-0.7500,  1.0000,  1.1250],\n",
            "          [-0.3750, -0.0625,  0.5625]],\n",
            "\n",
            "         [[-0.7500, -1.5000,  1.5000],\n",
            "          [ 0.1875, -0.5000, -0.3750],\n",
            "          [-1.5000, -0.7500,  1.1250]]],\n",
            "\n",
            "\n",
            "        [[[ 1.5000,  1.1250, -0.5625],\n",
            "          [-0.3750,  1.1250, -1.5000],\n",
            "          [-0.3750,  0.0625,  1.5000]],\n",
            "\n",
            "         [[ 0.5625, -1.5000,  0.0625],\n",
            "          [-0.2500, -0.7500, -0.3750],\n",
            "          [ 0.7500, -1.5000, -0.2500]],\n",
            "\n",
            "         [[ 0.2500, -0.0000,  0.7500],\n",
            "          [ 1.1250,  0.1875,  1.0000],\n",
            "          [-1.0000,  0.3750,  0.5625]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.7500, -0.3750,  0.1250],\n",
            "          [ 1.1250,  1.1250,  0.2500],\n",
            "          [ 0.1875, -1.5000, -0.2500]],\n",
            "\n",
            "         [[-1.0000,  0.3750, -1.0000],\n",
            "          [-1.5000, -0.7500, -1.5000],\n",
            "          [-0.0625,  0.5625,  1.5000]],\n",
            "\n",
            "         [[ 0.1250, -1.0000,  1.5000],\n",
            "          [ 1.5000,  1.1250,  1.1250],\n",
            "          [-1.5000, -0.7500, -0.5625]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-1.0000, -1.1250,  0.7500],\n",
            "          [ 0.1250,  1.1250, -0.5000],\n",
            "          [-0.7500,  1.5000,  1.0000]],\n",
            "\n",
            "         [[-0.5625,  0.0625,  0.5000],\n",
            "          [ 0.3750, -1.5000,  1.0000],\n",
            "          [ 0.1875,  0.0625,  1.5000]],\n",
            "\n",
            "         [[-1.1250, -0.5625, -1.5000],\n",
            "          [-1.5000, -1.0000, -1.1250],\n",
            "          [ 1.5000,  0.5000,  0.7500]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.5000,  1.0000,  1.0000],\n",
            "          [-0.5625, -0.5625, -0.5000],\n",
            "          [-0.5625,  0.7500,  0.5625]],\n",
            "\n",
            "         [[ 1.5000,  0.5625,  1.5000],\n",
            "          [ 1.5000,  1.1250,  1.5000],\n",
            "          [-1.1250, -1.1250,  1.0000]],\n",
            "\n",
            "         [[-1.1250,  1.0000, -0.5625],\n",
            "          [-0.5625,  1.1250, -1.1250],\n",
            "          [-1.5000,  1.0000, -1.5000]]],\n",
            "\n",
            "\n",
            "        [[[-0.3750, -0.7500,  1.5000],\n",
            "          [-1.0000, -1.5000, -1.1250],\n",
            "          [ 1.5000,  1.1250, -1.1250]],\n",
            "\n",
            "         [[ 1.5000,  1.5000, -0.7500],\n",
            "          [-1.0000, -0.7500, -0.1250],\n",
            "          [-1.5000, -0.5625,  0.7500]],\n",
            "\n",
            "         [[ 1.1250, -1.5000, -0.1875],\n",
            "          [ 1.5000, -0.1875,  0.1250],\n",
            "          [-0.1875,  1.5000,  1.5000]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.5000,  1.5000, -0.5625],\n",
            "          [ 1.5000, -0.5625, -1.0000],\n",
            "          [-0.5000, -0.7500, -0.2500]],\n",
            "\n",
            "         [[ 1.5000, -0.0625, -0.7500],\n",
            "          [-1.1250, -0.7500,  0.2500],\n",
            "          [ 1.0000, -0.3750, -0.5000]],\n",
            "\n",
            "         [[ 0.1250,  1.1250, -0.7500],\n",
            "          [-0.7500, -1.5000,  1.5000],\n",
            "          [-0.7500,  1.1250, -0.5000]]],\n",
            "\n",
            "\n",
            "        [[[-1.5000,  1.5000,  0.7500],\n",
            "          [ 1.5000,  0.7500, -0.1875],\n",
            "          [-1.5000, -1.5000,  0.1250]],\n",
            "\n",
            "         [[-0.5000, -0.3750,  1.1250],\n",
            "          [ 0.5000,  1.5000, -1.5000],\n",
            "          [ 1.5000, -0.7500, -1.5000]],\n",
            "\n",
            "         [[-0.5000,  0.5625,  0.5625],\n",
            "          [-1.5000,  0.1250, -0.1875],\n",
            "          [ 1.5000,  0.5000,  1.0000]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.5000, -0.5000,  0.2500],\n",
            "          [ 0.1250, -0.7500, -1.5000],\n",
            "          [-0.5625,  1.0000, -1.1250]],\n",
            "\n",
            "         [[-1.1250, -1.1250, -1.1250],\n",
            "          [-0.3750, -0.3750, -0.2500],\n",
            "          [-0.1250,  0.2500,  1.5000]],\n",
            "\n",
            "         [[ 1.0000, -1.5000,  0.2500],\n",
            "          [-0.7500,  0.5625, -1.1250],\n",
            "          [ 1.5000,  1.5000,  0.3750]]]], device='cuda:0',\n",
            "       grad_fn=<_pqBackward>)\n",
            "tensor([[[[ 0.7500]],\n",
            "\n",
            "         [[-0.7500]],\n",
            "\n",
            "         [[-1.5000]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.7500]],\n",
            "\n",
            "         [[ 1.0000]],\n",
            "\n",
            "         [[ 0.1250]]],\n",
            "\n",
            "\n",
            "        [[[-0.3750]],\n",
            "\n",
            "         [[ 0.5000]],\n",
            "\n",
            "         [[-1.5000]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.7500]],\n",
            "\n",
            "         [[-1.5000]],\n",
            "\n",
            "         [[-0.7500]]],\n",
            "\n",
            "\n",
            "        [[[ 1.5000]],\n",
            "\n",
            "         [[-0.7500]],\n",
            "\n",
            "         [[ 1.5000]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.5000]],\n",
            "\n",
            "         [[ 0.2500]],\n",
            "\n",
            "         [[ 0.3750]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-1.0000]],\n",
            "\n",
            "         [[-1.0000]],\n",
            "\n",
            "         [[ 1.5000]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.5625]],\n",
            "\n",
            "         [[-1.0000]],\n",
            "\n",
            "         [[-1.0000]]],\n",
            "\n",
            "\n",
            "        [[[-0.3750]],\n",
            "\n",
            "         [[ 1.0000]],\n",
            "\n",
            "         [[-0.1875]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.0000]],\n",
            "\n",
            "         [[ 1.0000]],\n",
            "\n",
            "         [[-0.0625]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0625]],\n",
            "\n",
            "         [[-0.7500]],\n",
            "\n",
            "         [[-1.5000]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.0000]],\n",
            "\n",
            "         [[ 0.7500]],\n",
            "\n",
            "         [[ 1.0000]]]], device='cuda:0', grad_fn=<_pqBackward>)\n",
            "tensor([[[[ 1.0000,  0.2500,  1.1250],\n",
            "          [-1.5000, -1.0000, -1.5000],\n",
            "          [-1.5000,  1.5000,  1.0000]],\n",
            "\n",
            "         [[-0.1875,  0.2500,  0.5000],\n",
            "          [ 1.0000, -1.5000,  1.1250],\n",
            "          [-1.0000,  1.1250, -1.5000]],\n",
            "\n",
            "         [[ 0.0000,  1.1250,  1.0000],\n",
            "          [ 0.1250, -1.5000, -1.5000],\n",
            "          [-0.0625,  0.1250,  0.0625]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.0000,  0.2500, -1.1250],\n",
            "          [-1.5000, -1.1250, -0.5625],\n",
            "          [ 1.5000,  0.2500, -0.0000]],\n",
            "\n",
            "         [[ 0.7500, -1.5000,  1.5000],\n",
            "          [-0.1875,  1.1250,  1.1250],\n",
            "          [ 0.3750,  0.2500,  0.5000]],\n",
            "\n",
            "         [[ 1.5000,  0.0000,  0.7500],\n",
            "          [ 1.0000,  1.5000,  1.0000],\n",
            "          [-0.5625, -1.5000, -1.0000]]],\n",
            "\n",
            "\n",
            "        [[[ 1.5000, -1.5000, -0.0625],\n",
            "          [ 1.1250,  1.5000,  0.3750],\n",
            "          [-1.1250, -0.7500, -1.0000]],\n",
            "\n",
            "         [[-0.3750, -0.5625, -0.5625],\n",
            "          [-0.5625, -1.1250, -0.1875],\n",
            "          [-1.1250,  1.5000, -0.7500]],\n",
            "\n",
            "         [[ 1.5000, -1.0000, -1.1250],\n",
            "          [ 1.1250, -0.2500, -0.7500],\n",
            "          [ 0.5625, -0.5625,  0.7500]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.7500, -1.5000,  0.3750],\n",
            "          [ 1.0000,  0.0625, -0.7500],\n",
            "          [-0.3750,  1.5000, -0.1250]],\n",
            "\n",
            "         [[-0.7500,  1.1250, -1.5000],\n",
            "          [-0.5625, -1.5000, -1.0000],\n",
            "          [ 0.1250, -1.5000, -0.0000]],\n",
            "\n",
            "         [[ 0.0625,  1.1250,  0.2500],\n",
            "          [-0.0625,  1.1250,  0.3750],\n",
            "          [ 1.5000, -1.1250, -0.1875]]],\n",
            "\n",
            "\n",
            "        [[[ 1.5000, -0.2500,  0.1250],\n",
            "          [ 0.0625,  0.0000, -1.0000],\n",
            "          [ 0.3750,  0.5625,  0.3750]],\n",
            "\n",
            "         [[-1.5000,  0.3750, -1.5000],\n",
            "          [-1.0000, -1.5000, -0.3750],\n",
            "          [ 0.7500, -0.5625,  0.5625]],\n",
            "\n",
            "         [[ 1.1250, -1.1250,  1.5000],\n",
            "          [-1.1250, -1.5000, -0.5625],\n",
            "          [ 1.5000,  1.5000, -1.1250]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.0000,  0.2500,  1.5000],\n",
            "          [ 0.2500, -0.3750, -0.7500],\n",
            "          [-0.7500, -1.5000, -0.1250]],\n",
            "\n",
            "         [[-1.5000,  0.7500, -1.0000],\n",
            "          [-1.5000, -1.5000, -1.5000],\n",
            "          [-1.5000,  0.7500,  1.5000]],\n",
            "\n",
            "         [[-1.0000, -0.0000, -0.7500],\n",
            "          [ 0.5000, -1.1250,  0.3750],\n",
            "          [ 1.5000, -1.1250,  1.5000]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-1.5000,  1.5000,  0.3750],\n",
            "          [-0.1250,  1.1250,  0.0625],\n",
            "          [ 0.1875,  0.1250,  1.5000]],\n",
            "\n",
            "         [[-0.5000, -0.5000, -0.5625],\n",
            "          [-0.7500,  1.0000, -0.0625],\n",
            "          [ 1.1250,  1.5000, -1.0000]],\n",
            "\n",
            "         [[-0.1250,  0.7500, -0.7500],\n",
            "          [-0.0000, -0.3750,  0.2500],\n",
            "          [ 1.1250, -1.0000,  0.0625]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.5000, -0.7500,  1.5000],\n",
            "          [ 0.5000, -1.5000, -0.7500],\n",
            "          [-0.7500,  0.3750,  0.0625]],\n",
            "\n",
            "         [[ 1.1250,  1.5000,  0.5625],\n",
            "          [ 0.5000,  0.1875,  0.5625],\n",
            "          [-0.7500,  0.0625, -0.2500]],\n",
            "\n",
            "         [[ 0.3750, -1.0000, -1.0000],\n",
            "          [-0.3750, -0.5000, -1.5000],\n",
            "          [ 1.0000, -0.5000,  1.0000]]],\n",
            "\n",
            "\n",
            "        [[[ 1.5000,  0.5000, -0.1875],\n",
            "          [-1.5000, -0.7500,  1.5000],\n",
            "          [ 1.5000, -0.2500,  1.1250]],\n",
            "\n",
            "         [[ 1.5000, -1.1250,  0.7500],\n",
            "          [ 0.5000, -0.2500, -1.1250],\n",
            "          [-0.5625, -0.7500,  0.5625]],\n",
            "\n",
            "         [[ 1.1250, -0.1875,  1.1250],\n",
            "          [-1.1250, -1.1250, -1.5000],\n",
            "          [-1.0000,  1.0000, -1.1250]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.1250,  1.5000,  0.5625],\n",
            "          [-1.0000, -0.1875, -0.5625],\n",
            "          [-1.0000,  0.2500,  0.1875]],\n",
            "\n",
            "         [[-1.5000,  1.5000, -0.7500],\n",
            "          [-1.0000, -0.2500,  1.5000],\n",
            "          [ 0.5625, -0.7500,  0.5625]],\n",
            "\n",
            "         [[-1.0000, -0.2500, -0.0625],\n",
            "          [ 1.1250, -0.3750, -1.5000],\n",
            "          [-0.3750, -0.7500,  0.0625]]],\n",
            "\n",
            "\n",
            "        [[[ 1.5000, -1.0000,  1.5000],\n",
            "          [-0.5000, -1.5000, -0.7500],\n",
            "          [ 1.5000,  1.5000,  1.1250]],\n",
            "\n",
            "         [[-1.5000, -0.5625, -0.2500],\n",
            "          [-0.7500, -0.1875, -0.3750],\n",
            "          [-1.1250, -0.5625,  0.7500]],\n",
            "\n",
            "         [[ 0.3750,  0.2500, -1.0000],\n",
            "          [-0.5625, -0.7500,  1.5000],\n",
            "          [-0.0625, -1.1250, -1.1250]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.3750, -0.7500, -1.5000],\n",
            "          [-0.0000, -1.1250, -0.1250],\n",
            "          [ 1.5000,  1.0000,  0.7500]],\n",
            "\n",
            "         [[ 0.7500, -0.7500, -0.1250],\n",
            "          [-1.1250,  1.5000, -0.2500],\n",
            "          [-0.3750, -1.5000, -0.7500]],\n",
            "\n",
            "         [[ 1.0000,  0.2500, -1.5000],\n",
            "          [-1.5000,  0.7500,  1.5000],\n",
            "          [-1.5000, -0.7500,  0.3750]]]], device='cuda:0',\n",
            "       grad_fn=<_pqBackward>)\n",
            "tensor([[[[-1.5000]],\n",
            "\n",
            "         [[ 0.7500]],\n",
            "\n",
            "         [[-1.5000]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0000]],\n",
            "\n",
            "         [[-1.1250]],\n",
            "\n",
            "         [[ 1.1250]]],\n",
            "\n",
            "\n",
            "        [[[-0.0000]],\n",
            "\n",
            "         [[ 0.2500]],\n",
            "\n",
            "         [[-1.5000]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0000]],\n",
            "\n",
            "         [[ 1.1250]],\n",
            "\n",
            "         [[ 0.0000]]],\n",
            "\n",
            "\n",
            "        [[[-1.5000]],\n",
            "\n",
            "         [[ 1.5000]],\n",
            "\n",
            "         [[ 0.5000]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.7500]],\n",
            "\n",
            "         [[ 1.5000]],\n",
            "\n",
            "         [[-1.0000]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.5625]],\n",
            "\n",
            "         [[-1.0000]],\n",
            "\n",
            "         [[ 1.5000]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.1250]],\n",
            "\n",
            "         [[ 0.0625]],\n",
            "\n",
            "         [[-0.2500]]],\n",
            "\n",
            "\n",
            "        [[[-0.7500]],\n",
            "\n",
            "         [[ 1.0000]],\n",
            "\n",
            "         [[ 0.0625]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.0000]],\n",
            "\n",
            "         [[-0.7500]],\n",
            "\n",
            "         [[-1.1250]]],\n",
            "\n",
            "\n",
            "        [[[ 1.5000]],\n",
            "\n",
            "         [[-0.3750]],\n",
            "\n",
            "         [[-0.2500]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.1250]],\n",
            "\n",
            "         [[ 1.5000]],\n",
            "\n",
            "         [[-0.3750]]]], device='cuda:0', grad_fn=<_pqBackward>)\n",
            "tensor([[[[-1.1250, -1.5000,  1.1250],\n",
            "          [-1.5000, -1.1250, -0.5000],\n",
            "          [ 0.5000,  0.1250,  0.1875]],\n",
            "\n",
            "         [[ 0.7500, -1.5000,  1.5000],\n",
            "          [ 0.1250, -1.0000, -0.7500],\n",
            "          [ 0.7500,  1.1250, -0.5625]],\n",
            "\n",
            "         [[-0.5000,  1.5000, -1.5000],\n",
            "          [-1.5000, -0.2500,  0.5000],\n",
            "          [ 0.3750,  2.0000,  0.7500]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.1250,  0.5625,  1.5000],\n",
            "          [ 1.0000, -1.0000, -1.5000],\n",
            "          [ 0.5625,  0.5000, -0.3750]],\n",
            "\n",
            "         [[ 1.5000,  0.3750, -1.1250],\n",
            "          [ 0.0000,  1.5000, -1.1250],\n",
            "          [ 0.1250, -1.1250,  0.0625]],\n",
            "\n",
            "         [[ 1.0000,  0.7500, -0.2500],\n",
            "          [-1.0000, -1.1250,  0.7500],\n",
            "          [ 1.5000,  0.1250, -0.2500]]],\n",
            "\n",
            "\n",
            "        [[[-0.1250, -1.0000,  1.1250],\n",
            "          [-1.5000,  1.5000, -0.5625],\n",
            "          [-0.0000,  1.0000, -1.1250]],\n",
            "\n",
            "         [[ 0.7500,  1.0000,  1.5000],\n",
            "          [-1.5000,  0.2500, -1.5000],\n",
            "          [-0.7500, -1.5000,  0.0000]],\n",
            "\n",
            "         [[-1.5000, -0.5625, -1.1250],\n",
            "          [ 1.0000, -0.5000, -0.1250],\n",
            "          [ 0.2500, -1.1250, -1.5000]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.5000, -1.5000, -1.1250],\n",
            "          [-0.7500,  1.5000, -1.0000],\n",
            "          [-0.7500,  1.0000,  1.0000]],\n",
            "\n",
            "         [[-1.5000, -0.3750,  0.7500],\n",
            "          [ 0.0000, -0.1250,  0.3750],\n",
            "          [-1.0000,  1.5000, -1.1250]],\n",
            "\n",
            "         [[ 1.5000,  0.5625, -0.5625],\n",
            "          [-0.7500,  1.1250, -0.7500],\n",
            "          [ 1.0000, -1.5000,  0.5625]]],\n",
            "\n",
            "\n",
            "        [[[ 0.5625, -1.5000, -1.5000],\n",
            "          [-0.3750, -0.7500, -0.1250],\n",
            "          [-0.1250,  1.5000, -1.5000]],\n",
            "\n",
            "         [[ 1.5000, -0.7500,  1.5000],\n",
            "          [ 1.0000,  0.5625, -0.5625],\n",
            "          [-0.7500,  2.0000,  0.7500]],\n",
            "\n",
            "         [[ 0.2500, -1.5000, -1.5000],\n",
            "          [-1.0000,  1.5000, -0.0625],\n",
            "          [ 1.5000,  1.5000, -1.1250]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.2500, -0.1875,  0.7500],\n",
            "          [ 0.1875,  0.5625, -1.0000],\n",
            "          [-0.2500,  0.0000,  1.0000]],\n",
            "\n",
            "         [[-1.0000, -1.5000,  0.5000],\n",
            "          [-0.5000, -1.0000,  1.5000],\n",
            "          [ 0.5000, -0.3750, -1.1250]],\n",
            "\n",
            "         [[ 0.2500, -0.5000, -1.5000],\n",
            "          [ 1.0000, -1.5000,  1.5000],\n",
            "          [-0.1875, -1.0000, -1.1250]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 1.5000,  0.1875, -0.1875],\n",
            "          [ 0.0625,  0.7500,  1.5000],\n",
            "          [-0.1875, -0.2500, -0.3750]],\n",
            "\n",
            "         [[-0.2500,  0.0000, -1.5000],\n",
            "          [-0.5000,  1.1250,  0.3750],\n",
            "          [-1.0000,  1.5000,  0.7500]],\n",
            "\n",
            "         [[-0.5625,  1.0000, -0.7500],\n",
            "          [ 0.7500, -1.1250, -0.7500],\n",
            "          [ 0.7500,  0.3750, -0.2500]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0625,  1.5000, -0.5000],\n",
            "          [-0.7500,  0.7500,  0.5000],\n",
            "          [ 0.7500, -1.0000,  1.0000]],\n",
            "\n",
            "         [[-1.0000, -0.5000, -1.1250],\n",
            "          [ 0.1875,  0.7500,  1.0000],\n",
            "          [-1.1250,  0.0625,  1.5000]],\n",
            "\n",
            "         [[ 0.0000,  0.7500, -0.2500],\n",
            "          [-0.5625,  0.7500, -1.5000],\n",
            "          [ 1.0000, -1.5000,  1.1250]]],\n",
            "\n",
            "\n",
            "        [[[-0.2500,  0.1875,  0.3750],\n",
            "          [-0.1250, -0.0625,  0.1875],\n",
            "          [-0.1875,  1.1250, -1.0000]],\n",
            "\n",
            "         [[-0.1875,  1.5000,  1.1250],\n",
            "          [ 0.7500, -1.1250, -1.5000],\n",
            "          [-0.2500, -1.5000, -0.7500]],\n",
            "\n",
            "         [[ 0.0000,  1.5000,  1.0000],\n",
            "          [ 0.2500, -1.5000, -1.1250],\n",
            "          [-0.3750, -0.7500,  0.5625]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.5000, -0.5625, -1.5000],\n",
            "          [-1.5000,  1.1250, -1.5000],\n",
            "          [ 0.0625,  0.0625, -0.2500]],\n",
            "\n",
            "         [[-0.7500,  0.3750, -1.1250],\n",
            "          [ 1.5000, -0.5000, -1.1250],\n",
            "          [ 0.3750, -0.2500, -0.5000]],\n",
            "\n",
            "         [[-0.1250,  0.7500,  0.0625],\n",
            "          [ 0.3750,  0.2500,  0.7500],\n",
            "          [ 1.0000,  0.7500, -0.3750]]],\n",
            "\n",
            "\n",
            "        [[[-1.0000, -0.7500, -0.5625],\n",
            "          [-1.5000,  1.5000,  0.7500],\n",
            "          [ 1.5000, -1.5000,  1.5000]],\n",
            "\n",
            "         [[-1.0000,  1.1250, -0.5000],\n",
            "          [-1.0000,  1.5000,  0.7500],\n",
            "          [ 0.1250,  0.5625, -0.3750]],\n",
            "\n",
            "         [[-0.0000,  0.5625,  1.0000],\n",
            "          [-0.1250, -1.1250, -0.3750],\n",
            "          [ 0.5625, -1.5000, -0.0000]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0625, -1.5000, -0.3750],\n",
            "          [ 1.0000, -0.1875,  0.1250],\n",
            "          [ 0.3750,  0.1875,  0.7500]],\n",
            "\n",
            "         [[-0.5625,  0.7500, -1.5000],\n",
            "          [ 0.3750, -0.7500,  1.5000],\n",
            "          [ 0.7500,  1.0000, -1.5000]],\n",
            "\n",
            "         [[-0.5625, -1.5000, -0.2500],\n",
            "          [ 0.5000,  1.1250, -1.1250],\n",
            "          [-0.2500,  1.5000, -1.1250]]]], device='cuda:0',\n",
            "       grad_fn=<_pqBackward>)\n",
            "tensor([[[[ 0.1250]],\n",
            "\n",
            "         [[ 1.0000]],\n",
            "\n",
            "         [[ 0.2500]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.0000]],\n",
            "\n",
            "         [[ 1.1250]],\n",
            "\n",
            "         [[-0.7500]]],\n",
            "\n",
            "\n",
            "        [[[-0.5625]],\n",
            "\n",
            "         [[ 0.1875]],\n",
            "\n",
            "         [[ 0.2500]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.1250]],\n",
            "\n",
            "         [[-0.0625]],\n",
            "\n",
            "         [[ 1.1250]]],\n",
            "\n",
            "\n",
            "        [[[-0.0000]],\n",
            "\n",
            "         [[ 1.5000]],\n",
            "\n",
            "         [[-0.3750]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.5000]],\n",
            "\n",
            "         [[ 1.1250]],\n",
            "\n",
            "         [[ 0.5000]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 1.5000]],\n",
            "\n",
            "         [[ 1.1250]],\n",
            "\n",
            "         [[-1.1250]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.5000]],\n",
            "\n",
            "         [[ 0.2500]],\n",
            "\n",
            "         [[-1.0000]]],\n",
            "\n",
            "\n",
            "        [[[-1.5000]],\n",
            "\n",
            "         [[ 0.7500]],\n",
            "\n",
            "         [[-0.3750]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.5000]],\n",
            "\n",
            "         [[-1.0000]],\n",
            "\n",
            "         [[ 0.3750]]],\n",
            "\n",
            "\n",
            "        [[[-0.1875]],\n",
            "\n",
            "         [[-0.2500]],\n",
            "\n",
            "         [[ 0.5625]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.5625]],\n",
            "\n",
            "         [[ 0.0625]],\n",
            "\n",
            "         [[-1.5000]]]], device='cuda:0', grad_fn=<_pqBackward>)\n",
            "tensor([[[[-0.5000, -0.7500, -0.2500],\n",
            "          [-0.0000, -0.5000, -0.1250],\n",
            "          [-0.5000,  1.1250,  0.7500]],\n",
            "\n",
            "         [[ 0.1250, -1.5000, -0.5000],\n",
            "          [ 1.0000, -1.5000, -1.5000],\n",
            "          [ 0.5000, -1.5000, -1.1250]],\n",
            "\n",
            "         [[ 1.5000, -1.1250,  1.5000],\n",
            "          [ 0.5625, -1.1250,  1.5000],\n",
            "          [-0.1875, -0.3750,  1.5000]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.7500,  0.3750, -0.7500],\n",
            "          [ 1.1250, -1.1250,  0.5625],\n",
            "          [-1.0000,  0.3750,  1.1250]],\n",
            "\n",
            "         [[ 0.7500, -0.7500, -1.1250],\n",
            "          [ 1.5000, -1.5000, -0.2500],\n",
            "          [ 1.1250,  1.5000,  1.0000]],\n",
            "\n",
            "         [[-1.5000,  0.0625,  0.1875],\n",
            "          [ 1.5000,  1.5000,  0.3750],\n",
            "          [ 1.5000, -1.5000, -0.2500]]],\n",
            "\n",
            "\n",
            "        [[[-1.1250,  1.5000,  0.5625],\n",
            "          [-1.5000, -0.3750, -0.5625],\n",
            "          [-0.7500,  0.5625,  1.1250]],\n",
            "\n",
            "         [[ 1.1250, -0.0000, -1.1250],\n",
            "          [ 1.5000,  0.3750,  1.0000],\n",
            "          [ 1.1250, -1.0000, -0.3750]],\n",
            "\n",
            "         [[ 1.5000, -0.1875, -1.5000],\n",
            "          [-0.3750,  0.5625, -0.2500],\n",
            "          [ 0.7500,  0.5000, -1.0000]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.0000,  0.5000,  0.7500],\n",
            "          [-1.1250,  1.0000,  1.0000],\n",
            "          [-0.0625,  1.5000,  1.1250]],\n",
            "\n",
            "         [[-0.2500,  0.7500,  0.1875],\n",
            "          [-1.5000, -0.3750,  1.0000],\n",
            "          [ 1.1250,  0.5000, -0.5000]],\n",
            "\n",
            "         [[-1.5000, -1.1250,  0.5625],\n",
            "          [-1.5000,  0.0625, -0.0625],\n",
            "          [ 1.5000, -1.5000, -1.5000]]],\n",
            "\n",
            "\n",
            "        [[[-0.1250, -0.2500, -1.0000],\n",
            "          [-0.5000, -1.1250,  1.0000],\n",
            "          [ 0.5625,  0.5000, -1.5000]],\n",
            "\n",
            "         [[ 1.5000,  0.5625, -1.5000],\n",
            "          [-0.0625, -0.1250, -1.5000],\n",
            "          [ 0.5000,  1.5000, -0.7500]],\n",
            "\n",
            "         [[-1.5000,  0.1250, -0.3750],\n",
            "          [-0.1875, -1.1250, -0.1250],\n",
            "          [ 0.2500, -0.2500,  0.1875]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.1250, -1.5000,  0.2500],\n",
            "          [-1.1250,  1.5000,  1.0000],\n",
            "          [-0.2500, -1.5000, -1.1250]],\n",
            "\n",
            "         [[ 0.3750, -0.0625,  1.5000],\n",
            "          [-1.1250, -1.1250, -1.5000],\n",
            "          [ 0.5000,  1.5000, -1.1250]],\n",
            "\n",
            "         [[ 0.7500, -1.1250, -0.7500],\n",
            "          [ 0.2500, -0.5625, -0.2500],\n",
            "          [-0.2500, -1.5000,  1.1250]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 1.5000,  1.5000, -0.5000],\n",
            "          [ 1.1250, -1.5000,  1.0000],\n",
            "          [-1.1250, -1.5000, -1.5000]],\n",
            "\n",
            "         [[ 1.5000,  1.5000, -1.1250],\n",
            "          [ 1.5000,  0.5000, -1.5000],\n",
            "          [ 0.1875,  1.0000,  1.5000]],\n",
            "\n",
            "         [[-0.5625, -1.0000, -0.5000],\n",
            "          [ 0.7500,  0.7500,  0.7500],\n",
            "          [-1.1250,  1.1250, -0.5000]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.5000, -0.7500, -1.5000],\n",
            "          [-0.5625,  1.5000,  1.1250],\n",
            "          [-1.1250,  0.7500, -0.1875]],\n",
            "\n",
            "         [[-0.3750, -0.7500, -0.2500],\n",
            "          [ 1.5000, -0.7500,  1.5000],\n",
            "          [-1.5000, -1.5000,  0.3750]],\n",
            "\n",
            "         [[-0.1875, -1.0000, -0.7500],\n",
            "          [-1.0000, -0.7500, -0.7500],\n",
            "          [-1.1250, -1.5000,  0.1250]]],\n",
            "\n",
            "\n",
            "        [[[ 0.7500, -0.1875, -1.0000],\n",
            "          [ 0.3750,  0.7500, -1.5000],\n",
            "          [-1.0000, -0.7500,  1.0000]],\n",
            "\n",
            "         [[ 0.7500, -0.1250, -0.5000],\n",
            "          [ 1.5000,  0.3750, -1.5000],\n",
            "          [ 1.1250, -0.1875,  1.1250]],\n",
            "\n",
            "         [[-0.5625,  1.5000, -0.1875],\n",
            "          [-0.3750, -0.7500,  1.1250],\n",
            "          [ 1.1250,  0.7500,  0.2500]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.5000,  0.2500, -1.1250],\n",
            "          [ 0.3750, -0.3750,  0.1250],\n",
            "          [-0.7500, -0.5625, -0.1250]],\n",
            "\n",
            "         [[ 0.7500,  1.5000,  1.5000],\n",
            "          [-0.5000,  1.5000,  0.5000],\n",
            "          [-1.1250, -1.0000,  0.1875]],\n",
            "\n",
            "         [[ 0.0625,  1.1250,  1.0000],\n",
            "          [ 0.0000, -0.2500, -0.3750],\n",
            "          [-1.0000, -0.1250,  1.5000]]],\n",
            "\n",
            "\n",
            "        [[[-1.0000, -0.7500,  0.5625],\n",
            "          [ 1.5000, -0.5000,  0.5625],\n",
            "          [ 1.5000,  0.1250,  1.5000]],\n",
            "\n",
            "         [[-0.1875, -1.1250,  0.2500],\n",
            "          [ 0.5000,  0.2500,  0.7500],\n",
            "          [ 1.5000, -0.7500,  0.5000]],\n",
            "\n",
            "         [[ 1.1250, -1.1250,  0.7500],\n",
            "          [-0.7500,  0.3750, -0.2500],\n",
            "          [ 0.5625, -1.1250,  1.1250]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.5000,  0.5000, -0.5000],\n",
            "          [ 0.7500, -1.5000,  0.3750],\n",
            "          [ 0.5000,  0.3750, -0.1875]],\n",
            "\n",
            "         [[-0.2500, -1.1250,  1.1250],\n",
            "          [-1.0000,  1.1250, -1.5000],\n",
            "          [-0.5000, -1.5000,  1.5000]],\n",
            "\n",
            "         [[ 1.5000,  1.1250,  1.5000],\n",
            "          [ 0.3750,  1.5000,  1.5000],\n",
            "          [ 1.5000, -1.0000, -0.5625]]]], device='cuda:0',\n",
            "       grad_fn=<_pqBackward>)\n",
            "tensor([[[[-0.7500]],\n",
            "\n",
            "         [[ 0.1875]],\n",
            "\n",
            "         [[ 1.5000]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.2500]],\n",
            "\n",
            "         [[-1.1250]],\n",
            "\n",
            "         [[ 0.2500]]],\n",
            "\n",
            "\n",
            "        [[[ 0.3750]],\n",
            "\n",
            "         [[-1.0000]],\n",
            "\n",
            "         [[ 0.2500]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.5000]],\n",
            "\n",
            "         [[ 1.5000]],\n",
            "\n",
            "         [[ 0.1875]]],\n",
            "\n",
            "\n",
            "        [[[ 1.1250]],\n",
            "\n",
            "         [[ 1.5000]],\n",
            "\n",
            "         [[-0.3750]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.5000]],\n",
            "\n",
            "         [[ 0.2500]],\n",
            "\n",
            "         [[-0.2500]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-1.5000]],\n",
            "\n",
            "         [[-0.5625]],\n",
            "\n",
            "         [[-1.1250]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.0000]],\n",
            "\n",
            "         [[ 0.2500]],\n",
            "\n",
            "         [[-0.3750]]],\n",
            "\n",
            "\n",
            "        [[[-0.5625]],\n",
            "\n",
            "         [[-1.5000]],\n",
            "\n",
            "         [[-0.7500]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.1250]],\n",
            "\n",
            "         [[-1.5000]],\n",
            "\n",
            "         [[ 0.2500]]],\n",
            "\n",
            "\n",
            "        [[[ 0.5625]],\n",
            "\n",
            "         [[-0.2500]],\n",
            "\n",
            "         [[-0.5625]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.7500]],\n",
            "\n",
            "         [[-1.1250]],\n",
            "\n",
            "         [[ 0.7500]]]], device='cuda:0', grad_fn=<_pqBackward>)\n",
            "tensor([[[[ 0.7500, -0.2500,  0.2500],\n",
            "          [ 1.1250,  1.5000, -1.1250],\n",
            "          [-1.0000, -1.1250,  0.7500]],\n",
            "\n",
            "         [[-0.5000,  1.0000,  1.5000],\n",
            "          [ 0.1875, -0.2500, -1.1250],\n",
            "          [ 0.2500,  1.1250, -0.7500]],\n",
            "\n",
            "         [[-0.7500, -0.1250, -0.1250],\n",
            "          [ 0.5000, -1.5000, -1.0000],\n",
            "          [ 1.5000,  0.5000, -0.5625]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.5000, -0.5000,  1.0000],\n",
            "          [ 0.5625,  0.0625, -0.5000],\n",
            "          [-1.1250, -1.1250, -0.7500]],\n",
            "\n",
            "         [[ 0.7500,  1.1250,  1.5000],\n",
            "          [-0.7500,  1.5000, -0.2500],\n",
            "          [ 0.7500, -0.7500, -0.5625]],\n",
            "\n",
            "         [[-0.1875,  1.1250,  0.2500],\n",
            "          [ 0.7500, -1.5000,  1.5000],\n",
            "          [ 1.0000, -0.2500, -0.0000]]],\n",
            "\n",
            "\n",
            "        [[[ 1.1250,  1.1250,  1.1250],\n",
            "          [-0.5625,  0.7500,  1.5000],\n",
            "          [-1.1250, -0.7500, -1.5000]],\n",
            "\n",
            "         [[-1.5000, -1.1250, -1.1250],\n",
            "          [-1.1250,  0.5000, -1.1250],\n",
            "          [-1.5000, -0.3750, -1.5000]],\n",
            "\n",
            "         [[ 0.0625,  1.5000, -0.1875],\n",
            "          [ 1.5000, -1.0000, -0.7500],\n",
            "          [ 1.1250, -1.1250, -0.5000]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.1250,  0.3750, -1.5000],\n",
            "          [ 0.7500,  0.3750,  1.5000],\n",
            "          [ 1.1250,  0.7500,  1.5000]],\n",
            "\n",
            "         [[-1.5000,  1.0000,  0.2500],\n",
            "          [ 1.0000,  1.0000,  0.5000],\n",
            "          [-0.5000,  1.5000, -0.5625]],\n",
            "\n",
            "         [[-1.5000, -1.0000,  0.2500],\n",
            "          [-1.0000, -0.3750, -0.2500],\n",
            "          [ 1.0000,  0.5000, -0.1875]]],\n",
            "\n",
            "\n",
            "        [[[ 1.5000,  0.0625, -1.5000],\n",
            "          [ 1.0000, -1.0000,  0.7500],\n",
            "          [-1.1250,  1.0000,  0.0625]],\n",
            "\n",
            "         [[ 0.7500,  0.5625, -0.1875],\n",
            "          [ 1.5000, -0.5000, -0.2500],\n",
            "          [-1.1250,  1.5000, -1.5000]],\n",
            "\n",
            "         [[ 1.1250, -1.5000,  0.2500],\n",
            "          [ 1.1250,  1.0000, -0.7500],\n",
            "          [-0.2500, -0.1875, -1.5000]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.5000,  1.5000, -0.1250],\n",
            "          [-1.1250,  1.0000, -0.2500],\n",
            "          [ 0.3750, -1.0000,  0.5000]],\n",
            "\n",
            "         [[-1.5000, -0.1875, -1.5000],\n",
            "          [-0.1250, -0.5000, -1.5000],\n",
            "          [ 1.5000, -1.0000, -0.2500]],\n",
            "\n",
            "         [[-1.1250,  0.5625, -0.2500],\n",
            "          [-1.1250, -0.1250,  1.1250],\n",
            "          [ 0.7500,  0.3750,  0.5625]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.0625, -0.1875, -1.5000],\n",
            "          [-1.1250, -1.5000, -0.5625],\n",
            "          [ 1.5000,  1.5000, -0.7500]],\n",
            "\n",
            "         [[-0.7500, -1.1250,  0.2500],\n",
            "          [ 1.0000,  0.5625, -1.1250],\n",
            "          [-1.5000,  1.5000,  0.5000]],\n",
            "\n",
            "         [[ 1.1250,  0.1875, -0.1250],\n",
            "          [ 0.2500,  1.5000, -1.0000],\n",
            "          [-0.5000,  0.5625, -1.1250]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.1250,  0.3750, -1.5000],\n",
            "          [ 1.5000, -1.1250,  1.1250],\n",
            "          [ 0.1250,  1.0000,  1.5000]],\n",
            "\n",
            "         [[-1.5000, -1.1250,  0.5000],\n",
            "          [-0.1250,  0.7500,  1.0000],\n",
            "          [-0.7500, -0.7500, -1.5000]],\n",
            "\n",
            "         [[-1.5000,  1.1250,  1.5000],\n",
            "          [-1.5000,  0.7500,  0.7500],\n",
            "          [ 1.5000,  1.5000, -1.5000]]],\n",
            "\n",
            "\n",
            "        [[[ 1.5000,  0.7500, -1.0000],\n",
            "          [ 0.5625,  0.5625,  1.1250],\n",
            "          [ 1.1250, -0.3750,  0.5000]],\n",
            "\n",
            "         [[-0.7500,  0.3750,  1.5000],\n",
            "          [ 1.5000,  0.5625, -0.2500],\n",
            "          [-0.7500, -1.5000,  0.1250]],\n",
            "\n",
            "         [[-1.1250, -1.5000,  1.0000],\n",
            "          [ 0.7500, -1.0000, -0.5625],\n",
            "          [-1.1250, -1.5000,  1.5000]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.0000,  0.3750,  1.0000],\n",
            "          [-1.1250, -1.5000, -1.5000],\n",
            "          [-1.5000, -0.1250, -1.1250]],\n",
            "\n",
            "         [[ 1.5000,  1.1250, -0.3750],\n",
            "          [-1.5000,  0.7500,  1.5000],\n",
            "          [-1.5000, -0.7500,  0.7500]],\n",
            "\n",
            "         [[ 0.1250, -1.5000,  0.7500],\n",
            "          [ 0.5625,  1.0000,  0.0625],\n",
            "          [ 1.0000, -0.0000,  0.7500]]],\n",
            "\n",
            "\n",
            "        [[[ 0.3750,  0.0000, -1.5000],\n",
            "          [ 0.2500,  0.2500, -0.0625],\n",
            "          [ 0.0625, -1.5000,  0.5625]],\n",
            "\n",
            "         [[ 0.0625,  1.1250, -0.1875],\n",
            "          [ 0.1875, -1.5000,  0.7500],\n",
            "          [-0.1875, -1.5000, -1.5000]],\n",
            "\n",
            "         [[-1.0000, -0.5625,  1.5000],\n",
            "          [ 1.5000, -0.5625, -0.7500],\n",
            "          [ 1.0000, -1.5000,  1.1250]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.0000,  1.0000, -1.5000],\n",
            "          [-1.5000, -1.5000,  0.1875],\n",
            "          [-0.0625, -0.5000,  1.1250]],\n",
            "\n",
            "         [[ 1.1250,  1.0000,  0.2500],\n",
            "          [-1.1250, -1.5000,  1.5000],\n",
            "          [ 1.1250,  0.7500,  1.5000]],\n",
            "\n",
            "         [[ 0.1875, -1.5000,  0.7500],\n",
            "          [ 1.5000,  0.7500, -1.1250],\n",
            "          [ 0.0000,  0.3750,  1.5000]]]], device='cuda:0',\n",
            "       grad_fn=<_pqBackward>)\n",
            "tensor([[[[-0.0625]],\n",
            "\n",
            "         [[-1.5000]],\n",
            "\n",
            "         [[ 0.7500]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.7500]],\n",
            "\n",
            "         [[-0.7500]],\n",
            "\n",
            "         [[-0.3750]]],\n",
            "\n",
            "\n",
            "        [[[ 0.7500]],\n",
            "\n",
            "         [[ 0.7500]],\n",
            "\n",
            "         [[-1.5000]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.1250]],\n",
            "\n",
            "         [[-1.5000]],\n",
            "\n",
            "         [[ 1.5000]]],\n",
            "\n",
            "\n",
            "        [[[-0.7500]],\n",
            "\n",
            "         [[ 1.0000]],\n",
            "\n",
            "         [[-1.5000]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.7500]],\n",
            "\n",
            "         [[ 1.0000]],\n",
            "\n",
            "         [[ 1.0000]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.3750]],\n",
            "\n",
            "         [[ 0.7500]],\n",
            "\n",
            "         [[ 1.5000]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.1250]],\n",
            "\n",
            "         [[ 0.5000]],\n",
            "\n",
            "         [[-0.3750]]],\n",
            "\n",
            "\n",
            "        [[[-0.5000]],\n",
            "\n",
            "         [[ 1.5000]],\n",
            "\n",
            "         [[-0.5625]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.1250]],\n",
            "\n",
            "         [[ 0.3750]],\n",
            "\n",
            "         [[ 1.0000]]],\n",
            "\n",
            "\n",
            "        [[[ 1.1250]],\n",
            "\n",
            "         [[-1.5000]],\n",
            "\n",
            "         [[ 0.3750]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.2500]],\n",
            "\n",
            "         [[-1.0000]],\n",
            "\n",
            "         [[-1.5000]]]], device='cuda:0', grad_fn=<_pqBackward>)\n",
            "tensor([[[[ 1.0000, -1.1250, -0.5000],\n",
            "          [-1.0000, -1.5000, -0.5625],\n",
            "          [-0.5625, -0.5000, -1.1250]],\n",
            "\n",
            "         [[ 1.0000, -1.1250,  0.1250],\n",
            "          [ 0.7500,  0.2500, -1.1250],\n",
            "          [-0.5000,  0.7500, -1.5000]],\n",
            "\n",
            "         [[ 0.2500,  0.7500,  0.7500],\n",
            "          [-0.7500,  0.5000,  0.7500],\n",
            "          [ 1.0000,  1.1250,  1.5000]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.5000, -0.7500, -1.1250],\n",
            "          [ 1.5000, -1.1250,  0.5625],\n",
            "          [-0.5625,  0.0000, -1.1250]],\n",
            "\n",
            "         [[ 0.7500, -1.0000,  1.5000],\n",
            "          [-1.0000,  1.5000, -1.5000],\n",
            "          [ 0.3750, -0.1875,  0.5000]],\n",
            "\n",
            "         [[-0.2500, -1.1250, -1.0000],\n",
            "          [ 1.5000,  1.5000, -0.0625],\n",
            "          [-1.5000,  0.1250, -1.5000]]],\n",
            "\n",
            "\n",
            "        [[[ 0.5000, -0.5000,  1.1250],\n",
            "          [ 1.0000, -1.0000,  0.1875],\n",
            "          [ 0.7500, -1.0000, -0.5000]],\n",
            "\n",
            "         [[ 1.5000,  0.7500, -1.0000],\n",
            "          [-0.5625,  0.1875, -1.5000],\n",
            "          [-1.1250,  0.1250, -1.1250]],\n",
            "\n",
            "         [[ 0.1875, -1.5000, -1.5000],\n",
            "          [ 1.1250,  1.5000,  0.3750],\n",
            "          [-0.5000, -1.5000, -0.3750]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.1250, -1.1250,  1.5000],\n",
            "          [ 1.5000,  0.5000, -0.5625],\n",
            "          [-0.2500,  1.5000,  1.1250]],\n",
            "\n",
            "         [[-0.5000, -0.3750,  0.5625],\n",
            "          [ 1.1250,  0.3750,  1.1250],\n",
            "          [-1.5000,  1.5000,  0.7500]],\n",
            "\n",
            "         [[ 0.7500, -1.1250,  0.7500],\n",
            "          [ 1.5000, -1.5000,  0.0625],\n",
            "          [ 0.7500, -0.5000, -0.1250]]],\n",
            "\n",
            "\n",
            "        [[[-1.0000, -1.1250,  1.5000],\n",
            "          [ 0.5625,  0.1250,  0.7500],\n",
            "          [ 0.1875,  0.3750,  0.0625]],\n",
            "\n",
            "         [[-0.5000, -0.7500, -0.3750],\n",
            "          [ 1.0000,  0.1250, -1.0000],\n",
            "          [-0.7500, -0.3750, -1.1250]],\n",
            "\n",
            "         [[ 1.0000, -1.5000,  1.0000],\n",
            "          [-1.5000, -0.5625,  0.7500],\n",
            "          [ 0.5000, -0.7500,  0.7500]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.7500, -0.5000, -0.0625],\n",
            "          [-0.5000, -1.5000,  1.5000],\n",
            "          [-0.5625, -1.5000,  1.5000]],\n",
            "\n",
            "         [[-1.5000,  1.1250, -0.7500],\n",
            "          [-0.2500,  1.5000, -0.1250],\n",
            "          [ 1.5000,  1.5000,  0.0625]],\n",
            "\n",
            "         [[ 1.5000,  1.5000,  1.5000],\n",
            "          [-0.7500, -0.0000,  0.2500],\n",
            "          [ 1.0000, -1.1250, -0.1250]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-1.1250,  1.1250,  1.5000],\n",
            "          [ 1.5000,  1.5000, -1.1250],\n",
            "          [-0.1250, -0.5625,  1.5000]],\n",
            "\n",
            "         [[-0.7500, -0.0000, -1.1250],\n",
            "          [-1.0000,  0.0625, -0.2500],\n",
            "          [-1.5000, -1.1250, -1.1250]],\n",
            "\n",
            "         [[-0.7500,  1.1250, -1.5000],\n",
            "          [-0.1875, -1.5000,  0.0625],\n",
            "          [-0.2500,  1.5000, -1.5000]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0000, -0.0000, -0.7500],\n",
            "          [-1.0000,  1.5000,  1.5000],\n",
            "          [ 0.2500,  0.5000,  0.7500]],\n",
            "\n",
            "         [[-1.1250, -1.0000,  0.1250],\n",
            "          [ 0.1250,  1.1250,  0.0000],\n",
            "          [ 0.5625, -0.5625, -0.1250]],\n",
            "\n",
            "         [[ 1.1250, -0.5625,  1.5000],\n",
            "          [-0.0000, -0.2500,  1.5000],\n",
            "          [ 1.0000,  1.1250,  0.5000]]],\n",
            "\n",
            "\n",
            "        [[[-1.5000,  0.7500,  1.5000],\n",
            "          [-1.1250, -0.1250,  0.5000],\n",
            "          [ 1.1250,  1.0000, -1.0000]],\n",
            "\n",
            "         [[ 1.5000, -1.1250,  1.1250],\n",
            "          [ 1.5000, -1.0000,  1.0000],\n",
            "          [ 1.5000, -0.7500, -1.5000]],\n",
            "\n",
            "         [[ 1.5000, -0.1875, -1.0000],\n",
            "          [ 1.1250,  1.1250, -1.5000],\n",
            "          [ 0.3750,  1.1250, -0.0000]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.5625, -1.1250,  1.5000],\n",
            "          [-1.0000,  1.1250, -1.1250],\n",
            "          [ 0.7500, -0.5000,  0.5000]],\n",
            "\n",
            "         [[-1.5000, -0.2500, -0.5625],\n",
            "          [ 0.7500, -0.5625,  1.0000],\n",
            "          [ 1.5000,  1.5000, -0.7500]],\n",
            "\n",
            "         [[-1.1250,  1.1250,  0.5625],\n",
            "          [-0.0625,  1.5000, -1.0000],\n",
            "          [-0.7500, -1.5000,  0.0000]]],\n",
            "\n",
            "\n",
            "        [[[-0.1875,  0.7500, -0.7500],\n",
            "          [ 1.1250,  1.0000, -0.5000],\n",
            "          [-0.2500, -0.5625, -0.2500]],\n",
            "\n",
            "         [[ 0.3750, -1.5000,  0.2500],\n",
            "          [-1.5000,  1.5000, -0.1875],\n",
            "          [ 1.5000, -0.1250, -1.5000]],\n",
            "\n",
            "         [[-1.5000, -0.7500,  0.5625],\n",
            "          [ 1.5000, -0.2500, -1.1250],\n",
            "          [ 0.1250,  0.5625, -1.0000]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.1250, -0.5625,  0.7500],\n",
            "          [ 1.0000, -0.1875,  0.3750],\n",
            "          [ 0.2500, -0.1875, -0.7500]],\n",
            "\n",
            "         [[-1.0000, -1.5000, -1.1250],\n",
            "          [-0.1250,  1.0000,  1.0000],\n",
            "          [ 0.7500,  1.0000,  1.5000]],\n",
            "\n",
            "         [[-0.5000,  0.1250,  0.1250],\n",
            "          [ 1.5000, -0.7500,  0.1250],\n",
            "          [-1.5000,  0.3750, -1.5000]]]], device='cuda:0',\n",
            "       grad_fn=<_pqBackward>)\n",
            "tensor([[[[-0.7500]],\n",
            "\n",
            "         [[-0.7500]],\n",
            "\n",
            "         [[-0.2500]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.5000]],\n",
            "\n",
            "         [[ 1.1250]],\n",
            "\n",
            "         [[ 0.3750]]],\n",
            "\n",
            "\n",
            "        [[[-0.0625]],\n",
            "\n",
            "         [[-1.1250]],\n",
            "\n",
            "         [[ 0.7500]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.5000]],\n",
            "\n",
            "         [[-1.0000]],\n",
            "\n",
            "         [[ 0.5625]]],\n",
            "\n",
            "\n",
            "        [[[ 0.5625]],\n",
            "\n",
            "         [[-1.5000]],\n",
            "\n",
            "         [[ 0.7500]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.5000]],\n",
            "\n",
            "         [[ 1.5000]],\n",
            "\n",
            "         [[-0.5625]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 1.5000]],\n",
            "\n",
            "         [[ 1.5000]],\n",
            "\n",
            "         [[-1.1250]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.2500]],\n",
            "\n",
            "         [[-1.1250]],\n",
            "\n",
            "         [[-0.1250]]],\n",
            "\n",
            "\n",
            "        [[[-1.5000]],\n",
            "\n",
            "         [[ 0.5625]],\n",
            "\n",
            "         [[ 0.7500]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.5625]],\n",
            "\n",
            "         [[-1.1250]],\n",
            "\n",
            "         [[-0.5625]]],\n",
            "\n",
            "\n",
            "        [[[-1.5000]],\n",
            "\n",
            "         [[-0.7500]],\n",
            "\n",
            "         [[-0.7500]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.0000]],\n",
            "\n",
            "         [[ 1.1250]],\n",
            "\n",
            "         [[-0.7500]]]], device='cuda:0', grad_fn=<_pqBackward>)\n",
            "tensor([[[[-1.0000,  0.5000,  1.1250],\n",
            "          [ 1.5000, -0.2500,  0.5000],\n",
            "          [ 1.1250,  1.5000, -0.2500]],\n",
            "\n",
            "         [[-1.1250, -0.7500, -0.0625],\n",
            "          [ 0.7500,  1.0000, -1.5000],\n",
            "          [ 0.1875,  0.5625, -0.5625]],\n",
            "\n",
            "         [[ 1.5000,  1.5000,  1.5000],\n",
            "          [-0.7500,  1.0000, -0.7500],\n",
            "          [-0.7500, -0.1250,  1.1250]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.2500,  1.5000, -0.7500],\n",
            "          [ 1.5000, -1.5000, -1.0000],\n",
            "          [-1.1250, -1.5000, -1.5000]],\n",
            "\n",
            "         [[ 0.2500,  0.1875,  1.5000],\n",
            "          [-0.5625, -1.5000, -0.5000],\n",
            "          [ 0.2500,  1.0000, -1.0000]],\n",
            "\n",
            "         [[ 1.1250, -1.5000,  1.0000],\n",
            "          [-0.7500, -1.1250,  0.5000],\n",
            "          [ 0.2500, -1.5000, -0.7500]]],\n",
            "\n",
            "\n",
            "        [[[-0.5000,  0.7500, -0.1250],\n",
            "          [ 1.5000, -1.5000, -0.2500],\n",
            "          [ 2.0000,  0.1875,  0.7500]],\n",
            "\n",
            "         [[ 0.7500,  0.7500, -0.5625],\n",
            "          [ 0.5625, -1.5000,  0.3750],\n",
            "          [ 0.2500, -1.1250,  1.0000]],\n",
            "\n",
            "         [[-1.1250,  1.5000, -0.7500],\n",
            "          [ 0.3750,  0.1250, -0.5625],\n",
            "          [-1.1250,  0.5625, -1.5000]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.0000, -0.2500, -1.0000],\n",
            "          [-0.7500,  1.1250, -1.0000],\n",
            "          [ 0.1875,  1.1250,  0.0625]],\n",
            "\n",
            "         [[-0.1875,  0.0625,  0.1250],\n",
            "          [ 0.3750,  1.5000, -1.0000],\n",
            "          [-0.2500, -0.5000, -1.5000]],\n",
            "\n",
            "         [[-0.3750,  1.5000, -1.0000],\n",
            "          [ 0.1875,  0.1875,  0.1250],\n",
            "          [ 1.1250,  1.5000, -1.5000]]],\n",
            "\n",
            "\n",
            "        [[[-1.5000,  0.2500, -1.0000],\n",
            "          [-1.1250,  0.5625,  1.1250],\n",
            "          [-1.5000,  0.3750, -1.5000]],\n",
            "\n",
            "         [[ 0.2500, -0.0625, -0.5625],\n",
            "          [-1.0000,  1.0000,  1.5000],\n",
            "          [-0.5000, -1.1250, -0.5625]],\n",
            "\n",
            "         [[-1.5000,  1.5000, -1.5000],\n",
            "          [-1.1250, -1.5000, -0.5625],\n",
            "          [-0.0625,  0.3750, -0.7500]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.1250, -1.5000, -0.5625],\n",
            "          [-1.5000,  1.5000,  1.5000],\n",
            "          [-1.5000,  0.7500, -0.1875]],\n",
            "\n",
            "         [[-0.0625,  0.2500, -1.5000],\n",
            "          [-1.5000, -0.7500,  1.1250],\n",
            "          [-1.5000,  0.5625, -1.0000]],\n",
            "\n",
            "         [[-1.5000,  1.1250, -0.0000],\n",
            "          [-0.5625,  1.1250,  1.1250],\n",
            "          [-1.1250,  1.0000, -0.5625]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 1.1250,  1.0000, -1.1250],\n",
            "          [-1.5000, -0.3750,  0.7500],\n",
            "          [ 0.7500, -1.0000, -1.1250]],\n",
            "\n",
            "         [[-1.1250, -1.0000,  0.7500],\n",
            "          [ 0.5000,  0.0000,  0.2500],\n",
            "          [ 1.5000,  1.1250,  1.5000]],\n",
            "\n",
            "         [[-1.1250,  0.2500, -1.0000],\n",
            "          [ 2.0000,  0.3750, -0.0625],\n",
            "          [-1.5000, -0.5000,  0.1250]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.5625,  1.5000, -1.5000],\n",
            "          [-0.7500, -1.0000,  0.7500],\n",
            "          [ 0.5000, -1.0000,  1.5000]],\n",
            "\n",
            "         [[-0.3750, -0.7500,  1.1250],\n",
            "          [-1.5000, -0.5625,  1.0000],\n",
            "          [-1.5000,  1.5000,  0.5000]],\n",
            "\n",
            "         [[-1.1250,  1.5000,  0.3750],\n",
            "          [ 0.7500,  0.5625, -0.1250],\n",
            "          [-1.5000, -1.5000, -0.7500]]],\n",
            "\n",
            "\n",
            "        [[[-0.1875,  1.5000, -1.0000],\n",
            "          [-0.2500, -0.7500, -0.2500],\n",
            "          [ 1.5000,  0.3750,  1.1250]],\n",
            "\n",
            "         [[-1.5000, -1.5000, -0.1250],\n",
            "          [-0.5625, -0.5625, -1.1250],\n",
            "          [ 1.5000,  0.3750, -1.1250]],\n",
            "\n",
            "         [[ 0.5625, -0.1875,  0.5625],\n",
            "          [-1.1250, -1.0000,  1.5000],\n",
            "          [ 0.7500,  1.1250,  1.1250]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.3750,  0.5625,  1.5000],\n",
            "          [ 1.5000,  1.0000, -0.1250],\n",
            "          [-1.5000,  1.5000,  0.5625]],\n",
            "\n",
            "         [[-1.5000, -1.1250, -1.1250],\n",
            "          [ 1.5000, -0.7500, -0.5625],\n",
            "          [ 1.5000,  1.1250,  1.0000]],\n",
            "\n",
            "         [[ 0.7500, -0.0625,  0.3750],\n",
            "          [ 0.7500, -0.7500, -0.7500],\n",
            "          [ 0.0000,  1.5000,  0.3750]]],\n",
            "\n",
            "\n",
            "        [[[-1.1250,  1.0000,  0.3750],\n",
            "          [-0.5000, -0.3750, -0.1250],\n",
            "          [-0.7500, -0.1875,  1.5000]],\n",
            "\n",
            "         [[-0.0000, -0.5625, -0.2500],\n",
            "          [-1.0000, -1.5000, -1.1250],\n",
            "          [ 1.1250,  0.5000, -1.1250]],\n",
            "\n",
            "         [[-1.0000,  0.5000, -0.2500],\n",
            "          [ 0.0625, -0.3750, -1.5000],\n",
            "          [-1.5000, -0.2500, -0.2500]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.5625,  0.5625,  1.1250],\n",
            "          [ 1.5000,  0.3750,  1.0000],\n",
            "          [-1.5000, -0.7500,  0.5625]],\n",
            "\n",
            "         [[-0.7500,  0.7500,  0.7500],\n",
            "          [-1.5000, -1.5000,  1.5000],\n",
            "          [-0.7500, -1.1250,  0.1875]],\n",
            "\n",
            "         [[-1.5000,  0.0625, -0.2500],\n",
            "          [-0.1875,  1.5000, -0.5000],\n",
            "          [ 0.1875, -1.0000,  1.1250]]]], device='cuda:0',\n",
            "       grad_fn=<_pqBackward>)\n",
            "tensor([[[[ 1.0000]],\n",
            "\n",
            "         [[ 0.7500]],\n",
            "\n",
            "         [[ 1.5000]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.5000]],\n",
            "\n",
            "         [[-0.7500]],\n",
            "\n",
            "         [[ 1.0000]]],\n",
            "\n",
            "\n",
            "        [[[-1.5000]],\n",
            "\n",
            "         [[-1.5000]],\n",
            "\n",
            "         [[ 1.5000]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.1250]],\n",
            "\n",
            "         [[-1.1250]],\n",
            "\n",
            "         [[ 1.0000]]],\n",
            "\n",
            "\n",
            "        [[[-1.5000]],\n",
            "\n",
            "         [[ 1.5000]],\n",
            "\n",
            "         [[-1.5000]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.1250]],\n",
            "\n",
            "         [[-0.7500]],\n",
            "\n",
            "         [[ 0.3750]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-1.5000]],\n",
            "\n",
            "         [[ 0.7500]],\n",
            "\n",
            "         [[-1.1250]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.1250]],\n",
            "\n",
            "         [[ 1.5000]],\n",
            "\n",
            "         [[ 1.5000]]],\n",
            "\n",
            "\n",
            "        [[[-0.7500]],\n",
            "\n",
            "         [[ 0.7500]],\n",
            "\n",
            "         [[-0.5625]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.1250]],\n",
            "\n",
            "         [[-1.5000]],\n",
            "\n",
            "         [[ 1.5000]]],\n",
            "\n",
            "\n",
            "        [[[-0.1250]],\n",
            "\n",
            "         [[ 0.0625]],\n",
            "\n",
            "         [[-1.5000]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.3750]],\n",
            "\n",
            "         [[ 1.5000]],\n",
            "\n",
            "         [[ 1.5000]]]], device='cuda:0', grad_fn=<_pqBackward>)\n",
            "tensor([[[[ 1.1250, -0.0625,  1.5000],\n",
            "          [-0.7500,  1.1250,  1.5000],\n",
            "          [-0.3750,  0.3750,  0.7500]],\n",
            "\n",
            "         [[ 1.5000, -1.1250,  1.1250],\n",
            "          [-0.5000,  0.5625, -1.1250],\n",
            "          [ 0.1875,  1.1250,  0.0625]],\n",
            "\n",
            "         [[-1.5000,  0.5625,  1.5000],\n",
            "          [-1.1250, -0.0000, -0.3750],\n",
            "          [-1.5000,  0.5000, -0.3750]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.3750, -0.3750,  0.3750],\n",
            "          [ 1.1250,  0.0625,  1.0000],\n",
            "          [ 1.5000,  0.3750, -0.0625]],\n",
            "\n",
            "         [[-1.1250,  1.5000,  1.0000],\n",
            "          [-0.0000,  0.3750, -1.1250],\n",
            "          [ 0.2500,  1.5000,  0.1250]],\n",
            "\n",
            "         [[-1.1250, -0.5625,  0.2500],\n",
            "          [-1.1250, -0.0625,  0.3750],\n",
            "          [-0.2500, -0.0625, -1.5000]]],\n",
            "\n",
            "\n",
            "        [[[-1.5000,  1.0000, -0.7500],\n",
            "          [ 0.5625, -0.5625,  0.5625],\n",
            "          [-0.5625,  0.1875,  0.7500]],\n",
            "\n",
            "         [[ 1.1250,  0.2500,  0.1875],\n",
            "          [ 0.7500,  0.7500,  0.5625],\n",
            "          [-0.3750,  1.5000, -0.2500]],\n",
            "\n",
            "         [[ 0.5000, -0.1250,  0.7500],\n",
            "          [-1.5000,  0.7500, -0.7500],\n",
            "          [ 1.5000, -1.5000, -0.2500]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.0000, -0.1250,  1.5000],\n",
            "          [-1.5000, -0.5000, -1.5000],\n",
            "          [ 0.0625, -1.1250, -0.7500]],\n",
            "\n",
            "         [[-1.5000, -0.7500, -0.0625],\n",
            "          [ 1.0000,  1.5000, -0.2500],\n",
            "          [ 1.5000,  0.7500,  0.3750]],\n",
            "\n",
            "         [[-1.1250,  0.2500, -0.3750],\n",
            "          [-1.5000, -0.5625, -0.2500],\n",
            "          [ 0.0000, -0.7500, -1.5000]]],\n",
            "\n",
            "\n",
            "        [[[ 0.3750, -0.7500,  1.5000],\n",
            "          [-1.0000, -0.5000, -1.5000],\n",
            "          [ 1.5000,  1.1250, -1.5000]],\n",
            "\n",
            "         [[ 1.5000, -1.5000,  0.3750],\n",
            "          [ 1.1250,  1.5000, -1.5000],\n",
            "          [ 1.1250,  0.7500,  1.1250]],\n",
            "\n",
            "         [[-0.1875,  1.0000, -1.5000],\n",
            "          [-1.1250,  0.3750, -1.5000],\n",
            "          [-1.5000,  0.7500, -1.5000]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.5000,  0.5000,  1.1250],\n",
            "          [-0.3750, -0.1250, -0.2500],\n",
            "          [ 1.0000, -1.5000, -1.5000]],\n",
            "\n",
            "         [[ 0.0000, -0.2500, -1.5000],\n",
            "          [-1.5000, -0.3750, -1.5000],\n",
            "          [-1.1250, -1.1250, -0.2500]],\n",
            "\n",
            "         [[-0.1250, -1.1250,  1.5000],\n",
            "          [ 1.5000, -0.7500, -1.1250],\n",
            "          [-0.3750, -1.5000, -1.5000]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 1.0000,  0.5625, -0.2500],\n",
            "          [-0.7500, -0.7500, -1.5000],\n",
            "          [ 1.0000,  1.1250, -1.5000]],\n",
            "\n",
            "         [[ 1.1250,  0.0000, -0.2500],\n",
            "          [-0.5625,  1.5000,  0.7500],\n",
            "          [-0.5000,  1.1250, -1.5000]],\n",
            "\n",
            "         [[-1.5000, -1.5000,  1.5000],\n",
            "          [-0.5000,  0.3750,  0.7500],\n",
            "          [-1.1250,  1.0000, -1.1250]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.2500, -0.7500,  1.1250],\n",
            "          [ 0.7500, -1.1250, -1.1250],\n",
            "          [-0.7500, -0.5000, -1.5000]],\n",
            "\n",
            "         [[-0.1875,  1.5000,  0.5625],\n",
            "          [ 0.5625,  0.1250,  0.1250],\n",
            "          [ 1.1250,  1.1250,  0.5000]],\n",
            "\n",
            "         [[-0.7500,  0.5625, -1.5000],\n",
            "          [-1.1250,  0.3750,  1.1250],\n",
            "          [ 1.5000, -0.3750,  0.1250]]],\n",
            "\n",
            "\n",
            "        [[[-0.7500, -1.0000,  1.0000],\n",
            "          [ 0.2500, -0.3750, -1.0000],\n",
            "          [-1.5000, -0.0000,  1.0000]],\n",
            "\n",
            "         [[ 1.5000,  1.0000,  0.7500],\n",
            "          [ 0.7500, -0.5625,  0.2500],\n",
            "          [-0.3750,  1.5000,  0.5000]],\n",
            "\n",
            "         [[ 0.5625,  0.7500,  0.2500],\n",
            "          [ 1.1250, -1.1250,  1.5000],\n",
            "          [ 1.5000, -0.5625,  1.0000]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.5000, -1.1250,  1.1250],\n",
            "          [-1.5000, -1.1250, -1.5000],\n",
            "          [-0.7500, -1.5000,  1.5000]],\n",
            "\n",
            "         [[ 1.0000,  1.5000,  0.1875],\n",
            "          [-1.5000,  0.3750,  0.5625],\n",
            "          [ 0.2500, -0.5625,  0.7500]],\n",
            "\n",
            "         [[-1.0000, -0.0625, -0.1250],\n",
            "          [ 0.5000, -1.1250, -1.5000],\n",
            "          [-0.5625, -0.7500,  1.5000]]],\n",
            "\n",
            "\n",
            "        [[[-0.2500,  0.3750,  1.1250],\n",
            "          [ 1.1250, -1.0000, -1.0000],\n",
            "          [ 0.5000, -1.0000, -0.5625]],\n",
            "\n",
            "         [[-1.1250,  0.1875,  1.5000],\n",
            "          [ 1.0000, -1.5000,  1.1250],\n",
            "          [-1.0000, -0.5000,  1.0000]],\n",
            "\n",
            "         [[-1.5000,  1.5000, -0.7500],\n",
            "          [ 0.7500,  0.3750,  1.1250],\n",
            "          [-0.0625,  0.7500, -1.5000]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.5000,  1.5000,  1.0000],\n",
            "          [-1.1250, -0.3750,  0.0625],\n",
            "          [-1.5000, -0.7500,  0.3750]],\n",
            "\n",
            "         [[-1.1250, -1.1250,  1.0000],\n",
            "          [ 0.5000,  1.1250, -1.1250],\n",
            "          [ 1.1250, -0.7500,  1.1250]],\n",
            "\n",
            "         [[-0.7500, -1.5000,  1.1250],\n",
            "          [-0.1250, -0.2500, -1.0000],\n",
            "          [ 1.5000,  1.1250, -0.5000]]]], device='cuda:0',\n",
            "       grad_fn=<_pqBackward>)\n",
            "tensor([[[[-0.3750]],\n",
            "\n",
            "         [[-1.5000]],\n",
            "\n",
            "         [[ 1.0000]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.1250]],\n",
            "\n",
            "         [[ 1.1250]],\n",
            "\n",
            "         [[ 0.2500]]],\n",
            "\n",
            "\n",
            "        [[[ 0.7500]],\n",
            "\n",
            "         [[ 1.1250]],\n",
            "\n",
            "         [[ 1.0000]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.1250]],\n",
            "\n",
            "         [[ 0.7500]],\n",
            "\n",
            "         [[-0.0000]]],\n",
            "\n",
            "\n",
            "        [[[ 1.0000]],\n",
            "\n",
            "         [[-1.1250]],\n",
            "\n",
            "         [[-1.1250]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.1250]],\n",
            "\n",
            "         [[-0.7500]],\n",
            "\n",
            "         [[-0.7500]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-1.5000]],\n",
            "\n",
            "         [[ 1.1250]],\n",
            "\n",
            "         [[ 0.5000]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0000]],\n",
            "\n",
            "         [[ 1.1250]],\n",
            "\n",
            "         [[-0.7500]]],\n",
            "\n",
            "\n",
            "        [[[-1.1250]],\n",
            "\n",
            "         [[ 0.5625]],\n",
            "\n",
            "         [[-1.1250]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.7500]],\n",
            "\n",
            "         [[-1.5000]],\n",
            "\n",
            "         [[ 1.1250]]],\n",
            "\n",
            "\n",
            "        [[[-0.2500]],\n",
            "\n",
            "         [[-1.5000]],\n",
            "\n",
            "         [[-1.5000]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.3750]],\n",
            "\n",
            "         [[-1.5000]],\n",
            "\n",
            "         [[ 1.5000]]]], device='cuda:0', grad_fn=<_pqBackward>)\n",
            "tensor([[[[-1.0000, -0.7500, -0.1250],\n",
            "          [-1.1250,  0.5000,  1.1250],\n",
            "          [-0.1875, -0.7500, -0.7500]],\n",
            "\n",
            "         [[-1.0000,  0.0625,  1.1250],\n",
            "          [-1.1250,  1.0000, -1.5000],\n",
            "          [ 0.0625, -1.5000, -0.3750]],\n",
            "\n",
            "         [[ 1.1250,  1.5000,  1.5000],\n",
            "          [ 1.0000, -1.1250,  1.5000],\n",
            "          [ 0.1250, -1.5000,  1.1250]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.1875,  1.5000, -1.5000],\n",
            "          [-1.5000,  0.3750, -1.1250],\n",
            "          [-1.5000,  0.1250,  1.0000]],\n",
            "\n",
            "         [[-1.1250,  1.5000, -0.5625],\n",
            "          [-1.5000, -0.7500,  0.0000],\n",
            "          [ 1.5000,  0.0625, -1.1250]],\n",
            "\n",
            "         [[-0.5000, -1.1250, -0.5625],\n",
            "          [-1.5000,  1.1250,  0.7500],\n",
            "          [-0.2500, -1.5000,  0.3750]]],\n",
            "\n",
            "\n",
            "        [[[-1.0000, -1.5000,  1.5000],\n",
            "          [ 0.1875,  0.7500,  0.5625],\n",
            "          [ 1.5000, -1.5000, -0.2500]],\n",
            "\n",
            "         [[-0.7500,  1.1250, -1.5000],\n",
            "          [-1.1250, -0.2500,  1.5000],\n",
            "          [ 1.5000,  0.3750,  0.1250]],\n",
            "\n",
            "         [[ 0.3750,  0.7500, -1.5000],\n",
            "          [ 0.3750, -0.2500, -0.1250],\n",
            "          [-1.5000,  0.3750,  0.7500]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.5000,  1.1250, -0.2500],\n",
            "          [ 0.5000, -0.7500, -0.5625],\n",
            "          [-1.0000,  0.2500, -1.5000]],\n",
            "\n",
            "         [[-1.0000, -0.7500,  1.0000],\n",
            "          [-1.0000,  1.1250,  0.3750],\n",
            "          [-1.0000, -1.0000, -1.5000]],\n",
            "\n",
            "         [[-1.0000, -0.5625,  0.7500],\n",
            "          [-1.5000, -0.3750,  0.1875],\n",
            "          [-1.5000, -0.7500,  1.5000]]],\n",
            "\n",
            "\n",
            "        [[[ 0.5625, -0.5000,  1.1250],\n",
            "          [ 0.0625, -0.3750, -1.5000],\n",
            "          [ 0.5625,  1.5000,  1.0000]],\n",
            "\n",
            "         [[-1.0000,  0.1250, -1.1250],\n",
            "          [ 1.0000,  1.5000, -0.7500],\n",
            "          [ 0.3750, -1.1250,  0.5625]],\n",
            "\n",
            "         [[-1.5000, -0.1250,  1.5000],\n",
            "          [-0.3750, -0.7500,  1.5000],\n",
            "          [ 0.7500,  0.7500,  1.5000]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.5000, -0.5625, -0.3750],\n",
            "          [ 1.5000,  0.7500, -0.3750],\n",
            "          [ 1.1250, -1.1250,  1.5000]],\n",
            "\n",
            "         [[-1.1250, -0.0625, -1.5000],\n",
            "          [-0.7500,  0.2500,  1.0000],\n",
            "          [ 0.2500,  0.1875, -0.7500]],\n",
            "\n",
            "         [[-0.5625,  1.5000, -0.7500],\n",
            "          [ 1.5000,  0.5625,  1.1250],\n",
            "          [ 1.0000, -0.0000, -0.2500]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.5625,  1.5000,  0.5625],\n",
            "          [ 1.0000,  1.1250, -1.5000],\n",
            "          [-0.7500,  0.5000,  1.0000]],\n",
            "\n",
            "         [[ 1.0000, -0.7500, -1.0000],\n",
            "          [ 1.5000, -1.0000, -0.3750],\n",
            "          [ 1.5000,  0.1875, -1.5000]],\n",
            "\n",
            "         [[-0.7500,  1.5000, -0.5625],\n",
            "          [ 0.5625, -1.0000, -1.1250],\n",
            "          [ 0.2500,  0.3750, -1.1250]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.1250,  0.5625,  1.0000],\n",
            "          [ 0.2500,  1.5000,  1.1250],\n",
            "          [-0.0625,  1.1250, -1.0000]],\n",
            "\n",
            "         [[ 1.0000,  1.5000, -1.0000],\n",
            "          [-1.5000,  1.1250, -0.5625],\n",
            "          [-1.5000,  1.0000, -0.7500]],\n",
            "\n",
            "         [[-1.1250, -1.0000,  1.5000],\n",
            "          [ 0.5625, -1.0000, -0.5000],\n",
            "          [ 0.7500, -0.5625, -1.5000]]],\n",
            "\n",
            "\n",
            "        [[[ 1.1250,  1.5000, -1.5000],\n",
            "          [ 0.3750, -1.0000, -0.0000],\n",
            "          [-0.2500,  1.5000,  0.1250]],\n",
            "\n",
            "         [[-0.7500, -0.5625,  1.5000],\n",
            "          [-0.3750, -0.2500, -0.3750],\n",
            "          [ 1.5000,  1.5000, -0.5625]],\n",
            "\n",
            "         [[-1.5000, -0.5625, -0.3750],\n",
            "          [-0.7500,  0.2500, -0.7500],\n",
            "          [-1.0000, -1.1250,  1.5000]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.1250,  0.3750, -1.5000],\n",
            "          [ 1.5000,  1.1250,  0.5625],\n",
            "          [-1.5000,  1.5000,  0.0625]],\n",
            "\n",
            "         [[ 0.5000,  0.0625, -0.7500],\n",
            "          [-0.5625, -0.1250,  0.5000],\n",
            "          [ 1.5000,  0.3750,  0.7500]],\n",
            "\n",
            "         [[ 0.5625, -0.2500, -1.5000],\n",
            "          [ 0.5625, -0.1875, -0.7500],\n",
            "          [-1.1250,  0.7500, -1.5000]]],\n",
            "\n",
            "\n",
            "        [[[-1.1250, -0.0625,  1.1250],\n",
            "          [-0.5625, -0.0000,  0.5000],\n",
            "          [-0.2500, -0.1250,  1.1250]],\n",
            "\n",
            "         [[ 0.5625,  0.7500,  0.2500],\n",
            "          [ 1.5000, -0.3750,  0.5625],\n",
            "          [ 1.0000, -1.5000,  0.1250]],\n",
            "\n",
            "         [[-1.5000,  1.5000,  0.7500],\n",
            "          [-1.0000, -0.2500, -1.1250],\n",
            "          [ 1.1250,  0.5000, -0.5000]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.5000, -1.5000, -0.3750],\n",
            "          [ 1.5000, -0.7500, -1.1250],\n",
            "          [-0.1250, -0.3750,  1.0000]],\n",
            "\n",
            "         [[ 1.1250,  1.0000, -0.7500],\n",
            "          [ 1.5000, -1.5000, -1.0000],\n",
            "          [-0.2500, -0.7500,  1.5000]],\n",
            "\n",
            "         [[-1.1250, -1.1250, -0.5000],\n",
            "          [ 1.1250,  0.7500, -1.5000],\n",
            "          [-0.5000,  1.0000, -1.1250]]]], device='cuda:0',\n",
            "       grad_fn=<_pqBackward>)\n",
            "tensor([[[[ 1.5000]],\n",
            "\n",
            "         [[ 0.7500]],\n",
            "\n",
            "         [[ 1.1250]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.2500]],\n",
            "\n",
            "         [[-0.7500]],\n",
            "\n",
            "         [[-0.3750]]],\n",
            "\n",
            "\n",
            "        [[[-1.5000]],\n",
            "\n",
            "         [[ 0.7500]],\n",
            "\n",
            "         [[-0.5000]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.3750]],\n",
            "\n",
            "         [[ 0.7500]],\n",
            "\n",
            "         [[ 1.0000]]],\n",
            "\n",
            "\n",
            "        [[[-0.2500]],\n",
            "\n",
            "         [[-1.5000]],\n",
            "\n",
            "         [[-1.1250]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.1250]],\n",
            "\n",
            "         [[ 1.0000]],\n",
            "\n",
            "         [[ 1.1250]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.7500]],\n",
            "\n",
            "         [[-0.1250]],\n",
            "\n",
            "         [[ 1.5000]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.5000]],\n",
            "\n",
            "         [[-1.0000]],\n",
            "\n",
            "         [[-0.3750]]],\n",
            "\n",
            "\n",
            "        [[[-0.3750]],\n",
            "\n",
            "         [[ 0.5625]],\n",
            "\n",
            "         [[ 1.5000]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.3750]],\n",
            "\n",
            "         [[ 0.7500]],\n",
            "\n",
            "         [[ 1.1250]]],\n",
            "\n",
            "\n",
            "        [[[ 1.0000]],\n",
            "\n",
            "         [[ 1.1250]],\n",
            "\n",
            "         [[-1.5000]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.5000]],\n",
            "\n",
            "         [[ 1.5000]],\n",
            "\n",
            "         [[ 1.0000]]]], device='cuda:0', grad_fn=<_pqBackward>)\n",
            "tensor([[[[ 1.0000, -1.5000, -1.1250],\n",
            "          [ 1.5000,  0.0625, -0.5625],\n",
            "          [ 1.1250,  0.7500,  0.0625]],\n",
            "\n",
            "         [[-1.0000, -0.7500,  0.1875],\n",
            "          [ 0.1875, -0.3750,  1.0000],\n",
            "          [-0.2500,  1.5000, -1.1250]],\n",
            "\n",
            "         [[-1.0000, -1.5000, -0.0625],\n",
            "          [-0.7500,  0.3750, -0.1250],\n",
            "          [-1.5000, -0.7500, -1.5000]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.1250, -1.5000, -0.3750],\n",
            "          [ 0.1875,  0.5625, -0.7500],\n",
            "          [-0.7500,  0.7500,  0.7500]],\n",
            "\n",
            "         [[ 0.7500,  1.1250, -1.1250],\n",
            "          [ 0.2500, -0.5000, -0.7500],\n",
            "          [ 1.5000, -1.1250, -1.5000]],\n",
            "\n",
            "         [[ 1.1250, -1.0000,  1.5000],\n",
            "          [ 1.5000, -0.3750, -1.1250],\n",
            "          [ 1.5000, -0.2500, -1.5000]]],\n",
            "\n",
            "\n",
            "        [[[-0.2500, -1.5000, -0.2500],\n",
            "          [ 1.5000,  1.5000,  0.0000],\n",
            "          [-0.5625, -0.5625, -1.1250]],\n",
            "\n",
            "         [[ 0.5625, -0.2500,  0.3750],\n",
            "          [ 0.1875, -1.5000,  1.0000],\n",
            "          [ 1.5000, -1.5000, -1.1250]],\n",
            "\n",
            "         [[-1.0000,  1.1250,  1.1250],\n",
            "          [-1.5000, -1.5000, -0.3750],\n",
            "          [ 1.5000,  1.1250, -0.5000]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.5000, -1.1250,  0.2500],\n",
            "          [ 0.5000, -0.7500,  1.0000],\n",
            "          [-0.2500, -0.3750,  0.2500]],\n",
            "\n",
            "         [[ 1.5000, -1.5000, -1.5000],\n",
            "          [-0.1875,  1.1250,  1.0000],\n",
            "          [-0.2500,  1.5000,  0.7500]],\n",
            "\n",
            "         [[-1.5000,  1.0000, -0.5000],\n",
            "          [-1.5000,  1.5000, -0.1875],\n",
            "          [-0.3750, -1.1250, -1.5000]]],\n",
            "\n",
            "\n",
            "        [[[-1.1250,  1.5000,  1.1250],\n",
            "          [-1.5000, -0.3750,  1.5000],\n",
            "          [ 1.1250,  0.7500, -1.5000]],\n",
            "\n",
            "         [[-0.7500, -0.5000,  1.5000],\n",
            "          [ 0.7500,  0.3750,  1.1250],\n",
            "          [ 0.3750, -1.5000, -0.1875]],\n",
            "\n",
            "         [[-1.5000, -1.1250,  1.5000],\n",
            "          [ 0.2500,  0.3750, -0.5625],\n",
            "          [ 0.2500, -0.0625, -1.1250]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0000,  1.5000, -1.5000],\n",
            "          [-1.0000, -0.7500, -0.5000],\n",
            "          [ 0.1250, -0.1875, -1.5000]],\n",
            "\n",
            "         [[ 1.0000,  0.3750, -1.5000],\n",
            "          [-0.7500,  0.7500, -1.5000],\n",
            "          [ 0.7500, -0.7500, -0.3750]],\n",
            "\n",
            "         [[-1.1250,  0.7500,  0.7500],\n",
            "          [ 1.1250,  1.5000, -0.1250],\n",
            "          [ 0.0625, -0.1250, -0.5625]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 1.5000,  0.5000,  1.5000],\n",
            "          [ 0.0000, -1.5000, -1.5000],\n",
            "          [-0.7500,  0.5625,  1.5000]],\n",
            "\n",
            "         [[ 0.1875,  0.2500, -1.0000],\n",
            "          [-1.1250,  0.2500,  1.5000],\n",
            "          [-0.2500,  1.5000,  1.0000]],\n",
            "\n",
            "         [[-0.1875,  0.1250,  0.7500],\n",
            "          [-1.5000,  0.5625,  0.3750],\n",
            "          [-0.1875,  0.1875, -0.7500]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.0000,  0.3750,  1.1250],\n",
            "          [ 0.0625, -0.5625,  0.2500],\n",
            "          [-0.1250, -1.0000,  1.5000]],\n",
            "\n",
            "         [[-0.3750, -1.5000, -1.0000],\n",
            "          [ 1.5000,  1.0000, -1.0000],\n",
            "          [ 1.0000, -0.1250, -1.1250]],\n",
            "\n",
            "         [[ 0.3750, -0.5000, -0.2500],\n",
            "          [ 0.0625,  0.3750,  1.5000],\n",
            "          [-0.1250,  0.5625,  1.5000]]],\n",
            "\n",
            "\n",
            "        [[[ 1.1250,  0.2500,  0.3750],\n",
            "          [-0.0625,  1.5000,  0.1875],\n",
            "          [ 1.5000,  1.0000,  1.1250]],\n",
            "\n",
            "         [[-1.5000, -1.0000, -1.5000],\n",
            "          [ 1.5000, -0.7500, -1.1250],\n",
            "          [-0.1875, -1.1250, -1.1250]],\n",
            "\n",
            "         [[ 0.7500, -1.5000,  1.5000],\n",
            "          [-0.0625,  1.1250,  1.5000],\n",
            "          [-1.5000, -1.5000,  0.0625]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.1250,  0.5000, -1.5000],\n",
            "          [-1.5000,  0.2500,  1.1250],\n",
            "          [ 1.1250, -1.0000,  1.1250]],\n",
            "\n",
            "         [[-1.5000, -0.5625, -0.3750],\n",
            "          [-1.1250,  1.1250,  0.0000],\n",
            "          [-0.5625, -1.5000, -0.5000]],\n",
            "\n",
            "         [[-1.0000, -1.5000,  1.5000],\n",
            "          [ 1.5000, -1.5000, -1.0000],\n",
            "          [-1.1250,  0.5625, -0.7500]]],\n",
            "\n",
            "\n",
            "        [[[-0.5000,  0.5625,  0.3750],\n",
            "          [-0.3750,  0.5625,  0.2500],\n",
            "          [ 0.5625, -1.5000, -0.7500]],\n",
            "\n",
            "         [[ 1.5000, -0.5000,  1.0000],\n",
            "          [-1.1250,  0.5625,  1.5000],\n",
            "          [ 1.5000,  1.1250,  1.1250]],\n",
            "\n",
            "         [[ 0.1250, -0.7500,  1.5000],\n",
            "          [-0.7500,  1.0000, -0.7500],\n",
            "          [-0.1875,  1.5000, -0.3750]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.3750, -1.0000,  1.1250],\n",
            "          [-1.1250, -1.5000,  0.5625],\n",
            "          [-1.1250, -1.1250,  0.0625]],\n",
            "\n",
            "         [[-1.5000,  0.3750, -1.5000],\n",
            "          [-1.5000, -1.1250, -0.0625],\n",
            "          [ 0.1875,  0.2500, -1.5000]],\n",
            "\n",
            "         [[ 0.5625, -1.5000, -0.5625],\n",
            "          [ 1.5000, -1.5000,  0.7500],\n",
            "          [-0.7500, -1.5000, -0.2500]]]], device='cuda:0',\n",
            "       grad_fn=<_pqBackward>)\n",
            "tensor([[[[ 1.5000]],\n",
            "\n",
            "         [[ 0.0625]],\n",
            "\n",
            "         [[ 1.5000]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.5000]],\n",
            "\n",
            "         [[ 1.1250]],\n",
            "\n",
            "         [[ 0.5625]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1250]],\n",
            "\n",
            "         [[ 1.5000]],\n",
            "\n",
            "         [[ 0.3750]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.0000]],\n",
            "\n",
            "         [[-1.5000]],\n",
            "\n",
            "         [[-0.5625]]],\n",
            "\n",
            "\n",
            "        [[[-1.5000]],\n",
            "\n",
            "         [[ 0.1250]],\n",
            "\n",
            "         [[ 0.7500]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.1250]],\n",
            "\n",
            "         [[-0.5000]],\n",
            "\n",
            "         [[ 0.1250]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 1.0000]],\n",
            "\n",
            "         [[-1.5000]],\n",
            "\n",
            "         [[ 0.5625]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.1250]],\n",
            "\n",
            "         [[ 0.7500]],\n",
            "\n",
            "         [[-0.7500]]],\n",
            "\n",
            "\n",
            "        [[[ 0.7500]],\n",
            "\n",
            "         [[ 1.1250]],\n",
            "\n",
            "         [[-0.2500]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.5625]],\n",
            "\n",
            "         [[ 1.0000]],\n",
            "\n",
            "         [[ 1.1250]]],\n",
            "\n",
            "\n",
            "        [[[-0.2500]],\n",
            "\n",
            "         [[-1.0000]],\n",
            "\n",
            "         [[-1.1250]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.5000]],\n",
            "\n",
            "         [[-1.0000]],\n",
            "\n",
            "         [[ 0.7500]]]], device='cuda:0', grad_fn=<_pqBackward>)\n",
            "tensor([[[[-1.5000, -1.5000,  0.7500],\n",
            "          [-1.5000, -0.2500, -0.5625],\n",
            "          [-1.1250,  0.3750,  0.0625]],\n",
            "\n",
            "         [[ 1.1250, -1.5000,  0.5000],\n",
            "          [ 1.0000,  1.5000,  1.5000],\n",
            "          [ 1.5000,  1.0000,  1.1250]],\n",
            "\n",
            "         [[ 0.7500, -0.7500, -0.5625],\n",
            "          [ 1.1250, -0.5625,  1.5000],\n",
            "          [ 1.0000,  1.1250, -1.5000]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.1250,  1.5000,  1.5000],\n",
            "          [ 0.5625, -0.3750, -0.5000],\n",
            "          [ 1.1250, -1.5000, -0.1250]],\n",
            "\n",
            "         [[ 0.1250,  0.7500,  1.5000],\n",
            "          [ 1.5000,  0.3750, -0.1250],\n",
            "          [-0.5625, -0.1875,  0.7500]],\n",
            "\n",
            "         [[ 1.0000,  0.1250, -1.0000],\n",
            "          [-1.0000,  1.5000, -1.5000],\n",
            "          [-0.7500, -1.1250, -0.2500]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1250,  0.3750,  0.7500],\n",
            "          [ 1.0000, -0.3750,  1.1250],\n",
            "          [-0.2500, -1.5000, -1.5000]],\n",
            "\n",
            "         [[-1.5000,  0.7500, -1.1250],\n",
            "          [-0.5000, -1.5000, -0.7500],\n",
            "          [-0.5625, -1.0000, -1.1250]],\n",
            "\n",
            "         [[-0.1875, -1.0000,  1.0000],\n",
            "          [-0.0000,  1.5000,  1.5000],\n",
            "          [-1.1250,  1.1250, -1.5000]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.0000, -0.0625,  1.0000],\n",
            "          [ 1.5000, -0.1875, -1.1250],\n",
            "          [ 0.5625, -1.0000, -1.1250]],\n",
            "\n",
            "         [[-0.0625, -1.5000, -1.5000],\n",
            "          [-1.1250, -1.0000,  1.5000],\n",
            "          [ 0.5625, -0.7500, -1.5000]],\n",
            "\n",
            "         [[ 1.1250, -0.1250, -1.5000],\n",
            "          [ 1.5000,  1.5000,  0.7500],\n",
            "          [-0.0625, -1.5000, -0.2500]]],\n",
            "\n",
            "\n",
            "        [[[-0.0625,  1.5000, -0.5000],\n",
            "          [ 1.1250, -0.1250,  0.5000],\n",
            "          [-0.7500,  0.0625, -1.1250]],\n",
            "\n",
            "         [[ 1.5000,  1.5000,  0.3750],\n",
            "          [ 1.5000,  1.5000,  1.0000],\n",
            "          [-0.1250,  1.1250, -1.5000]],\n",
            "\n",
            "         [[-0.2500,  1.5000,  0.3750],\n",
            "          [-0.1250, -1.1250, -0.5625],\n",
            "          [ 0.7500,  1.5000,  1.1250]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.3750,  1.5000, -1.0000],\n",
            "          [-0.7500,  0.3750, -1.5000],\n",
            "          [-0.5625,  1.0000,  1.5000]],\n",
            "\n",
            "         [[ 1.5000,  0.2500,  0.1875],\n",
            "          [-0.5625, -0.3750, -0.0625],\n",
            "          [-0.5625,  0.7500, -0.1875]],\n",
            "\n",
            "         [[ 0.7500, -0.2500,  1.0000],\n",
            "          [ 1.1250,  0.3750,  0.7500],\n",
            "          [ 1.1250,  1.0000, -0.1875]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.1250,  0.2500, -1.1250],\n",
            "          [ 1.5000,  1.5000, -1.0000],\n",
            "          [-1.0000, -1.0000,  0.0625]],\n",
            "\n",
            "         [[ 1.5000,  0.7500, -1.1250],\n",
            "          [-1.1250,  1.5000, -0.5000],\n",
            "          [ 1.5000,  1.1250, -0.0625]],\n",
            "\n",
            "         [[ 0.5000,  0.1250,  1.5000],\n",
            "          [-0.2500,  1.5000,  1.5000],\n",
            "          [-0.7500,  0.1250,  0.7500]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.5000, -1.1250, -1.0000],\n",
            "          [ 0.7500, -0.2500,  0.1875],\n",
            "          [-1.5000, -1.5000, -0.5625]],\n",
            "\n",
            "         [[ 0.5000,  1.1250,  0.3750],\n",
            "          [-0.7500,  1.5000, -1.5000],\n",
            "          [-1.0000, -0.1250,  0.1250]],\n",
            "\n",
            "         [[-0.2500, -0.3750, -1.5000],\n",
            "          [-1.5000,  0.0625, -1.1250],\n",
            "          [ 0.0625,  0.5625, -0.7500]]],\n",
            "\n",
            "\n",
            "        [[[ 1.1250,  0.5625, -0.3750],\n",
            "          [ 0.2500,  1.1250, -1.0000],\n",
            "          [-1.5000, -1.0000, -0.5625]],\n",
            "\n",
            "         [[-0.5625,  1.5000,  0.5000],\n",
            "          [ 1.1250, -0.0625, -1.1250],\n",
            "          [-1.1250,  0.2500,  1.1250]],\n",
            "\n",
            "         [[-1.5000, -1.5000,  1.5000],\n",
            "          [-0.5000, -0.2500, -1.5000],\n",
            "          [ 0.3750, -0.3750,  1.1250]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.0000, -1.5000, -1.1250],\n",
            "          [-0.7500,  1.5000,  1.5000],\n",
            "          [-0.7500,  1.0000, -1.0000]],\n",
            "\n",
            "         [[ 1.0000, -1.1250, -0.7500],\n",
            "          [-1.0000, -0.5625, -0.0625],\n",
            "          [-1.5000,  0.1250, -1.5000]],\n",
            "\n",
            "         [[ 1.5000, -0.3750, -1.1250],\n",
            "          [-0.0000,  1.0000, -1.5000],\n",
            "          [-1.5000, -0.1250, -0.2500]]],\n",
            "\n",
            "\n",
            "        [[[-0.7500,  0.1250, -0.3750],\n",
            "          [ 0.0000,  0.1250,  0.1875],\n",
            "          [-0.0000, -0.3750,  1.5000]],\n",
            "\n",
            "         [[ 1.1250,  0.3750, -0.5625],\n",
            "          [ 1.0000,  0.2500, -1.5000],\n",
            "          [ 0.5625,  1.0000, -0.0625]],\n",
            "\n",
            "         [[ 0.2500,  1.5000, -1.5000],\n",
            "          [-1.1250,  0.2500, -0.0625],\n",
            "          [ 1.1250, -1.0000,  1.1250]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.7500,  1.1250, -1.1250],\n",
            "          [ 0.5625, -0.7500, -0.0625],\n",
            "          [ 0.3750, -0.5000,  0.1875]],\n",
            "\n",
            "         [[-1.1250, -0.5625,  1.0000],\n",
            "          [-1.5000,  0.3750, -1.5000],\n",
            "          [ 1.1250,  0.5625, -1.1250]],\n",
            "\n",
            "         [[-1.5000,  0.5625,  0.7500],\n",
            "          [ 1.0000, -1.0000, -0.0625],\n",
            "          [ 1.1250, -1.0000,  0.7500]]]], device='cuda:0',\n",
            "       grad_fn=<_pqBackward>)\n",
            "tensor([[[[ 0.1250]],\n",
            "\n",
            "         [[ 1.5000]],\n",
            "\n",
            "         [[ 1.5000]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.5000]],\n",
            "\n",
            "         [[-0.7500]],\n",
            "\n",
            "         [[ 0.5000]]],\n",
            "\n",
            "\n",
            "        [[[-0.7500]],\n",
            "\n",
            "         [[-0.7500]],\n",
            "\n",
            "         [[ 0.0000]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.5000]],\n",
            "\n",
            "         [[-0.2500]],\n",
            "\n",
            "         [[-0.7500]]],\n",
            "\n",
            "\n",
            "        [[[ 0.7500]],\n",
            "\n",
            "         [[-1.0000]],\n",
            "\n",
            "         [[-0.7500]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.5000]],\n",
            "\n",
            "         [[-0.7500]],\n",
            "\n",
            "         [[ 1.1250]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.1250]],\n",
            "\n",
            "         [[-1.0000]],\n",
            "\n",
            "         [[ 0.2500]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.5000]],\n",
            "\n",
            "         [[-0.7500]],\n",
            "\n",
            "         [[ 0.2500]]],\n",
            "\n",
            "\n",
            "        [[[-0.3750]],\n",
            "\n",
            "         [[-1.5000]],\n",
            "\n",
            "         [[-1.0000]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.3750]],\n",
            "\n",
            "         [[ 1.5000]],\n",
            "\n",
            "         [[ 0.7500]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1875]],\n",
            "\n",
            "         [[ 1.5000]],\n",
            "\n",
            "         [[-0.3750]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.5000]],\n",
            "\n",
            "         [[ 0.5000]],\n",
            "\n",
            "         [[ 1.5000]]]], device='cuda:0', grad_fn=<_pqBackward>)\n",
            "tensor([[[[ 0.0625, -1.1250, -0.2500],\n",
            "          [-1.5000, -0.7500, -0.5000],\n",
            "          [-1.5000, -1.5000,  0.7500]],\n",
            "\n",
            "         [[ 1.1250,  0.7500, -0.1250],\n",
            "          [-1.5000, -1.1250,  1.5000],\n",
            "          [-0.2500,  0.0000,  1.0000]],\n",
            "\n",
            "         [[ 0.3750,  0.7500,  0.5000],\n",
            "          [ 0.2500, -1.5000, -1.0000],\n",
            "          [ 0.5625,  1.0000,  1.5000]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.0000,  1.0000,  0.0625],\n",
            "          [ 1.5000,  1.5000,  1.5000],\n",
            "          [-1.0000, -0.7500,  1.0000]],\n",
            "\n",
            "         [[-0.5000, -1.0000,  0.3750],\n",
            "          [ 0.7500,  1.1250, -0.2500],\n",
            "          [-1.1250,  1.5000, -0.1250]],\n",
            "\n",
            "         [[ 1.5000, -0.2500,  0.5625],\n",
            "          [-0.5625, -0.7500,  0.7500],\n",
            "          [-0.2500, -0.7500,  0.7500]]],\n",
            "\n",
            "\n",
            "        [[[ 0.5625,  1.1250,  0.0000],\n",
            "          [ 1.5000,  1.5000, -0.7500],\n",
            "          [-1.5000,  1.1250, -0.3750]],\n",
            "\n",
            "         [[-1.1250, -0.1875,  0.5000],\n",
            "          [ 1.5000, -0.7500,  0.3750],\n",
            "          [ 0.5000,  1.5000,  0.1875]],\n",
            "\n",
            "         [[-1.5000, -0.0625,  0.1875],\n",
            "          [-1.1250, -0.7500, -0.1250],\n",
            "          [ 0.1875, -0.7500, -0.7500]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.7500, -0.0625, -0.0625],\n",
            "          [-1.5000, -1.5000,  1.5000],\n",
            "          [ 1.5000, -0.7500,  1.5000]],\n",
            "\n",
            "         [[ 1.0000,  0.2500,  0.7500],\n",
            "          [-0.7500, -0.3750, -0.7500],\n",
            "          [ 0.3750,  1.0000,  0.1875]],\n",
            "\n",
            "         [[ 1.5000, -0.1250, -1.1250],\n",
            "          [ 0.2500, -0.2500,  0.7500],\n",
            "          [ 0.5625, -1.1250, -1.1250]]],\n",
            "\n",
            "\n",
            "        [[[ 1.1250, -1.5000,  0.2500],\n",
            "          [ 0.0625, -0.5000,  1.5000],\n",
            "          [-1.1250,  0.1250, -1.1250]],\n",
            "\n",
            "         [[ 1.1250, -0.1875, -1.5000],\n",
            "          [ 0.7500, -1.5000,  0.7500],\n",
            "          [-0.0000,  0.7500,  1.1250]],\n",
            "\n",
            "         [[ 1.0000,  0.7500, -1.1250],\n",
            "          [ 0.5625,  0.5625,  1.5000],\n",
            "          [ 0.5000,  0.5000, -0.5000]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.7500,  1.5000, -0.3750],\n",
            "          [ 1.5000, -0.3750, -1.1250],\n",
            "          [-1.0000, -0.0000,  1.1250]],\n",
            "\n",
            "         [[ 0.2500,  1.5000,  1.5000],\n",
            "          [-1.0000,  0.1875,  1.1250],\n",
            "          [ 0.7500, -0.2500,  1.5000]],\n",
            "\n",
            "         [[ 1.1250,  0.5625,  1.1250],\n",
            "          [-0.5625,  0.3750,  0.7500],\n",
            "          [-1.0000,  1.5000,  1.5000]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.3750, -1.5000,  0.5625],\n",
            "          [-0.2500,  1.5000, -0.7500],\n",
            "          [-0.5000, -0.0000,  1.5000]],\n",
            "\n",
            "         [[-1.5000,  1.1250,  0.7500],\n",
            "          [ 1.5000,  1.5000,  1.0000],\n",
            "          [ 1.5000,  1.5000,  1.1250]],\n",
            "\n",
            "         [[ 0.0625, -1.0000, -1.5000],\n",
            "          [-0.0625, -0.7500, -0.2500],\n",
            "          [-0.5000,  1.1250, -0.5000]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.5000,  0.5625, -1.5000],\n",
            "          [-1.5000,  1.1250,  1.0000],\n",
            "          [-0.5625,  0.5625, -1.1250]],\n",
            "\n",
            "         [[-0.1250, -0.2500, -1.1250],\n",
            "          [-0.7500, -1.1250,  0.7500],\n",
            "          [ 0.0000,  1.0000,  1.0000]],\n",
            "\n",
            "         [[ 1.0000, -1.5000,  0.5000],\n",
            "          [ 1.5000,  1.5000,  0.7500],\n",
            "          [ 0.1875,  0.5625, -0.3750]]],\n",
            "\n",
            "\n",
            "        [[[-0.1875, -0.7500, -1.5000],\n",
            "          [-0.7500, -0.3750, -1.0000],\n",
            "          [-0.3750,  0.7500,  1.0000]],\n",
            "\n",
            "         [[ 1.0000,  0.5000,  0.7500],\n",
            "          [ 1.5000, -0.5000, -0.3750],\n",
            "          [-0.7500, -1.5000,  1.5000]],\n",
            "\n",
            "         [[-0.5625,  0.3750, -1.0000],\n",
            "          [ 1.0000, -1.0000, -1.5000],\n",
            "          [ 0.5625,  1.1250, -1.5000]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.7500, -0.3750,  1.1250],\n",
            "          [ 0.3750, -0.7500,  1.5000],\n",
            "          [ 0.1250, -1.0000, -1.1250]],\n",
            "\n",
            "         [[-1.1250,  1.0000,  0.1250],\n",
            "          [ 1.5000,  1.5000,  1.5000],\n",
            "          [ 0.7500, -0.7500,  1.0000]],\n",
            "\n",
            "         [[ 0.5625, -0.7500,  0.3750],\n",
            "          [ 1.0000, -0.7500,  0.7500],\n",
            "          [-1.5000, -1.5000,  0.0625]]],\n",
            "\n",
            "\n",
            "        [[[ 0.7500,  0.2500,  1.5000],\n",
            "          [ 1.5000, -0.1875, -0.7500],\n",
            "          [ 0.7500, -1.5000,  0.3750]],\n",
            "\n",
            "         [[-1.1250, -0.0625, -1.1250],\n",
            "          [ 1.5000, -1.5000, -0.0625],\n",
            "          [-0.1875,  1.0000, -0.7500]],\n",
            "\n",
            "         [[-0.3750, -0.0000, -1.0000],\n",
            "          [ 1.5000, -1.0000, -1.0000],\n",
            "          [ 1.5000,  0.7500, -1.5000]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.7500, -1.5000,  0.1875],\n",
            "          [ 0.5000, -1.5000,  0.1250],\n",
            "          [ 1.5000,  0.0000,  0.5000]],\n",
            "\n",
            "         [[-1.5000, -1.0000,  1.0000],\n",
            "          [-0.7500,  1.5000, -0.1250],\n",
            "          [ 0.7500, -1.1250, -0.1250]],\n",
            "\n",
            "         [[ 1.5000,  1.1250,  0.1250],\n",
            "          [-0.0625, -1.5000, -0.1250],\n",
            "          [-0.5625, -0.1250,  0.7500]]]], device='cuda:0',\n",
            "       grad_fn=<_pqBackward>)\n",
            "tensor([[[[ 1.1250]],\n",
            "\n",
            "         [[-0.2500]],\n",
            "\n",
            "         [[-1.5000]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.5625]],\n",
            "\n",
            "         [[-0.1250]],\n",
            "\n",
            "         [[-1.5000]]],\n",
            "\n",
            "\n",
            "        [[[-0.7500]],\n",
            "\n",
            "         [[ 0.0625]],\n",
            "\n",
            "         [[-0.3750]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.5000]],\n",
            "\n",
            "         [[-0.2500]],\n",
            "\n",
            "         [[-0.3750]]],\n",
            "\n",
            "\n",
            "        [[[ 0.3750]],\n",
            "\n",
            "         [[ 0.2500]],\n",
            "\n",
            "         [[-1.0000]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0625]],\n",
            "\n",
            "         [[-1.1250]],\n",
            "\n",
            "         [[ 1.5000]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.7500]],\n",
            "\n",
            "         [[-1.0000]],\n",
            "\n",
            "         [[-0.1875]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.5000]],\n",
            "\n",
            "         [[-0.5000]],\n",
            "\n",
            "         [[-0.1250]]],\n",
            "\n",
            "\n",
            "        [[[ 1.1250]],\n",
            "\n",
            "         [[ 0.7500]],\n",
            "\n",
            "         [[ 0.3750]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.2500]],\n",
            "\n",
            "         [[-1.1250]],\n",
            "\n",
            "         [[-0.3750]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0625]],\n",
            "\n",
            "         [[-0.0000]],\n",
            "\n",
            "         [[-0.5625]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.1250]],\n",
            "\n",
            "         [[ 1.1250]],\n",
            "\n",
            "         [[ 1.0000]]]], device='cuda:0', grad_fn=<_pqBackward>)\n",
            "tensor([[[[-1.1250, -0.1875,  1.0000],\n",
            "          [ 1.5000, -1.1250,  0.3750],\n",
            "          [ 1.5000, -0.1875, -0.7500]],\n",
            "\n",
            "         [[-1.1250, -0.0000, -1.1250],\n",
            "          [-1.5000,  1.0000, -0.5625],\n",
            "          [-1.0000,  1.1250, -1.1250]],\n",
            "\n",
            "         [[ 0.7500, -1.5000, -1.5000],\n",
            "          [ 1.5000, -1.0000,  0.3750],\n",
            "          [ 0.0625,  0.3750,  1.0000]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.5625, -0.3750, -1.1250],\n",
            "          [ 0.1875, -1.1250, -1.5000],\n",
            "          [ 1.5000,  0.3750, -1.5000]],\n",
            "\n",
            "         [[-0.0000, -0.3750, -0.5625],\n",
            "          [-1.1250, -0.1250, -1.5000],\n",
            "          [ 1.5000,  1.0000, -1.5000]],\n",
            "\n",
            "         [[-1.1250, -1.1250,  1.5000],\n",
            "          [ 0.5000,  1.5000,  0.3750],\n",
            "          [-1.1250,  0.7500, -0.5000]]],\n",
            "\n",
            "\n",
            "        [[[ 0.7500, -1.0000,  1.1250],\n",
            "          [-1.0000,  0.5625, -0.1250],\n",
            "          [ 0.1250, -0.5000,  1.1250]],\n",
            "\n",
            "         [[-1.5000,  1.5000, -1.0000],\n",
            "          [ 1.5000, -1.1250,  1.0000],\n",
            "          [ 1.5000, -0.3750, -0.5000]],\n",
            "\n",
            "         [[-1.0000,  0.3750,  1.5000],\n",
            "          [-0.7500, -1.1250,  0.7500],\n",
            "          [ 0.5625, -0.1250,  0.0625]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.5000, -1.5000,  0.3750],\n",
            "          [ 1.5000, -0.5625, -0.5625],\n",
            "          [-1.0000,  0.7500,  0.7500]],\n",
            "\n",
            "         [[-0.3750, -0.5000, -0.0625],\n",
            "          [-1.5000,  1.1250,  0.1250],\n",
            "          [-1.5000, -0.3750, -1.5000]],\n",
            "\n",
            "         [[-1.1250, -1.1250,  1.0000],\n",
            "          [-0.5000, -0.7500, -1.5000],\n",
            "          [-0.5000, -1.5000, -0.3750]]],\n",
            "\n",
            "\n",
            "        [[[ 0.3750,  1.1250, -1.1250],\n",
            "          [ 1.1250, -1.5000, -1.5000],\n",
            "          [-1.5000, -0.5000, -0.1875]],\n",
            "\n",
            "         [[-0.3750, -1.5000, -1.1250],\n",
            "          [ 1.5000,  1.0000, -1.5000],\n",
            "          [ 1.1250, -1.5000, -1.5000]],\n",
            "\n",
            "         [[ 1.5000, -1.5000, -0.0625],\n",
            "          [-1.5000,  1.5000, -0.1250],\n",
            "          [ 1.1250, -1.5000,  0.2500]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.7500,  0.5625,  0.1875],\n",
            "          [-0.3750,  0.1875, -1.5000],\n",
            "          [-0.7500,  0.7500,  1.0000]],\n",
            "\n",
            "         [[-1.1250,  0.7500,  1.5000],\n",
            "          [-0.5000,  1.5000, -0.5625],\n",
            "          [-0.5625, -0.5625, -1.0000]],\n",
            "\n",
            "         [[-1.5000,  0.5000,  1.5000],\n",
            "          [ 0.0625,  0.5625,  1.1250],\n",
            "          [ 1.5000,  0.3750, -0.3750]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.5000,  0.1875,  0.3750],\n",
            "          [ 1.5000, -1.0000, -1.0000],\n",
            "          [-1.5000,  0.1250,  1.1250]],\n",
            "\n",
            "         [[-0.1250,  0.3750, -1.1250],\n",
            "          [ 1.1250,  0.7500, -0.3750],\n",
            "          [ 1.1250,  0.1250,  0.5000]],\n",
            "\n",
            "         [[-1.5000,  1.5000,  0.7500],\n",
            "          [-0.7500,  0.5000, -1.1250],\n",
            "          [ 0.5000, -1.0000, -1.5000]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.7500,  2.0000,  0.3750],\n",
            "          [ 1.1250, -1.5000, -1.5000],\n",
            "          [ 0.7500, -1.5000,  1.0000]],\n",
            "\n",
            "         [[-0.5000,  1.5000,  1.1250],\n",
            "          [ 1.0000, -0.7500,  0.5625],\n",
            "          [-0.0000, -0.7500, -0.2500]],\n",
            "\n",
            "         [[ 1.1250, -1.1250,  1.0000],\n",
            "          [-0.5625, -0.7500, -1.1250],\n",
            "          [ 0.5625,  1.5000, -0.5625]]],\n",
            "\n",
            "\n",
            "        [[[-1.5000,  0.7500, -1.5000],\n",
            "          [ 1.1250,  1.5000,  0.0000],\n",
            "          [-0.3750,  1.1250, -0.7500]],\n",
            "\n",
            "         [[ 1.0000,  0.5625, -0.5625],\n",
            "          [-1.5000, -1.0000, -0.7500],\n",
            "          [-0.3750, -1.0000,  0.7500]],\n",
            "\n",
            "         [[-1.5000, -1.0000,  0.0000],\n",
            "          [-1.0000, -0.5625,  1.5000],\n",
            "          [-0.7500, -1.1250, -0.2500]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.3750, -1.1250, -0.7500],\n",
            "          [-1.1250, -0.1875,  0.2500],\n",
            "          [-0.0000, -0.7500, -1.5000]],\n",
            "\n",
            "         [[ 1.1250,  0.3750, -0.5625],\n",
            "          [ 1.5000,  0.3750, -1.1250],\n",
            "          [-1.0000, -0.3750,  2.0000]],\n",
            "\n",
            "         [[-0.1250,  0.3750,  0.3750],\n",
            "          [-1.1250, -1.5000, -0.7500],\n",
            "          [-1.1250, -1.0000, -1.5000]]],\n",
            "\n",
            "\n",
            "        [[[-1.5000, -1.5000, -0.7500],\n",
            "          [ 0.3750, -0.3750, -0.0625],\n",
            "          [-0.1250, -1.5000,  1.0000]],\n",
            "\n",
            "         [[-1.1250, -0.7500,  1.5000],\n",
            "          [-1.1250, -1.0000, -1.5000],\n",
            "          [ 0.7500, -0.5625, -0.7500]],\n",
            "\n",
            "         [[ 0.7500,  1.5000,  1.0000],\n",
            "          [ 0.3750,  0.7500,  0.7500],\n",
            "          [-1.5000, -1.0000, -1.0000]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.1250,  1.0000, -0.1250],\n",
            "          [ 1.1250,  1.1250,  0.0625],\n",
            "          [-0.1250,  0.0625, -0.2500]],\n",
            "\n",
            "         [[-1.5000, -1.5000, -1.5000],\n",
            "          [-0.7500, -0.2500,  0.5000],\n",
            "          [-1.5000, -0.2500,  1.0000]],\n",
            "\n",
            "         [[-1.5000,  0.1250, -0.1875],\n",
            "          [-1.5000,  1.5000,  0.1875],\n",
            "          [ 1.5000,  1.5000, -1.5000]]]], device='cuda:0',\n",
            "       grad_fn=<_pqBackward>)\n",
            "tensor([[[[-0.0000]],\n",
            "\n",
            "         [[ 0.0000]],\n",
            "\n",
            "         [[-1.5000]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0625]],\n",
            "\n",
            "         [[-0.7500]],\n",
            "\n",
            "         [[ 0.3750]]],\n",
            "\n",
            "\n",
            "        [[[-0.5625]],\n",
            "\n",
            "         [[ 1.1250]],\n",
            "\n",
            "         [[-1.0000]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.5000]],\n",
            "\n",
            "         [[ 0.5000]],\n",
            "\n",
            "         [[ 0.5000]]],\n",
            "\n",
            "\n",
            "        [[[-0.5000]],\n",
            "\n",
            "         [[-0.3750]],\n",
            "\n",
            "         [[ 1.5000]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.5625]],\n",
            "\n",
            "         [[ 0.5000]],\n",
            "\n",
            "         [[-1.5000]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 1.5000]],\n",
            "\n",
            "         [[-0.7500]],\n",
            "\n",
            "         [[ 1.5000]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.0000]],\n",
            "\n",
            "         [[ 0.1250]],\n",
            "\n",
            "         [[ 0.7500]]],\n",
            "\n",
            "\n",
            "        [[[ 1.1250]],\n",
            "\n",
            "         [[ 1.0000]],\n",
            "\n",
            "         [[-1.1250]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.5000]],\n",
            "\n",
            "         [[-1.5000]],\n",
            "\n",
            "         [[ 1.5000]]],\n",
            "\n",
            "\n",
            "        [[[-0.3750]],\n",
            "\n",
            "         [[ 1.5000]],\n",
            "\n",
            "         [[-1.5000]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.1250]],\n",
            "\n",
            "         [[-1.5000]],\n",
            "\n",
            "         [[ 0.3750]]]], device='cuda:0', grad_fn=<_pqBackward>)\n",
            "tensor([[[[ 0.3750, -1.0000, -0.3750],\n",
            "          [-0.7500, -0.0000,  0.5625],\n",
            "          [ 1.0000, -0.7500,  1.1250]],\n",
            "\n",
            "         [[ 1.5000, -1.5000,  0.5000],\n",
            "          [-1.0000, -1.5000,  1.1250],\n",
            "          [ 1.0000, -1.1250,  1.0000]],\n",
            "\n",
            "         [[-0.2500,  1.5000,  1.1250],\n",
            "          [ 1.5000,  1.5000, -0.7500],\n",
            "          [-1.5000,  0.1875,  1.1250]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.5000, -0.2500, -1.5000],\n",
            "          [ 0.7500,  1.5000,  1.0000],\n",
            "          [ 0.7500, -0.5625,  0.3750]],\n",
            "\n",
            "         [[ 1.5000,  0.7500,  0.1250],\n",
            "          [ 1.1250, -1.0000,  1.0000],\n",
            "          [ 0.3750, -0.3750, -0.5625]],\n",
            "\n",
            "         [[ 1.1250, -0.7500, -1.1250],\n",
            "          [ 0.2500,  0.7500, -0.7500],\n",
            "          [-0.3750,  1.5000, -0.7500]]],\n",
            "\n",
            "\n",
            "        [[[ 1.1250,  0.2500,  1.0000],\n",
            "          [-0.5000,  1.5000, -0.5000],\n",
            "          [-0.5625, -1.0000, -1.1250]],\n",
            "\n",
            "         [[-1.5000,  1.5000, -1.5000],\n",
            "          [ 1.1250,  0.2500, -1.1250],\n",
            "          [ 0.5000, -1.0000, -0.2500]],\n",
            "\n",
            "         [[-1.1250, -0.5000, -0.0000],\n",
            "          [-0.5000,  1.1250,  0.5625],\n",
            "          [-0.5625, -0.3750, -1.1250]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.1875, -0.5625, -0.3750],\n",
            "          [ 0.3750, -1.5000, -0.2500],\n",
            "          [ 1.5000,  0.1250,  0.7500]],\n",
            "\n",
            "         [[-1.1250,  0.3750, -1.5000],\n",
            "          [-0.7500,  0.2500, -0.7500],\n",
            "          [ 0.7500,  1.5000, -0.5000]],\n",
            "\n",
            "         [[-1.1250, -1.0000,  1.0000],\n",
            "          [ 0.2500, -1.1250, -1.1250],\n",
            "          [-1.5000,  1.0000,  1.1250]]],\n",
            "\n",
            "\n",
            "        [[[ 0.7500, -1.5000, -1.5000],\n",
            "          [-0.1875, -0.7500, -1.5000],\n",
            "          [ 1.0000,  1.1250,  1.0000]],\n",
            "\n",
            "         [[ 0.5000, -0.3750, -0.5625],\n",
            "          [-1.5000, -1.5000,  1.1250],\n",
            "          [ 0.5000, -0.3750,  0.3750]],\n",
            "\n",
            "         [[ 1.1250, -0.5000,  0.7500],\n",
            "          [ 1.5000,  0.5625, -1.5000],\n",
            "          [ 1.0000, -0.7500,  1.1250]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.5000, -1.5000,  1.1250],\n",
            "          [-1.1250,  1.5000,  0.5625],\n",
            "          [-0.2500, -0.7500, -0.5625]],\n",
            "\n",
            "         [[ 0.1250, -1.0000,  0.5625],\n",
            "          [ 0.3750, -0.7500, -1.5000],\n",
            "          [ 1.5000,  1.1250,  0.7500]],\n",
            "\n",
            "         [[ 1.0000,  1.5000,  0.2500],\n",
            "          [ 0.7500,  0.7500, -1.5000],\n",
            "          [-1.1250,  1.5000, -0.7500]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.3750, -0.7500, -0.2500],\n",
            "          [ 1.5000,  0.5625,  0.5625],\n",
            "          [-1.5000,  1.5000, -0.2500]],\n",
            "\n",
            "         [[ 1.0000, -1.0000, -0.1250],\n",
            "          [-0.1250, -0.1875,  0.5000],\n",
            "          [-1.5000, -1.1250, -0.3750]],\n",
            "\n",
            "         [[ 1.5000, -1.1250, -1.0000],\n",
            "          [ 0.2500, -1.5000,  0.0000],\n",
            "          [-1.1250, -0.1250, -1.1250]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.7500, -0.5625, -1.1250],\n",
            "          [-0.7500,  0.7500, -1.5000],\n",
            "          [-0.3750, -1.0000, -1.5000]],\n",
            "\n",
            "         [[ 1.1250,  0.3750, -1.5000],\n",
            "          [-1.1250, -1.0000, -1.0000],\n",
            "          [ 1.0000, -0.5625,  0.5625]],\n",
            "\n",
            "         [[ 0.0625, -0.7500, -1.0000],\n",
            "          [ 1.1250, -0.7500,  1.1250],\n",
            "          [-0.7500,  1.5000, -0.0625]]],\n",
            "\n",
            "\n",
            "        [[[ 1.0000, -0.5625,  1.0000],\n",
            "          [ 1.1250, -1.5000, -1.5000],\n",
            "          [ 1.5000,  1.5000,  1.5000]],\n",
            "\n",
            "         [[ 0.3750,  0.5000, -0.7500],\n",
            "          [ 0.3750, -1.0000, -0.3750],\n",
            "          [ 0.5625, -0.3750, -1.5000]],\n",
            "\n",
            "         [[ 1.0000, -1.0000, -0.1875],\n",
            "          [ 1.5000, -1.1250,  0.5625],\n",
            "          [-0.5000, -0.7500, -0.0625]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.7500, -0.2500, -0.2500],\n",
            "          [-0.0000, -0.5000,  0.1875],\n",
            "          [ 0.2500, -1.1250,  0.0000]],\n",
            "\n",
            "         [[-1.5000, -0.1250,  0.5000],\n",
            "          [-1.0000,  1.1250, -0.1875],\n",
            "          [-0.7500, -1.1250,  1.5000]],\n",
            "\n",
            "         [[-1.1250, -1.5000,  0.5625],\n",
            "          [-1.5000, -1.5000, -1.0000],\n",
            "          [-0.3750, -1.5000,  0.5625]]],\n",
            "\n",
            "\n",
            "        [[[-1.5000, -1.5000, -1.1250],\n",
            "          [-0.3750,  0.5000,  1.0000],\n",
            "          [ 1.5000, -0.7500, -1.5000]],\n",
            "\n",
            "         [[-0.5625, -0.7500, -0.1875],\n",
            "          [-1.0000, -0.5625,  0.2500],\n",
            "          [-1.5000, -0.7500, -0.3750]],\n",
            "\n",
            "         [[-0.7500, -1.5000, -1.5000],\n",
            "          [ 0.1250, -0.5000,  1.1250],\n",
            "          [ 0.2500, -1.0000,  1.5000]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.7500,  1.5000,  0.5625],\n",
            "          [-0.5000,  1.1250,  0.1250],\n",
            "          [-1.5000,  0.7500, -0.2500]],\n",
            "\n",
            "         [[ 0.2500, -1.1250,  0.3750],\n",
            "          [ 0.2500,  0.7500, -1.5000],\n",
            "          [ 1.5000,  1.5000,  1.5000]],\n",
            "\n",
            "         [[-0.1875,  0.7500,  0.5625],\n",
            "          [ 0.3750,  0.5625,  1.5000],\n",
            "          [ 0.7500, -0.7500, -1.5000]]]], device='cuda:0',\n",
            "       grad_fn=<_pqBackward>)\n",
            "tensor([[[[ 0.7500]],\n",
            "\n",
            "         [[ 1.1250]],\n",
            "\n",
            "         [[-1.1250]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.5000]],\n",
            "\n",
            "         [[ 1.0000]],\n",
            "\n",
            "         [[-1.1250]]],\n",
            "\n",
            "\n",
            "        [[[-1.0000]],\n",
            "\n",
            "         [[ 1.0000]],\n",
            "\n",
            "         [[ 0.5625]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.1250]],\n",
            "\n",
            "         [[ 0.3750]],\n",
            "\n",
            "         [[-1.1250]]],\n",
            "\n",
            "\n",
            "        [[[-1.5000]],\n",
            "\n",
            "         [[ 1.1250]],\n",
            "\n",
            "         [[ 0.1250]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.3750]],\n",
            "\n",
            "         [[-0.3750]],\n",
            "\n",
            "         [[ 0.7500]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.7500]],\n",
            "\n",
            "         [[-1.5000]],\n",
            "\n",
            "         [[ 0.5625]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.3750]],\n",
            "\n",
            "         [[-1.5000]],\n",
            "\n",
            "         [[ 0.0625]]],\n",
            "\n",
            "\n",
            "        [[[ 0.5625]],\n",
            "\n",
            "         [[-1.1250]],\n",
            "\n",
            "         [[-0.0625]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.3750]],\n",
            "\n",
            "         [[-0.3750]],\n",
            "\n",
            "         [[ 0.5000]]],\n",
            "\n",
            "\n",
            "        [[[-1.5000]],\n",
            "\n",
            "         [[ 0.7500]],\n",
            "\n",
            "         [[ 0.1250]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.0000]],\n",
            "\n",
            "         [[-0.1875]],\n",
            "\n",
            "         [[ 0.3750]]]], device='cuda:0', grad_fn=<_pqBackward>)\n",
            "tensor([[[[-1.0000, -1.5000, -1.5000],\n",
            "          [-1.5000, -1.5000,  0.1875],\n",
            "          [-1.5000, -0.0625, -0.1250]],\n",
            "\n",
            "         [[-1.1250, -0.7500,  0.5000],\n",
            "          [ 0.1875, -0.1875, -0.5625],\n",
            "          [ 0.7500, -0.3750, -1.1250]],\n",
            "\n",
            "         [[ 1.5000,  0.7500, -0.5625],\n",
            "          [-1.0000, -1.0000, -0.3750],\n",
            "          [-0.5000,  1.1250,  1.1250]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.5000,  0.5000, -0.7500],\n",
            "          [ 0.5625, -1.5000, -0.1875],\n",
            "          [-1.5000, -1.0000,  1.5000]],\n",
            "\n",
            "         [[-1.1250, -0.7500,  1.1250],\n",
            "          [ 1.1250, -1.1250,  1.5000],\n",
            "          [ 1.5000,  0.7500,  0.0625]],\n",
            "\n",
            "         [[ 1.1250,  0.1875,  0.2500],\n",
            "          [ 0.7500, -0.5000,  1.5000],\n",
            "          [ 1.1250, -0.0625,  1.5000]]],\n",
            "\n",
            "\n",
            "        [[[ 1.1250, -1.1250, -1.5000],\n",
            "          [ 0.1250,  1.5000,  1.5000],\n",
            "          [-1.1250,  1.1250, -1.5000]],\n",
            "\n",
            "         [[ 0.2500, -1.5000,  1.0000],\n",
            "          [-0.2500,  1.0000, -0.3750],\n",
            "          [ 0.2500,  1.1250,  0.7500]],\n",
            "\n",
            "         [[-0.2500, -0.7500,  0.5625],\n",
            "          [-1.1250, -1.0000,  1.5000],\n",
            "          [-0.0000,  0.0625,  0.7500]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.2500, -1.1250,  0.3750],\n",
            "          [ 1.1250, -0.1875, -1.0000],\n",
            "          [ 0.1250,  0.3750,  0.5000]],\n",
            "\n",
            "         [[-0.1250, -1.5000, -0.1875],\n",
            "          [ 1.0000,  0.3750,  1.5000],\n",
            "          [ 1.1250,  0.5625, -1.1250]],\n",
            "\n",
            "         [[ 1.1250, -0.7500,  0.5000],\n",
            "          [-1.5000,  1.1250, -1.1250],\n",
            "          [-1.5000, -0.7500, -0.0000]]],\n",
            "\n",
            "\n",
            "        [[[-1.5000,  0.5625, -1.5000],\n",
            "          [ 1.1250,  0.5000, -0.1875],\n",
            "          [-0.0625, -0.5625,  0.5000]],\n",
            "\n",
            "         [[-0.0625, -1.0000,  1.1250],\n",
            "          [ 0.7500,  0.5000, -0.0625],\n",
            "          [-1.5000,  0.3750, -0.1250]],\n",
            "\n",
            "         [[ 0.7500, -0.7500,  1.5000],\n",
            "          [ 1.0000,  1.5000,  0.1250],\n",
            "          [-0.7500,  0.3750,  1.1250]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.1250, -1.5000, -0.2500],\n",
            "          [ 0.7500, -1.0000, -1.5000],\n",
            "          [ 0.3750,  0.1875,  1.1250]],\n",
            "\n",
            "         [[-0.3750,  0.1875, -0.5625],\n",
            "          [-1.5000,  1.5000,  0.7500],\n",
            "          [-0.5625, -1.5000, -1.5000]],\n",
            "\n",
            "         [[ 1.0000,  1.0000, -1.5000],\n",
            "          [-1.5000,  1.0000, -1.1250],\n",
            "          [ 0.3750, -0.3750, -1.5000]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.7500,  0.1875,  0.1875],\n",
            "          [ 1.5000, -0.3750, -1.5000],\n",
            "          [-0.0625,  0.7500,  0.3750]],\n",
            "\n",
            "         [[-0.1875, -1.1250,  0.3750],\n",
            "          [-1.0000, -0.5000,  1.5000],\n",
            "          [ 0.2500,  0.0625, -0.7500]],\n",
            "\n",
            "         [[ 1.5000, -1.5000,  0.1875],\n",
            "          [ 0.7500,  1.1250,  0.7500],\n",
            "          [-1.0000, -0.7500,  1.5000]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.3750,  1.5000,  0.3750],\n",
            "          [-1.5000, -0.5625, -0.2500],\n",
            "          [-1.1250, -1.5000,  0.5625]],\n",
            "\n",
            "         [[ 1.5000, -0.7500, -0.5625],\n",
            "          [-1.1250, -1.5000,  0.3750],\n",
            "          [-0.2500, -0.1875, -1.1250]],\n",
            "\n",
            "         [[-1.1250, -1.0000, -0.7500],\n",
            "          [ 1.1250, -0.3750,  1.1250],\n",
            "          [-1.5000, -0.7500, -1.0000]]],\n",
            "\n",
            "\n",
            "        [[[ 1.0000, -1.5000,  1.5000],\n",
            "          [-1.1250, -0.3750,  0.7500],\n",
            "          [-1.1250, -1.5000, -0.7500]],\n",
            "\n",
            "         [[ 0.1875, -0.7500,  1.5000],\n",
            "          [ 0.5000,  1.5000,  0.1875],\n",
            "          [-0.1875, -0.0625, -1.0000]],\n",
            "\n",
            "         [[ 1.1250,  1.1250, -0.7500],\n",
            "          [ 0.1875,  1.5000,  1.1250],\n",
            "          [-0.7500, -1.1250,  1.1250]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.5000, -0.7500, -1.5000],\n",
            "          [-0.1250, -0.7500, -1.1250],\n",
            "          [ 1.5000,  1.0000,  0.5000]],\n",
            "\n",
            "         [[ 1.5000,  0.2500,  0.7500],\n",
            "          [ 0.5000, -1.5000, -0.5000],\n",
            "          [-1.5000,  0.5000,  1.5000]],\n",
            "\n",
            "         [[-0.2500,  0.7500,  1.5000],\n",
            "          [-0.7500, -1.5000,  0.7500],\n",
            "          [-1.5000,  1.5000,  0.5625]]],\n",
            "\n",
            "\n",
            "        [[[-0.7500,  1.1250,  1.5000],\n",
            "          [ 0.0000, -1.1250,  1.5000],\n",
            "          [ 1.0000,  0.3750, -0.1875]],\n",
            "\n",
            "         [[-1.1250, -0.5000, -0.3750],\n",
            "          [ 1.0000,  0.5625,  0.7500],\n",
            "          [ 0.5000,  1.1250, -0.5000]],\n",
            "\n",
            "         [[ 1.1250, -0.2500,  1.0000],\n",
            "          [-0.3750,  1.5000,  0.2500],\n",
            "          [-0.3750,  1.5000, -1.1250]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.1250,  1.5000,  1.5000],\n",
            "          [-0.5625,  1.5000, -0.2500],\n",
            "          [ 0.5000, -1.1250,  0.7500]],\n",
            "\n",
            "         [[ 1.1250,  1.1250, -1.0000],\n",
            "          [-1.0000, -0.0000,  0.3750],\n",
            "          [ 0.7500, -0.0625, -0.0000]],\n",
            "\n",
            "         [[-1.1250,  1.5000,  1.5000],\n",
            "          [-1.1250, -1.0000,  0.7500],\n",
            "          [-0.2500,  0.0625, -1.1250]]]], device='cuda:0',\n",
            "       grad_fn=<_pqBackward>)\n",
            "tensor([[[[-0.7500]],\n",
            "\n",
            "         [[-0.1250]],\n",
            "\n",
            "         [[-0.5625]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.5625]],\n",
            "\n",
            "         [[ 0.7500]],\n",
            "\n",
            "         [[-1.5000]]],\n",
            "\n",
            "\n",
            "        [[[-1.5000]],\n",
            "\n",
            "         [[-1.5000]],\n",
            "\n",
            "         [[-0.0625]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.5000]],\n",
            "\n",
            "         [[-0.7500]],\n",
            "\n",
            "         [[-0.5625]]],\n",
            "\n",
            "\n",
            "        [[[-0.7500]],\n",
            "\n",
            "         [[ 1.5000]],\n",
            "\n",
            "         [[ 0.5000]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.5000]],\n",
            "\n",
            "         [[ 0.7500]],\n",
            "\n",
            "         [[-1.5000]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-1.5000]],\n",
            "\n",
            "         [[ 1.1250]],\n",
            "\n",
            "         [[ 0.7500]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.5000]],\n",
            "\n",
            "         [[-0.3750]],\n",
            "\n",
            "         [[-0.5625]]],\n",
            "\n",
            "\n",
            "        [[[-1.5000]],\n",
            "\n",
            "         [[ 1.1250]],\n",
            "\n",
            "         [[ 0.1875]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.5625]],\n",
            "\n",
            "         [[ 1.1250]],\n",
            "\n",
            "         [[ 1.1250]]],\n",
            "\n",
            "\n",
            "        [[[ 0.3750]],\n",
            "\n",
            "         [[ 1.5000]],\n",
            "\n",
            "         [[-1.5000]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.3750]],\n",
            "\n",
            "         [[-0.3750]],\n",
            "\n",
            "         [[ 0.5000]]]], device='cuda:0', grad_fn=<_pqBackward>)\n",
            "tensor([[[[-1.5000, -0.5000, -1.1250],\n",
            "          [-0.0625, -1.5000,  0.3750],\n",
            "          [-1.5000, -0.3750, -0.3750]],\n",
            "\n",
            "         [[ 0.5625,  0.7500,  0.7500],\n",
            "          [-0.5625,  0.5625, -1.0000],\n",
            "          [-1.1250, -0.7500, -1.0000]],\n",
            "\n",
            "         [[-1.0000,  1.1250,  0.7500],\n",
            "          [ 1.1250,  1.5000,  0.7500],\n",
            "          [ 1.1250,  1.1250, -0.0625]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.5000, -1.5000,  0.7500],\n",
            "          [-1.5000,  0.1250,  1.1250],\n",
            "          [-1.0000,  1.1250,  1.1250]],\n",
            "\n",
            "         [[-0.7500,  0.2500, -1.5000],\n",
            "          [ 0.5625, -0.1875,  0.7500],\n",
            "          [-0.3750, -0.5625,  1.1250]],\n",
            "\n",
            "         [[-0.3750,  0.7500, -1.5000],\n",
            "          [ 0.5625, -1.1250,  0.5000],\n",
            "          [ 1.1250, -1.1250, -1.1250]]],\n",
            "\n",
            "\n",
            "        [[[ 1.5000, -0.3750,  1.0000],\n",
            "          [ 1.1250,  1.0000, -0.5625],\n",
            "          [ 0.1250,  1.1250,  1.5000]],\n",
            "\n",
            "         [[ 1.0000, -1.5000, -1.0000],\n",
            "          [-0.3750, -0.1875,  0.5000],\n",
            "          [-0.1250,  1.1250, -1.1250]],\n",
            "\n",
            "         [[-0.2500,  1.5000, -1.1250],\n",
            "          [ 0.7500,  1.1250,  0.5625],\n",
            "          [ 0.5625, -1.5000, -1.1250]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.1250, -1.0000,  0.5625],\n",
            "          [-1.5000, -1.5000, -0.2500],\n",
            "          [ 1.1250, -0.7500,  0.1875]],\n",
            "\n",
            "         [[ 1.5000, -1.5000, -0.0625],\n",
            "          [ 0.5625,  1.0000,  0.5000],\n",
            "          [ 0.3750, -0.0000,  0.3750]],\n",
            "\n",
            "         [[ 1.5000,  1.1250, -0.7500],\n",
            "          [-1.0000, -0.7500, -0.1875],\n",
            "          [ 0.7500,  0.1875, -0.5625]]],\n",
            "\n",
            "\n",
            "        [[[-1.5000, -1.5000,  0.7500],\n",
            "          [-1.5000, -1.1250,  0.3750],\n",
            "          [ 0.5000,  1.1250,  1.5000]],\n",
            "\n",
            "         [[-0.7500,  1.5000,  0.0625],\n",
            "          [ 1.5000,  0.7500,  0.7500],\n",
            "          [ 0.2500,  0.1250,  0.1250]],\n",
            "\n",
            "         [[-0.7500,  1.5000, -1.5000],\n",
            "          [ 0.7500, -0.1250, -0.5000],\n",
            "          [ 0.0000,  0.3750,  0.7500]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.7500,  0.7500,  1.5000],\n",
            "          [-0.3750, -0.7500,  0.7500],\n",
            "          [ 0.2500, -1.1250, -0.5625]],\n",
            "\n",
            "         [[-0.7500, -0.1250,  1.5000],\n",
            "          [-0.1250, -0.5000, -0.7500],\n",
            "          [ 0.5625, -0.3750,  1.5000]],\n",
            "\n",
            "         [[ 0.7500, -0.5625,  0.1250],\n",
            "          [-1.5000,  0.7500, -1.5000],\n",
            "          [ 0.5625,  1.0000,  0.7500]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.3750,  0.3750,  1.1250],\n",
            "          [-1.1250,  1.5000, -1.0000],\n",
            "          [ 1.1250,  1.0000,  0.5000]],\n",
            "\n",
            "         [[-1.5000, -0.5625,  1.5000],\n",
            "          [ 1.5000,  1.5000,  1.1250],\n",
            "          [ 1.1250,  1.5000, -1.1250]],\n",
            "\n",
            "         [[ 0.3750,  1.0000, -1.0000],\n",
            "          [ 1.5000, -1.5000,  1.0000],\n",
            "          [-0.7500, -1.5000,  0.3750]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.5000, -0.5625,  0.3750],\n",
            "          [ 0.2500,  1.5000,  1.5000],\n",
            "          [-1.0000,  0.0625,  0.5000]],\n",
            "\n",
            "         [[-0.7500, -0.7500,  1.0000],\n",
            "          [ 1.5000,  1.5000,  1.1250],\n",
            "          [-1.5000, -1.0000,  0.2500]],\n",
            "\n",
            "         [[ 1.1250,  0.5000,  1.5000],\n",
            "          [ 1.5000,  0.3750,  0.2500],\n",
            "          [-0.5625, -1.5000, -0.5000]]],\n",
            "\n",
            "\n",
            "        [[[ 0.5000, -0.3750,  1.1250],\n",
            "          [ 0.7500, -1.5000, -1.5000],\n",
            "          [ 0.5000,  0.0625, -1.1250]],\n",
            "\n",
            "         [[-0.7500, -0.5625, -0.3750],\n",
            "          [-0.3750,  0.1250, -1.0000],\n",
            "          [ 0.2500,  1.5000, -1.0000]],\n",
            "\n",
            "         [[-1.5000, -1.1250, -1.0000],\n",
            "          [ 1.5000, -0.5000, -0.7500],\n",
            "          [ 0.7500, -0.1875,  1.5000]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.1250, -0.5000,  0.7500],\n",
            "          [-1.5000, -1.5000, -1.5000],\n",
            "          [-0.5625,  1.1250,  0.7500]],\n",
            "\n",
            "         [[ 0.3750,  1.5000,  1.1250],\n",
            "          [-0.3750, -1.0000, -1.5000],\n",
            "          [-0.2500, -1.5000,  0.5000]],\n",
            "\n",
            "         [[ 0.2500,  0.2500,  0.5000],\n",
            "          [-0.7500,  0.7500, -0.3750],\n",
            "          [-1.0000,  1.1250, -0.7500]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1250, -1.5000, -1.0000],\n",
            "          [ 1.0000, -0.5625,  1.5000],\n",
            "          [-0.1875, -1.1250,  0.1250]],\n",
            "\n",
            "         [[ 1.0000, -0.5000, -0.7500],\n",
            "          [ 0.3750, -1.0000,  1.5000],\n",
            "          [-1.1250,  0.1250, -0.7500]],\n",
            "\n",
            "         [[-1.5000,  0.0625, -1.5000],\n",
            "          [-0.7500, -1.1250, -0.5000],\n",
            "          [ 1.5000, -1.5000, -1.5000]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.5000, -0.5625,  0.3750],\n",
            "          [ 0.7500,  1.5000, -0.1875],\n",
            "          [-1.5000,  0.3750, -0.3750]],\n",
            "\n",
            "         [[-0.7500, -1.5000,  1.5000],\n",
            "          [-1.5000,  0.1875,  1.1250],\n",
            "          [-0.5625, -0.0000,  1.1250]],\n",
            "\n",
            "         [[-1.5000, -0.2500,  0.1875],\n",
            "          [-1.1250, -1.1250, -0.5625],\n",
            "          [ 0.1875, -0.3750,  1.0000]]]], device='cuda:0',\n",
            "       grad_fn=<_pqBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYkf28v9NV1u"
      },
      "source": [
        "optimizer = torch.optim.SGD(model_quant.parameters(),lr = 0.001)\r\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ALznSY5yN6xB",
        "outputId": "7ae78e16-e5e4-47cc-d585-9d9699767f75"
      },
      "source": [
        "train_losses, valid_losses, train_acc, valid_acc = training(trainloader, validloader, model_quant, criterion, optimizer,n_epochs=350)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 1 \ttraining Loss: 1.162761 \tvalidation Loss: 1.066015\n",
            "validation loss decreased (inf --> 1.066015).  Saving model ...\n",
            "lr : 0.01 for epochs : 0\n",
            "epoch: 2 \ttraining Loss: 0.884332 \tvalidation Loss: 0.871543\n",
            "validation loss decreased (1.066015 --> 0.871543).  Saving model ...\n",
            "lr : 0.01 for epochs : 1\n",
            "epoch: 3 \ttraining Loss: 0.779017 \tvalidation Loss: 0.804190\n",
            "validation loss decreased (0.871543 --> 0.804190).  Saving model ...\n",
            "lr : 0.01 for epochs : 2\n",
            "epoch: 4 \ttraining Loss: 0.713184 \tvalidation Loss: 0.717825\n",
            "validation loss decreased (0.804190 --> 0.717825).  Saving model ...\n",
            "lr : 0.01 for epochs : 3\n",
            "epoch: 5 \ttraining Loss: 0.685637 \tvalidation Loss: 0.715333\n",
            "validation loss decreased (0.717825 --> 0.715333).  Saving model ...\n",
            "lr : 0.01 for epochs : 4\n",
            "epoch: 6 \ttraining Loss: 0.616280 \tvalidation Loss: 0.711009\n",
            "validation loss decreased (0.715333 --> 0.711009).  Saving model ...\n",
            "lr : 0.01 for epochs : 5\n",
            "epoch: 7 \ttraining Loss: 0.601006 \tvalidation Loss: 0.678774\n",
            "validation loss decreased (0.711009 --> 0.678774).  Saving model ...\n",
            "lr : 0.01 for epochs : 6\n",
            "epoch: 8 \ttraining Loss: 0.582837 \tvalidation Loss: 0.652703\n",
            "validation loss decreased (0.678774 --> 0.652703).  Saving model ...\n",
            "lr : 0.01 for epochs : 7\n",
            "epoch: 9 \ttraining Loss: 0.561474 \tvalidation Loss: 0.625065\n",
            "validation loss decreased (0.652703 --> 0.625065).  Saving model ...\n",
            "lr : 0.01 for epochs : 8\n",
            "epoch: 10 \ttraining Loss: 0.543293 \tvalidation Loss: 0.642215\n",
            "lr : 0.01 for epochs : 9\n",
            "epoch: 11 \ttraining Loss: 0.534851 \tvalidation Loss: 0.602009\n",
            "validation loss decreased (0.625065 --> 0.602009).  Saving model ...\n",
            "lr : 0.01 for epochs : 10\n",
            "epoch: 12 \ttraining Loss: 0.522105 \tvalidation Loss: 0.605961\n",
            "lr : 0.01 for epochs : 11\n",
            "epoch: 13 \ttraining Loss: 0.514617 \tvalidation Loss: 0.598589\n",
            "validation loss decreased (0.602009 --> 0.598589).  Saving model ...\n",
            "lr : 0.01 for epochs : 12\n",
            "epoch: 14 \ttraining Loss: 0.503118 \tvalidation Loss: 0.624249\n",
            "lr : 0.01 for epochs : 13\n",
            "epoch: 15 \ttraining Loss: 0.515136 \tvalidation Loss: 0.672590\n",
            "lr : 0.01 for epochs : 14\n",
            "epoch: 16 \ttraining Loss: 0.611496 \tvalidation Loss: 0.603170\n",
            "lr : 0.01 for epochs : 15\n",
            "epoch: 17 \ttraining Loss: 0.589140 \tvalidation Loss: 0.678703\n",
            "lr : 0.01 for epochs : 16\n",
            "epoch: 18 \ttraining Loss: 0.528918 \tvalidation Loss: 0.516566\n",
            "validation loss decreased (0.598589 --> 0.516566).  Saving model ...\n",
            "lr : 0.01 for epochs : 17\n",
            "epoch: 19 \ttraining Loss: 0.471865 \tvalidation Loss: 0.502940\n",
            "validation loss decreased (0.516566 --> 0.502940).  Saving model ...\n",
            "lr : 0.01 for epochs : 18\n",
            "epoch: 20 \ttraining Loss: 0.436990 \tvalidation Loss: 0.479981\n",
            "validation loss decreased (0.502940 --> 0.479981).  Saving model ...\n",
            "lr : 0.01 for epochs : 19\n",
            "epoch: 21 \ttraining Loss: 0.426052 \tvalidation Loss: 0.477899\n",
            "validation loss decreased (0.479981 --> 0.477899).  Saving model ...\n",
            "lr : 0.01 for epochs : 20\n",
            "epoch: 22 \ttraining Loss: 0.405046 \tvalidation Loss: 0.451436\n",
            "validation loss decreased (0.477899 --> 0.451436).  Saving model ...\n",
            "lr : 0.01 for epochs : 21\n",
            "epoch: 23 \ttraining Loss: 0.398560 \tvalidation Loss: 0.455642\n",
            "lr : 0.01 for epochs : 22\n",
            "epoch: 24 \ttraining Loss: 0.385824 \tvalidation Loss: 0.426515\n",
            "validation loss decreased (0.451436 --> 0.426515).  Saving model ...\n",
            "lr : 0.01 for epochs : 23\n",
            "epoch: 25 \ttraining Loss: 0.374174 \tvalidation Loss: 0.432301\n",
            "lr : 0.01 for epochs : 24\n",
            "epoch: 26 \ttraining Loss: 0.369917 \tvalidation Loss: 0.441313\n",
            "lr : 0.01 for epochs : 25\n",
            "epoch: 27 \ttraining Loss: 0.380070 \tvalidation Loss: 0.423290\n",
            "validation loss decreased (0.426515 --> 0.423290).  Saving model ...\n",
            "lr : 0.01 for epochs : 26\n",
            "epoch: 28 \ttraining Loss: 0.359608 \tvalidation Loss: 0.411710\n",
            "validation loss decreased (0.423290 --> 0.411710).  Saving model ...\n",
            "lr : 0.01 for epochs : 27\n",
            "epoch: 29 \ttraining Loss: 0.352481 \tvalidation Loss: 0.423659\n",
            "lr : 0.01 for epochs : 28\n",
            "epoch: 30 \ttraining Loss: 0.358945 \tvalidation Loss: 0.421462\n",
            "lr : 0.01 for epochs : 29\n",
            "epoch: 31 \ttraining Loss: 0.347941 \tvalidation Loss: 0.425440\n",
            "lr : 0.01 for epochs : 30\n",
            "epoch: 32 \ttraining Loss: 0.341892 \tvalidation Loss: 0.394586\n",
            "validation loss decreased (0.411710 --> 0.394586).  Saving model ...\n",
            "lr : 0.01 for epochs : 31\n",
            "epoch: 33 \ttraining Loss: 0.333651 \tvalidation Loss: 0.416433\n",
            "lr : 0.01 for epochs : 32\n",
            "epoch: 34 \ttraining Loss: 0.329844 \tvalidation Loss: 0.420954\n",
            "lr : 0.01 for epochs : 33\n",
            "epoch: 35 \ttraining Loss: 0.319674 \tvalidation Loss: 0.402695\n",
            "lr : 0.01 for epochs : 34\n",
            "epoch: 36 \ttraining Loss: 0.310917 \tvalidation Loss: 0.403442\n",
            "lr : 0.01 for epochs : 35\n",
            "epoch: 37 \ttraining Loss: 0.322038 \tvalidation Loss: 0.421855\n",
            "lr : 0.01 for epochs : 36\n",
            "epoch: 38 \ttraining Loss: 0.319571 \tvalidation Loss: 0.398222\n",
            "lr : 0.01 for epochs : 37\n",
            "epoch: 39 \ttraining Loss: 0.312250 \tvalidation Loss: 0.410487\n",
            "lr : 0.01 for epochs : 38\n",
            "epoch: 40 \ttraining Loss: 0.308323 \tvalidation Loss: 0.389792\n",
            "validation loss decreased (0.394586 --> 0.389792).  Saving model ...\n",
            "lr : 0.01 for epochs : 39\n",
            "epoch: 41 \ttraining Loss: 0.304097 \tvalidation Loss: 0.387287\n",
            "validation loss decreased (0.389792 --> 0.387287).  Saving model ...\n",
            "lr : 0.01 for epochs : 40\n",
            "epoch: 42 \ttraining Loss: 0.294082 \tvalidation Loss: 0.385877\n",
            "validation loss decreased (0.387287 --> 0.385877).  Saving model ...\n",
            "lr : 0.01 for epochs : 41\n",
            "epoch: 43 \ttraining Loss: 0.290745 \tvalidation Loss: 0.406193\n",
            "lr : 0.01 for epochs : 42\n",
            "epoch: 44 \ttraining Loss: 0.294737 \tvalidation Loss: 0.394786\n",
            "lr : 0.01 for epochs : 43\n",
            "epoch: 45 \ttraining Loss: 0.286114 \tvalidation Loss: 0.404580\n",
            "lr : 0.01 for epochs : 44\n",
            "epoch: 46 \ttraining Loss: 0.290972 \tvalidation Loss: 0.374983\n",
            "validation loss decreased (0.385877 --> 0.374983).  Saving model ...\n",
            "lr : 0.01 for epochs : 45\n",
            "epoch: 47 \ttraining Loss: 0.279984 \tvalidation Loss: 0.399138\n",
            "lr : 0.01 for epochs : 46\n",
            "epoch: 48 \ttraining Loss: 0.281223 \tvalidation Loss: 0.393805\n",
            "lr : 0.01 for epochs : 47\n",
            "epoch: 49 \ttraining Loss: 0.292082 \tvalidation Loss: 0.387428\n",
            "lr : 0.01 for epochs : 48\n",
            "epoch: 50 \ttraining Loss: 0.277954 \tvalidation Loss: 0.408410\n",
            "lr : 0.01 for epochs : 49\n",
            "epoch: 51 \ttraining Loss: 0.274184 \tvalidation Loss: 0.403734\n",
            "lr : 0.01 for epochs : 50\n",
            "epoch: 52 \ttraining Loss: 0.270807 \tvalidation Loss: 0.390440\n",
            "lr : 0.01 for epochs : 51\n",
            "epoch: 53 \ttraining Loss: 0.276477 \tvalidation Loss: 0.393224\n",
            "lr : 0.01 for epochs : 52\n",
            "epoch: 54 \ttraining Loss: 0.277015 \tvalidation Loss: 0.393155\n",
            "lr : 0.01 for epochs : 53\n",
            "epoch: 55 \ttraining Loss: 0.273268 \tvalidation Loss: 0.400703\n",
            "lr : 0.01 for epochs : 54\n",
            "epoch: 56 \ttraining Loss: 0.265221 \tvalidation Loss: 0.384267\n",
            "lr : 0.01 for epochs : 55\n",
            "epoch: 57 \ttraining Loss: 0.257809 \tvalidation Loss: 0.385326\n",
            "lr : 0.01 for epochs : 56\n",
            "epoch: 58 \ttraining Loss: 0.255199 \tvalidation Loss: 0.393724\n",
            "lr : 0.01 for epochs : 57\n",
            "epoch: 59 \ttraining Loss: 0.254395 \tvalidation Loss: 0.391492\n",
            "lr : 0.01 for epochs : 58\n",
            "epoch: 60 \ttraining Loss: 0.274577 \tvalidation Loss: 0.392746\n",
            "lr : 0.01 for epochs : 59\n",
            "epoch: 61 \ttraining Loss: 0.286748 \tvalidation Loss: 0.440846\n",
            "lr : 0.01 for epochs : 60\n",
            "epoch: 62 \ttraining Loss: 0.370413 \tvalidation Loss: 0.738950\n",
            "lr : 0.01 for epochs : 61\n",
            "epoch: 63 \ttraining Loss: 0.353345 \tvalidation Loss: 0.437747\n",
            "lr : 0.01 for epochs : 62\n",
            "epoch: 64 \ttraining Loss: 0.308664 \tvalidation Loss: 0.439794\n",
            "lr : 0.01 for epochs : 63\n",
            "epoch: 65 \ttraining Loss: 0.304664 \tvalidation Loss: 0.437616\n",
            "lr : 0.01 for epochs : 64\n",
            "epoch: 66 \ttraining Loss: 0.307217 \tvalidation Loss: 0.430026\n",
            "lr : 0.01 for epochs : 65\n",
            "epoch: 67 \ttraining Loss: 0.296404 \tvalidation Loss: 0.445027\n",
            "lr : 0.01 for epochs : 66\n",
            "epoch: 68 \ttraining Loss: 0.294598 \tvalidation Loss: 0.432647\n",
            "lr : 0.01 for epochs : 67\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-3785c36a71ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_quant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m350\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-6-2df4b830d952>\u001b[0m in \u001b[0;36mtraining\u001b[0;34m(train_loader, valid_loader, model, criterion, optimizer, n_epochs)\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# clear the gradients of all optimized variables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# forward pass: compute predicted outputs by passing inputs to the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# calculate the loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# backward pass: compute gradient of the loss with respect to model parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-f81a4d39c5d0>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrans1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrans2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrans3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-f81a4d39c5d0>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mrelu\u001b[0;34m(input, inplace)\u001b[0m\n\u001b[1;32m   1204\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1205\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1206\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1207\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9BaNRHChzjKq",
        "outputId": "9471d4cc-dd05-4905-ac89-c5beb95a8fcb"
      },
      "source": [
        "loaded_cpt=torch.load('model_densenet121_0.1.pt')\r\n",
        "model_quant.load_state_dict(loaded_cpt)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n5v7x3s9zdiv",
        "outputId": "7825ce39-f2ba-4a99-fb78-93e50b885c5b"
      },
      "source": [
        "evaluation(model_quant, testloader, criterion)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test Loss: 0.437395\n",
            "\n",
            "test accuracy of plane: 85% (859/1000)\n",
            "test accuracy of car: 95% (955/1000)\n",
            "test accuracy of bird: 80% (804/1000)\n",
            "test accuracy of cat: 73% (738/1000)\n",
            "test accuracy of deer: 85% (855/1000)\n",
            "test accuracy of dog: 75% (755/1000)\n",
            "test accuracy of frog: 90% (904/1000)\n",
            "test accuracy of horse: 88% (889/1000)\n",
            "test accuracy of ship: 90% (905/1000)\n",
            "test accuracy of truck: 91% (917/1000)\n",
            "\n",
            "test accuracy (overall): 85.81% (8581/10000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "60mgorDcqYsK"
      },
      "source": [
        "# BWN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4YxUySUDbVix"
      },
      "source": [
        "import torch.nn as nn\r\n",
        "import numpy\r\n",
        "from torch.autograd import Variable\r\n",
        "\r\n",
        "\r\n",
        "class BC():\r\n",
        "    def __init__(self, model):\r\n",
        "\r\n",
        "        # First we need to \r\n",
        "        # count the number of Conv2d and Linear\r\n",
        "        # This will be used next in order to build a list of all \r\n",
        "        # parameters of the model \r\n",
        "\r\n",
        "        count_targets = 0\r\n",
        "        for m in model.modules():\r\n",
        "            if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\r\n",
        "                count_targets = count_targets + 1\r\n",
        "\r\n",
        "        start_range = 0\r\n",
        "        end_range = count_targets-1\r\n",
        "        self.bin_range = numpy.linspace(start_range,\r\n",
        "                end_range, end_range-start_range+1)\\\r\n",
        "                        .astype('int').tolist()\r\n",
        "\r\n",
        "        # Now we can initialize the list of parameters\r\n",
        "\r\n",
        "        self.num_of_params = len(self.bin_range)\r\n",
        "        self.saved_params = [] # This will be used to save the full precision weights\r\n",
        "        \r\n",
        "        self.target_modules = [] # this will contain the list of modules to be modified\r\n",
        "\r\n",
        "        self.model = model # this contains the model that will be trained and quantified\r\n",
        "\r\n",
        "        ### This builds the initial copy of all parameters and target modules\r\n",
        "        index = -1\r\n",
        "        for m in model.modules():\r\n",
        "            if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\r\n",
        "                index = index + 1\r\n",
        "                if index in self.bin_range:\r\n",
        "                    tmp = m.weight.data.clone()\r\n",
        "                    self.saved_params.append(tmp)\r\n",
        "                    self.target_modules.append(m.weight)\r\n",
        "\r\n",
        "\r\n",
        "    def save_params(self):\r\n",
        "\r\n",
        "        ### This loop goes through the list of target modules, and saves the corresponding weights into the list of saved_parameters\r\n",
        "\r\n",
        "        for index in range(self.num_of_params):\r\n",
        "            self.saved_params[index].copy_(self.target_modules[index].data)\r\n",
        "\r\n",
        "    def binarization(self):\r\n",
        "\r\n",
        "        ### To be completed\r\n",
        "        ### (1) Save the current full precision parameters using the save_params method\r\n",
        "\r\n",
        "#         self.save_params()\r\n",
        "#          ### (2) Binarize the weights in the model, by iterating through the list of target modules and overwrite the values with their binary version\r\n",
        "#         for index in range(self.num_of_params):\r\n",
        "\r\n",
        "#             self.target_modules[index].data.copy_((self.target_modules[index]>=0).float())  # Nous \r\n",
        "#             self.target_modules[index].data[self.target_modules[index].data==0.]=-1\r\n",
        "\r\n",
        "            \r\n",
        "            \r\n",
        "        self.save_params()\r\n",
        "        for index in range(self.num_of_params):\r\n",
        "            self.target_modules[index].data.copy_(self.target_modules[index].data.sign()) # Le mec\r\n",
        "\r\n",
        "    def BWN(self): # Binary Weight Network\r\n",
        "        self.save_params()\r\n",
        "        for index in range(self.num_of_params):\r\n",
        "            E=self.target_modules[index].data.abs().mean()\r\n",
        "            self.target_modules[index].data.copy_(self.target_modules[index].data.sign() *E)\r\n",
        "            \r\n",
        "\r\n",
        "    def restore(self):\r\n",
        "\r\n",
        "        ### restore the copy from self.saved_params into the model \r\n",
        "\r\n",
        "        for index in range(self.num_of_params):\r\n",
        "            self.target_modules[index].data.copy_(self.saved_params[index])\r\n",
        "      \r\n",
        "    def clip(self):\r\n",
        "\r\n",
        "        ## To be completed \r\n",
        "        ## Clip all parameters to the range [-1,1] using Hard Tanh \r\n",
        "        ## you can use the nn.Hardtanh function\r\n",
        "            \r\n",
        "        clip_scale=[]\r\n",
        "        m=nn.Hardtanh(-1, 1)\r\n",
        "        for index in range(self.num_of_params):\r\n",
        "            clip_scale.append(m(Variable(self.target_modules[index].data)))\r\n",
        "        for index in range(self.num_of_params):\r\n",
        "            self.target_modules[index].data.copy_(clip_scale[index].data)  # Le mec \r\n",
        "\r\n",
        "\r\n",
        "#         for index in range(self.num_of_params):\r\n",
        "#             hardtanh = nn.Hardtanh()\r\n",
        "#             self.target_modules[index].data.copy_(hardtanh(self.target_modules[index].data)) # Nous\r\n",
        "\r\n",
        "\r\n",
        "    def forward(self,x):\r\n",
        "\r\n",
        "        ### This function is used so that the model can be used while training\r\n",
        "        out = self.model(x)\r\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "n5HPG0p0cwrP",
        "outputId": "6dfe54f9-d03b-4dd2-f92d-5e36ec58d4d2"
      },
      "source": [
        "train_losses, valid_losses, train_acc, valid_acc = training_binary(n_epochs, trainloader, validloader, modelbc, criterion, optimizer_bc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-eb003743ae54>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-6-2df4b830d952>\u001b[0m in \u001b[0;36mtraining\u001b[0;34m(train_loader, valid_loader, model, criterion, optimizer, n_epochs)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mvalid_loss_min\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInf\u001b[0m  \u001b[0;31m# set initial \"min\" to infinity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;31m# monitor losses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mclass_correct_train\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mclass_total_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'SGD' object cannot be interpreted as an integer"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17wqht-mcRM1"
      },
      "source": [
        "def evaluation_binary(model, test_loader, criterion): \r\n",
        "\r\n",
        "  test_loss = 0.0\r\n",
        "  class_correct = list(0. for i in range(10))\r\n",
        "  class_total = list(0. for i in range(10))\r\n",
        "\r\n",
        "  model.model.eval()\r\n",
        "  #model.binarization()\r\n",
        "  model.BWN()\r\n",
        "  for data, label in test_loader:\r\n",
        "      data = data.to(device=device, dtype=torch.float32)\r\n",
        "      label = label.to(device=device, dtype=torch.long)\r\n",
        "      #with torch.no_grad():\r\n",
        "      output = model.forward(data)\r\n",
        "      #print(output)\r\n",
        "      loss = criterion(output, label)\r\n",
        "      test_loss += loss.item()*data.size(0)\r\n",
        "      _, pred = torch.max(output, 1)\r\n",
        "      correct = np.squeeze(pred.eq(label.data.view_as(pred)))\r\n",
        "      for i in range(len(label)):\r\n",
        "          digit = label.data[i]\r\n",
        "          class_correct[digit] += correct[i].item()\r\n",
        "          class_total[digit] += 1\r\n",
        "\r\n",
        "  test_loss = test_loss/len(test_loader.sampler)\r\n",
        "  print('test Loss: {:.6f}\\n'.format(test_loss))\r\n",
        "  for i in range(10):\r\n",
        "\r\n",
        "      if(np.sum(class_total[i])==0):\r\n",
        "        print(class_names[i])\r\n",
        "      else:\r\n",
        "        print('test accuracy of %s: %2d%% (%2d/%2d)' % (class_names[i], 100 * class_correct[i] / class_total[i], np.sum(class_correct[i]), np.sum(class_total[i])))\r\n",
        "  print('\\ntest accuracy (overall): %2.2f%% (%2d/%2d)' % (100. * np.sum(class_correct) / np.sum(class_total), np.sum(class_correct), np.sum(class_total)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXxvzHS1c1fu"
      },
      "source": [
        "n_epochs = 100 # number of epochs to train the model\r\n",
        "\r\n",
        "def training_binary(n_epochs, train_loader, valid_loader, model, criterion, optimizer):\r\n",
        "  '''Method who train the GNN for n_epochs, return the different loss so we can plot it'''\r\n",
        "  train_losses, valid_losses, train_acc, valid_acc = [], [], [], []\r\n",
        "  # initialize tracker for minimum validation loss\r\n",
        "  valid_loss_min = np.Inf  # set initial \"min\" to infinity\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "  for epoch in range(n_epochs):\r\n",
        "    train_loss, valid_loss, test_loss = 0, 0, 0 # monitor losses\r\n",
        "    class_correct_train ,class_total_train = 0, 0 \r\n",
        "    class_correct_valid ,class_total_valid = 0, 0 \r\n",
        "    class_correct_test ,class_total_test = 0, 0 \r\n",
        "\r\n",
        "\r\n",
        "    # train the model\r\n",
        "    model.model.train() # prep model for training\r\n",
        "    for data, label in train_loader:\r\n",
        "        data = data.to(device=device, dtype=torch.float32)\r\n",
        "#         data=data.half()\r\n",
        "        label = label.to(device=device, dtype=torch.long)\r\n",
        "        #model.binarization()\r\n",
        "        model.BWN()\r\n",
        "        optimizer.zero_grad()\r\n",
        "    \r\n",
        "         # clear the gradients of all optimized variables\r\n",
        "        \r\n",
        "        \r\n",
        "        output = model.forward(data) # forward pass: compute predicted outputs by passing inputs to the model\r\n",
        "        loss = criterion(output, label) # calculate the loss\r\n",
        "        \r\n",
        "        loss.backward() # backward pass: compute gradient of the loss with respect to model parameters\r\n",
        "        model.restore()\r\n",
        "        optimizer.step() # perform a single optimization step (parameter update)\r\n",
        "        model.clip()\r\n",
        "        \r\n",
        "        train_loss += loss.item() * data.size(0) # update running training loss\r\n",
        "\r\n",
        "        _, pred = torch.max(output, 1)\r\n",
        "        correct = np.squeeze(pred.eq(label.data.view_as(pred)))\r\n",
        "        for i in range(len(label)):\r\n",
        "            digit = label.data[i]\r\n",
        "            class_correct_train += correct[i].item()\r\n",
        "            class_total_train += 1\r\n",
        "        \r\n",
        "\r\n",
        "    # validate the model\r\n",
        "    model.model.eval()\r\n",
        "    #model.binarization()\r\n",
        "    model.BWN()\r\n",
        "    for data, label in valid_loader:\r\n",
        "        data = data.to(device=device, dtype=torch.float32)\r\n",
        "        label = label.to(device=device, dtype=torch.long)\r\n",
        "        with torch.no_grad():\r\n",
        "            output = model.model(data)\r\n",
        "        loss = criterion(output,label)\r\n",
        "        valid_loss += loss.item() * data.size(0)\r\n",
        "\r\n",
        "        _, pred = torch.max(output, 1)\r\n",
        "        correct = np.squeeze(pred.eq(label.data.view_as(pred)))\r\n",
        "        for i in range(len(label)):\r\n",
        "            digit = label.data[i]\r\n",
        "            class_correct_valid += correct[i].item()\r\n",
        "            class_total_valid += 1\r\n",
        "    model.restore()\r\n",
        "\r\n",
        "    # calculate average loss over an epoch\r\n",
        "    train_loss /= len(train_loader.sampler)\r\n",
        "    valid_loss /= len(valid_loader.sampler)\r\n",
        "    train_losses.append(train_loss)\r\n",
        "    valid_losses.append(valid_loss)\r\n",
        "\r\n",
        "    train_acc.append(class_correct_train/class_total_train)\r\n",
        "    valid_acc.append(class_correct_valid/class_total_valid)\r\n",
        "\r\n",
        "    print('epoch: {} \\ttraining Loss: {:.6f} \\tvalidation Loss: {:.6f}'.format(epoch+1, train_loss, valid_loss))\r\n",
        "\r\n",
        "    # save model if validation loss has decreased\r\n",
        "    if valid_loss <= valid_loss_min:\r\n",
        "        print('validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\r\n",
        "        valid_loss_min,\r\n",
        "        valid_loss))\r\n",
        "        torch.save(model.model.state_dict(), 'model_binary.pt')\r\n",
        "        valid_loss_min = valid_loss\r\n",
        "\r\n",
        "  return train_losses, valid_losses, train_acc, valid_acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mcX8Go1ctxQ"
      },
      "source": [
        "modelbc = BC(model)\r\n",
        "modelbc.model = modelbc.model.to(device)\r\n",
        "criterion = nn.CrossEntropyLoss()\r\n",
        "\r\n",
        "optimizer_bc = torch.optim.SGD(modelbc.model.parameters(),lr = 0.00001)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}