{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Densenet import *\n",
    "from util import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "n_classes_cifar10 = 10\n",
    "train_size = 0.8\n",
    "R = 5\n",
    "\n",
    "\n",
    "# Download the entire CIFAR10 dataset\n",
    "\n",
    "from torchvision.datasets import CIFAR10\n",
    "import numpy as np \n",
    "from torch.utils.data import Subset\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "## Normalization is different when training from scratch and when training using an imagenet pretrained backbone\n",
    "\n",
    "normalize_scratch = transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "\n",
    "\n",
    "# Data augmentation is needed in order to train from scratch\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    normalize_scratch,\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    normalize_scratch,\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "### The data from CIFAR10 will be downloaded in the following dataset\n",
    "rootdir = './data/cifar10'\n",
    "\n",
    "c10train = CIFAR10(rootdir,train=True,download=True,transform=transform_train)\n",
    "c10test = CIFAR10(rootdir,train=False,download=True,transform=transform_test)\n",
    "\n",
    "\n",
    "\n",
    "# CIFAR10 is sufficiently large so that training a model up to the state of the art performance will take approximately 3 hours on the 1060 GPU available on your machine. \n",
    "\n",
    "\n",
    "def train_validation_split(train_size, num_train_examples):\n",
    "    # obtain training indices that will be used for validation\n",
    "    indices = list(range(num_train_examples))\n",
    "    np.random.shuffle(indices)\n",
    "    idx_split = int(np.floor(train_size * num_train_examples))\n",
    "    train_index, valid_index = indices[:idx_split], indices[idx_split:]\n",
    "\n",
    "    # define samplers for obtaining training and validation batches\n",
    "    train_sampler = SubsetRandomSampler(train_index)\n",
    "    valid_sampler = SubsetRandomSampler(valid_index)\n",
    "\n",
    "    return train_sampler,valid_sampler\n",
    "\n",
    "def generate_subset(dataset,n_classes,reducefactor,n_ex_class_init):\n",
    "\n",
    "    nb_examples_per_class = int(np.floor(n_ex_class_init / reducefactor))\n",
    "    # Generate the indices. They are the same for each class, could easily be modified to have different ones. But be careful to keep the random seed! \n",
    "\n",
    "    indices_split = np.random.RandomState(seed=42).choice(n_ex_class_init,nb_examples_per_class,replace=False)\n",
    "\n",
    "    all_indices = []\n",
    "    for curclas in range(n_classes):\n",
    "        curtargets = np.where(np.array(dataset.targets) == curclas)\n",
    "        indices_curclas = curtargets[0]\n",
    "        indices_subset = indices_curclas[indices_split]\n",
    "        #print(len(indices_subset))\n",
    "        all_indices.append(indices_subset)\n",
    "    all_indices = np.hstack(all_indices)\n",
    "    \n",
    "    return Subset(dataset,indices=all_indices)\n",
    "    \n",
    "\n",
    "\n",
    "### These dataloader are ready to be used to train for scratch \n",
    "cifar10_train= generate_subset(dataset=c10train,n_classes=n_classes_cifar10,reducefactor=R,n_ex_class_init=5000)\n",
    "num_train_examples=len(cifar10_train)\n",
    "train_sampler,valid_sampler=train_validation_split(train_size, num_train_examples)\n",
    "\n",
    "cifar10_test = generate_subset(dataset=c10test,n_classes=n_classes_cifar10,reducefactor=1,n_ex_class_init=1000) \n",
    "\n",
    "\n",
    "\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "\n",
    "trainloader = DataLoader(c10train,batch_size=32,sampler=train_sampler)\n",
    "validloader = DataLoader(c10train,batch_size=32,sampler=valid_sampler)\n",
    "testloader = DataLoader(c10test,batch_size=32) \n",
    "\n",
    "\n",
    "def evaluation(model, test_loader, criterion): \n",
    "    class_names = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "    \n",
    "\n",
    "    test_loss = 0.0\n",
    "    class_correct = list(0. for i in range(10))\n",
    "    class_total = list(0. for i in range(10))\n",
    "\n",
    "    model.eval()\n",
    "    for data, label in test_loader:\n",
    "        data = data.to(device=device, dtype=torch.float32)\n",
    "        label = label.to(device=device, dtype=torch.long)\n",
    "        with torch.no_grad():\n",
    "            output = model(data)\n",
    "        loss = criterion(output, label)\n",
    "        test_loss += loss.item()*data.size(0)\n",
    "        _, pred = torch.max(output, 1)\n",
    "        correct = np.squeeze(pred.eq(label.data.view_as(pred)))\n",
    "        for i in range(len(label)):\n",
    "            digit = label.data[i]\n",
    "            class_correct[digit] += correct[i].item()\n",
    "            class_total[digit] += 1\n",
    "\n",
    "    test_loss = test_loss/len(test_loader.sampler)\n",
    "    print('test Loss: {:.6f}\\n'.format(test_loss))\n",
    "    for i in range(10):\n",
    "\n",
    "        if(np.sum(class_total[i])==0):\n",
    "            print(class_names[i])\n",
    "        else:\n",
    "            print('test accuracy of %s: %2d%% (%2d/%2d)' % (class_names[i], 100 * class_correct[i] / class_total[i], np.sum(class_correct[i]), np.sum(class_total[i])))\n",
    "    print('\\ntest accuracy (overall): %2.2f%% (%2d/%2d)' % (100. * np.sum(class_correct) / np.sum(class_total), np.sum(class_correct), np.sum(class_total)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from minicifar import minicifar_train,minicifar_test,train_sampler,valid_sampler\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "\n",
    "trainloader = DataLoader(c10train,batch_size=128,sampler=train_sampler)\n",
    "validloader = DataLoader(c10train,batch_size=128,sampler=valid_sampler)\n",
    "testloader = DataLoader(c10test,batch_size=128) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device '+str(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn.utils.prune as prune\n",
    "import torch.nn as nn\n",
    "\n",
    "def count_conv2d(m, x, y):\n",
    "    x = x[0] # remove tuple\n",
    "\n",
    "    fin = m.in_channels\n",
    "    fout = m.out_channels\n",
    "    sh, sw = m.kernel_size\n",
    "\n",
    "    # ops per output element\n",
    "    kernel_mul = sh * sw * fin\n",
    "    kernel_add = sh * sw * fin - 1\n",
    "    bias_ops = 1 if m.bias is not None else 0\n",
    "    kernel_mul = kernel_mul/8 # FP4\n",
    "    ops = kernel_mul + kernel_add + bias_ops\n",
    "\n",
    "    # total ops\n",
    "    num_out_elements = y.numel()\n",
    "    total_ops = num_out_elements * ops\n",
    "    \n",
    "    # total params \n",
    "    \n",
    "\n",
    "    print(\"Conv2d: S_c={}, F_in={}, F_out={}, P={}, params={}, operations={}\".format(sh,fin,fout,x.size()[2:].numel(),int(m.total_params.item()),int(total_ops)))\n",
    "    # incase same conv is used multiple times\n",
    "    m.total_ops += torch.Tensor([int(total_ops)])\n",
    "\n",
    "\n",
    "def count_bn2d(m, x, y):\n",
    "    x = x[0] # remove tuple\n",
    "\n",
    "    nelements = x.numel()\n",
    "    total_sub = 2*nelements\n",
    "    total_div = nelements\n",
    "    total_ops = total_sub + total_div\n",
    "\n",
    "    m.total_ops += torch.Tensor([int(total_ops)])\n",
    "    print(\"Batch norm: F_in={} P={}, params={}, operations={}\".format(x.size(1),x.size()[2:].numel(),int(m.total_params.item()),int(total_ops)))\n",
    "\n",
    "\n",
    "def count_relu(m, x, y):\n",
    "    x = x[0]\n",
    "\n",
    "    nelements = x.numel()\n",
    "    total_ops = nelements\n",
    "\n",
    "    m.total_ops += torch.Tensor([int(total_ops)])\n",
    "    print(\"ReLU: F_in={} P={}, params={}, operations={}\".format(x.size(1),x.size()[2:].numel(),0,int(total_ops)))\n",
    "\n",
    "\n",
    "\n",
    "def count_avgpool(m, x, y):\n",
    "    x = x[0]\n",
    "    total_add = torch.prod(torch.Tensor([m.kernel_size])) - 1\n",
    "    total_div = 1\n",
    "    kernel_ops = total_add + total_div\n",
    "    num_elements = y.numel()\n",
    "    total_ops = kernel_ops * num_elements\n",
    "\n",
    "    m.total_ops += torch.Tensor([int(total_ops)])\n",
    "    print(\"AvgPool: S={}, F_in={}, P={}, params={}, operations={}\".format(m.kernel_size,x.size(1),x.size()[2:].numel(),0,int(total_ops)))\n",
    "\n",
    "def count_linear(m, x, y):\n",
    "    # per output element\n",
    "    total_mul = m.in_features/2\n",
    "    total_add = m.in_features - 1\n",
    "    num_elements = y.numel()\n",
    "    total_ops = (total_mul + total_add) * num_elements\n",
    "    print(\"Linear: F_in={}, F_out={}, params={}, operations={}\".format(m.in_features,m.out_features,int(m.total_params.item()),int(total_ops)))\n",
    "    m.total_ops += torch.Tensor([int(total_ops)])\n",
    "\n",
    "def count_sequential(m, x, y):\n",
    "    print (\"Sequential: No additional parameters  / op\")\n",
    "\n",
    "# custom ops could be used to pass variable customized ratios for quantization\n",
    "def profile(model, input_size, custom_ops = {}):\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    def add_hooks(m):\n",
    "        if len(list(m.children())) > 0: return\n",
    "        m.register_buffer('total_ops', torch.zeros(1))\n",
    "        m.register_buffer('total_params', torch.zeros(1))\n",
    "\n",
    "\n",
    "        #for p in m.parameters():\n",
    "         #   m.total_params += torch.Tensor([torch.count_nonzero(p.data)]) / 8\n",
    "            \n",
    "\n",
    "\n",
    "        if isinstance(m, nn.Conv2d):\n",
    "            m.register_forward_hook(count_conv2d)\n",
    "        elif isinstance(m, nn.BatchNorm2d):\n",
    "            m.register_forward_hook(count_bn2d)\n",
    "        elif isinstance(m, nn.ReLU):\n",
    "            m.register_forward_hook(count_relu)\n",
    "        elif isinstance(m, (nn.AvgPool2d)):\n",
    "            m.register_forward_hook(count_avgpool)\n",
    "        elif isinstance(m, nn.Linear):\n",
    "            m.register_forward_hook(count_linear)\n",
    "        elif isinstance(m, nn.Sequential):\n",
    "            m.register_forward_hook(count_sequential)\n",
    "        else:\n",
    "            print(\"Not implemented for \", m)\n",
    "\n",
    "    model.apply(add_hooks)\n",
    "\n",
    "    x = torch.zeros(input_size)\n",
    "    model(x)\n",
    "\n",
    "    total_ops = 0\n",
    "    total_params = 0\n",
    "    for m in model.modules():\n",
    "        if len(list(m.children())) > 0: continue\n",
    "        total_ops += m.total_ops\n",
    "        total_params += m.total_params\n",
    "\n",
    "    return total_ops, total_params\n",
    "\n",
    "def score(model , filename, pruning = False, quantization = False):\n",
    "    ref_params = 5586981\n",
    "    ref_flops  = 834362880\n",
    "    if(pruning):\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        parameters_to_prune=[]\n",
    "        for name, module in model.named_modules():\n",
    "            if isinstance(module, torch.nn.Conv2d) or isinstance(module, torch.nn.Linear) :\n",
    "                parameters_to_prune.append((module,'weight'))\n",
    "        prune.global_unstructured(parameters_to_prune, pruning_method=prune.L1Unstructured, amount=0.2)\n",
    "        loaded_cpt=torch.load(filename)\n",
    "        model.load_state_dict(loaded_cpt)\n",
    "        evaluation(model, testloader, criterion)\n",
    "        \n",
    "    flops, _ = profile(model, (1,3,32,32))\n",
    "    flops = flops.item()\n",
    "    \n",
    "    params = 0\n",
    "    if(quantization):\n",
    "        for name, para in model.named_parameters():\n",
    "            if \"conv\" in name and name.startswith(\"conv\") == False:\n",
    "                params+= para.nonzero().size(0)/8\n",
    "            else:\n",
    "                params+= para.nonzero().size(0)/2\n",
    "    else:\n",
    "        for name, para in model.named_parameters():\n",
    "            params+= para.nonzero().size(0)/2\n",
    "    return flops/ref_flops , params/ref_params\n",
    "\n",
    "        \n",
    "\n",
    "def main():\n",
    "\n",
    "    ref_params = 5586981\n",
    "    ref_flops  = 834362880\n",
    "\n",
    "    import torch.nn.utils.prune as prune\n",
    "    model = densenet_cifar()\n",
    "    \n",
    "    model.to(device=device)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    evaluation(model, testloader, criterion)\n",
    "    \n",
    "    parameters_to_prune=[]\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, torch.nn.Conv2d) or isinstance(module, torch.nn.Linear) :\n",
    "            parameters_to_prune.append((module,'weight'))\n",
    "    prune.global_unstructured(parameters_to_prune, pruning_method=prune.L1Unstructured, amount=0.2)\n",
    "    loaded_cpt=torch.load('densenet_cifar_10_pruning_globally_0.06.pt')\n",
    "    model.load_state_dict(loaded_cpt)\n",
    "    \n",
    "    \n",
    "\n",
    "    evaluation(model, testloader, criterion)\n",
    "\n",
    "    \n",
    "    from torchvision import models\n",
    "\n",
    "\n",
    "    model.to(device=device)\n",
    "\n",
    "    \n",
    "    evaluation(model,testloader, criterion)\n",
    "    \n",
    "    flops, params = profile(model, (1,3,32,32))\n",
    "    flops, params = flops.item(), params.item()\n",
    "    \n",
    "    params = 0\n",
    "    for name, para in model.named_parameters():\n",
    "        if \"conv\" in name:\n",
    "            params+= para.nonzero().size(0)/8\n",
    "        else:\n",
    "            params+= para.nonzero().size(0)/2\n",
    "    \n",
    "    print(sum(p.numel() for p in model.parameters()))\n",
    "    \n",
    "    score_flops = flops / ref_flops\n",
    "    score_params = params / ref_params\n",
    "    score = score_flops + score_params\n",
    "    print(\"Flops: {}, Params: {}\".format(flops,params))\n",
    "    print(\"Score flops: {} Score Params: {}\".format(score_flops,score_params))\n",
    "    print(\"Final score: {}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d: S_c=3, F_in=3, F_out=24, P=1024, params=0, operations=721920\n",
      "Batch norm: F_in=24 P=1024, params=0, operations=73728\n",
      "Conv2d: S_c=1, F_in=24, F_out=48, P=1024, params=0, operations=1277952\n",
      "Batch norm: F_in=48 P=1024, params=0, operations=147456\n",
      "Conv2d: S_c=3, F_in=48, F_out=12, P=1024, params=0, operations=5959680\n",
      "Batch norm: F_in=36 P=1024, params=0, operations=110592\n",
      "Conv2d: S_c=1, F_in=36, F_out=48, P=1024, params=0, operations=1941504\n",
      "Batch norm: F_in=48 P=1024, params=0, operations=147456\n",
      "Conv2d: S_c=3, F_in=48, F_out=12, P=1024, params=0, operations=5959680\n",
      "Batch norm: F_in=48 P=1024, params=0, operations=147456\n",
      "Conv2d: S_c=1, F_in=48, F_out=48, P=1024, params=0, operations=2605056\n",
      "Batch norm: F_in=48 P=1024, params=0, operations=147456\n",
      "Conv2d: S_c=3, F_in=48, F_out=12, P=1024, params=0, operations=5959680\n",
      "Batch norm: F_in=60 P=1024, params=0, operations=184320\n",
      "Conv2d: S_c=1, F_in=60, F_out=48, P=1024, params=0, operations=3268608\n",
      "Batch norm: F_in=48 P=1024, params=0, operations=147456\n",
      "Conv2d: S_c=3, F_in=48, F_out=12, P=1024, params=0, operations=5959680\n",
      "Batch norm: F_in=72 P=1024, params=0, operations=221184\n",
      "Conv2d: S_c=1, F_in=72, F_out=48, P=1024, params=0, operations=3932160\n",
      "Batch norm: F_in=48 P=1024, params=0, operations=147456\n",
      "Conv2d: S_c=3, F_in=48, F_out=12, P=1024, params=0, operations=5959680\n",
      "Batch norm: F_in=84 P=1024, params=0, operations=258048\n",
      "Conv2d: S_c=1, F_in=84, F_out=48, P=1024, params=0, operations=4595712\n",
      "Batch norm: F_in=48 P=1024, params=0, operations=147456\n",
      "Conv2d: S_c=3, F_in=48, F_out=12, P=1024, params=0, operations=5959680\n",
      "Batch norm: F_in=96 P=1024, params=0, operations=294912\n",
      "Conv2d: S_c=1, F_in=96, F_out=48, P=1024, params=0, operations=5259264\n",
      "Batch norm: F_in=48 P=256, params=0, operations=36864\n",
      "Conv2d: S_c=1, F_in=48, F_out=48, P=256, params=0, operations=651264\n",
      "Batch norm: F_in=48 P=256, params=0, operations=36864\n",
      "Conv2d: S_c=3, F_in=48, F_out=12, P=256, params=0, operations=1489920\n",
      "Batch norm: F_in=60 P=256, params=0, operations=46080\n",
      "Conv2d: S_c=1, F_in=60, F_out=48, P=256, params=0, operations=817152\n",
      "Batch norm: F_in=48 P=256, params=0, operations=36864\n",
      "Conv2d: S_c=3, F_in=48, F_out=12, P=256, params=0, operations=1489920\n",
      "Batch norm: F_in=72 P=256, params=0, operations=55296\n",
      "Conv2d: S_c=1, F_in=72, F_out=48, P=256, params=0, operations=983040\n",
      "Batch norm: F_in=48 P=256, params=0, operations=36864\n",
      "Conv2d: S_c=3, F_in=48, F_out=12, P=256, params=0, operations=1489920\n",
      "Batch norm: F_in=84 P=256, params=0, operations=64512\n",
      "Conv2d: S_c=1, F_in=84, F_out=48, P=256, params=0, operations=1148928\n",
      "Batch norm: F_in=48 P=256, params=0, operations=36864\n",
      "Conv2d: S_c=3, F_in=48, F_out=12, P=256, params=0, operations=1489920\n",
      "Batch norm: F_in=96 P=256, params=0, operations=73728\n",
      "Conv2d: S_c=1, F_in=96, F_out=48, P=256, params=0, operations=1314816\n",
      "Batch norm: F_in=48 P=256, params=0, operations=36864\n",
      "Conv2d: S_c=3, F_in=48, F_out=12, P=256, params=0, operations=1489920\n",
      "Batch norm: F_in=108 P=256, params=0, operations=82944\n",
      "Conv2d: S_c=1, F_in=108, F_out=48, P=256, params=0, operations=1480704\n",
      "Batch norm: F_in=48 P=256, params=0, operations=36864\n",
      "Conv2d: S_c=3, F_in=48, F_out=12, P=256, params=0, operations=1489920\n",
      "Batch norm: F_in=120 P=256, params=0, operations=92160\n",
      "Conv2d: S_c=1, F_in=120, F_out=48, P=256, params=0, operations=1646592\n",
      "Batch norm: F_in=48 P=256, params=0, operations=36864\n",
      "Conv2d: S_c=3, F_in=48, F_out=12, P=256, params=0, operations=1489920\n",
      "Batch norm: F_in=132 P=256, params=0, operations=101376\n",
      "Conv2d: S_c=1, F_in=132, F_out=48, P=256, params=0, operations=1812480\n",
      "Batch norm: F_in=48 P=256, params=0, operations=36864\n",
      "Conv2d: S_c=3, F_in=48, F_out=12, P=256, params=0, operations=1489920\n",
      "Batch norm: F_in=144 P=256, params=0, operations=110592\n",
      "Conv2d: S_c=1, F_in=144, F_out=48, P=256, params=0, operations=1978368\n",
      "Batch norm: F_in=48 P=256, params=0, operations=36864\n",
      "Conv2d: S_c=3, F_in=48, F_out=12, P=256, params=0, operations=1489920\n",
      "Batch norm: F_in=156 P=256, params=0, operations=119808\n",
      "Conv2d: S_c=1, F_in=156, F_out=48, P=256, params=0, operations=2144256\n",
      "Batch norm: F_in=48 P=256, params=0, operations=36864\n",
      "Conv2d: S_c=3, F_in=48, F_out=12, P=256, params=0, operations=1489920\n",
      "Batch norm: F_in=168 P=256, params=0, operations=129024\n",
      "Conv2d: S_c=1, F_in=168, F_out=48, P=256, params=0, operations=2310144\n",
      "Batch norm: F_in=48 P=256, params=0, operations=36864\n",
      "Conv2d: S_c=3, F_in=48, F_out=12, P=256, params=0, operations=1489920\n",
      "Batch norm: F_in=180 P=256, params=0, operations=138240\n",
      "Conv2d: S_c=1, F_in=180, F_out=48, P=256, params=0, operations=2476032\n",
      "Batch norm: F_in=48 P=256, params=0, operations=36864\n",
      "Conv2d: S_c=3, F_in=48, F_out=12, P=256, params=0, operations=1489920\n",
      "Batch norm: F_in=192 P=256, params=0, operations=147456\n",
      "Conv2d: S_c=1, F_in=192, F_out=96, P=256, params=0, operations=5283840\n",
      "Batch norm: F_in=96 P=64, params=0, operations=18432\n",
      "Conv2d: S_c=1, F_in=96, F_out=48, P=64, params=0, operations=328704\n",
      "Batch norm: F_in=48 P=64, params=0, operations=9216\n",
      "Conv2d: S_c=3, F_in=48, F_out=12, P=64, params=0, operations=372480\n",
      "Batch norm: F_in=108 P=64, params=0, operations=20736\n",
      "Conv2d: S_c=1, F_in=108, F_out=48, P=64, params=0, operations=370176\n",
      "Batch norm: F_in=48 P=64, params=0, operations=9216\n",
      "Conv2d: S_c=3, F_in=48, F_out=12, P=64, params=0, operations=372480\n",
      "Batch norm: F_in=120 P=64, params=0, operations=23040\n",
      "Conv2d: S_c=1, F_in=120, F_out=48, P=64, params=0, operations=411648\n",
      "Batch norm: F_in=48 P=64, params=0, operations=9216\n",
      "Conv2d: S_c=3, F_in=48, F_out=12, P=64, params=0, operations=372480\n",
      "Batch norm: F_in=132 P=64, params=0, operations=25344\n",
      "Conv2d: S_c=1, F_in=132, F_out=48, P=64, params=0, operations=453120\n",
      "Batch norm: F_in=48 P=64, params=0, operations=9216\n",
      "Conv2d: S_c=3, F_in=48, F_out=12, P=64, params=0, operations=372480\n",
      "Batch norm: F_in=144 P=64, params=0, operations=27648\n",
      "Conv2d: S_c=1, F_in=144, F_out=48, P=64, params=0, operations=494592\n",
      "Batch norm: F_in=48 P=64, params=0, operations=9216\n",
      "Conv2d: S_c=3, F_in=48, F_out=12, P=64, params=0, operations=372480\n",
      "Batch norm: F_in=156 P=64, params=0, operations=29952\n",
      "Conv2d: S_c=1, F_in=156, F_out=48, P=64, params=0, operations=536064\n",
      "Batch norm: F_in=48 P=64, params=0, operations=9216\n",
      "Conv2d: S_c=3, F_in=48, F_out=12, P=64, params=0, operations=372480\n",
      "Batch norm: F_in=168 P=64, params=0, operations=32256\n",
      "Conv2d: S_c=1, F_in=168, F_out=48, P=64, params=0, operations=577536\n",
      "Batch norm: F_in=48 P=64, params=0, operations=9216\n",
      "Conv2d: S_c=3, F_in=48, F_out=12, P=64, params=0, operations=372480\n",
      "Batch norm: F_in=180 P=64, params=0, operations=34560\n",
      "Conv2d: S_c=1, F_in=180, F_out=48, P=64, params=0, operations=619008\n",
      "Batch norm: F_in=48 P=64, params=0, operations=9216\n",
      "Conv2d: S_c=3, F_in=48, F_out=12, P=64, params=0, operations=372480\n",
      "Batch norm: F_in=192 P=64, params=0, operations=36864\n",
      "Conv2d: S_c=1, F_in=192, F_out=48, P=64, params=0, operations=660480\n",
      "Batch norm: F_in=48 P=64, params=0, operations=9216\n",
      "Conv2d: S_c=3, F_in=48, F_out=12, P=64, params=0, operations=372480\n",
      "Batch norm: F_in=204 P=64, params=0, operations=39168\n",
      "Conv2d: S_c=1, F_in=204, F_out=48, P=64, params=0, operations=701952\n",
      "Batch norm: F_in=48 P=64, params=0, operations=9216\n",
      "Conv2d: S_c=3, F_in=48, F_out=12, P=64, params=0, operations=372480\n",
      "Batch norm: F_in=216 P=64, params=0, operations=41472\n",
      "Conv2d: S_c=1, F_in=216, F_out=48, P=64, params=0, operations=743424\n",
      "Batch norm: F_in=48 P=64, params=0, operations=9216\n",
      "Conv2d: S_c=3, F_in=48, F_out=12, P=64, params=0, operations=372480\n",
      "Batch norm: F_in=228 P=64, params=0, operations=43776\n",
      "Conv2d: S_c=1, F_in=228, F_out=48, P=64, params=0, operations=784896\n",
      "Batch norm: F_in=48 P=64, params=0, operations=9216\n",
      "Conv2d: S_c=3, F_in=48, F_out=12, P=64, params=0, operations=372480\n",
      "Batch norm: F_in=240 P=64, params=0, operations=46080\n",
      "Conv2d: S_c=1, F_in=240, F_out=48, P=64, params=0, operations=826368\n",
      "Batch norm: F_in=48 P=64, params=0, operations=9216\n",
      "Conv2d: S_c=3, F_in=48, F_out=12, P=64, params=0, operations=372480\n",
      "Batch norm: F_in=252 P=64, params=0, operations=48384\n",
      "Conv2d: S_c=1, F_in=252, F_out=48, P=64, params=0, operations=867840\n",
      "Batch norm: F_in=48 P=64, params=0, operations=9216\n",
      "Conv2d: S_c=3, F_in=48, F_out=12, P=64, params=0, operations=372480\n",
      "Batch norm: F_in=264 P=64, params=0, operations=50688\n",
      "Conv2d: S_c=1, F_in=264, F_out=48, P=64, params=0, operations=909312\n",
      "Batch norm: F_in=48 P=64, params=0, operations=9216\n",
      "Conv2d: S_c=3, F_in=48, F_out=12, P=64, params=0, operations=372480\n",
      "Batch norm: F_in=276 P=64, params=0, operations=52992\n",
      "Conv2d: S_c=1, F_in=276, F_out=48, P=64, params=0, operations=950784\n",
      "Batch norm: F_in=48 P=64, params=0, operations=9216\n",
      "Conv2d: S_c=3, F_in=48, F_out=12, P=64, params=0, operations=372480\n",
      "Batch norm: F_in=288 P=64, params=0, operations=55296\n",
      "Conv2d: S_c=1, F_in=288, F_out=48, P=64, params=0, operations=992256\n",
      "Batch norm: F_in=48 P=64, params=0, operations=9216\n",
      "Conv2d: S_c=3, F_in=48, F_out=12, P=64, params=0, operations=372480\n",
      "Batch norm: F_in=300 P=64, params=0, operations=57600\n",
      "Conv2d: S_c=1, F_in=300, F_out=48, P=64, params=0, operations=1033728\n",
      "Batch norm: F_in=48 P=64, params=0, operations=9216\n",
      "Conv2d: S_c=3, F_in=48, F_out=12, P=64, params=0, operations=372480\n",
      "Batch norm: F_in=312 P=64, params=0, operations=59904\n",
      "Conv2d: S_c=1, F_in=312, F_out=48, P=64, params=0, operations=1075200\n",
      "Batch norm: F_in=48 P=64, params=0, operations=9216\n",
      "Conv2d: S_c=3, F_in=48, F_out=12, P=64, params=0, operations=372480\n",
      "Batch norm: F_in=324 P=64, params=0, operations=62208\n",
      "Conv2d: S_c=1, F_in=324, F_out=48, P=64, params=0, operations=1116672\n",
      "Batch norm: F_in=48 P=64, params=0, operations=9216\n",
      "Conv2d: S_c=3, F_in=48, F_out=12, P=64, params=0, operations=372480\n",
      "Batch norm: F_in=336 P=64, params=0, operations=64512\n",
      "Conv2d: S_c=1, F_in=336, F_out=48, P=64, params=0, operations=1158144\n",
      "Batch norm: F_in=48 P=64, params=0, operations=9216\n",
      "Conv2d: S_c=3, F_in=48, F_out=12, P=64, params=0, operations=372480\n",
      "Batch norm: F_in=348 P=64, params=0, operations=66816\n",
      "Conv2d: S_c=1, F_in=348, F_out=48, P=64, params=0, operations=1199616\n",
      "Batch norm: F_in=48 P=64, params=0, operations=9216\n",
      "Conv2d: S_c=3, F_in=48, F_out=12, P=64, params=0, operations=372480\n",
      "Batch norm: F_in=360 P=64, params=0, operations=69120\n",
      "Conv2d: S_c=1, F_in=360, F_out=48, P=64, params=0, operations=1241088\n",
      "Batch norm: F_in=48 P=64, params=0, operations=9216\n",
      "Conv2d: S_c=3, F_in=48, F_out=12, P=64, params=0, operations=372480\n",
      "Batch norm: F_in=372 P=64, params=0, operations=71424\n",
      "Conv2d: S_c=1, F_in=372, F_out=48, P=64, params=0, operations=1282560\n",
      "Batch norm: F_in=48 P=64, params=0, operations=9216\n",
      "Conv2d: S_c=3, F_in=48, F_out=12, P=64, params=0, operations=372480\n",
      "Batch norm: F_in=384 P=64, params=0, operations=73728\n",
      "Conv2d: S_c=1, F_in=384, F_out=192, P=64, params=0, operations=5296128\n",
      "Batch norm: F_in=192 P=16, params=0, operations=9216\n",
      "Conv2d: S_c=1, F_in=192, F_out=48, P=16, params=0, operations=165120\n",
      "Batch norm: F_in=48 P=16, params=0, operations=2304\n",
      "Conv2d: S_c=3, F_in=48, F_out=12, P=16, params=0, operations=93120\n",
      "Batch norm: F_in=204 P=16, params=0, operations=9792\n",
      "Conv2d: S_c=1, F_in=204, F_out=48, P=16, params=0, operations=175488\n",
      "Batch norm: F_in=48 P=16, params=0, operations=2304\n",
      "Conv2d: S_c=3, F_in=48, F_out=12, P=16, params=0, operations=93120\n",
      "Batch norm: F_in=216 P=16, params=0, operations=10368\n",
      "Conv2d: S_c=1, F_in=216, F_out=48, P=16, params=0, operations=185856\n",
      "Batch norm: F_in=48 P=16, params=0, operations=2304\n",
      "Conv2d: S_c=3, F_in=48, F_out=12, P=16, params=0, operations=93120\n",
      "Batch norm: F_in=228 P=16, params=0, operations=10944\n",
      "Conv2d: S_c=1, F_in=228, F_out=48, P=16, params=0, operations=196224\n",
      "Batch norm: F_in=48 P=16, params=0, operations=2304\n",
      "Conv2d: S_c=3, F_in=48, F_out=12, P=16, params=0, operations=93120\n",
      "Batch norm: F_in=240 P=16, params=0, operations=11520\n",
      "Conv2d: S_c=1, F_in=240, F_out=48, P=16, params=0, operations=206592\n",
      "Batch norm: F_in=48 P=16, params=0, operations=2304\n",
      "Conv2d: S_c=3, F_in=48, F_out=12, P=16, params=0, operations=93120\n",
      "Batch norm: F_in=252 P=16, params=0, operations=12096\n",
      "Conv2d: S_c=1, F_in=252, F_out=48, P=16, params=0, operations=216960\n",
      "Batch norm: F_in=48 P=16, params=0, operations=2304\n",
      "Conv2d: S_c=3, F_in=48, F_out=12, P=16, params=0, operations=93120\n",
      "Batch norm: F_in=264 P=16, params=0, operations=12672\n",
      "Conv2d: S_c=1, F_in=264, F_out=48, P=16, params=0, operations=227328\n",
      "Batch norm: F_in=48 P=16, params=0, operations=2304\n",
      "Conv2d: S_c=3, F_in=48, F_out=12, P=16, params=0, operations=93120\n",
      "Batch norm: F_in=276 P=16, params=0, operations=13248\n",
      "Conv2d: S_c=1, F_in=276, F_out=48, P=16, params=0, operations=237696\n",
      "Batch norm: F_in=48 P=16, params=0, operations=2304\n",
      "Conv2d: S_c=3, F_in=48, F_out=12, P=16, params=0, operations=93120\n",
      "Batch norm: F_in=288 P=16, params=0, operations=13824\n",
      "Conv2d: S_c=1, F_in=288, F_out=48, P=16, params=0, operations=248064\n",
      "Batch norm: F_in=48 P=16, params=0, operations=2304\n",
      "Conv2d: S_c=3, F_in=48, F_out=12, P=16, params=0, operations=93120\n",
      "Batch norm: F_in=300 P=16, params=0, operations=14400\n",
      "Conv2d: S_c=1, F_in=300, F_out=48, P=16, params=0, operations=258432\n",
      "Batch norm: F_in=48 P=16, params=0, operations=2304\n",
      "Conv2d: S_c=3, F_in=48, F_out=12, P=16, params=0, operations=93120\n",
      "Batch norm: F_in=312 P=16, params=0, operations=14976\n",
      "Conv2d: S_c=1, F_in=312, F_out=48, P=16, params=0, operations=268800\n",
      "Batch norm: F_in=48 P=16, params=0, operations=2304\n",
      "Conv2d: S_c=3, F_in=48, F_out=12, P=16, params=0, operations=93120\n",
      "Batch norm: F_in=324 P=16, params=0, operations=15552\n",
      "Conv2d: S_c=1, F_in=324, F_out=48, P=16, params=0, operations=279168\n",
      "Batch norm: F_in=48 P=16, params=0, operations=2304\n",
      "Conv2d: S_c=3, F_in=48, F_out=12, P=16, params=0, operations=93120\n",
      "Batch norm: F_in=336 P=16, params=0, operations=16128\n",
      "Conv2d: S_c=1, F_in=336, F_out=48, P=16, params=0, operations=289536\n",
      "Batch norm: F_in=48 P=16, params=0, operations=2304\n",
      "Conv2d: S_c=3, F_in=48, F_out=12, P=16, params=0, operations=93120\n",
      "Batch norm: F_in=348 P=16, params=0, operations=16704\n",
      "Conv2d: S_c=1, F_in=348, F_out=48, P=16, params=0, operations=299904\n",
      "Batch norm: F_in=48 P=16, params=0, operations=2304\n",
      "Conv2d: S_c=3, F_in=48, F_out=12, P=16, params=0, operations=93120\n",
      "Batch norm: F_in=360 P=16, params=0, operations=17280\n",
      "Conv2d: S_c=1, F_in=360, F_out=48, P=16, params=0, operations=310272\n",
      "Batch norm: F_in=48 P=16, params=0, operations=2304\n",
      "Conv2d: S_c=3, F_in=48, F_out=12, P=16, params=0, operations=93120\n",
      "Batch norm: F_in=372 P=16, params=0, operations=17856\n",
      "Conv2d: S_c=1, F_in=372, F_out=48, P=16, params=0, operations=320640\n",
      "Batch norm: F_in=48 P=16, params=0, operations=2304\n",
      "Conv2d: S_c=3, F_in=48, F_out=12, P=16, params=0, operations=93120\n",
      "Batch norm: F_in=384 P=16, params=0, operations=18432\n",
      "Linear: F_in=384, F_out=10, params=0, operations=5750\n",
      "(0.17462420188203961, 0.023389913085439168)\n"
     ]
    }
   ],
   "source": [
    "model = densenet_cifar()\n",
    "print(score(model,\"\",quantization = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 2.303173\n",
      "\n",
      "test accuracy of plane:  0% ( 0/1000)\n",
      "test accuracy of car:  0% ( 0/1000)\n",
      "test accuracy of bird:  0% ( 0/1000)\n",
      "test accuracy of cat:  0% ( 0/1000)\n",
      "test accuracy of deer:  0% ( 0/1000)\n",
      "test accuracy of dog:  0% ( 0/1000)\n",
      "test accuracy of frog:  0% ( 0/1000)\n",
      "test accuracy of horse:  0% ( 0/1000)\n",
      "test accuracy of ship:  0% ( 0/1000)\n",
      "test accuracy of truck: 100% (1000/1000)\n",
      "\n",
      "test accuracy (overall): 10.00% (1000/10000)\n",
      "test Loss: 0.292871\n",
      "\n",
      "test accuracy of plane: 92% (923/1000)\n",
      "test accuracy of car: 96% (967/1000)\n",
      "test accuracy of bird: 89% (892/1000)\n",
      "test accuracy of cat: 83% (830/1000)\n",
      "test accuracy of deer: 93% (933/1000)\n",
      "test accuracy of dog: 86% (867/1000)\n",
      "test accuracy of frog: 95% (951/1000)\n",
      "test accuracy of horse: 93% (938/1000)\n",
      "test accuracy of ship: 95% (953/1000)\n",
      "test accuracy of truck: 94% (945/1000)\n",
      "\n",
      "test accuracy (overall): 91.99% (9199/10000)\n",
      "test Loss: 0.292871\n",
      "\n",
      "test accuracy of plane: 92% (923/1000)\n",
      "test accuracy of car: 96% (967/1000)\n",
      "test accuracy of bird: 89% (892/1000)\n",
      "test accuracy of cat: 83% (830/1000)\n",
      "test accuracy of deer: 93% (933/1000)\n",
      "test accuracy of dog: 86% (867/1000)\n",
      "test accuracy of frog: 95% (951/1000)\n",
      "test accuracy of horse: 93% (938/1000)\n",
      "test accuracy of ship: 95% (953/1000)\n",
      "test accuracy of truck: 94% (945/1000)\n",
      "\n",
      "test accuracy (overall): 91.99% (9199/10000)\n",
      "Conv2d: S_c=3, F_in=3, F_out=16, P=1024, params=0, operations=481280\n",
      "Batch norm: F_in=16 P=1024, params=0, operations=49152\n",
      "Conv2d: S_c=1, F_in=16, F_out=32, P=1024, params=0, operations=557056\n",
      "Batch norm: F_in=32 P=1024, params=0, operations=98304\n",
      "Conv2d: S_c=3, F_in=32, F_out=8, P=1024, params=0, operations=2646016\n",
      "Batch norm: F_in=24 P=1024, params=0, operations=73728\n",
      "Conv2d: S_c=1, F_in=24, F_out=32, P=1024, params=0, operations=851968\n",
      "Batch norm: F_in=32 P=1024, params=0, operations=98304\n",
      "Conv2d: S_c=3, F_in=32, F_out=8, P=1024, params=0, operations=2646016\n",
      "Batch norm: F_in=32 P=1024, params=0, operations=98304\n",
      "Conv2d: S_c=1, F_in=32, F_out=32, P=1024, params=0, operations=1146880\n",
      "Batch norm: F_in=32 P=1024, params=0, operations=98304\n",
      "Conv2d: S_c=3, F_in=32, F_out=8, P=1024, params=0, operations=2646016\n",
      "Batch norm: F_in=40 P=1024, params=0, operations=122880\n",
      "Conv2d: S_c=1, F_in=40, F_out=32, P=1024, params=0, operations=1441792\n",
      "Batch norm: F_in=32 P=1024, params=0, operations=98304\n",
      "Conv2d: S_c=3, F_in=32, F_out=8, P=1024, params=0, operations=2646016\n",
      "Batch norm: F_in=48 P=1024, params=0, operations=147456\n",
      "Conv2d: S_c=1, F_in=48, F_out=32, P=1024, params=0, operations=1736704\n",
      "Batch norm: F_in=32 P=1024, params=0, operations=98304\n",
      "Conv2d: S_c=3, F_in=32, F_out=8, P=1024, params=0, operations=2646016\n",
      "Batch norm: F_in=56 P=1024, params=0, operations=172032\n",
      "Conv2d: S_c=1, F_in=56, F_out=32, P=1024, params=0, operations=2031616\n",
      "Batch norm: F_in=32 P=1024, params=0, operations=98304\n",
      "Conv2d: S_c=3, F_in=32, F_out=8, P=1024, params=0, operations=2646016\n",
      "Batch norm: F_in=64 P=1024, params=0, operations=196608\n",
      "Conv2d: S_c=1, F_in=64, F_out=32, P=1024, params=0, operations=2326528\n",
      "Batch norm: F_in=32 P=256, params=0, operations=24576\n",
      "Conv2d: S_c=1, F_in=32, F_out=32, P=256, params=0, operations=286720\n",
      "Batch norm: F_in=32 P=256, params=0, operations=24576\n",
      "Conv2d: S_c=3, F_in=32, F_out=8, P=256, params=0, operations=661504\n",
      "Batch norm: F_in=40 P=256, params=0, operations=30720\n",
      "Conv2d: S_c=1, F_in=40, F_out=32, P=256, params=0, operations=360448\n",
      "Batch norm: F_in=32 P=256, params=0, operations=24576\n",
      "Conv2d: S_c=3, F_in=32, F_out=8, P=256, params=0, operations=661504\n",
      "Batch norm: F_in=48 P=256, params=0, operations=36864\n",
      "Conv2d: S_c=1, F_in=48, F_out=32, P=256, params=0, operations=434176\n",
      "Batch norm: F_in=32 P=256, params=0, operations=24576\n",
      "Conv2d: S_c=3, F_in=32, F_out=8, P=256, params=0, operations=661504\n",
      "Batch norm: F_in=56 P=256, params=0, operations=43008\n",
      "Conv2d: S_c=1, F_in=56, F_out=32, P=256, params=0, operations=507904\n",
      "Batch norm: F_in=32 P=256, params=0, operations=24576\n",
      "Conv2d: S_c=3, F_in=32, F_out=8, P=256, params=0, operations=661504\n",
      "Batch norm: F_in=64 P=256, params=0, operations=49152\n",
      "Conv2d: S_c=1, F_in=64, F_out=32, P=256, params=0, operations=581632\n",
      "Batch norm: F_in=32 P=256, params=0, operations=24576\n",
      "Conv2d: S_c=3, F_in=32, F_out=8, P=256, params=0, operations=661504\n",
      "Batch norm: F_in=72 P=256, params=0, operations=55296\n",
      "Conv2d: S_c=1, F_in=72, F_out=32, P=256, params=0, operations=655360\n",
      "Batch norm: F_in=32 P=256, params=0, operations=24576\n",
      "Conv2d: S_c=3, F_in=32, F_out=8, P=256, params=0, operations=661504\n",
      "Batch norm: F_in=80 P=256, params=0, operations=61440\n",
      "Conv2d: S_c=1, F_in=80, F_out=32, P=256, params=0, operations=729088\n",
      "Batch norm: F_in=32 P=256, params=0, operations=24576\n",
      "Conv2d: S_c=3, F_in=32, F_out=8, P=256, params=0, operations=661504\n",
      "Batch norm: F_in=88 P=256, params=0, operations=67584\n",
      "Conv2d: S_c=1, F_in=88, F_out=32, P=256, params=0, operations=802816\n",
      "Batch norm: F_in=32 P=256, params=0, operations=24576\n",
      "Conv2d: S_c=3, F_in=32, F_out=8, P=256, params=0, operations=661504\n",
      "Batch norm: F_in=96 P=256, params=0, operations=73728\n",
      "Conv2d: S_c=1, F_in=96, F_out=32, P=256, params=0, operations=876544\n",
      "Batch norm: F_in=32 P=256, params=0, operations=24576\n",
      "Conv2d: S_c=3, F_in=32, F_out=8, P=256, params=0, operations=661504\n",
      "Batch norm: F_in=104 P=256, params=0, operations=79872\n",
      "Conv2d: S_c=1, F_in=104, F_out=32, P=256, params=0, operations=950272\n",
      "Batch norm: F_in=32 P=256, params=0, operations=24576\n",
      "Conv2d: S_c=3, F_in=32, F_out=8, P=256, params=0, operations=661504\n",
      "Batch norm: F_in=112 P=256, params=0, operations=86016\n",
      "Conv2d: S_c=1, F_in=112, F_out=56, P=256, params=0, operations=1792000\n",
      "Batch norm: F_in=56 P=64, params=0, operations=10752\n",
      "Conv2d: S_c=1, F_in=56, F_out=32, P=64, params=0, operations=126976\n",
      "Batch norm: F_in=32 P=64, params=0, operations=6144\n",
      "Conv2d: S_c=3, F_in=32, F_out=8, P=64, params=0, operations=165376\n",
      "Batch norm: F_in=64 P=64, params=0, operations=12288\n",
      "Conv2d: S_c=1, F_in=64, F_out=32, P=64, params=0, operations=145408\n",
      "Batch norm: F_in=32 P=64, params=0, operations=6144\n",
      "Conv2d: S_c=3, F_in=32, F_out=8, P=64, params=0, operations=165376\n",
      "Batch norm: F_in=72 P=64, params=0, operations=13824\n",
      "Conv2d: S_c=1, F_in=72, F_out=32, P=64, params=0, operations=163840\n",
      "Batch norm: F_in=32 P=64, params=0, operations=6144\n",
      "Conv2d: S_c=3, F_in=32, F_out=8, P=64, params=0, operations=165376\n",
      "Batch norm: F_in=80 P=64, params=0, operations=15360\n",
      "Conv2d: S_c=1, F_in=80, F_out=32, P=64, params=0, operations=182272\n",
      "Batch norm: F_in=32 P=64, params=0, operations=6144\n",
      "Conv2d: S_c=3, F_in=32, F_out=8, P=64, params=0, operations=165376\n",
      "Batch norm: F_in=88 P=64, params=0, operations=16896\n",
      "Conv2d: S_c=1, F_in=88, F_out=32, P=64, params=0, operations=200704\n",
      "Batch norm: F_in=32 P=64, params=0, operations=6144\n",
      "Conv2d: S_c=3, F_in=32, F_out=8, P=64, params=0, operations=165376\n",
      "Batch norm: F_in=96 P=64, params=0, operations=18432\n",
      "Conv2d: S_c=1, F_in=96, F_out=32, P=64, params=0, operations=219136\n",
      "Batch norm: F_in=32 P=64, params=0, operations=6144\n",
      "Conv2d: S_c=3, F_in=32, F_out=8, P=64, params=0, operations=165376\n",
      "Batch norm: F_in=104 P=64, params=0, operations=19968\n",
      "Conv2d: S_c=1, F_in=104, F_out=32, P=64, params=0, operations=237568\n",
      "Batch norm: F_in=32 P=64, params=0, operations=6144\n",
      "Conv2d: S_c=3, F_in=32, F_out=8, P=64, params=0, operations=165376\n",
      "Batch norm: F_in=112 P=64, params=0, operations=21504\n",
      "Conv2d: S_c=1, F_in=112, F_out=32, P=64, params=0, operations=256000\n",
      "Batch norm: F_in=32 P=64, params=0, operations=6144\n",
      "Conv2d: S_c=3, F_in=32, F_out=8, P=64, params=0, operations=165376\n",
      "Batch norm: F_in=120 P=64, params=0, operations=23040\n",
      "Conv2d: S_c=1, F_in=120, F_out=32, P=64, params=0, operations=274432\n",
      "Batch norm: F_in=32 P=64, params=0, operations=6144\n",
      "Conv2d: S_c=3, F_in=32, F_out=8, P=64, params=0, operations=165376\n",
      "Batch norm: F_in=128 P=64, params=0, operations=24576\n",
      "Conv2d: S_c=1, F_in=128, F_out=32, P=64, params=0, operations=292864\n",
      "Batch norm: F_in=32 P=64, params=0, operations=6144\n",
      "Conv2d: S_c=3, F_in=32, F_out=8, P=64, params=0, operations=165376\n",
      "Batch norm: F_in=136 P=64, params=0, operations=26112\n",
      "Conv2d: S_c=1, F_in=136, F_out=32, P=64, params=0, operations=311296\n",
      "Batch norm: F_in=32 P=64, params=0, operations=6144\n",
      "Conv2d: S_c=3, F_in=32, F_out=8, P=64, params=0, operations=165376\n",
      "Batch norm: F_in=144 P=64, params=0, operations=27648\n",
      "Conv2d: S_c=1, F_in=144, F_out=32, P=64, params=0, operations=329728\n",
      "Batch norm: F_in=32 P=64, params=0, operations=6144\n",
      "Conv2d: S_c=3, F_in=32, F_out=8, P=64, params=0, operations=165376\n",
      "Batch norm: F_in=152 P=64, params=0, operations=29184\n",
      "Conv2d: S_c=1, F_in=152, F_out=32, P=64, params=0, operations=348160\n",
      "Batch norm: F_in=32 P=64, params=0, operations=6144\n",
      "Conv2d: S_c=3, F_in=32, F_out=8, P=64, params=0, operations=165376\n",
      "Batch norm: F_in=160 P=64, params=0, operations=30720\n",
      "Conv2d: S_c=1, F_in=160, F_out=32, P=64, params=0, operations=366592\n",
      "Batch norm: F_in=32 P=64, params=0, operations=6144\n",
      "Conv2d: S_c=3, F_in=32, F_out=8, P=64, params=0, operations=165376\n",
      "Batch norm: F_in=168 P=64, params=0, operations=32256\n",
      "Conv2d: S_c=1, F_in=168, F_out=32, P=64, params=0, operations=385024\n",
      "Batch norm: F_in=32 P=64, params=0, operations=6144\n",
      "Conv2d: S_c=3, F_in=32, F_out=8, P=64, params=0, operations=165376\n",
      "Batch norm: F_in=176 P=64, params=0, operations=33792\n",
      "Conv2d: S_c=1, F_in=176, F_out=32, P=64, params=0, operations=403456\n",
      "Batch norm: F_in=32 P=64, params=0, operations=6144\n",
      "Conv2d: S_c=3, F_in=32, F_out=8, P=64, params=0, operations=165376\n",
      "Batch norm: F_in=184 P=64, params=0, operations=35328\n",
      "Conv2d: S_c=1, F_in=184, F_out=32, P=64, params=0, operations=421888\n",
      "Batch norm: F_in=32 P=64, params=0, operations=6144\n",
      "Conv2d: S_c=3, F_in=32, F_out=8, P=64, params=0, operations=165376\n",
      "Batch norm: F_in=192 P=64, params=0, operations=36864\n",
      "Conv2d: S_c=1, F_in=192, F_out=32, P=64, params=0, operations=440320\n",
      "Batch norm: F_in=32 P=64, params=0, operations=6144\n",
      "Conv2d: S_c=3, F_in=32, F_out=8, P=64, params=0, operations=165376\n",
      "Batch norm: F_in=200 P=64, params=0, operations=38400\n",
      "Conv2d: S_c=1, F_in=200, F_out=32, P=64, params=0, operations=458752\n",
      "Batch norm: F_in=32 P=64, params=0, operations=6144\n",
      "Conv2d: S_c=3, F_in=32, F_out=8, P=64, params=0, operations=165376\n",
      "Batch norm: F_in=208 P=64, params=0, operations=39936\n",
      "Conv2d: S_c=1, F_in=208, F_out=32, P=64, params=0, operations=477184\n",
      "Batch norm: F_in=32 P=64, params=0, operations=6144\n",
      "Conv2d: S_c=3, F_in=32, F_out=8, P=64, params=0, operations=165376\n",
      "Batch norm: F_in=216 P=64, params=0, operations=41472\n",
      "Conv2d: S_c=1, F_in=216, F_out=108, P=64, params=0, operations=1672704\n",
      "Batch norm: F_in=108 P=16, params=0, operations=5184\n",
      "Conv2d: S_c=1, F_in=108, F_out=32, P=16, params=0, operations=61696\n",
      "Batch norm: F_in=32 P=16, params=0, operations=1536\n",
      "Conv2d: S_c=3, F_in=32, F_out=8, P=16, params=0, operations=41344\n",
      "Batch norm: F_in=116 P=16, params=0, operations=5568\n",
      "Conv2d: S_c=1, F_in=116, F_out=32, P=16, params=0, operations=66304\n",
      "Batch norm: F_in=32 P=16, params=0, operations=1536\n",
      "Conv2d: S_c=3, F_in=32, F_out=8, P=16, params=0, operations=41344\n",
      "Batch norm: F_in=124 P=16, params=0, operations=5952\n",
      "Conv2d: S_c=1, F_in=124, F_out=32, P=16, params=0, operations=70912\n",
      "Batch norm: F_in=32 P=16, params=0, operations=1536\n",
      "Conv2d: S_c=3, F_in=32, F_out=8, P=16, params=0, operations=41344\n",
      "Batch norm: F_in=132 P=16, params=0, operations=6336\n",
      "Conv2d: S_c=1, F_in=132, F_out=32, P=16, params=0, operations=75520\n",
      "Batch norm: F_in=32 P=16, params=0, operations=1536\n",
      "Conv2d: S_c=3, F_in=32, F_out=8, P=16, params=0, operations=41344\n",
      "Batch norm: F_in=140 P=16, params=0, operations=6720\n",
      "Conv2d: S_c=1, F_in=140, F_out=32, P=16, params=0, operations=80128\n",
      "Batch norm: F_in=32 P=16, params=0, operations=1536\n",
      "Conv2d: S_c=3, F_in=32, F_out=8, P=16, params=0, operations=41344\n",
      "Batch norm: F_in=148 P=16, params=0, operations=7104\n",
      "Conv2d: S_c=1, F_in=148, F_out=32, P=16, params=0, operations=84736\n",
      "Batch norm: F_in=32 P=16, params=0, operations=1536\n",
      "Conv2d: S_c=3, F_in=32, F_out=8, P=16, params=0, operations=41344\n",
      "Batch norm: F_in=156 P=16, params=0, operations=7488\n",
      "Conv2d: S_c=1, F_in=156, F_out=32, P=16, params=0, operations=89344\n",
      "Batch norm: F_in=32 P=16, params=0, operations=1536\n",
      "Conv2d: S_c=3, F_in=32, F_out=8, P=16, params=0, operations=41344\n",
      "Batch norm: F_in=164 P=16, params=0, operations=7872\n",
      "Conv2d: S_c=1, F_in=164, F_out=32, P=16, params=0, operations=93952\n",
      "Batch norm: F_in=32 P=16, params=0, operations=1536\n",
      "Conv2d: S_c=3, F_in=32, F_out=8, P=16, params=0, operations=41344\n",
      "Batch norm: F_in=172 P=16, params=0, operations=8256\n",
      "Conv2d: S_c=1, F_in=172, F_out=32, P=16, params=0, operations=98560\n",
      "Batch norm: F_in=32 P=16, params=0, operations=1536\n",
      "Conv2d: S_c=3, F_in=32, F_out=8, P=16, params=0, operations=41344\n",
      "Batch norm: F_in=180 P=16, params=0, operations=8640\n",
      "Conv2d: S_c=1, F_in=180, F_out=32, P=16, params=0, operations=103168\n",
      "Batch norm: F_in=32 P=16, params=0, operations=1536\n",
      "Conv2d: S_c=3, F_in=32, F_out=8, P=16, params=0, operations=41344\n",
      "Batch norm: F_in=188 P=16, params=0, operations=9024\n",
      "Conv2d: S_c=1, F_in=188, F_out=32, P=16, params=0, operations=107776\n",
      "Batch norm: F_in=32 P=16, params=0, operations=1536\n",
      "Conv2d: S_c=3, F_in=32, F_out=8, P=16, params=0, operations=41344\n",
      "Batch norm: F_in=196 P=16, params=0, operations=9408\n",
      "Conv2d: S_c=1, F_in=196, F_out=32, P=16, params=0, operations=112384\n",
      "Batch norm: F_in=32 P=16, params=0, operations=1536\n",
      "Conv2d: S_c=3, F_in=32, F_out=8, P=16, params=0, operations=41344\n",
      "Batch norm: F_in=204 P=16, params=0, operations=9792\n",
      "Linear: F_in=204, F_out=10, params=0, operations=3050\n",
      "331226\n",
      "Flops: 56698408.0, Params: 47791.0\n",
      "Score flops: 0.06795413525587332 Score Params: 0.008553993650595912\n",
      "Final score: 0.07650812890646923\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
