{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''DenseNet in PyTorch.'''\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    def __init__(self, in_planes, growth_rate):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.bn1 = nn.BatchNorm2d(in_planes)\n",
    "        self.conv1 = nn.Conv2d(in_planes, 4*growth_rate, kernel_size=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(4*growth_rate)\n",
    "        self.conv2 = nn.Conv2d(4*growth_rate, growth_rate, kernel_size=3, padding=1, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(F.relu(self.bn1(x)))\n",
    "        out = self.conv2(F.relu(self.bn2(out)))\n",
    "        out = torch.cat([out,x], 1)\n",
    "        return out\n",
    "\n",
    "class Bottleneck_Quant(nn.Module):\n",
    "    def __init__(self, in_planes, growth_rate):\n",
    "        super(Bottleneck_Quant, self).__init__()\n",
    "        self.bn1 = nn.BatchNorm2d(in_planes)\n",
    "        self.conv1 = QuantConv2d(in_planes, 4*growth_rate, kernel_size=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(4*growth_rate)\n",
    "        self.conv2 = QuantConv2d(4*growth_rate, growth_rate, kernel_size=3, padding=1, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(F.relu(self.bn1(x)))\n",
    "        out = self.conv2(F.relu(self.bn2(out)))\n",
    "        out = torch.cat([out,x], 1)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Transition(nn.Module):\n",
    "    def __init__(self, in_planes, out_planes):\n",
    "        super(Transition, self).__init__()\n",
    "        self.bn = nn.BatchNorm2d(in_planes)\n",
    "        self.conv = nn.Conv2d(in_planes, out_planes, kernel_size=1, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv(F.relu(self.bn(x)))\n",
    "        out = F.avg_pool2d(out, 2)\n",
    "        return out\n",
    "\n",
    "class Transition_Quant(nn.Module):\n",
    "    def __init__(self, in_planes, out_planes):\n",
    "        super(Transition_Quant, self).__init__()\n",
    "        self.bn = nn.BatchNorm2d(in_planes)\n",
    "        self.conv = QuantConv2d(in_planes, out_planes, kernel_size=1, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv(F.relu(self.bn(x)))\n",
    "        out = F.avg_pool2d(out, 2)\n",
    "        return out\n",
    "\n",
    "\n",
    "class DenseNet(nn.Module):\n",
    "    def __init__(self, block, nblocks, growth_rate=12, reduction=0.5, num_classes=10):\n",
    "        super(DenseNet, self).__init__()\n",
    "        self.growth_rate = growth_rate\n",
    "\n",
    "        num_planes = 2*growth_rate\n",
    "        self.conv1 = nn.Conv2d(3, num_planes, kernel_size=3, padding=1, bias=False)\n",
    "\n",
    "        self.dense1 = self._make_dense_layers(block, num_planes, nblocks[0])\n",
    "        num_planes += nblocks[0]*growth_rate\n",
    "        out_planes = int(math.floor(num_planes*reduction))\n",
    "        self.trans1 = Transition(num_planes, out_planes)\n",
    "        num_planes = out_planes\n",
    "\n",
    "        self.dense2 = self._make_dense_layers(block, num_planes, nblocks[1])\n",
    "        num_planes += nblocks[1]*growth_rate\n",
    "        out_planes = int(math.floor(num_planes*reduction))\n",
    "        self.trans2 = Transition(num_planes, out_planes)\n",
    "        num_planes = out_planes\n",
    "\n",
    "        self.dense3 = self._make_dense_layers(block, num_planes, nblocks[2])\n",
    "        num_planes += nblocks[2]*growth_rate\n",
    "        out_planes = int(math.floor(num_planes*reduction))\n",
    "        self.trans3 = Transition(num_planes, out_planes)\n",
    "        num_planes = out_planes\n",
    "\n",
    "        self.dense4 = self._make_dense_layers(block, num_planes, nblocks[3])\n",
    "        num_planes += nblocks[3]*growth_rate\n",
    "\n",
    "        self.bn = nn.BatchNorm2d(num_planes)\n",
    "        self.linear = nn.Linear(num_planes, num_classes)\n",
    "\n",
    "    def _make_dense_layers(self, block, in_planes, nblock):\n",
    "        layers = []\n",
    "        for i in range(nblock):\n",
    "            layers.append(block(in_planes, self.growth_rate))\n",
    "            in_planes += self.growth_rate\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.trans1(self.dense1(out))\n",
    "        out = self.trans2(self.dense2(out))\n",
    "        out = self.trans3(self.dense3(out))\n",
    "        out = self.dense4(out)\n",
    "        out = F.avg_pool2d(F.relu(self.bn(out)), 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "    def show_params(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, QuantConv2d):\n",
    "                m.show_params()\n",
    "\n",
    "class DenseNet_Quant(nn.Module):\n",
    "    def __init__(self, block, nblocks, growth_rate=12, reduction=0.5, num_classes=10):\n",
    "        super(DenseNet_Quant, self).__init__()\n",
    "        self.growth_rate = growth_rate\n",
    "\n",
    "        num_planes = 2*growth_rate\n",
    "        self.conv1 = nn.Conv2d(3, num_planes, kernel_size=3, padding=1, bias=False)\n",
    "\n",
    "        self.dense1 = self._make_dense_layers(block, num_planes, nblocks[0])\n",
    "        num_planes += nblocks[0]*growth_rate\n",
    "        out_planes = int(math.floor(num_planes*reduction))\n",
    "        self.trans1 = Transition_Quant(num_planes, out_planes)\n",
    "        num_planes = out_planes\n",
    "\n",
    "        self.dense2 = self._make_dense_layers(block, num_planes, nblocks[1])\n",
    "        num_planes += nblocks[1]*growth_rate\n",
    "        out_planes = int(math.floor(num_planes*reduction))\n",
    "        self.trans2 = Transition_Quant(num_planes, out_planes)\n",
    "        num_planes = out_planes\n",
    "\n",
    "        self.dense3 = self._make_dense_layers(block, num_planes, nblocks[2])\n",
    "        num_planes += nblocks[2]*growth_rate\n",
    "        out_planes = int(math.floor(num_planes*reduction))\n",
    "        self.trans3 = Transition_Quant(num_planes, out_planes)\n",
    "        num_planes = out_planes\n",
    "\n",
    "        self.dense4 = self._make_dense_layers(block, num_planes, nblocks[3])\n",
    "        num_planes += nblocks[3]*growth_rate\n",
    "\n",
    "        self.bn = nn.BatchNorm2d(num_planes)\n",
    "        self.linear = nn.Linear(num_planes, num_classes)\n",
    "\n",
    "    def _make_dense_layers(self, block, in_planes, nblock):\n",
    "        layers = []\n",
    "        for i in range(nblock):\n",
    "            layers.append(block(in_planes, self.growth_rate))\n",
    "            in_planes += self.growth_rate\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.trans1(self.dense1(out))\n",
    "        out = self.trans2(self.dense2(out))\n",
    "        out = self.trans3(self.dense3(out))\n",
    "        out = self.dense4(out)\n",
    "        out = F.avg_pool2d(F.relu(self.bn(out)), 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "    def show_params(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, QuantConv2d):\n",
    "                m.show_params()\n",
    "\n",
    "\n",
    "def DenseNet121():\n",
    "    return DenseNet(Bottleneck, [6,12,24,16], growth_rate=32)\n",
    "\n",
    "def DenseNet169():\n",
    "    return DenseNet(Bottleneck, [6,12,32,32], growth_rate=32)\n",
    "\n",
    "def DenseNet201():\n",
    "    return DenseNet(Bottleneck, [6,12,48,32], growth_rate=32)\n",
    "\n",
    "def DenseNet161():\n",
    "    return DenseNet(Bottleneck, [6,12,36,24], growth_rate=48)\n",
    "\n",
    "def densenet_cifar():\n",
    "    return DenseNet(Bottleneck, [6,10,20,12], growth_rate=8)\n",
    "\n",
    "def densenet_cifar_quant():\n",
    "    return DenseNet_Quant(Bottleneck_Quant, [6,12,24,16], growth_rate=12)\n",
    "\n",
    "def test():\n",
    "    net = densenet_cifar()\n",
    "    x = torch.randn(1,3,32,32)\n",
    "    y = net(x)\n",
    "    print(y)\n",
    "\n",
    "# test()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "n_classes_cifar10 = 10\n",
    "train_size = 0.8\n",
    "R = 5\n",
    "\n",
    "\n",
    "# Download the entire CIFAR10 dataset\n",
    "\n",
    "from torchvision.datasets import CIFAR10\n",
    "import numpy as np \n",
    "from torch.utils.data import Subset\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "## Normalization is different when training from scratch and when training using an imagenet pretrained backbone\n",
    "\n",
    "normalize_scratch = transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "\n",
    "\n",
    "# Data augmentation is needed in order to train from scratch\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    normalize_scratch,\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    normalize_scratch,\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "### The data from CIFAR10 will be downloaded in the following dataset\n",
    "rootdir = './data/cifar10'\n",
    "\n",
    "c10train = CIFAR10(rootdir,train=True,download=True,transform=transform_train)\n",
    "c10test = CIFAR10(rootdir,train=False,download=True,transform=transform_test)\n",
    "\n",
    "\n",
    "\n",
    "# CIFAR10 is sufficiently large so that training a model up to the state of the art performance will take approximately 3 hours on the 1060 GPU available on your machine. \n",
    "\n",
    "\n",
    "def train_validation_split(train_size, num_train_examples):\n",
    "    # obtain training indices that will be used for validation\n",
    "    indices = list(range(num_train_examples))\n",
    "    np.random.shuffle(indices)\n",
    "    idx_split = int(np.floor(train_size * num_train_examples))\n",
    "    train_index, valid_index = indices[:idx_split], indices[idx_split:]\n",
    "\n",
    "    # define samplers for obtaining training and validation batches\n",
    "    train_sampler = SubsetRandomSampler(train_index)\n",
    "    valid_sampler = SubsetRandomSampler(valid_index)\n",
    "\n",
    "    return train_sampler,valid_sampler\n",
    "\n",
    "def generate_subset(dataset,n_classes,reducefactor,n_ex_class_init):\n",
    "\n",
    "    nb_examples_per_class = int(np.floor(n_ex_class_init / reducefactor))\n",
    "    # Generate the indices. They are the same for each class, could easily be modified to have different ones. But be careful to keep the random seed! \n",
    "\n",
    "    indices_split = np.random.RandomState(seed=42).choice(n_ex_class_init,nb_examples_per_class,replace=False)\n",
    "\n",
    "    all_indices = []\n",
    "    for curclas in range(n_classes):\n",
    "        curtargets = np.where(np.array(dataset.targets) == curclas)\n",
    "        indices_curclas = curtargets[0]\n",
    "        indices_subset = indices_curclas[indices_split]\n",
    "        #print(len(indices_subset))\n",
    "        all_indices.append(indices_subset)\n",
    "    all_indices = np.hstack(all_indices)\n",
    "    \n",
    "    return Subset(dataset,indices=all_indices)\n",
    "    \n",
    "\n",
    "\n",
    "### These dataloader are ready to be used to train for scratch \n",
    "cifar10_train= generate_subset(dataset=c10train,n_classes=n_classes_cifar10,reducefactor=R,n_ex_class_init=5000)\n",
    "num_train_examples=len(cifar10_train)\n",
    "train_sampler,valid_sampler=train_validation_split(train_size, num_train_examples)\n",
    "\n",
    "cifar10_test = generate_subset(dataset=c10test,n_classes=n_classes_cifar10,reducefactor=1,n_ex_class_init=1000) \n",
    "\n",
    "\n",
    "\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "\n",
    "trainloader = DataLoader(c10train,batch_size=32,sampler=train_sampler)\n",
    "validloader = DataLoader(c10train,batch_size=32,sampler=valid_sampler)\n",
    "testloader = DataLoader(c10test,batch_size=32) \n",
    "\n",
    "\n",
    "def evaluation(model, test_loader, criterion): \n",
    "    class_names = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "    \n",
    "\n",
    "    test_loss = 0.0\n",
    "    class_correct = list(0. for i in range(10))\n",
    "    class_total = list(0. for i in range(10))\n",
    "\n",
    "    model.eval()\n",
    "    for data, label in test_loader:\n",
    "        data = data.to(device=device, dtype=torch.float32)\n",
    "        label = label.to(device=device, dtype=torch.long)\n",
    "        with torch.no_grad():\n",
    "            output = model(data)\n",
    "        loss = criterion(output, label)\n",
    "        test_loss += loss.item()*data.size(0)\n",
    "        _, pred = torch.max(output, 1)\n",
    "        correct = np.squeeze(pred.eq(label.data.view_as(pred)))\n",
    "        for i in range(len(label)):\n",
    "            digit = label.data[i]\n",
    "            class_correct[digit] += correct[i].item()\n",
    "            class_total[digit] += 1\n",
    "\n",
    "    test_loss = test_loss/len(test_loader.sampler)\n",
    "    print('test Loss: {:.6f}\\n'.format(test_loss))\n",
    "    for i in range(10):\n",
    "\n",
    "        if(np.sum(class_total[i])==0):\n",
    "            print(class_names[i])\n",
    "        else:\n",
    "            print('test accuracy of %s: %2d%% (%2d/%2d)' % (class_names[i], 100 * class_correct[i] / class_total[i], np.sum(class_correct[i]), np.sum(class_total[i])))\n",
    "    print('\\ntest accuracy (overall): %2.2f%% (%2d/%2d)' % (100. * np.sum(class_correct) / np.sum(class_total), np.sum(class_correct), np.sum(class_total)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from minicifar import minicifar_train,minicifar_test,train_sampler,valid_sampler\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "\n",
    "trainloader = DataLoader(c10train,batch_size=128,sampler=train_sampler)\n",
    "validloader = DataLoader(c10train,batch_size=128,sampler=valid_sampler)\n",
    "testloader = DataLoader(c10test,batch_size=128) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(model, test_loader, criterion): \n",
    "\n",
    "    test_loss = 0.0\n",
    "    class_correct = list(0. for i in range(10))\n",
    "    class_total = list(0. for i in range(10))\n",
    "\n",
    "    model.eval()\n",
    "    for data, label in test_loader:\n",
    "        data = data.to(device=device, dtype=torch.float32)\n",
    "        label = label.to(device=device, dtype=torch.long)\n",
    "        with torch.no_grad():\n",
    "            output = model(data)\n",
    "        loss = criterion(output, label)\n",
    "        test_loss += loss.item()*data.size(0)\n",
    "        _, pred = torch.max(output, 1)\n",
    "        correct = np.squeeze(pred.eq(label.data.view_as(pred)))\n",
    "        for i in range(len(label)):\n",
    "            digit = label.data[i]\n",
    "            class_correct[digit] += correct[i].item()\n",
    "            class_total[digit] += 1\n",
    "\n",
    "    test_loss = test_loss/len(test_loader.sampler)\n",
    "    print('test Loss: {:.6f}\\n'.format(test_loss))\n",
    "    for i in range(10):\n",
    "\n",
    "        if(np.sum(class_total[i])==0):\n",
    "            print(class_names[i])\n",
    "        else:\n",
    "            print('test accuracy of %s: %2d%% (%2d/%2d)' % (class_names[i], 100 * class_correct[i] / class_total[i], np.sum(class_correct[i]), np.sum(class_total[i])))\n",
    "    print('\\ntest accuracy (overall): %2.2f%% (%2d/%2d)' % (100. * np.sum(class_correct) / np.sum(class_total), np.sum(class_correct), np.sum(class_total)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device '+str(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def count_conv2d(m, x, y):\n",
    "    x = x[0] # remove tuple\n",
    "\n",
    "    fin = m.in_channels\n",
    "    fout = m.out_channels\n",
    "    sh, sw = m.kernel_size\n",
    "\n",
    "    # ops per output element\n",
    "    kernel_mul = sh * sw * fin\n",
    "    kernel_add = sh * sw * fin - 1\n",
    "    bias_ops = 1 if m.bias is not None else 0\n",
    "    kernel_mul = kernel_mul/8 # FP4\n",
    "    ops = kernel_mul + kernel_add + bias_ops\n",
    "\n",
    "    # total ops\n",
    "    num_out_elements = y.numel()\n",
    "    total_ops = num_out_elements * ops\n",
    "    \n",
    "    # total params \n",
    "    \n",
    "\n",
    "    print(\"Conv2d: S_c={}, F_in={}, F_out={}, P={}, params={}, operations={}\".format(sh,fin,fout,x.size()[2:].numel(),int(m.total_params.item()),int(total_ops)))\n",
    "    # incase same conv is used multiple times\n",
    "    m.total_ops += torch.Tensor([int(total_ops)])\n",
    "\n",
    "\n",
    "def count_bn2d(m, x, y):\n",
    "    x = x[0] # remove tuple\n",
    "\n",
    "    nelements = x.numel()\n",
    "    total_sub = 2*nelements\n",
    "    total_div = nelements\n",
    "    total_ops = total_sub + total_div\n",
    "\n",
    "    m.total_ops += torch.Tensor([int(total_ops)])\n",
    "    print(\"Batch norm: F_in={} P={}, params={}, operations={}\".format(x.size(1),x.size()[2:].numel(),int(m.total_params.item()),int(total_ops)))\n",
    "\n",
    "\n",
    "def count_relu(m, x, y):\n",
    "    x = x[0]\n",
    "\n",
    "    nelements = x.numel()\n",
    "    total_ops = nelements\n",
    "\n",
    "    m.total_ops += torch.Tensor([int(total_ops)])\n",
    "    print(\"ReLU: F_in={} P={}, params={}, operations={}\".format(x.size(1),x.size()[2:].numel(),0,int(total_ops)))\n",
    "\n",
    "\n",
    "\n",
    "def count_avgpool(m, x, y):\n",
    "    x = x[0]\n",
    "    total_add = torch.prod(torch.Tensor([m.kernel_size])) - 1\n",
    "    total_div = 1\n",
    "    kernel_ops = total_add + total_div\n",
    "    num_elements = y.numel()\n",
    "    total_ops = kernel_ops * num_elements\n",
    "\n",
    "    m.total_ops += torch.Tensor([int(total_ops)])\n",
    "    print(\"AvgPool: S={}, F_in={}, P={}, params={}, operations={}\".format(m.kernel_size,x.size(1),x.size()[2:].numel(),0,int(total_ops)))\n",
    "\n",
    "def count_linear(m, x, y):\n",
    "    # per output element\n",
    "    total_mul = m.in_features/2\n",
    "    total_add = m.in_features - 1\n",
    "    num_elements = y.numel()\n",
    "    total_ops = (total_mul + total_add) * num_elements\n",
    "    print(\"Linear: F_in={}, F_out={}, params={}, operations={}\".format(m.in_features,m.out_features,int(m.total_params.item()),int(total_ops)))\n",
    "    m.total_ops += torch.Tensor([int(total_ops)])\n",
    "\n",
    "def count_sequential(m, x, y):\n",
    "    print (\"Sequential: No additional parameters  / op\")\n",
    "\n",
    "# custom ops could be used to pass variable customized ratios for quantization\n",
    "def profile(model, input_size, custom_ops = {}):\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    def add_hooks(m):\n",
    "        if len(list(m.children())) > 0: return\n",
    "        m.register_buffer('total_ops', torch.zeros(1))\n",
    "        m.register_buffer('total_params', torch.zeros(1))\n",
    "\n",
    "\n",
    "        #for p in m.parameters():\n",
    "         #   m.total_params += torch.Tensor([torch.count_nonzero(p.data)]) / 8\n",
    "            \n",
    "\n",
    "\n",
    "        if isinstance(m, nn.Conv2d):\n",
    "            m.register_forward_hook(count_conv2d)\n",
    "        elif isinstance(m, nn.BatchNorm2d):\n",
    "            m.register_forward_hook(count_bn2d)\n",
    "        elif isinstance(m, nn.ReLU):\n",
    "            m.register_forward_hook(count_relu)\n",
    "        elif isinstance(m, (nn.AvgPool2d)):\n",
    "            m.register_forward_hook(count_avgpool)\n",
    "        elif isinstance(m, nn.Linear):\n",
    "            m.register_forward_hook(count_linear)\n",
    "        elif isinstance(m, nn.Sequential):\n",
    "            m.register_forward_hook(count_sequential)\n",
    "        else:\n",
    "            print(\"Not implemented for \", m)\n",
    "\n",
    "    model.apply(add_hooks)\n",
    "\n",
    "    x = torch.zeros(input_size).cuda()\n",
    "    model(x)\n",
    "\n",
    "    total_ops = 0\n",
    "    total_params = 0\n",
    "    for m in model.modules():\n",
    "        if len(list(m.children())) > 0: continue\n",
    "        total_ops += m.total_ops\n",
    "        total_params += m.total_params\n",
    "\n",
    "    return total_ops, total_params\n",
    "\n",
    "def main():\n",
    "\n",
    "    ref_params = 5586981\n",
    "    ref_flops  = 834362880\n",
    "\n",
    "    import torch.nn.utils.prune as prune\n",
    "    model = densenet_cifar()\n",
    "    \n",
    "    model.to(device=device)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    evaluation(model, testloader, criterion)\n",
    "\n",
    "    \n",
    "    import torch.nn.utils.prune as prune\n",
    "    \n",
    "    parameters_to_prune=[]\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, torch.nn.Conv2d) or isinstance(module, torch.nn.Linear) :\n",
    "            parameters_to_prune.append((module,'weight'))\n",
    "    prune.global_unstructured(parameters_to_prune, pruning_method=prune.L1Unstructured, amount=0.2)\n",
    "    loaded_cpt=torch.load('densenet_cifar_10_pruning_globally_0.06.pt')\n",
    "    model.load_state_dict(loaded_cpt)\n",
    "    \n",
    "    \n",
    "\n",
    "    evaluation(model, testloader, criterion)\n",
    "\n",
    "    \n",
    "    from torchvision import models\n",
    "\n",
    "\n",
    "    class Identity(torch.nn.Module):\n",
    "        def __init__(self):\n",
    "            super(Identity, self).__init__()\n",
    "\n",
    "        def forward(self, x):\n",
    "            return x\n",
    "    \n",
    "#     model.dense4= Identity()\n",
    "#     model.trans3.conv= nn.Conv2d(216, 204, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "    \n",
    "    model.to(device=device)\n",
    "\n",
    "    \n",
    "    evaluation(model,testloader, criterion)\n",
    "    \n",
    "    flops, params = profile(model, (1,3,32,32))\n",
    "    flops, params = flops.item(), params.item()\n",
    "    \n",
    "    params = 0\n",
    "    for name, para in model.named_parameters():\n",
    "        if \"conv\" in name:\n",
    "            params+= para.nonzero().size(0)/8\n",
    "        else:\n",
    "            params+= para.nonzero().size(0)/2\n",
    "    \n",
    "    print(sum(p.numel() for p in model.parameters()))\n",
    "    \n",
    "    score_flops = flops / ref_flops\n",
    "    score_params = params / ref_params\n",
    "    score = score_flops + score_params\n",
    "    print(\"Flops: {}, Params: {}\".format(flops,params))\n",
    "    print(\"Score flops: {} Score Params: {}\".format(score_flops,score_params))\n",
    "    print(\"Final score: {}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 2.303173\n",
      "\n",
      "test accuracy of plane:  0% ( 0/1000)\n",
      "test accuracy of car:  0% ( 0/1000)\n",
      "test accuracy of bird:  0% ( 0/1000)\n",
      "test accuracy of cat:  0% ( 0/1000)\n",
      "test accuracy of deer:  0% ( 0/1000)\n",
      "test accuracy of dog:  0% ( 0/1000)\n",
      "test accuracy of frog:  0% ( 0/1000)\n",
      "test accuracy of horse:  0% ( 0/1000)\n",
      "test accuracy of ship:  0% ( 0/1000)\n",
      "test accuracy of truck: 100% (1000/1000)\n",
      "\n",
      "test accuracy (overall): 10.00% (1000/10000)\n",
      "test Loss: 0.292871\n",
      "\n",
      "test accuracy of plane: 92% (923/1000)\n",
      "test accuracy of car: 96% (967/1000)\n",
      "test accuracy of bird: 89% (892/1000)\n",
      "test accuracy of cat: 83% (830/1000)\n",
      "test accuracy of deer: 93% (933/1000)\n",
      "test accuracy of dog: 86% (867/1000)\n",
      "test accuracy of frog: 95% (951/1000)\n",
      "test accuracy of horse: 93% (938/1000)\n",
      "test accuracy of ship: 95% (953/1000)\n",
      "test accuracy of truck: 94% (945/1000)\n",
      "\n",
      "test accuracy (overall): 91.99% (9199/10000)\n",
      "test Loss: 0.292871\n",
      "\n",
      "test accuracy of plane: 92% (923/1000)\n",
      "test accuracy of car: 96% (967/1000)\n",
      "test accuracy of bird: 89% (892/1000)\n",
      "test accuracy of cat: 83% (830/1000)\n",
      "test accuracy of deer: 93% (933/1000)\n",
      "test accuracy of dog: 86% (867/1000)\n",
      "test accuracy of frog: 95% (951/1000)\n",
      "test accuracy of horse: 93% (938/1000)\n",
      "test accuracy of ship: 95% (953/1000)\n",
      "test accuracy of truck: 94% (945/1000)\n",
      "\n",
      "test accuracy (overall): 91.99% (9199/10000)\n",
      "Conv2d: S_c=3, F_in=3, F_out=16, P=1024, params=0, operations=481280\n",
      "Batch norm: F_in=16 P=1024, params=0, operations=49152\n",
      "Conv2d: S_c=1, F_in=16, F_out=32, P=1024, params=0, operations=557056\n",
      "Batch norm: F_in=32 P=1024, params=0, operations=98304\n",
      "Conv2d: S_c=3, F_in=32, F_out=8, P=1024, params=0, operations=2646016\n",
      "Batch norm: F_in=24 P=1024, params=0, operations=73728\n",
      "Conv2d: S_c=1, F_in=24, F_out=32, P=1024, params=0, operations=851968\n",
      "Batch norm: F_in=32 P=1024, params=0, operations=98304\n",
      "Conv2d: S_c=3, F_in=32, F_out=8, P=1024, params=0, operations=2646016\n",
      "Batch norm: F_in=32 P=1024, params=0, operations=98304\n",
      "Conv2d: S_c=1, F_in=32, F_out=32, P=1024, params=0, operations=1146880\n",
      "Batch norm: F_in=32 P=1024, params=0, operations=98304\n",
      "Conv2d: S_c=3, F_in=32, F_out=8, P=1024, params=0, operations=2646016\n",
      "Batch norm: F_in=40 P=1024, params=0, operations=122880\n",
      "Conv2d: S_c=1, F_in=40, F_out=32, P=1024, params=0, operations=1441792\n",
      "Batch norm: F_in=32 P=1024, params=0, operations=98304\n",
      "Conv2d: S_c=3, F_in=32, F_out=8, P=1024, params=0, operations=2646016\n",
      "Batch norm: F_in=48 P=1024, params=0, operations=147456\n",
      "Conv2d: S_c=1, F_in=48, F_out=32, P=1024, params=0, operations=1736704\n",
      "Batch norm: F_in=32 P=1024, params=0, operations=98304\n",
      "Conv2d: S_c=3, F_in=32, F_out=8, P=1024, params=0, operations=2646016\n",
      "Batch norm: F_in=56 P=1024, params=0, operations=172032\n",
      "Conv2d: S_c=1, F_in=56, F_out=32, P=1024, params=0, operations=2031616\n",
      "Batch norm: F_in=32 P=1024, params=0, operations=98304\n",
      "Conv2d: S_c=3, F_in=32, F_out=8, P=1024, params=0, operations=2646016\n",
      "Batch norm: F_in=64 P=1024, params=0, operations=196608\n",
      "Conv2d: S_c=1, F_in=64, F_out=32, P=1024, params=0, operations=2326528\n",
      "Batch norm: F_in=32 P=256, params=0, operations=24576\n",
      "Conv2d: S_c=1, F_in=32, F_out=32, P=256, params=0, operations=286720\n",
      "Batch norm: F_in=32 P=256, params=0, operations=24576\n",
      "Conv2d: S_c=3, F_in=32, F_out=8, P=256, params=0, operations=661504\n",
      "Batch norm: F_in=40 P=256, params=0, operations=30720\n",
      "Conv2d: S_c=1, F_in=40, F_out=32, P=256, params=0, operations=360448\n",
      "Batch norm: F_in=32 P=256, params=0, operations=24576\n",
      "Conv2d: S_c=3, F_in=32, F_out=8, P=256, params=0, operations=661504\n",
      "Batch norm: F_in=48 P=256, params=0, operations=36864\n",
      "Conv2d: S_c=1, F_in=48, F_out=32, P=256, params=0, operations=434176\n",
      "Batch norm: F_in=32 P=256, params=0, operations=24576\n",
      "Conv2d: S_c=3, F_in=32, F_out=8, P=256, params=0, operations=661504\n",
      "Batch norm: F_in=56 P=256, params=0, operations=43008\n",
      "Conv2d: S_c=1, F_in=56, F_out=32, P=256, params=0, operations=507904\n",
      "Batch norm: F_in=32 P=256, params=0, operations=24576\n",
      "Conv2d: S_c=3, F_in=32, F_out=8, P=256, params=0, operations=661504\n",
      "Batch norm: F_in=64 P=256, params=0, operations=49152\n",
      "Conv2d: S_c=1, F_in=64, F_out=32, P=256, params=0, operations=581632\n",
      "Batch norm: F_in=32 P=256, params=0, operations=24576\n",
      "Conv2d: S_c=3, F_in=32, F_out=8, P=256, params=0, operations=661504\n",
      "Batch norm: F_in=72 P=256, params=0, operations=55296\n",
      "Conv2d: S_c=1, F_in=72, F_out=32, P=256, params=0, operations=655360\n",
      "Batch norm: F_in=32 P=256, params=0, operations=24576\n",
      "Conv2d: S_c=3, F_in=32, F_out=8, P=256, params=0, operations=661504\n",
      "Batch norm: F_in=80 P=256, params=0, operations=61440\n",
      "Conv2d: S_c=1, F_in=80, F_out=32, P=256, params=0, operations=729088\n",
      "Batch norm: F_in=32 P=256, params=0, operations=24576\n",
      "Conv2d: S_c=3, F_in=32, F_out=8, P=256, params=0, operations=661504\n",
      "Batch norm: F_in=88 P=256, params=0, operations=67584\n",
      "Conv2d: S_c=1, F_in=88, F_out=32, P=256, params=0, operations=802816\n",
      "Batch norm: F_in=32 P=256, params=0, operations=24576\n",
      "Conv2d: S_c=3, F_in=32, F_out=8, P=256, params=0, operations=661504\n",
      "Batch norm: F_in=96 P=256, params=0, operations=73728\n",
      "Conv2d: S_c=1, F_in=96, F_out=32, P=256, params=0, operations=876544\n",
      "Batch norm: F_in=32 P=256, params=0, operations=24576\n",
      "Conv2d: S_c=3, F_in=32, F_out=8, P=256, params=0, operations=661504\n",
      "Batch norm: F_in=104 P=256, params=0, operations=79872\n",
      "Conv2d: S_c=1, F_in=104, F_out=32, P=256, params=0, operations=950272\n",
      "Batch norm: F_in=32 P=256, params=0, operations=24576\n",
      "Conv2d: S_c=3, F_in=32, F_out=8, P=256, params=0, operations=661504\n",
      "Batch norm: F_in=112 P=256, params=0, operations=86016\n",
      "Conv2d: S_c=1, F_in=112, F_out=56, P=256, params=0, operations=1792000\n",
      "Batch norm: F_in=56 P=64, params=0, operations=10752\n",
      "Conv2d: S_c=1, F_in=56, F_out=32, P=64, params=0, operations=126976\n",
      "Batch norm: F_in=32 P=64, params=0, operations=6144\n",
      "Conv2d: S_c=3, F_in=32, F_out=8, P=64, params=0, operations=165376\n",
      "Batch norm: F_in=64 P=64, params=0, operations=12288\n",
      "Conv2d: S_c=1, F_in=64, F_out=32, P=64, params=0, operations=145408\n",
      "Batch norm: F_in=32 P=64, params=0, operations=6144\n",
      "Conv2d: S_c=3, F_in=32, F_out=8, P=64, params=0, operations=165376\n",
      "Batch norm: F_in=72 P=64, params=0, operations=13824\n",
      "Conv2d: S_c=1, F_in=72, F_out=32, P=64, params=0, operations=163840\n",
      "Batch norm: F_in=32 P=64, params=0, operations=6144\n",
      "Conv2d: S_c=3, F_in=32, F_out=8, P=64, params=0, operations=165376\n",
      "Batch norm: F_in=80 P=64, params=0, operations=15360\n",
      "Conv2d: S_c=1, F_in=80, F_out=32, P=64, params=0, operations=182272\n",
      "Batch norm: F_in=32 P=64, params=0, operations=6144\n",
      "Conv2d: S_c=3, F_in=32, F_out=8, P=64, params=0, operations=165376\n",
      "Batch norm: F_in=88 P=64, params=0, operations=16896\n",
      "Conv2d: S_c=1, F_in=88, F_out=32, P=64, params=0, operations=200704\n",
      "Batch norm: F_in=32 P=64, params=0, operations=6144\n",
      "Conv2d: S_c=3, F_in=32, F_out=8, P=64, params=0, operations=165376\n",
      "Batch norm: F_in=96 P=64, params=0, operations=18432\n",
      "Conv2d: S_c=1, F_in=96, F_out=32, P=64, params=0, operations=219136\n",
      "Batch norm: F_in=32 P=64, params=0, operations=6144\n",
      "Conv2d: S_c=3, F_in=32, F_out=8, P=64, params=0, operations=165376\n",
      "Batch norm: F_in=104 P=64, params=0, operations=19968\n",
      "Conv2d: S_c=1, F_in=104, F_out=32, P=64, params=0, operations=237568\n",
      "Batch norm: F_in=32 P=64, params=0, operations=6144\n",
      "Conv2d: S_c=3, F_in=32, F_out=8, P=64, params=0, operations=165376\n",
      "Batch norm: F_in=112 P=64, params=0, operations=21504\n",
      "Conv2d: S_c=1, F_in=112, F_out=32, P=64, params=0, operations=256000\n",
      "Batch norm: F_in=32 P=64, params=0, operations=6144\n",
      "Conv2d: S_c=3, F_in=32, F_out=8, P=64, params=0, operations=165376\n",
      "Batch norm: F_in=120 P=64, params=0, operations=23040\n",
      "Conv2d: S_c=1, F_in=120, F_out=32, P=64, params=0, operations=274432\n",
      "Batch norm: F_in=32 P=64, params=0, operations=6144\n",
      "Conv2d: S_c=3, F_in=32, F_out=8, P=64, params=0, operations=165376\n",
      "Batch norm: F_in=128 P=64, params=0, operations=24576\n",
      "Conv2d: S_c=1, F_in=128, F_out=32, P=64, params=0, operations=292864\n",
      "Batch norm: F_in=32 P=64, params=0, operations=6144\n",
      "Conv2d: S_c=3, F_in=32, F_out=8, P=64, params=0, operations=165376\n",
      "Batch norm: F_in=136 P=64, params=0, operations=26112\n",
      "Conv2d: S_c=1, F_in=136, F_out=32, P=64, params=0, operations=311296\n",
      "Batch norm: F_in=32 P=64, params=0, operations=6144\n",
      "Conv2d: S_c=3, F_in=32, F_out=8, P=64, params=0, operations=165376\n",
      "Batch norm: F_in=144 P=64, params=0, operations=27648\n",
      "Conv2d: S_c=1, F_in=144, F_out=32, P=64, params=0, operations=329728\n",
      "Batch norm: F_in=32 P=64, params=0, operations=6144\n",
      "Conv2d: S_c=3, F_in=32, F_out=8, P=64, params=0, operations=165376\n",
      "Batch norm: F_in=152 P=64, params=0, operations=29184\n",
      "Conv2d: S_c=1, F_in=152, F_out=32, P=64, params=0, operations=348160\n",
      "Batch norm: F_in=32 P=64, params=0, operations=6144\n",
      "Conv2d: S_c=3, F_in=32, F_out=8, P=64, params=0, operations=165376\n",
      "Batch norm: F_in=160 P=64, params=0, operations=30720\n",
      "Conv2d: S_c=1, F_in=160, F_out=32, P=64, params=0, operations=366592\n",
      "Batch norm: F_in=32 P=64, params=0, operations=6144\n",
      "Conv2d: S_c=3, F_in=32, F_out=8, P=64, params=0, operations=165376\n",
      "Batch norm: F_in=168 P=64, params=0, operations=32256\n",
      "Conv2d: S_c=1, F_in=168, F_out=32, P=64, params=0, operations=385024\n",
      "Batch norm: F_in=32 P=64, params=0, operations=6144\n",
      "Conv2d: S_c=3, F_in=32, F_out=8, P=64, params=0, operations=165376\n",
      "Batch norm: F_in=176 P=64, params=0, operations=33792\n",
      "Conv2d: S_c=1, F_in=176, F_out=32, P=64, params=0, operations=403456\n",
      "Batch norm: F_in=32 P=64, params=0, operations=6144\n",
      "Conv2d: S_c=3, F_in=32, F_out=8, P=64, params=0, operations=165376\n",
      "Batch norm: F_in=184 P=64, params=0, operations=35328\n",
      "Conv2d: S_c=1, F_in=184, F_out=32, P=64, params=0, operations=421888\n",
      "Batch norm: F_in=32 P=64, params=0, operations=6144\n",
      "Conv2d: S_c=3, F_in=32, F_out=8, P=64, params=0, operations=165376\n",
      "Batch norm: F_in=192 P=64, params=0, operations=36864\n",
      "Conv2d: S_c=1, F_in=192, F_out=32, P=64, params=0, operations=440320\n",
      "Batch norm: F_in=32 P=64, params=0, operations=6144\n",
      "Conv2d: S_c=3, F_in=32, F_out=8, P=64, params=0, operations=165376\n",
      "Batch norm: F_in=200 P=64, params=0, operations=38400\n",
      "Conv2d: S_c=1, F_in=200, F_out=32, P=64, params=0, operations=458752\n",
      "Batch norm: F_in=32 P=64, params=0, operations=6144\n",
      "Conv2d: S_c=3, F_in=32, F_out=8, P=64, params=0, operations=165376\n",
      "Batch norm: F_in=208 P=64, params=0, operations=39936\n",
      "Conv2d: S_c=1, F_in=208, F_out=32, P=64, params=0, operations=477184\n",
      "Batch norm: F_in=32 P=64, params=0, operations=6144\n",
      "Conv2d: S_c=3, F_in=32, F_out=8, P=64, params=0, operations=165376\n",
      "Batch norm: F_in=216 P=64, params=0, operations=41472\n",
      "Conv2d: S_c=1, F_in=216, F_out=108, P=64, params=0, operations=1672704\n",
      "Batch norm: F_in=108 P=16, params=0, operations=5184\n",
      "Conv2d: S_c=1, F_in=108, F_out=32, P=16, params=0, operations=61696\n",
      "Batch norm: F_in=32 P=16, params=0, operations=1536\n",
      "Conv2d: S_c=3, F_in=32, F_out=8, P=16, params=0, operations=41344\n",
      "Batch norm: F_in=116 P=16, params=0, operations=5568\n",
      "Conv2d: S_c=1, F_in=116, F_out=32, P=16, params=0, operations=66304\n",
      "Batch norm: F_in=32 P=16, params=0, operations=1536\n",
      "Conv2d: S_c=3, F_in=32, F_out=8, P=16, params=0, operations=41344\n",
      "Batch norm: F_in=124 P=16, params=0, operations=5952\n",
      "Conv2d: S_c=1, F_in=124, F_out=32, P=16, params=0, operations=70912\n",
      "Batch norm: F_in=32 P=16, params=0, operations=1536\n",
      "Conv2d: S_c=3, F_in=32, F_out=8, P=16, params=0, operations=41344\n",
      "Batch norm: F_in=132 P=16, params=0, operations=6336\n",
      "Conv2d: S_c=1, F_in=132, F_out=32, P=16, params=0, operations=75520\n",
      "Batch norm: F_in=32 P=16, params=0, operations=1536\n",
      "Conv2d: S_c=3, F_in=32, F_out=8, P=16, params=0, operations=41344\n",
      "Batch norm: F_in=140 P=16, params=0, operations=6720\n",
      "Conv2d: S_c=1, F_in=140, F_out=32, P=16, params=0, operations=80128\n",
      "Batch norm: F_in=32 P=16, params=0, operations=1536\n",
      "Conv2d: S_c=3, F_in=32, F_out=8, P=16, params=0, operations=41344\n",
      "Batch norm: F_in=148 P=16, params=0, operations=7104\n",
      "Conv2d: S_c=1, F_in=148, F_out=32, P=16, params=0, operations=84736\n",
      "Batch norm: F_in=32 P=16, params=0, operations=1536\n",
      "Conv2d: S_c=3, F_in=32, F_out=8, P=16, params=0, operations=41344\n",
      "Batch norm: F_in=156 P=16, params=0, operations=7488\n",
      "Conv2d: S_c=1, F_in=156, F_out=32, P=16, params=0, operations=89344\n",
      "Batch norm: F_in=32 P=16, params=0, operations=1536\n",
      "Conv2d: S_c=3, F_in=32, F_out=8, P=16, params=0, operations=41344\n",
      "Batch norm: F_in=164 P=16, params=0, operations=7872\n",
      "Conv2d: S_c=1, F_in=164, F_out=32, P=16, params=0, operations=93952\n",
      "Batch norm: F_in=32 P=16, params=0, operations=1536\n",
      "Conv2d: S_c=3, F_in=32, F_out=8, P=16, params=0, operations=41344\n",
      "Batch norm: F_in=172 P=16, params=0, operations=8256\n",
      "Conv2d: S_c=1, F_in=172, F_out=32, P=16, params=0, operations=98560\n",
      "Batch norm: F_in=32 P=16, params=0, operations=1536\n",
      "Conv2d: S_c=3, F_in=32, F_out=8, P=16, params=0, operations=41344\n",
      "Batch norm: F_in=180 P=16, params=0, operations=8640\n",
      "Conv2d: S_c=1, F_in=180, F_out=32, P=16, params=0, operations=103168\n",
      "Batch norm: F_in=32 P=16, params=0, operations=1536\n",
      "Conv2d: S_c=3, F_in=32, F_out=8, P=16, params=0, operations=41344\n",
      "Batch norm: F_in=188 P=16, params=0, operations=9024\n",
      "Conv2d: S_c=1, F_in=188, F_out=32, P=16, params=0, operations=107776\n",
      "Batch norm: F_in=32 P=16, params=0, operations=1536\n",
      "Conv2d: S_c=3, F_in=32, F_out=8, P=16, params=0, operations=41344\n",
      "Batch norm: F_in=196 P=16, params=0, operations=9408\n",
      "Conv2d: S_c=1, F_in=196, F_out=32, P=16, params=0, operations=112384\n",
      "Batch norm: F_in=32 P=16, params=0, operations=1536\n",
      "Conv2d: S_c=3, F_in=32, F_out=8, P=16, params=0, operations=41344\n",
      "Batch norm: F_in=204 P=16, params=0, operations=9792\n",
      "Linear: F_in=204, F_out=10, params=0, operations=3050\n",
      "331226\n",
      "Flops: 56698408.0, Params: 47791.0\n",
      "Score flops: 0.06795413525587332 Score Params: 0.008553993650595912\n",
      "Final score: 0.07650812890646923\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Score flops: 0.06776267899166367 Score Params: 0.006698250808441983"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Params: 65407.0\n",
    "Score Params: 0.01170703820184819"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "130842\n",
    "Flops: 21293626.0, Params: 17779.25\n",
    "Score flops: 0.025520821348140512 Score Params: 0.00318226426758924\n",
    "Final score: 0.02870308561572975"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
